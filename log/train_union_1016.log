WARNING: Logging before InitGoogleLogging() is written to STDERR
I1016 09:56:11.281301   329 solver.cpp:63] Initializing solver from parameters: 
train_net: "proto/union/MobileNetSSD_train.prototxt"
test_net: "proto/union/MobileNetSSD_test.prototxt"
test_iter: 673
test_interval: 99999999
base_lr: 0.0005
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 500
snapshot_prefix: "snapshot/union/"
solver_mode: GPU
debug_info: false
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I1016 09:56:11.281890   329 solver.cpp:96] Creating training net from train_net file: proto/union/MobileNetSSD_train.prototxt
I1016 09:56:11.283087   329 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_train.prototxt
I1016 09:56:11.283099   329 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 09:56:11.284083   329 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_trainval_lmdb/"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_
I1016 09:56:11.284613   329 layer_factory.hpp:77] Creating layer data
I1016 09:56:11.284796   329 net.cpp:100] Creating Layer data
I1016 09:56:11.284808   329 net.cpp:408] data -> data
I1016 09:56:11.284835   329 net.cpp:408] data -> label
I1016 09:56:11.284842   329 net.cpp:408] data -> label_seg
I1016 09:56:11.284852   329 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1016 09:56:11.286911   365 db_lmdb.cpp:35] Opened lmdb lmdb/seg_trainval_lmdb/
I1016 09:56:11.374822   329 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 4,3,320,480
I1016 09:56:11.391539   329 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1016 09:56:11.391609   329 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1016 09:56:11.391614   329 net.cpp:150] Setting up data
I1016 09:56:11.391623   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391628   329 net.cpp:157] Top shape: 1 1 6 8 (48)
I1016 09:56:11.391631   329 net.cpp:157] Top shape: 4 1 320 480 (614400)
I1016 09:56:11.391633   329 net.cpp:165] Memory required for data: 9830592
I1016 09:56:11.391639   329 layer_factory.hpp:77] Creating layer data_data_0_split
I1016 09:56:11.391652   329 net.cpp:100] Creating Layer data_data_0_split
I1016 09:56:11.391655   329 net.cpp:434] data_data_0_split <- data
I1016 09:56:11.391664   329 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1016 09:56:11.391672   329 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1016 09:56:11.391679   329 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1016 09:56:11.391683   329 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1016 09:56:11.391687   329 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1016 09:56:11.391692   329 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1016 09:56:11.391698   329 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1016 09:56:11.391702   329 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1016 09:56:11.391789   329 net.cpp:150] Setting up data_data_0_split
I1016 09:56:11.391793   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391798   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391800   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391803   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391805   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391808   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391811   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391814   329 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1016 09:56:11.391816   329 net.cpp:165] Memory required for data: 68812992
I1016 09:56:11.391819   329 layer_factory.hpp:77] Creating layer conv0
I1016 09:56:11.391830   329 net.cpp:100] Creating Layer conv0
I1016 09:56:11.391834   329 net.cpp:434] conv0 <- data_data_0_split_0
I1016 09:56:11.391839   329 net.cpp:408] conv0 -> conv0
I1016 09:56:11.394085   366 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1016 09:56:11.941548   329 net.cpp:150] Setting up conv0
I1016 09:56:11.941573   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.941578   329 net.cpp:165] Memory required for data: 88473792
I1016 09:56:11.941607   329 layer_factory.hpp:77] Creating layer conv0/bn
I1016 09:56:11.941617   329 net.cpp:100] Creating Layer conv0/bn
I1016 09:56:11.941620   329 net.cpp:434] conv0/bn <- conv0
I1016 09:56:11.941625   329 net.cpp:395] conv0/bn -> conv0 (in-place)
I1016 09:56:11.942633   329 net.cpp:150] Setting up conv0/bn
I1016 09:56:11.942646   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.942651   329 net.cpp:165] Memory required for data: 108134592
I1016 09:56:11.942663   329 layer_factory.hpp:77] Creating layer conv0/scale
I1016 09:56:11.942673   329 net.cpp:100] Creating Layer conv0/scale
I1016 09:56:11.942677   329 net.cpp:434] conv0/scale <- conv0
I1016 09:56:11.942680   329 net.cpp:395] conv0/scale -> conv0 (in-place)
I1016 09:56:11.942718   329 layer_factory.hpp:77] Creating layer conv0/scale
I1016 09:56:11.942869   329 net.cpp:150] Setting up conv0/scale
I1016 09:56:11.942876   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.942879   329 net.cpp:165] Memory required for data: 127795392
I1016 09:56:11.942885   329 layer_factory.hpp:77] Creating layer conv0/relu
I1016 09:56:11.942890   329 net.cpp:100] Creating Layer conv0/relu
I1016 09:56:11.942893   329 net.cpp:434] conv0/relu <- conv0
I1016 09:56:11.942896   329 net.cpp:395] conv0/relu -> conv0 (in-place)
I1016 09:56:11.943213   329 net.cpp:150] Setting up conv0/relu
I1016 09:56:11.943224   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.943228   329 net.cpp:165] Memory required for data: 147456192
I1016 09:56:11.943233   329 layer_factory.hpp:77] Creating layer conv1/dw
I1016 09:56:11.943243   329 net.cpp:100] Creating Layer conv1/dw
I1016 09:56:11.943245   329 net.cpp:434] conv1/dw <- conv0
I1016 09:56:11.943251   329 net.cpp:408] conv1/dw -> conv1/dw
I1016 09:56:11.943426   329 net.cpp:150] Setting up conv1/dw
I1016 09:56:11.943434   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.943439   329 net.cpp:165] Memory required for data: 167116992
I1016 09:56:11.943444   329 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1016 09:56:11.943449   329 net.cpp:100] Creating Layer conv1/dw/bn
I1016 09:56:11.943450   329 net.cpp:434] conv1/dw/bn <- conv1/dw
I1016 09:56:11.943454   329 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1016 09:56:11.943632   329 net.cpp:150] Setting up conv1/dw/bn
I1016 09:56:11.943640   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.943644   329 net.cpp:165] Memory required for data: 186777792
I1016 09:56:11.943653   329 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1016 09:56:11.943660   329 net.cpp:100] Creating Layer conv1/dw/scale
I1016 09:56:11.943662   329 net.cpp:434] conv1/dw/scale <- conv1/dw
I1016 09:56:11.943667   329 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1016 09:56:11.943701   329 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1016 09:56:11.943833   329 net.cpp:150] Setting up conv1/dw/scale
I1016 09:56:11.943840   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.943841   329 net.cpp:165] Memory required for data: 206438592
I1016 09:56:11.943846   329 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1016 09:56:11.943850   329 net.cpp:100] Creating Layer conv1/dw/relu
I1016 09:56:11.943852   329 net.cpp:434] conv1/dw/relu <- conv1/dw
I1016 09:56:11.943856   329 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1016 09:56:11.944161   329 net.cpp:150] Setting up conv1/dw/relu
I1016 09:56:11.944171   329 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1016 09:56:11.944175   329 net.cpp:165] Memory required for data: 226099392
I1016 09:56:11.944178   329 layer_factory.hpp:77] Creating layer conv1
I1016 09:56:11.944186   329 net.cpp:100] Creating Layer conv1
I1016 09:56:11.944190   329 net.cpp:434] conv1 <- conv1/dw
I1016 09:56:11.944195   329 net.cpp:408] conv1 -> conv1
I1016 09:56:11.946362   329 net.cpp:150] Setting up conv1
I1016 09:56:11.946375   329 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1016 09:56:11.946379   329 net.cpp:165] Memory required for data: 265420992
I1016 09:56:11.946386   329 layer_factory.hpp:77] Creating layer conv1/bn
I1016 09:56:11.946393   329 net.cpp:100] Creating Layer conv1/bn
I1016 09:56:11.946395   329 net.cpp:434] conv1/bn <- conv1
I1016 09:56:11.946399   329 net.cpp:395] conv1/bn -> conv1 (in-place)
I1016 09:56:11.946584   329 net.cpp:150] Setting up conv1/bn
I1016 09:56:11.946593   329 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1016 09:56:11.946597   329 net.cpp:165] Memory required for data: 304742592
I1016 09:56:11.946604   329 layer_factory.hpp:77] Creating layer conv1/scale
I1016 09:56:11.946609   329 net.cpp:100] Creating Layer conv1/scale
I1016 09:56:11.946612   329 net.cpp:434] conv1/scale <- conv1
I1016 09:56:11.946617   329 net.cpp:395] conv1/scale -> conv1 (in-place)
I1016 09:56:11.946652   329 layer_factory.hpp:77] Creating layer conv1/scale
I1016 09:56:11.946794   329 net.cpp:150] Setting up conv1/scale
I1016 09:56:11.946802   329 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1016 09:56:11.946806   329 net.cpp:165] Memory required for data: 344064192
I1016 09:56:11.946815   329 layer_factory.hpp:77] Creating layer conv1/relu
I1016 09:56:11.946820   329 net.cpp:100] Creating Layer conv1/relu
I1016 09:56:11.946822   329 net.cpp:434] conv1/relu <- conv1
I1016 09:56:11.946827   329 net.cpp:395] conv1/relu -> conv1 (in-place)
I1016 09:56:11.947427   329 net.cpp:150] Setting up conv1/relu
I1016 09:56:11.947438   329 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1016 09:56:11.947443   329 net.cpp:165] Memory required for data: 383385792
I1016 09:56:11.947448   329 layer_factory.hpp:77] Creating layer conv2/dw
I1016 09:56:11.947456   329 net.cpp:100] Creating Layer conv2/dw
I1016 09:56:11.947458   329 net.cpp:434] conv2/dw <- conv1
I1016 09:56:11.947464   329 net.cpp:408] conv2/dw -> conv2/dw
I1016 09:56:11.947638   329 net.cpp:150] Setting up conv2/dw
I1016 09:56:11.947646   329 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1016 09:56:11.947650   329 net.cpp:165] Memory required for data: 393216192
I1016 09:56:11.947655   329 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1016 09:56:11.947660   329 net.cpp:100] Creating Layer conv2/dw/bn
I1016 09:56:11.947662   329 net.cpp:434] conv2/dw/bn <- conv2/dw
I1016 09:56:11.947666   329 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1016 09:56:11.948603   329 net.cpp:150] Setting up conv2/dw/bn
I1016 09:56:11.948616   329 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1016 09:56:11.948621   329 net.cpp:165] Memory required for data: 403046592
I1016 09:56:11.948629   329 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1016 09:56:11.948637   329 net.cpp:100] Creating Layer conv2/dw/scale
I1016 09:56:11.948640   329 net.cpp:434] conv2/dw/scale <- conv2/dw
I1016 09:56:11.948647   329 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1016 09:56:11.948688   329 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1016 09:56:11.948792   329 net.cpp:150] Setting up conv2/dw/scale
I1016 09:56:11.948799   329 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1016 09:56:11.948801   329 net.cpp:165] Memory required for data: 412876992
I1016 09:56:11.948806   329 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1016 09:56:11.948810   329 net.cpp:100] Creating Layer conv2/dw/relu
I1016 09:56:11.948813   329 net.cpp:434] conv2/dw/relu <- conv2/dw
I1016 09:56:11.948817   329 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1016 09:56:11.949142   329 net.cpp:150] Setting up conv2/dw/relu
I1016 09:56:11.949152   329 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1016 09:56:11.949157   329 net.cpp:165] Memory required for data: 422707392
I1016 09:56:11.949162   329 layer_factory.hpp:77] Creating layer conv2
I1016 09:56:11.949168   329 net.cpp:100] Creating Layer conv2
I1016 09:56:11.949172   329 net.cpp:434] conv2 <- conv2/dw
I1016 09:56:11.949177   329 net.cpp:408] conv2 -> conv2
I1016 09:56:11.951107   329 net.cpp:150] Setting up conv2
I1016 09:56:11.951122   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.951125   329 net.cpp:165] Memory required for data: 442368192
I1016 09:56:11.951133   329 layer_factory.hpp:77] Creating layer conv2/bn
I1016 09:56:11.951140   329 net.cpp:100] Creating Layer conv2/bn
I1016 09:56:11.951143   329 net.cpp:434] conv2/bn <- conv2
I1016 09:56:11.951148   329 net.cpp:395] conv2/bn -> conv2 (in-place)
I1016 09:56:11.951328   329 net.cpp:150] Setting up conv2/bn
I1016 09:56:11.951336   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.951339   329 net.cpp:165] Memory required for data: 462028992
I1016 09:56:11.951346   329 layer_factory.hpp:77] Creating layer conv2/scale
I1016 09:56:11.951352   329 net.cpp:100] Creating Layer conv2/scale
I1016 09:56:11.951354   329 net.cpp:434] conv2/scale <- conv2
I1016 09:56:11.951359   329 net.cpp:395] conv2/scale -> conv2 (in-place)
I1016 09:56:11.951396   329 layer_factory.hpp:77] Creating layer conv2/scale
I1016 09:56:11.951501   329 net.cpp:150] Setting up conv2/scale
I1016 09:56:11.951508   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.951511   329 net.cpp:165] Memory required for data: 481689792
I1016 09:56:11.951517   329 layer_factory.hpp:77] Creating layer conv2/relu
I1016 09:56:11.951524   329 net.cpp:100] Creating Layer conv2/relu
I1016 09:56:11.951526   329 net.cpp:434] conv2/relu <- conv2
I1016 09:56:11.951530   329 net.cpp:395] conv2/relu -> conv2 (in-place)
I1016 09:56:11.951905   329 net.cpp:150] Setting up conv2/relu
I1016 09:56:11.951915   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.951920   329 net.cpp:165] Memory required for data: 501350592
I1016 09:56:11.951923   329 layer_factory.hpp:77] Creating layer conv3/dw
I1016 09:56:11.951931   329 net.cpp:100] Creating Layer conv3/dw
I1016 09:56:11.951934   329 net.cpp:434] conv3/dw <- conv2
I1016 09:56:11.951938   329 net.cpp:408] conv3/dw -> conv3/dw
I1016 09:56:11.952132   329 net.cpp:150] Setting up conv3/dw
I1016 09:56:11.952142   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.952145   329 net.cpp:165] Memory required for data: 521011392
I1016 09:56:11.952150   329 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1016 09:56:11.952155   329 net.cpp:100] Creating Layer conv3/dw/bn
I1016 09:56:11.952158   329 net.cpp:434] conv3/dw/bn <- conv3/dw
I1016 09:56:11.952162   329 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1016 09:56:11.952327   329 net.cpp:150] Setting up conv3/dw/bn
I1016 09:56:11.952335   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.952339   329 net.cpp:165] Memory required for data: 540672192
I1016 09:56:11.952349   329 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1016 09:56:11.952354   329 net.cpp:100] Creating Layer conv3/dw/scale
I1016 09:56:11.952358   329 net.cpp:434] conv3/dw/scale <- conv3/dw
I1016 09:56:11.952363   329 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1016 09:56:11.952400   329 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1016 09:56:11.952502   329 net.cpp:150] Setting up conv3/dw/scale
I1016 09:56:11.952512   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.952513   329 net.cpp:165] Memory required for data: 560332992
I1016 09:56:11.952518   329 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1016 09:56:11.952522   329 net.cpp:100] Creating Layer conv3/dw/relu
I1016 09:56:11.952524   329 net.cpp:434] conv3/dw/relu <- conv3/dw
I1016 09:56:11.952527   329 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1016 09:56:11.953196   329 net.cpp:150] Setting up conv3/dw/relu
I1016 09:56:11.953208   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.953212   329 net.cpp:165] Memory required for data: 579993792
I1016 09:56:11.953217   329 layer_factory.hpp:77] Creating layer conv3
I1016 09:56:11.953227   329 net.cpp:100] Creating Layer conv3
I1016 09:56:11.953230   329 net.cpp:434] conv3 <- conv3/dw
I1016 09:56:11.953235   329 net.cpp:408] conv3 -> conv3
I1016 09:56:11.954952   329 net.cpp:150] Setting up conv3
I1016 09:56:11.954968   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.954973   329 net.cpp:165] Memory required for data: 599654592
I1016 09:56:11.954979   329 layer_factory.hpp:77] Creating layer conv3/bn
I1016 09:56:11.954984   329 net.cpp:100] Creating Layer conv3/bn
I1016 09:56:11.954989   329 net.cpp:434] conv3/bn <- conv3
I1016 09:56:11.954996   329 net.cpp:395] conv3/bn -> conv3 (in-place)
I1016 09:56:11.955178   329 net.cpp:150] Setting up conv3/bn
I1016 09:56:11.955188   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.955191   329 net.cpp:165] Memory required for data: 619315392
I1016 09:56:11.955199   329 layer_factory.hpp:77] Creating layer conv3/scale
I1016 09:56:11.955206   329 net.cpp:100] Creating Layer conv3/scale
I1016 09:56:11.955210   329 net.cpp:434] conv3/scale <- conv3
I1016 09:56:11.955215   329 net.cpp:395] conv3/scale -> conv3 (in-place)
I1016 09:56:11.955256   329 layer_factory.hpp:77] Creating layer conv3/scale
I1016 09:56:11.955368   329 net.cpp:150] Setting up conv3/scale
I1016 09:56:11.955376   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.955380   329 net.cpp:165] Memory required for data: 638976192
I1016 09:56:11.955386   329 layer_factory.hpp:77] Creating layer conv3/relu
I1016 09:56:11.955390   329 net.cpp:100] Creating Layer conv3/relu
I1016 09:56:11.955394   329 net.cpp:434] conv3/relu <- conv3
I1016 09:56:11.955400   329 net.cpp:395] conv3/relu -> conv3 (in-place)
I1016 09:56:11.955765   329 net.cpp:150] Setting up conv3/relu
I1016 09:56:11.955775   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.955780   329 net.cpp:165] Memory required for data: 658636992
I1016 09:56:11.955783   329 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1016 09:56:11.955790   329 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1016 09:56:11.955794   329 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1016 09:56:11.955799   329 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1016 09:56:11.955806   329 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1016 09:56:11.955852   329 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1016 09:56:11.955857   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.955860   329 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1016 09:56:11.955862   329 net.cpp:165] Memory required for data: 697958592
I1016 09:56:11.955865   329 layer_factory.hpp:77] Creating layer conv4/dw
I1016 09:56:11.955873   329 net.cpp:100] Creating Layer conv4/dw
I1016 09:56:11.955875   329 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1016 09:56:11.955883   329 net.cpp:408] conv4/dw -> conv4/dw
I1016 09:56:11.956073   329 net.cpp:150] Setting up conv4/dw
I1016 09:56:11.956082   329 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1016 09:56:11.956085   329 net.cpp:165] Memory required for data: 702873792
I1016 09:56:11.956091   329 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1016 09:56:11.956100   329 net.cpp:100] Creating Layer conv4/dw/bn
I1016 09:56:11.956104   329 net.cpp:434] conv4/dw/bn <- conv4/dw
I1016 09:56:11.956110   329 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1016 09:56:11.956272   329 net.cpp:150] Setting up conv4/dw/bn
I1016 09:56:11.956279   329 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1016 09:56:11.956284   329 net.cpp:165] Memory required for data: 707788992
I1016 09:56:11.956290   329 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1016 09:56:11.956295   329 net.cpp:100] Creating Layer conv4/dw/scale
I1016 09:56:11.956298   329 net.cpp:434] conv4/dw/scale <- conv4/dw
I1016 09:56:11.956303   329 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1016 09:56:11.956343   329 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1016 09:56:11.956459   329 net.cpp:150] Setting up conv4/dw/scale
I1016 09:56:11.956467   329 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1016 09:56:11.956471   329 net.cpp:165] Memory required for data: 712704192
I1016 09:56:11.956476   329 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1016 09:56:11.956481   329 net.cpp:100] Creating Layer conv4/dw/relu
I1016 09:56:11.956485   329 net.cpp:434] conv4/dw/relu <- conv4/dw
I1016 09:56:11.956490   329 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1016 09:56:11.956861   329 net.cpp:150] Setting up conv4/dw/relu
I1016 09:56:11.956873   329 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1016 09:56:11.956876   329 net.cpp:165] Memory required for data: 717619392
I1016 09:56:11.956881   329 layer_factory.hpp:77] Creating layer conv4
I1016 09:56:11.956889   329 net.cpp:100] Creating Layer conv4
I1016 09:56:11.956893   329 net.cpp:434] conv4 <- conv4/dw
I1016 09:56:11.956899   329 net.cpp:408] conv4 -> conv4
I1016 09:56:11.958971   329 net.cpp:150] Setting up conv4
I1016 09:56:11.958983   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.958988   329 net.cpp:165] Memory required for data: 727449792
I1016 09:56:11.958994   329 layer_factory.hpp:77] Creating layer conv4/bn
I1016 09:56:11.959002   329 net.cpp:100] Creating Layer conv4/bn
I1016 09:56:11.959005   329 net.cpp:434] conv4/bn <- conv4
I1016 09:56:11.959009   329 net.cpp:395] conv4/bn -> conv4 (in-place)
I1016 09:56:11.959197   329 net.cpp:150] Setting up conv4/bn
I1016 09:56:11.959208   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.959211   329 net.cpp:165] Memory required for data: 737280192
I1016 09:56:11.959218   329 layer_factory.hpp:77] Creating layer conv4/scale
I1016 09:56:11.959224   329 net.cpp:100] Creating Layer conv4/scale
I1016 09:56:11.959228   329 net.cpp:434] conv4/scale <- conv4
I1016 09:56:11.959233   329 net.cpp:395] conv4/scale -> conv4 (in-place)
I1016 09:56:11.959276   329 layer_factory.hpp:77] Creating layer conv4/scale
I1016 09:56:11.959388   329 net.cpp:150] Setting up conv4/scale
I1016 09:56:11.959395   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.959399   329 net.cpp:165] Memory required for data: 747110592
I1016 09:56:11.959405   329 layer_factory.hpp:77] Creating layer conv4/relu
I1016 09:56:11.959411   329 net.cpp:100] Creating Layer conv4/relu
I1016 09:56:11.959414   329 net.cpp:434] conv4/relu <- conv4
I1016 09:56:11.959419   329 net.cpp:395] conv4/relu -> conv4 (in-place)
I1016 09:56:11.959805   329 net.cpp:150] Setting up conv4/relu
I1016 09:56:11.959816   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.959820   329 net.cpp:165] Memory required for data: 756940992
I1016 09:56:11.959823   329 layer_factory.hpp:77] Creating layer conv5/dw
I1016 09:56:11.959831   329 net.cpp:100] Creating Layer conv5/dw
I1016 09:56:11.959836   329 net.cpp:434] conv5/dw <- conv4
I1016 09:56:11.959843   329 net.cpp:408] conv5/dw -> conv5/dw
I1016 09:56:11.960053   329 net.cpp:150] Setting up conv5/dw
I1016 09:56:11.960062   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.960067   329 net.cpp:165] Memory required for data: 766771392
I1016 09:56:11.960072   329 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1016 09:56:11.960075   329 net.cpp:100] Creating Layer conv5/dw/bn
I1016 09:56:11.960078   329 net.cpp:434] conv5/dw/bn <- conv5/dw
I1016 09:56:11.960083   329 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1016 09:56:11.960247   329 net.cpp:150] Setting up conv5/dw/bn
I1016 09:56:11.960256   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.960260   329 net.cpp:165] Memory required for data: 776601792
I1016 09:56:11.960266   329 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1016 09:56:11.960271   329 net.cpp:100] Creating Layer conv5/dw/scale
I1016 09:56:11.960274   329 net.cpp:434] conv5/dw/scale <- conv5/dw
I1016 09:56:11.960279   329 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1016 09:56:11.960317   329 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1016 09:56:11.960427   329 net.cpp:150] Setting up conv5/dw/scale
I1016 09:56:11.960435   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.960438   329 net.cpp:165] Memory required for data: 786432192
I1016 09:56:11.960444   329 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1016 09:56:11.960449   329 net.cpp:100] Creating Layer conv5/dw/relu
I1016 09:56:11.960453   329 net.cpp:434] conv5/dw/relu <- conv5/dw
I1016 09:56:11.960459   329 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1016 09:56:11.961129   329 net.cpp:150] Setting up conv5/dw/relu
I1016 09:56:11.961141   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.961145   329 net.cpp:165] Memory required for data: 796262592
I1016 09:56:11.961149   329 layer_factory.hpp:77] Creating layer conv5
I1016 09:56:11.961159   329 net.cpp:100] Creating Layer conv5
I1016 09:56:11.961163   329 net.cpp:434] conv5 <- conv5/dw
I1016 09:56:11.961171   329 net.cpp:408] conv5 -> conv5
I1016 09:56:11.963948   329 net.cpp:150] Setting up conv5
I1016 09:56:11.963963   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.963966   329 net.cpp:165] Memory required for data: 806092992
I1016 09:56:11.963973   329 layer_factory.hpp:77] Creating layer conv5/bn
I1016 09:56:11.963979   329 net.cpp:100] Creating Layer conv5/bn
I1016 09:56:11.963982   329 net.cpp:434] conv5/bn <- conv5
I1016 09:56:11.963989   329 net.cpp:395] conv5/bn -> conv5 (in-place)
I1016 09:56:11.964165   329 net.cpp:150] Setting up conv5/bn
I1016 09:56:11.964174   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.964177   329 net.cpp:165] Memory required for data: 815923392
I1016 09:56:11.964184   329 layer_factory.hpp:77] Creating layer conv5/scale
I1016 09:56:11.964191   329 net.cpp:100] Creating Layer conv5/scale
I1016 09:56:11.964195   329 net.cpp:434] conv5/scale <- conv5
I1016 09:56:11.964200   329 net.cpp:395] conv5/scale -> conv5 (in-place)
I1016 09:56:11.964242   329 layer_factory.hpp:77] Creating layer conv5/scale
I1016 09:56:11.964354   329 net.cpp:150] Setting up conv5/scale
I1016 09:56:11.964361   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.964365   329 net.cpp:165] Memory required for data: 825753792
I1016 09:56:11.964378   329 layer_factory.hpp:77] Creating layer conv5/relu
I1016 09:56:11.964385   329 net.cpp:100] Creating Layer conv5/relu
I1016 09:56:11.964388   329 net.cpp:434] conv5/relu <- conv5
I1016 09:56:11.964392   329 net.cpp:395] conv5/relu -> conv5 (in-place)
I1016 09:56:11.964761   329 net.cpp:150] Setting up conv5/relu
I1016 09:56:11.964771   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.964776   329 net.cpp:165] Memory required for data: 835584192
I1016 09:56:11.964779   329 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1016 09:56:11.964785   329 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1016 09:56:11.964787   329 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1016 09:56:11.964794   329 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1016 09:56:11.964802   329 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1016 09:56:11.964848   329 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1016 09:56:11.964854   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.964859   329 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1016 09:56:11.964861   329 net.cpp:165] Memory required for data: 855244992
I1016 09:56:11.964864   329 layer_factory.hpp:77] Creating layer conv6/dw
I1016 09:56:11.964872   329 net.cpp:100] Creating Layer conv6/dw
I1016 09:56:11.964875   329 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1016 09:56:11.964879   329 net.cpp:408] conv6/dw -> conv6/dw
I1016 09:56:11.965076   329 net.cpp:150] Setting up conv6/dw
I1016 09:56:11.965085   329 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1016 09:56:11.965088   329 net.cpp:165] Memory required for data: 857702592
I1016 09:56:11.965101   329 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1016 09:56:11.965106   329 net.cpp:100] Creating Layer conv6/dw/bn
I1016 09:56:11.965109   329 net.cpp:434] conv6/dw/bn <- conv6/dw
I1016 09:56:11.965114   329 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1016 09:56:11.965294   329 net.cpp:150] Setting up conv6/dw/bn
I1016 09:56:11.965301   329 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1016 09:56:11.965306   329 net.cpp:165] Memory required for data: 860160192
I1016 09:56:11.965312   329 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1016 09:56:11.965318   329 net.cpp:100] Creating Layer conv6/dw/scale
I1016 09:56:11.965322   329 net.cpp:434] conv6/dw/scale <- conv6/dw
I1016 09:56:11.965328   329 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1016 09:56:11.965368   329 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1016 09:56:11.965484   329 net.cpp:150] Setting up conv6/dw/scale
I1016 09:56:11.965492   329 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1016 09:56:11.965497   329 net.cpp:165] Memory required for data: 862617792
I1016 09:56:11.965502   329 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1016 09:56:11.965507   329 net.cpp:100] Creating Layer conv6/dw/relu
I1016 09:56:11.965509   329 net.cpp:434] conv6/dw/relu <- conv6/dw
I1016 09:56:11.965515   329 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1016 09:56:11.965895   329 net.cpp:150] Setting up conv6/dw/relu
I1016 09:56:11.965906   329 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1016 09:56:11.965909   329 net.cpp:165] Memory required for data: 865075392
I1016 09:56:11.965914   329 layer_factory.hpp:77] Creating layer conv6
I1016 09:56:11.965922   329 net.cpp:100] Creating Layer conv6
I1016 09:56:11.965926   329 net.cpp:434] conv6 <- conv6/dw
I1016 09:56:11.965932   329 net.cpp:408] conv6 -> conv6
I1016 09:56:11.969280   329 net.cpp:150] Setting up conv6
I1016 09:56:11.969295   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.969300   329 net.cpp:165] Memory required for data: 869990592
I1016 09:56:11.969305   329 layer_factory.hpp:77] Creating layer conv6/bn
I1016 09:56:11.969311   329 net.cpp:100] Creating Layer conv6/bn
I1016 09:56:11.969314   329 net.cpp:434] conv6/bn <- conv6
I1016 09:56:11.969322   329 net.cpp:395] conv6/bn -> conv6 (in-place)
I1016 09:56:11.969506   329 net.cpp:150] Setting up conv6/bn
I1016 09:56:11.969516   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.969518   329 net.cpp:165] Memory required for data: 874905792
I1016 09:56:11.969525   329 layer_factory.hpp:77] Creating layer conv6/scale
I1016 09:56:11.969530   329 net.cpp:100] Creating Layer conv6/scale
I1016 09:56:11.969534   329 net.cpp:434] conv6/scale <- conv6
I1016 09:56:11.969542   329 net.cpp:395] conv6/scale -> conv6 (in-place)
I1016 09:56:11.969580   329 layer_factory.hpp:77] Creating layer conv6/scale
I1016 09:56:11.969696   329 net.cpp:150] Setting up conv6/scale
I1016 09:56:11.969703   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.969707   329 net.cpp:165] Memory required for data: 879820992
I1016 09:56:11.969713   329 layer_factory.hpp:77] Creating layer conv6/relu
I1016 09:56:11.969717   329 net.cpp:100] Creating Layer conv6/relu
I1016 09:56:11.969720   329 net.cpp:434] conv6/relu <- conv6
I1016 09:56:11.969725   329 net.cpp:395] conv6/relu -> conv6 (in-place)
I1016 09:56:11.970429   329 net.cpp:150] Setting up conv6/relu
I1016 09:56:11.970443   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.970446   329 net.cpp:165] Memory required for data: 884736192
I1016 09:56:11.970450   329 layer_factory.hpp:77] Creating layer conv7/dw
I1016 09:56:11.970460   329 net.cpp:100] Creating Layer conv7/dw
I1016 09:56:11.970464   329 net.cpp:434] conv7/dw <- conv6
I1016 09:56:11.970472   329 net.cpp:408] conv7/dw -> conv7/dw
I1016 09:56:11.970693   329 net.cpp:150] Setting up conv7/dw
I1016 09:56:11.970702   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.970706   329 net.cpp:165] Memory required for data: 889651392
I1016 09:56:11.970711   329 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1016 09:56:11.970717   329 net.cpp:100] Creating Layer conv7/dw/bn
I1016 09:56:11.970721   329 net.cpp:434] conv7/dw/bn <- conv7/dw
I1016 09:56:11.970726   329 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1016 09:56:11.970899   329 net.cpp:150] Setting up conv7/dw/bn
I1016 09:56:11.970907   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.970911   329 net.cpp:165] Memory required for data: 894566592
I1016 09:56:11.970918   329 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1016 09:56:11.970926   329 net.cpp:100] Creating Layer conv7/dw/scale
I1016 09:56:11.970929   329 net.cpp:434] conv7/dw/scale <- conv7/dw
I1016 09:56:11.970934   329 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1016 09:56:11.970978   329 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1016 09:56:11.971091   329 net.cpp:150] Setting up conv7/dw/scale
I1016 09:56:11.971099   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.971102   329 net.cpp:165] Memory required for data: 899481792
I1016 09:56:11.971108   329 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1016 09:56:11.971113   329 net.cpp:100] Creating Layer conv7/dw/relu
I1016 09:56:11.971117   329 net.cpp:434] conv7/dw/relu <- conv7/dw
I1016 09:56:11.971123   329 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1016 09:56:11.971491   329 net.cpp:150] Setting up conv7/dw/relu
I1016 09:56:11.971503   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.971506   329 net.cpp:165] Memory required for data: 904396992
I1016 09:56:11.971509   329 layer_factory.hpp:77] Creating layer conv7
I1016 09:56:11.971518   329 net.cpp:100] Creating Layer conv7
I1016 09:56:11.971521   329 net.cpp:434] conv7 <- conv7/dw
I1016 09:56:11.971527   329 net.cpp:408] conv7 -> conv7
I1016 09:56:11.975081   329 net.cpp:150] Setting up conv7
I1016 09:56:11.975095   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.975098   329 net.cpp:165] Memory required for data: 909312192
I1016 09:56:11.975106   329 layer_factory.hpp:77] Creating layer conv7/bn
I1016 09:56:11.975113   329 net.cpp:100] Creating Layer conv7/bn
I1016 09:56:11.975116   329 net.cpp:434] conv7/bn <- conv7
I1016 09:56:11.975121   329 net.cpp:395] conv7/bn -> conv7 (in-place)
I1016 09:56:11.975304   329 net.cpp:150] Setting up conv7/bn
I1016 09:56:11.975312   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.975317   329 net.cpp:165] Memory required for data: 914227392
I1016 09:56:11.975323   329 layer_factory.hpp:77] Creating layer conv7/scale
I1016 09:56:11.975330   329 net.cpp:100] Creating Layer conv7/scale
I1016 09:56:11.975334   329 net.cpp:434] conv7/scale <- conv7
I1016 09:56:11.975339   329 net.cpp:395] conv7/scale -> conv7 (in-place)
I1016 09:56:11.975383   329 layer_factory.hpp:77] Creating layer conv7/scale
I1016 09:56:11.975497   329 net.cpp:150] Setting up conv7/scale
I1016 09:56:11.975504   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.975507   329 net.cpp:165] Memory required for data: 919142592
I1016 09:56:11.975513   329 layer_factory.hpp:77] Creating layer conv7/relu
I1016 09:56:11.975520   329 net.cpp:100] Creating Layer conv7/relu
I1016 09:56:11.975524   329 net.cpp:434] conv7/relu <- conv7
I1016 09:56:11.975528   329 net.cpp:395] conv7/relu -> conv7 (in-place)
I1016 09:56:11.975925   329 net.cpp:150] Setting up conv7/relu
I1016 09:56:11.975936   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.975939   329 net.cpp:165] Memory required for data: 924057792
I1016 09:56:11.975944   329 layer_factory.hpp:77] Creating layer conv8/dw
I1016 09:56:11.975961   329 net.cpp:100] Creating Layer conv8/dw
I1016 09:56:11.975965   329 net.cpp:434] conv8/dw <- conv7
I1016 09:56:11.975970   329 net.cpp:408] conv8/dw -> conv8/dw
I1016 09:56:11.976186   329 net.cpp:150] Setting up conv8/dw
I1016 09:56:11.976195   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.976199   329 net.cpp:165] Memory required for data: 928972992
I1016 09:56:11.976205   329 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1016 09:56:11.976210   329 net.cpp:100] Creating Layer conv8/dw/bn
I1016 09:56:11.976214   329 net.cpp:434] conv8/dw/bn <- conv8/dw
I1016 09:56:11.976219   329 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1016 09:56:11.976397   329 net.cpp:150] Setting up conv8/dw/bn
I1016 09:56:11.976404   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.976408   329 net.cpp:165] Memory required for data: 933888192
I1016 09:56:11.976415   329 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1016 09:56:11.976420   329 net.cpp:100] Creating Layer conv8/dw/scale
I1016 09:56:11.976423   329 net.cpp:434] conv8/dw/scale <- conv8/dw
I1016 09:56:11.976428   329 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1016 09:56:11.976472   329 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1016 09:56:11.976585   329 net.cpp:150] Setting up conv8/dw/scale
I1016 09:56:11.976594   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.976598   329 net.cpp:165] Memory required for data: 938803392
I1016 09:56:11.976603   329 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1016 09:56:11.976608   329 net.cpp:100] Creating Layer conv8/dw/relu
I1016 09:56:11.976610   329 net.cpp:434] conv8/dw/relu <- conv8/dw
I1016 09:56:11.976615   329 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1016 09:56:11.977298   329 net.cpp:150] Setting up conv8/dw/relu
I1016 09:56:11.977313   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.977318   329 net.cpp:165] Memory required for data: 943718592
I1016 09:56:11.977321   329 layer_factory.hpp:77] Creating layer conv8
I1016 09:56:11.977331   329 net.cpp:100] Creating Layer conv8
I1016 09:56:11.977335   329 net.cpp:434] conv8 <- conv8/dw
I1016 09:56:11.977342   329 net.cpp:408] conv8 -> conv8
I1016 09:56:11.982560   329 net.cpp:150] Setting up conv8
I1016 09:56:11.982578   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.982581   329 net.cpp:165] Memory required for data: 948633792
I1016 09:56:11.982589   329 layer_factory.hpp:77] Creating layer conv8/bn
I1016 09:56:11.982596   329 net.cpp:100] Creating Layer conv8/bn
I1016 09:56:11.982599   329 net.cpp:434] conv8/bn <- conv8
I1016 09:56:11.982604   329 net.cpp:395] conv8/bn -> conv8 (in-place)
I1016 09:56:11.982792   329 net.cpp:150] Setting up conv8/bn
I1016 09:56:11.982800   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.982805   329 net.cpp:165] Memory required for data: 953548992
I1016 09:56:11.982811   329 layer_factory.hpp:77] Creating layer conv8/scale
I1016 09:56:11.982817   329 net.cpp:100] Creating Layer conv8/scale
I1016 09:56:11.982821   329 net.cpp:434] conv8/scale <- conv8
I1016 09:56:11.982826   329 net.cpp:395] conv8/scale -> conv8 (in-place)
I1016 09:56:11.982872   329 layer_factory.hpp:77] Creating layer conv8/scale
I1016 09:56:11.982983   329 net.cpp:150] Setting up conv8/scale
I1016 09:56:11.982992   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.982996   329 net.cpp:165] Memory required for data: 958464192
I1016 09:56:11.983001   329 layer_factory.hpp:77] Creating layer conv8/relu
I1016 09:56:11.983006   329 net.cpp:100] Creating Layer conv8/relu
I1016 09:56:11.983008   329 net.cpp:434] conv8/relu <- conv8
I1016 09:56:11.983012   329 net.cpp:395] conv8/relu -> conv8 (in-place)
I1016 09:56:11.983472   329 net.cpp:150] Setting up conv8/relu
I1016 09:56:11.983486   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.983489   329 net.cpp:165] Memory required for data: 963379392
I1016 09:56:11.983494   329 layer_factory.hpp:77] Creating layer conv9/dw
I1016 09:56:11.983505   329 net.cpp:100] Creating Layer conv9/dw
I1016 09:56:11.983510   329 net.cpp:434] conv9/dw <- conv8
I1016 09:56:11.983517   329 net.cpp:408] conv9/dw -> conv9/dw
I1016 09:56:11.983834   329 net.cpp:150] Setting up conv9/dw
I1016 09:56:11.983844   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.983849   329 net.cpp:165] Memory required for data: 968294592
I1016 09:56:11.983853   329 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1016 09:56:11.983860   329 net.cpp:100] Creating Layer conv9/dw/bn
I1016 09:56:11.983865   329 net.cpp:434] conv9/dw/bn <- conv9/dw
I1016 09:56:11.983870   329 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1016 09:56:11.984112   329 net.cpp:150] Setting up conv9/dw/bn
I1016 09:56:11.984122   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.984125   329 net.cpp:165] Memory required for data: 973209792
I1016 09:56:11.984134   329 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1016 09:56:11.984143   329 net.cpp:100] Creating Layer conv9/dw/scale
I1016 09:56:11.984148   329 net.cpp:434] conv9/dw/scale <- conv9/dw
I1016 09:56:11.984153   329 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1016 09:56:11.984206   329 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1016 09:56:11.984354   329 net.cpp:150] Setting up conv9/dw/scale
I1016 09:56:11.984362   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.984365   329 net.cpp:165] Memory required for data: 978124992
I1016 09:56:11.984372   329 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1016 09:56:11.984380   329 net.cpp:100] Creating Layer conv9/dw/relu
I1016 09:56:11.984385   329 net.cpp:434] conv9/dw/relu <- conv9/dw
I1016 09:56:11.984390   329 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1016 09:56:11.984936   329 net.cpp:150] Setting up conv9/dw/relu
I1016 09:56:11.984947   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.984951   329 net.cpp:165] Memory required for data: 983040192
I1016 09:56:11.984956   329 layer_factory.hpp:77] Creating layer conv9
I1016 09:56:11.984972   329 net.cpp:100] Creating Layer conv9
I1016 09:56:11.984977   329 net.cpp:434] conv9 <- conv9/dw
I1016 09:56:11.984982   329 net.cpp:408] conv9 -> conv9
I1016 09:56:11.989161   329 net.cpp:150] Setting up conv9
I1016 09:56:11.989178   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.989182   329 net.cpp:165] Memory required for data: 987955392
I1016 09:56:11.989190   329 layer_factory.hpp:77] Creating layer conv9/bn
I1016 09:56:11.989197   329 net.cpp:100] Creating Layer conv9/bn
I1016 09:56:11.989199   329 net.cpp:434] conv9/bn <- conv9
I1016 09:56:11.989204   329 net.cpp:395] conv9/bn -> conv9 (in-place)
I1016 09:56:11.989398   329 net.cpp:150] Setting up conv9/bn
I1016 09:56:11.989405   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.989409   329 net.cpp:165] Memory required for data: 992870592
I1016 09:56:11.989416   329 layer_factory.hpp:77] Creating layer conv9/scale
I1016 09:56:11.989424   329 net.cpp:100] Creating Layer conv9/scale
I1016 09:56:11.989428   329 net.cpp:434] conv9/scale <- conv9
I1016 09:56:11.989434   329 net.cpp:395] conv9/scale -> conv9 (in-place)
I1016 09:56:11.989480   329 layer_factory.hpp:77] Creating layer conv9/scale
I1016 09:56:11.989593   329 net.cpp:150] Setting up conv9/scale
I1016 09:56:11.989600   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.989603   329 net.cpp:165] Memory required for data: 997785792
I1016 09:56:11.989610   329 layer_factory.hpp:77] Creating layer conv9/relu
I1016 09:56:11.989615   329 net.cpp:100] Creating Layer conv9/relu
I1016 09:56:11.989617   329 net.cpp:434] conv9/relu <- conv9
I1016 09:56:11.989622   329 net.cpp:395] conv9/relu -> conv9 (in-place)
I1016 09:56:11.990028   329 net.cpp:150] Setting up conv9/relu
I1016 09:56:11.990039   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.990043   329 net.cpp:165] Memory required for data: 1002700992
I1016 09:56:11.990047   329 layer_factory.hpp:77] Creating layer conv10/dw
I1016 09:56:11.990056   329 net.cpp:100] Creating Layer conv10/dw
I1016 09:56:11.990061   329 net.cpp:434] conv10/dw <- conv9
I1016 09:56:11.990068   329 net.cpp:408] conv10/dw -> conv10/dw
I1016 09:56:11.990293   329 net.cpp:150] Setting up conv10/dw
I1016 09:56:11.990301   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.990304   329 net.cpp:165] Memory required for data: 1007616192
I1016 09:56:11.990310   329 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1016 09:56:11.990314   329 net.cpp:100] Creating Layer conv10/dw/bn
I1016 09:56:11.990319   329 net.cpp:434] conv10/dw/bn <- conv10/dw
I1016 09:56:11.990324   329 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1016 09:56:11.990499   329 net.cpp:150] Setting up conv10/dw/bn
I1016 09:56:11.990506   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.990509   329 net.cpp:165] Memory required for data: 1012531392
I1016 09:56:11.990517   329 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1016 09:56:11.990523   329 net.cpp:100] Creating Layer conv10/dw/scale
I1016 09:56:11.990527   329 net.cpp:434] conv10/dw/scale <- conv10/dw
I1016 09:56:11.990532   329 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1016 09:56:11.990576   329 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1016 09:56:11.990687   329 net.cpp:150] Setting up conv10/dw/scale
I1016 09:56:11.990695   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.990698   329 net.cpp:165] Memory required for data: 1017446592
I1016 09:56:11.990705   329 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1016 09:56:11.990710   329 net.cpp:100] Creating Layer conv10/dw/relu
I1016 09:56:11.990713   329 net.cpp:434] conv10/dw/relu <- conv10/dw
I1016 09:56:11.990720   329 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1016 09:56:11.991401   329 net.cpp:150] Setting up conv10/dw/relu
I1016 09:56:11.991413   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.991417   329 net.cpp:165] Memory required for data: 1022361792
I1016 09:56:11.991421   329 layer_factory.hpp:77] Creating layer conv10
I1016 09:56:11.991436   329 net.cpp:100] Creating Layer conv10
I1016 09:56:11.991441   329 net.cpp:434] conv10 <- conv10/dw
I1016 09:56:11.991447   329 net.cpp:408] conv10 -> conv10
I1016 09:56:11.995833   329 net.cpp:150] Setting up conv10
I1016 09:56:11.995847   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.995852   329 net.cpp:165] Memory required for data: 1027276992
I1016 09:56:11.995858   329 layer_factory.hpp:77] Creating layer conv10/bn
I1016 09:56:11.995864   329 net.cpp:100] Creating Layer conv10/bn
I1016 09:56:11.995868   329 net.cpp:434] conv10/bn <- conv10
I1016 09:56:11.995874   329 net.cpp:395] conv10/bn -> conv10 (in-place)
I1016 09:56:11.996060   329 net.cpp:150] Setting up conv10/bn
I1016 09:56:11.996069   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.996073   329 net.cpp:165] Memory required for data: 1032192192
I1016 09:56:11.996080   329 layer_factory.hpp:77] Creating layer conv10/scale
I1016 09:56:11.996088   329 net.cpp:100] Creating Layer conv10/scale
I1016 09:56:11.996091   329 net.cpp:434] conv10/scale <- conv10
I1016 09:56:11.996098   329 net.cpp:395] conv10/scale -> conv10 (in-place)
I1016 09:56:11.996143   329 layer_factory.hpp:77] Creating layer conv10/scale
I1016 09:56:11.996258   329 net.cpp:150] Setting up conv10/scale
I1016 09:56:11.996265   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.996269   329 net.cpp:165] Memory required for data: 1037107392
I1016 09:56:11.996275   329 layer_factory.hpp:77] Creating layer conv10/relu
I1016 09:56:11.996280   329 net.cpp:100] Creating Layer conv10/relu
I1016 09:56:11.996284   329 net.cpp:434] conv10/relu <- conv10
I1016 09:56:11.996289   329 net.cpp:395] conv10/relu -> conv10 (in-place)
I1016 09:56:11.996664   329 net.cpp:150] Setting up conv10/relu
I1016 09:56:11.996675   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.996677   329 net.cpp:165] Memory required for data: 1042022592
I1016 09:56:11.996682   329 layer_factory.hpp:77] Creating layer conv11/dw
I1016 09:56:11.996692   329 net.cpp:100] Creating Layer conv11/dw
I1016 09:56:11.996696   329 net.cpp:434] conv11/dw <- conv10
I1016 09:56:11.996703   329 net.cpp:408] conv11/dw -> conv11/dw
I1016 09:56:11.996920   329 net.cpp:150] Setting up conv11/dw
I1016 09:56:11.996929   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.996932   329 net.cpp:165] Memory required for data: 1046937792
I1016 09:56:11.996938   329 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1016 09:56:11.996943   329 net.cpp:100] Creating Layer conv11/dw/bn
I1016 09:56:11.996948   329 net.cpp:434] conv11/dw/bn <- conv11/dw
I1016 09:56:11.996953   329 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1016 09:56:11.997130   329 net.cpp:150] Setting up conv11/dw/bn
I1016 09:56:11.997139   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.997143   329 net.cpp:165] Memory required for data: 1051852992
I1016 09:56:11.997164   329 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1016 09:56:11.997169   329 net.cpp:100] Creating Layer conv11/dw/scale
I1016 09:56:11.997172   329 net.cpp:434] conv11/dw/scale <- conv11/dw
I1016 09:56:11.997176   329 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1016 09:56:11.997225   329 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1016 09:56:11.997334   329 net.cpp:150] Setting up conv11/dw/scale
I1016 09:56:11.997341   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.997345   329 net.cpp:165] Memory required for data: 1056768192
I1016 09:56:11.997351   329 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1016 09:56:11.997355   329 net.cpp:100] Creating Layer conv11/dw/relu
I1016 09:56:11.997360   329 net.cpp:434] conv11/dw/relu <- conv11/dw
I1016 09:56:11.997365   329 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1016 09:56:11.997737   329 net.cpp:150] Setting up conv11/dw/relu
I1016 09:56:11.997748   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:11.997752   329 net.cpp:165] Memory required for data: 1061683392
I1016 09:56:11.997756   329 layer_factory.hpp:77] Creating layer conv11
I1016 09:56:11.997766   329 net.cpp:100] Creating Layer conv11
I1016 09:56:11.997769   329 net.cpp:434] conv11 <- conv11/dw
I1016 09:56:11.997776   329 net.cpp:408] conv11 -> conv11
I1016 09:56:12.001623   329 net.cpp:150] Setting up conv11
I1016 09:56:12.001638   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.001643   329 net.cpp:165] Memory required for data: 1066598592
I1016 09:56:12.001649   329 layer_factory.hpp:77] Creating layer conv11/bn
I1016 09:56:12.001657   329 net.cpp:100] Creating Layer conv11/bn
I1016 09:56:12.001660   329 net.cpp:434] conv11/bn <- conv11
I1016 09:56:12.001665   329 net.cpp:395] conv11/bn -> conv11 (in-place)
I1016 09:56:12.001863   329 net.cpp:150] Setting up conv11/bn
I1016 09:56:12.001873   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.001876   329 net.cpp:165] Memory required for data: 1071513792
I1016 09:56:12.001883   329 layer_factory.hpp:77] Creating layer conv11/scale
I1016 09:56:12.001890   329 net.cpp:100] Creating Layer conv11/scale
I1016 09:56:12.001894   329 net.cpp:434] conv11/scale <- conv11
I1016 09:56:12.001899   329 net.cpp:395] conv11/scale -> conv11 (in-place)
I1016 09:56:12.001948   329 layer_factory.hpp:77] Creating layer conv11/scale
I1016 09:56:12.002063   329 net.cpp:150] Setting up conv11/scale
I1016 09:56:12.002071   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.002074   329 net.cpp:165] Memory required for data: 1076428992
I1016 09:56:12.002080   329 layer_factory.hpp:77] Creating layer conv11/relu
I1016 09:56:12.002085   329 net.cpp:100] Creating Layer conv11/relu
I1016 09:56:12.002089   329 net.cpp:434] conv11/relu <- conv11
I1016 09:56:12.002094   329 net.cpp:395] conv11/relu -> conv11 (in-place)
I1016 09:56:12.002847   329 net.cpp:150] Setting up conv11/relu
I1016 09:56:12.002859   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.002863   329 net.cpp:165] Memory required for data: 1081344192
I1016 09:56:12.002867   329 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1016 09:56:12.002876   329 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1016 09:56:12.002882   329 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1016 09:56:12.002887   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1016 09:56:12.002895   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1016 09:56:12.002900   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1016 09:56:12.002907   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1016 09:56:12.002913   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1016 09:56:12.003001   329 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1016 09:56:12.003008   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.003013   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.003018   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.003021   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.003024   329 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1016 09:56:12.003027   329 net.cpp:165] Memory required for data: 1105920192
I1016 09:56:12.003031   329 layer_factory.hpp:77] Creating layer conv12/dw
I1016 09:56:12.003039   329 net.cpp:100] Creating Layer conv12/dw
I1016 09:56:12.003042   329 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1016 09:56:12.003047   329 net.cpp:408] conv12/dw -> conv12/dw
I1016 09:56:12.003262   329 net.cpp:150] Setting up conv12/dw
I1016 09:56:12.003269   329 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1016 09:56:12.003273   329 net.cpp:165] Memory required for data: 1107148992
I1016 09:56:12.003278   329 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1016 09:56:12.003283   329 net.cpp:100] Creating Layer conv12/dw/bn
I1016 09:56:12.003288   329 net.cpp:434] conv12/dw/bn <- conv12/dw
I1016 09:56:12.003293   329 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1016 09:56:12.003484   329 net.cpp:150] Setting up conv12/dw/bn
I1016 09:56:12.003492   329 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1016 09:56:12.003495   329 net.cpp:165] Memory required for data: 1108377792
I1016 09:56:12.003504   329 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1016 09:56:12.003509   329 net.cpp:100] Creating Layer conv12/dw/scale
I1016 09:56:12.003513   329 net.cpp:434] conv12/dw/scale <- conv12/dw
I1016 09:56:12.003518   329 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1016 09:56:12.003559   329 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1016 09:56:12.003679   329 net.cpp:150] Setting up conv12/dw/scale
I1016 09:56:12.003690   329 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1016 09:56:12.003692   329 net.cpp:165] Memory required for data: 1109606592
I1016 09:56:12.003696   329 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1016 09:56:12.003700   329 net.cpp:100] Creating Layer conv12/dw/relu
I1016 09:56:12.003703   329 net.cpp:434] conv12/dw/relu <- conv12/dw
I1016 09:56:12.003706   329 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1016 09:56:12.004076   329 net.cpp:150] Setting up conv12/dw/relu
I1016 09:56:12.004086   329 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1016 09:56:12.004087   329 net.cpp:165] Memory required for data: 1110835392
I1016 09:56:12.004091   329 layer_factory.hpp:77] Creating layer conv12
I1016 09:56:12.004098   329 net.cpp:100] Creating Layer conv12
I1016 09:56:12.004101   329 net.cpp:434] conv12 <- conv12/dw
I1016 09:56:12.004108   329 net.cpp:408] conv12 -> conv12
I1016 09:56:12.010622   329 net.cpp:150] Setting up conv12
I1016 09:56:12.010634   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.010653   329 net.cpp:165] Memory required for data: 1113292992
I1016 09:56:12.010658   329 layer_factory.hpp:77] Creating layer conv12/bn
I1016 09:56:12.010663   329 net.cpp:100] Creating Layer conv12/bn
I1016 09:56:12.010666   329 net.cpp:434] conv12/bn <- conv12
I1016 09:56:12.010670   329 net.cpp:395] conv12/bn -> conv12 (in-place)
I1016 09:56:12.010848   329 net.cpp:150] Setting up conv12/bn
I1016 09:56:12.010854   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.010856   329 net.cpp:165] Memory required for data: 1115750592
I1016 09:56:12.010862   329 layer_factory.hpp:77] Creating layer conv12/scale
I1016 09:56:12.010867   329 net.cpp:100] Creating Layer conv12/scale
I1016 09:56:12.010869   329 net.cpp:434] conv12/scale <- conv12
I1016 09:56:12.010874   329 net.cpp:395] conv12/scale -> conv12 (in-place)
I1016 09:56:12.010908   329 layer_factory.hpp:77] Creating layer conv12/scale
I1016 09:56:12.011008   329 net.cpp:150] Setting up conv12/scale
I1016 09:56:12.011013   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.011014   329 net.cpp:165] Memory required for data: 1118208192
I1016 09:56:12.011019   329 layer_factory.hpp:77] Creating layer conv12/relu
I1016 09:56:12.011023   329 net.cpp:100] Creating Layer conv12/relu
I1016 09:56:12.011025   329 net.cpp:434] conv12/relu <- conv12
I1016 09:56:12.011029   329 net.cpp:395] conv12/relu -> conv12 (in-place)
I1016 09:56:12.011407   329 net.cpp:150] Setting up conv12/relu
I1016 09:56:12.011416   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.011418   329 net.cpp:165] Memory required for data: 1120665792
I1016 09:56:12.011421   329 layer_factory.hpp:77] Creating layer conv13/dw
I1016 09:56:12.011430   329 net.cpp:100] Creating Layer conv13/dw
I1016 09:56:12.011432   329 net.cpp:434] conv13/dw <- conv12
I1016 09:56:12.011436   329 net.cpp:408] conv13/dw -> conv13/dw
I1016 09:56:12.011682   329 net.cpp:150] Setting up conv13/dw
I1016 09:56:12.011689   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.011692   329 net.cpp:165] Memory required for data: 1123123392
I1016 09:56:12.011695   329 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1016 09:56:12.011699   329 net.cpp:100] Creating Layer conv13/dw/bn
I1016 09:56:12.011703   329 net.cpp:434] conv13/dw/bn <- conv13/dw
I1016 09:56:12.011705   329 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1016 09:56:12.011870   329 net.cpp:150] Setting up conv13/dw/bn
I1016 09:56:12.011878   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.011879   329 net.cpp:165] Memory required for data: 1125580992
I1016 09:56:12.011884   329 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1016 09:56:12.011889   329 net.cpp:100] Creating Layer conv13/dw/scale
I1016 09:56:12.011891   329 net.cpp:434] conv13/dw/scale <- conv13/dw
I1016 09:56:12.011895   329 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1016 09:56:12.011930   329 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1016 09:56:12.012027   329 net.cpp:150] Setting up conv13/dw/scale
I1016 09:56:12.012033   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.012035   329 net.cpp:165] Memory required for data: 1128038592
I1016 09:56:12.012040   329 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1016 09:56:12.012043   329 net.cpp:100] Creating Layer conv13/dw/relu
I1016 09:56:12.012046   329 net.cpp:434] conv13/dw/relu <- conv13/dw
I1016 09:56:12.012049   329 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1016 09:56:12.012723   329 net.cpp:150] Setting up conv13/dw/relu
I1016 09:56:12.012735   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.012738   329 net.cpp:165] Memory required for data: 1130496192
I1016 09:56:12.012742   329 layer_factory.hpp:77] Creating layer conv13
I1016 09:56:12.012748   329 net.cpp:100] Creating Layer conv13
I1016 09:56:12.012751   329 net.cpp:434] conv13 <- conv13/dw
I1016 09:56:12.012756   329 net.cpp:408] conv13 -> conv13
I1016 09:56:12.023972   329 net.cpp:150] Setting up conv13
I1016 09:56:12.023986   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.023989   329 net.cpp:165] Memory required for data: 1132953792
I1016 09:56:12.023994   329 layer_factory.hpp:77] Creating layer conv13/bn
I1016 09:56:12.024001   329 net.cpp:100] Creating Layer conv13/bn
I1016 09:56:12.024005   329 net.cpp:434] conv13/bn <- conv13
I1016 09:56:12.024010   329 net.cpp:395] conv13/bn -> conv13 (in-place)
I1016 09:56:12.024196   329 net.cpp:150] Setting up conv13/bn
I1016 09:56:12.024204   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024205   329 net.cpp:165] Memory required for data: 1135411392
I1016 09:56:12.024210   329 layer_factory.hpp:77] Creating layer conv13/scale
I1016 09:56:12.024216   329 net.cpp:100] Creating Layer conv13/scale
I1016 09:56:12.024219   329 net.cpp:434] conv13/scale <- conv13
I1016 09:56:12.024222   329 net.cpp:395] conv13/scale -> conv13 (in-place)
I1016 09:56:12.024260   329 layer_factory.hpp:77] Creating layer conv13/scale
I1016 09:56:12.024358   329 net.cpp:150] Setting up conv13/scale
I1016 09:56:12.024365   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024368   329 net.cpp:165] Memory required for data: 1137868992
I1016 09:56:12.024371   329 layer_factory.hpp:77] Creating layer conv13/relu
I1016 09:56:12.024375   329 net.cpp:100] Creating Layer conv13/relu
I1016 09:56:12.024379   329 net.cpp:434] conv13/relu <- conv13
I1016 09:56:12.024381   329 net.cpp:395] conv13/relu -> conv13 (in-place)
I1016 09:56:12.024734   329 net.cpp:150] Setting up conv13/relu
I1016 09:56:12.024754   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024756   329 net.cpp:165] Memory required for data: 1140326592
I1016 09:56:12.024758   329 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1016 09:56:12.024765   329 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1016 09:56:12.024766   329 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1016 09:56:12.024772   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1016 09:56:12.024778   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1016 09:56:12.024783   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1016 09:56:12.024788   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1016 09:56:12.024792   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1016 09:56:12.024863   329 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1016 09:56:12.024868   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024871   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024874   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024876   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024879   329 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1016 09:56:12.024881   329 net.cpp:165] Memory required for data: 1152614592
I1016 09:56:12.024883   329 layer_factory.hpp:77] Creating layer conv14_1
I1016 09:56:12.024891   329 net.cpp:100] Creating Layer conv14_1
I1016 09:56:12.024893   329 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1016 09:56:12.024899   329 net.cpp:408] conv14_1 -> conv14_1
I1016 09:56:12.029220   329 net.cpp:150] Setting up conv14_1
I1016 09:56:12.029233   329 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1016 09:56:12.029235   329 net.cpp:165] Memory required for data: 1153228992
I1016 09:56:12.029240   329 layer_factory.hpp:77] Creating layer conv14_1/bn
I1016 09:56:12.029247   329 net.cpp:100] Creating Layer conv14_1/bn
I1016 09:56:12.029250   329 net.cpp:434] conv14_1/bn <- conv14_1
I1016 09:56:12.029254   329 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1016 09:56:12.029425   329 net.cpp:150] Setting up conv14_1/bn
I1016 09:56:12.029433   329 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1016 09:56:12.029434   329 net.cpp:165] Memory required for data: 1153843392
I1016 09:56:12.029440   329 layer_factory.hpp:77] Creating layer conv14_1/scale
I1016 09:56:12.029444   329 net.cpp:100] Creating Layer conv14_1/scale
I1016 09:56:12.029448   329 net.cpp:434] conv14_1/scale <- conv14_1
I1016 09:56:12.029450   329 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1016 09:56:12.029486   329 layer_factory.hpp:77] Creating layer conv14_1/scale
I1016 09:56:12.029579   329 net.cpp:150] Setting up conv14_1/scale
I1016 09:56:12.029585   329 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1016 09:56:12.029587   329 net.cpp:165] Memory required for data: 1154457792
I1016 09:56:12.029592   329 layer_factory.hpp:77] Creating layer conv14_1/relu
I1016 09:56:12.029597   329 net.cpp:100] Creating Layer conv14_1/relu
I1016 09:56:12.029600   329 net.cpp:434] conv14_1/relu <- conv14_1
I1016 09:56:12.029603   329 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1016 09:56:12.029966   329 net.cpp:150] Setting up conv14_1/relu
I1016 09:56:12.029976   329 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1016 09:56:12.029979   329 net.cpp:165] Memory required for data: 1155072192
I1016 09:56:12.029981   329 layer_factory.hpp:77] Creating layer conv14_2
I1016 09:56:12.029989   329 net.cpp:100] Creating Layer conv14_2
I1016 09:56:12.029990   329 net.cpp:434] conv14_2 <- conv14_1
I1016 09:56:12.029996   329 net.cpp:408] conv14_2 -> conv14_2
I1016 09:56:12.042454   329 net.cpp:150] Setting up conv14_2
I1016 09:56:12.042476   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.042480   329 net.cpp:165] Memory required for data: 1155399872
I1016 09:56:12.042487   329 layer_factory.hpp:77] Creating layer conv14_2/bn
I1016 09:56:12.042495   329 net.cpp:100] Creating Layer conv14_2/bn
I1016 09:56:12.042500   329 net.cpp:434] conv14_2/bn <- conv14_2
I1016 09:56:12.042507   329 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1016 09:56:12.042707   329 net.cpp:150] Setting up conv14_2/bn
I1016 09:56:12.042712   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.042716   329 net.cpp:165] Memory required for data: 1155727552
I1016 09:56:12.042721   329 layer_factory.hpp:77] Creating layer conv14_2/scale
I1016 09:56:12.042727   329 net.cpp:100] Creating Layer conv14_2/scale
I1016 09:56:12.042731   329 net.cpp:434] conv14_2/scale <- conv14_2
I1016 09:56:12.042734   329 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1016 09:56:12.042770   329 layer_factory.hpp:77] Creating layer conv14_2/scale
I1016 09:56:12.042876   329 net.cpp:150] Setting up conv14_2/scale
I1016 09:56:12.042881   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.042882   329 net.cpp:165] Memory required for data: 1156055232
I1016 09:56:12.042886   329 layer_factory.hpp:77] Creating layer conv14_2/relu
I1016 09:56:12.042891   329 net.cpp:100] Creating Layer conv14_2/relu
I1016 09:56:12.042893   329 net.cpp:434] conv14_2/relu <- conv14_2
I1016 09:56:12.042896   329 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1016 09:56:12.043269   329 net.cpp:150] Setting up conv14_2/relu
I1016 09:56:12.043280   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.043282   329 net.cpp:165] Memory required for data: 1156382912
I1016 09:56:12.043285   329 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1016 09:56:12.043290   329 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1016 09:56:12.043293   329 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1016 09:56:12.043298   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1016 09:56:12.043304   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1016 09:56:12.043310   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1016 09:56:12.043315   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1016 09:56:12.043376   329 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1016 09:56:12.043381   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.043383   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.043386   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.043390   329 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1016 09:56:12.043391   329 net.cpp:165] Memory required for data: 1157693632
I1016 09:56:12.043393   329 layer_factory.hpp:77] Creating layer conv15_1
I1016 09:56:12.043401   329 net.cpp:100] Creating Layer conv15_1
I1016 09:56:12.043404   329 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1016 09:56:12.043409   329 net.cpp:408] conv15_1 -> conv15_1
I1016 09:56:12.045544   329 net.cpp:150] Setting up conv15_1
I1016 09:56:12.045557   329 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1016 09:56:12.045559   329 net.cpp:165] Memory required for data: 1157775552
I1016 09:56:12.045563   329 layer_factory.hpp:77] Creating layer conv15_1/bn
I1016 09:56:12.045568   329 net.cpp:100] Creating Layer conv15_1/bn
I1016 09:56:12.045573   329 net.cpp:434] conv15_1/bn <- conv15_1
I1016 09:56:12.045578   329 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1016 09:56:12.045749   329 net.cpp:150] Setting up conv15_1/bn
I1016 09:56:12.045758   329 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1016 09:56:12.045760   329 net.cpp:165] Memory required for data: 1157857472
I1016 09:56:12.045765   329 layer_factory.hpp:77] Creating layer conv15_1/scale
I1016 09:56:12.045770   329 net.cpp:100] Creating Layer conv15_1/scale
I1016 09:56:12.045773   329 net.cpp:434] conv15_1/scale <- conv15_1
I1016 09:56:12.045778   329 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1016 09:56:12.045814   329 layer_factory.hpp:77] Creating layer conv15_1/scale
I1016 09:56:12.045917   329 net.cpp:150] Setting up conv15_1/scale
I1016 09:56:12.045922   329 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1016 09:56:12.045924   329 net.cpp:165] Memory required for data: 1157939392
I1016 09:56:12.045928   329 layer_factory.hpp:77] Creating layer conv15_1/relu
I1016 09:56:12.045933   329 net.cpp:100] Creating Layer conv15_1/relu
I1016 09:56:12.045936   329 net.cpp:434] conv15_1/relu <- conv15_1
I1016 09:56:12.045940   329 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1016 09:56:12.046615   329 net.cpp:150] Setting up conv15_1/relu
I1016 09:56:12.046627   329 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1016 09:56:12.046629   329 net.cpp:165] Memory required for data: 1158021312
I1016 09:56:12.046633   329 layer_factory.hpp:77] Creating layer conv15_2
I1016 09:56:12.046640   329 net.cpp:100] Creating Layer conv15_2
I1016 09:56:12.046643   329 net.cpp:434] conv15_2 <- conv15_1
I1016 09:56:12.046649   329 net.cpp:408] conv15_2 -> conv15_2
I1016 09:56:12.051319   329 net.cpp:150] Setting up conv15_2
I1016 09:56:12.051332   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.051335   329 net.cpp:165] Memory required for data: 1158070464
I1016 09:56:12.051339   329 layer_factory.hpp:77] Creating layer conv15_2/bn
I1016 09:56:12.051362   329 net.cpp:100] Creating Layer conv15_2/bn
I1016 09:56:12.051367   329 net.cpp:434] conv15_2/bn <- conv15_2
I1016 09:56:12.051370   329 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1016 09:56:12.051548   329 net.cpp:150] Setting up conv15_2/bn
I1016 09:56:12.051555   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.051558   329 net.cpp:165] Memory required for data: 1158119616
I1016 09:56:12.051563   329 layer_factory.hpp:77] Creating layer conv15_2/scale
I1016 09:56:12.051570   329 net.cpp:100] Creating Layer conv15_2/scale
I1016 09:56:12.051573   329 net.cpp:434] conv15_2/scale <- conv15_2
I1016 09:56:12.051576   329 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1016 09:56:12.051614   329 layer_factory.hpp:77] Creating layer conv15_2/scale
I1016 09:56:12.051710   329 net.cpp:150] Setting up conv15_2/scale
I1016 09:56:12.051717   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.051718   329 net.cpp:165] Memory required for data: 1158168768
I1016 09:56:12.051723   329 layer_factory.hpp:77] Creating layer conv15_2/relu
I1016 09:56:12.051728   329 net.cpp:100] Creating Layer conv15_2/relu
I1016 09:56:12.051730   329 net.cpp:434] conv15_2/relu <- conv15_2
I1016 09:56:12.051734   329 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1016 09:56:12.052093   329 net.cpp:150] Setting up conv15_2/relu
I1016 09:56:12.052101   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.052104   329 net.cpp:165] Memory required for data: 1158217920
I1016 09:56:12.052108   329 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1016 09:56:12.052114   329 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1016 09:56:12.052115   329 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1016 09:56:12.052122   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1016 09:56:12.052129   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1016 09:56:12.052134   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1016 09:56:12.052137   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1016 09:56:12.052199   329 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1016 09:56:12.052204   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.052207   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.052209   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.052212   329 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1016 09:56:12.052214   329 net.cpp:165] Memory required for data: 1158414528
I1016 09:56:12.052217   329 layer_factory.hpp:77] Creating layer conv16_1
I1016 09:56:12.052223   329 net.cpp:100] Creating Layer conv16_1
I1016 09:56:12.052227   329 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1016 09:56:12.052232   329 net.cpp:408] conv16_1 -> conv16_1
I1016 09:56:12.056499   329 net.cpp:150] Setting up conv16_1
I1016 09:56:12.056519   329 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1016 09:56:12.056522   329 net.cpp:165] Memory required for data: 1158439104
I1016 09:56:12.056529   329 layer_factory.hpp:77] Creating layer conv16_1/bn
I1016 09:56:12.056535   329 net.cpp:100] Creating Layer conv16_1/bn
I1016 09:56:12.056540   329 net.cpp:434] conv16_1/bn <- conv16_1
I1016 09:56:12.056547   329 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1016 09:56:12.056730   329 net.cpp:150] Setting up conv16_1/bn
I1016 09:56:12.056735   329 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1016 09:56:12.056738   329 net.cpp:165] Memory required for data: 1158463680
I1016 09:56:12.056743   329 layer_factory.hpp:77] Creating layer conv16_1/scale
I1016 09:56:12.056751   329 net.cpp:100] Creating Layer conv16_1/scale
I1016 09:56:12.056753   329 net.cpp:434] conv16_1/scale <- conv16_1
I1016 09:56:12.056758   329 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1016 09:56:12.056795   329 layer_factory.hpp:77] Creating layer conv16_1/scale
I1016 09:56:12.056901   329 net.cpp:150] Setting up conv16_1/scale
I1016 09:56:12.056906   329 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1016 09:56:12.056908   329 net.cpp:165] Memory required for data: 1158488256
I1016 09:56:12.056913   329 layer_factory.hpp:77] Creating layer conv16_1/relu
I1016 09:56:12.056918   329 net.cpp:100] Creating Layer conv16_1/relu
I1016 09:56:12.056921   329 net.cpp:434] conv16_1/relu <- conv16_1
I1016 09:56:12.056924   329 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1016 09:56:12.057286   329 net.cpp:150] Setting up conv16_1/relu
I1016 09:56:12.057296   329 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1016 09:56:12.057297   329 net.cpp:165] Memory required for data: 1158512832
I1016 09:56:12.057301   329 layer_factory.hpp:77] Creating layer conv16_2
I1016 09:56:12.057310   329 net.cpp:100] Creating Layer conv16_2
I1016 09:56:12.057313   329 net.cpp:434] conv16_2 <- conv16_1
I1016 09:56:12.057317   329 net.cpp:408] conv16_2 -> conv16_2
I1016 09:56:12.062866   329 net.cpp:150] Setting up conv16_2
I1016 09:56:12.062880   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.062882   329 net.cpp:165] Memory required for data: 1158529216
I1016 09:56:12.062887   329 layer_factory.hpp:77] Creating layer conv16_2/bn
I1016 09:56:12.062891   329 net.cpp:100] Creating Layer conv16_2/bn
I1016 09:56:12.062896   329 net.cpp:434] conv16_2/bn <- conv16_2
I1016 09:56:12.062899   329 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1016 09:56:12.063078   329 net.cpp:150] Setting up conv16_2/bn
I1016 09:56:12.063083   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.063086   329 net.cpp:165] Memory required for data: 1158545600
I1016 09:56:12.063091   329 layer_factory.hpp:77] Creating layer conv16_2/scale
I1016 09:56:12.063098   329 net.cpp:100] Creating Layer conv16_2/scale
I1016 09:56:12.063100   329 net.cpp:434] conv16_2/scale <- conv16_2
I1016 09:56:12.063105   329 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1016 09:56:12.063140   329 layer_factory.hpp:77] Creating layer conv16_2/scale
I1016 09:56:12.063237   329 net.cpp:150] Setting up conv16_2/scale
I1016 09:56:12.063243   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.063246   329 net.cpp:165] Memory required for data: 1158561984
I1016 09:56:12.063251   329 layer_factory.hpp:77] Creating layer conv16_2/relu
I1016 09:56:12.063254   329 net.cpp:100] Creating Layer conv16_2/relu
I1016 09:56:12.063256   329 net.cpp:434] conv16_2/relu <- conv16_2
I1016 09:56:12.063261   329 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1016 09:56:12.063971   329 net.cpp:150] Setting up conv16_2/relu
I1016 09:56:12.063983   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.063987   329 net.cpp:165] Memory required for data: 1158578368
I1016 09:56:12.063989   329 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1016 09:56:12.063995   329 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1016 09:56:12.063997   329 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1016 09:56:12.064003   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1016 09:56:12.064010   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1016 09:56:12.064014   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1016 09:56:12.064020   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1016 09:56:12.064085   329 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1016 09:56:12.064090   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.064093   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.064096   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.064098   329 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1016 09:56:12.064101   329 net.cpp:165] Memory required for data: 1158643904
I1016 09:56:12.064103   329 layer_factory.hpp:77] Creating layer conv17_1
I1016 09:56:12.064110   329 net.cpp:100] Creating Layer conv17_1
I1016 09:56:12.064113   329 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1016 09:56:12.064119   329 net.cpp:408] conv17_1 -> conv17_1
I1016 09:56:12.065903   329 net.cpp:150] Setting up conv17_1
I1016 09:56:12.065915   329 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1016 09:56:12.065917   329 net.cpp:165] Memory required for data: 1158648000
I1016 09:56:12.065922   329 layer_factory.hpp:77] Creating layer conv17_1/bn
I1016 09:56:12.065927   329 net.cpp:100] Creating Layer conv17_1/bn
I1016 09:56:12.065929   329 net.cpp:434] conv17_1/bn <- conv17_1
I1016 09:56:12.065942   329 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1016 09:56:12.066130   329 net.cpp:150] Setting up conv17_1/bn
I1016 09:56:12.066138   329 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1016 09:56:12.066140   329 net.cpp:165] Memory required for data: 1158652096
I1016 09:56:12.066145   329 layer_factory.hpp:77] Creating layer conv17_1/scale
I1016 09:56:12.066151   329 net.cpp:100] Creating Layer conv17_1/scale
I1016 09:56:12.066154   329 net.cpp:434] conv17_1/scale <- conv17_1
I1016 09:56:12.066157   329 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1016 09:56:12.066195   329 layer_factory.hpp:77] Creating layer conv17_1/scale
I1016 09:56:12.066298   329 net.cpp:150] Setting up conv17_1/scale
I1016 09:56:12.066303   329 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1016 09:56:12.066304   329 net.cpp:165] Memory required for data: 1158656192
I1016 09:56:12.066309   329 layer_factory.hpp:77] Creating layer conv17_1/relu
I1016 09:56:12.066314   329 net.cpp:100] Creating Layer conv17_1/relu
I1016 09:56:12.066318   329 net.cpp:434] conv17_1/relu <- conv17_1
I1016 09:56:12.066320   329 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1016 09:56:12.066684   329 net.cpp:150] Setting up conv17_1/relu
I1016 09:56:12.066694   329 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1016 09:56:12.066695   329 net.cpp:165] Memory required for data: 1158660288
I1016 09:56:12.066699   329 layer_factory.hpp:77] Creating layer conv17_2
I1016 09:56:12.066706   329 net.cpp:100] Creating Layer conv17_2
I1016 09:56:12.066709   329 net.cpp:434] conv17_2 <- conv17_1
I1016 09:56:12.066715   329 net.cpp:408] conv17_2 -> conv17_2
I1016 09:56:12.068898   329 net.cpp:150] Setting up conv17_2
I1016 09:56:12.068909   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.068912   329 net.cpp:165] Memory required for data: 1158662336
I1016 09:56:12.068917   329 layer_factory.hpp:77] Creating layer conv17_2/bn
I1016 09:56:12.068924   329 net.cpp:100] Creating Layer conv17_2/bn
I1016 09:56:12.068928   329 net.cpp:434] conv17_2/bn <- conv17_2
I1016 09:56:12.068933   329 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1016 09:56:12.069105   329 net.cpp:150] Setting up conv17_2/bn
I1016 09:56:12.069113   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069114   329 net.cpp:165] Memory required for data: 1158664384
I1016 09:56:12.069119   329 layer_factory.hpp:77] Creating layer conv17_2/scale
I1016 09:56:12.069125   329 net.cpp:100] Creating Layer conv17_2/scale
I1016 09:56:12.069128   329 net.cpp:434] conv17_2/scale <- conv17_2
I1016 09:56:12.069131   329 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1016 09:56:12.069169   329 layer_factory.hpp:77] Creating layer conv17_2/scale
I1016 09:56:12.069269   329 net.cpp:150] Setting up conv17_2/scale
I1016 09:56:12.069277   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069278   329 net.cpp:165] Memory required for data: 1158666432
I1016 09:56:12.069283   329 layer_factory.hpp:77] Creating layer conv17_2/relu
I1016 09:56:12.069288   329 net.cpp:100] Creating Layer conv17_2/relu
I1016 09:56:12.069289   329 net.cpp:434] conv17_2/relu <- conv17_2
I1016 09:56:12.069293   329 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1016 09:56:12.069655   329 net.cpp:150] Setting up conv17_2/relu
I1016 09:56:12.069664   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069666   329 net.cpp:165] Memory required for data: 1158668480
I1016 09:56:12.069669   329 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1016 09:56:12.069674   329 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1016 09:56:12.069677   329 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1016 09:56:12.069681   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1016 09:56:12.069687   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1016 09:56:12.069694   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1016 09:56:12.069746   329 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1016 09:56:12.069749   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069752   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069756   329 net.cpp:157] Top shape: 4 128 1 1 (512)
I1016 09:56:12.069757   329 net.cpp:165] Memory required for data: 1158674624
I1016 09:56:12.069759   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1016 09:56:12.069767   329 net.cpp:100] Creating Layer conv11_mbox_loc
I1016 09:56:12.069772   329 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1016 09:56:12.069777   329 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1016 09:56:12.071516   329 net.cpp:150] Setting up conv11_mbox_loc
I1016 09:56:12.071528   329 net.cpp:157] Top shape: 4 12 20 30 (28800)
I1016 09:56:12.071532   329 net.cpp:165] Memory required for data: 1158789824
I1016 09:56:12.071537   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1016 09:56:12.071543   329 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1016 09:56:12.071547   329 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1016 09:56:12.071552   329 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1016 09:56:12.071650   329 net.cpp:150] Setting up conv11_mbox_loc_perm
I1016 09:56:12.071655   329 net.cpp:157] Top shape: 4 20 30 12 (28800)
I1016 09:56:12.071657   329 net.cpp:165] Memory required for data: 1158905024
I1016 09:56:12.071660   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1016 09:56:12.071666   329 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1016 09:56:12.071669   329 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1016 09:56:12.071672   329 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1016 09:56:12.071696   329 net.cpp:150] Setting up conv11_mbox_loc_flat
I1016 09:56:12.071700   329 net.cpp:157] Top shape: 4 7200 (28800)
I1016 09:56:12.071702   329 net.cpp:165] Memory required for data: 1159020224
I1016 09:56:12.071704   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1016 09:56:12.071712   329 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1016 09:56:12.071714   329 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1016 09:56:12.071720   329 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1016 09:56:12.073482   329 net.cpp:150] Setting up conv11_mbox_conf_new
I1016 09:56:12.073495   329 net.cpp:157] Top shape: 4 9 20 30 (21600)
I1016 09:56:12.073498   329 net.cpp:165] Memory required for data: 1159106624
I1016 09:56:12.073503   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1016 09:56:12.073508   329 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1016 09:56:12.073511   329 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1016 09:56:12.073518   329 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1016 09:56:12.073616   329 net.cpp:150] Setting up conv11_mbox_conf_perm
I1016 09:56:12.073621   329 net.cpp:157] Top shape: 4 20 30 9 (21600)
I1016 09:56:12.073623   329 net.cpp:165] Memory required for data: 1159193024
I1016 09:56:12.073626   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1016 09:56:12.073631   329 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1016 09:56:12.073633   329 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1016 09:56:12.073638   329 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1016 09:56:12.073660   329 net.cpp:150] Setting up conv11_mbox_conf_flat
I1016 09:56:12.073667   329 net.cpp:157] Top shape: 4 5400 (21600)
I1016 09:56:12.073668   329 net.cpp:165] Memory required for data: 1159279424
I1016 09:56:12.073670   329 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1016 09:56:12.073675   329 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1016 09:56:12.073678   329 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1016 09:56:12.073683   329 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1016 09:56:12.073688   329 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1016 09:56:12.073712   329 net.cpp:150] Setting up conv11_mbox_priorbox
I1016 09:56:12.073717   329 net.cpp:157] Top shape: 1 2 7200 (14400)
I1016 09:56:12.073719   329 net.cpp:165] Memory required for data: 1159337024
I1016 09:56:12.073721   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1016 09:56:12.073729   329 net.cpp:100] Creating Layer conv13_mbox_loc
I1016 09:56:12.073732   329 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1016 09:56:12.073737   329 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1016 09:56:12.075633   329 net.cpp:150] Setting up conv13_mbox_loc
I1016 09:56:12.075644   329 net.cpp:157] Top shape: 4 24 10 15 (14400)
I1016 09:56:12.075646   329 net.cpp:165] Memory required for data: 1159394624
I1016 09:56:12.075651   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1016 09:56:12.075659   329 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1016 09:56:12.075661   329 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1016 09:56:12.075666   329 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1016 09:56:12.075767   329 net.cpp:150] Setting up conv13_mbox_loc_perm
I1016 09:56:12.075773   329 net.cpp:157] Top shape: 4 10 15 24 (14400)
I1016 09:56:12.075774   329 net.cpp:165] Memory required for data: 1159452224
I1016 09:56:12.075778   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1016 09:56:12.075781   329 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1016 09:56:12.075784   329 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1016 09:56:12.075789   329 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1016 09:56:12.075812   329 net.cpp:150] Setting up conv13_mbox_loc_flat
I1016 09:56:12.075816   329 net.cpp:157] Top shape: 4 3600 (14400)
I1016 09:56:12.075819   329 net.cpp:165] Memory required for data: 1159509824
I1016 09:56:12.075820   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1016 09:56:12.075829   329 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1016 09:56:12.075831   329 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1016 09:56:12.075836   329 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1016 09:56:12.077668   329 net.cpp:150] Setting up conv13_mbox_conf_new
I1016 09:56:12.077679   329 net.cpp:157] Top shape: 4 18 10 15 (10800)
I1016 09:56:12.077682   329 net.cpp:165] Memory required for data: 1159553024
I1016 09:56:12.077688   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1016 09:56:12.077695   329 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1016 09:56:12.077698   329 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1016 09:56:12.077702   329 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1016 09:56:12.077800   329 net.cpp:150] Setting up conv13_mbox_conf_perm
I1016 09:56:12.077807   329 net.cpp:157] Top shape: 4 10 15 18 (10800)
I1016 09:56:12.077810   329 net.cpp:165] Memory required for data: 1159596224
I1016 09:56:12.077811   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1016 09:56:12.077817   329 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1016 09:56:12.077826   329 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1016 09:56:12.077829   329 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1016 09:56:12.077854   329 net.cpp:150] Setting up conv13_mbox_conf_flat
I1016 09:56:12.077859   329 net.cpp:157] Top shape: 4 2700 (10800)
I1016 09:56:12.077862   329 net.cpp:165] Memory required for data: 1159639424
I1016 09:56:12.077863   329 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1016 09:56:12.077869   329 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1016 09:56:12.077872   329 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1016 09:56:12.077875   329 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1016 09:56:12.077881   329 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1016 09:56:12.077904   329 net.cpp:150] Setting up conv13_mbox_priorbox
I1016 09:56:12.077909   329 net.cpp:157] Top shape: 1 2 3600 (7200)
I1016 09:56:12.077910   329 net.cpp:165] Memory required for data: 1159668224
I1016 09:56:12.077913   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1016 09:56:12.077922   329 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1016 09:56:12.077925   329 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1016 09:56:12.077929   329 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1016 09:56:12.079717   329 net.cpp:150] Setting up conv14_2_mbox_loc
I1016 09:56:12.079730   329 net.cpp:157] Top shape: 4 24 5 8 (3840)
I1016 09:56:12.079733   329 net.cpp:165] Memory required for data: 1159683584
I1016 09:56:12.079738   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1016 09:56:12.079743   329 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1016 09:56:12.079746   329 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1016 09:56:12.079752   329 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1016 09:56:12.079854   329 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1016 09:56:12.079859   329 net.cpp:157] Top shape: 4 5 8 24 (3840)
I1016 09:56:12.079859   329 net.cpp:165] Memory required for data: 1159698944
I1016 09:56:12.079862   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1016 09:56:12.079867   329 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1016 09:56:12.079870   329 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1016 09:56:12.079875   329 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1016 09:56:12.079896   329 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1016 09:56:12.079900   329 net.cpp:157] Top shape: 4 960 (3840)
I1016 09:56:12.079902   329 net.cpp:165] Memory required for data: 1159714304
I1016 09:56:12.079905   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1016 09:56:12.079915   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1016 09:56:12.079917   329 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1016 09:56:12.079921   329 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1016 09:56:12.082021   329 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1016 09:56:12.082032   329 net.cpp:157] Top shape: 4 18 5 8 (2880)
I1016 09:56:12.082036   329 net.cpp:165] Memory required for data: 1159725824
I1016 09:56:12.082041   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1016 09:56:12.082047   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1016 09:56:12.082051   329 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1016 09:56:12.082056   329 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1016 09:56:12.082154   329 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1016 09:56:12.082160   329 net.cpp:157] Top shape: 4 5 8 18 (2880)
I1016 09:56:12.082164   329 net.cpp:165] Memory required for data: 1159737344
I1016 09:56:12.082165   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1016 09:56:12.082170   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1016 09:56:12.082172   329 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1016 09:56:12.082178   329 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1016 09:56:12.082202   329 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1016 09:56:12.082206   329 net.cpp:157] Top shape: 4 720 (2880)
I1016 09:56:12.082208   329 net.cpp:165] Memory required for data: 1159748864
I1016 09:56:12.082211   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1016 09:56:12.082216   329 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1016 09:56:12.082219   329 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1016 09:56:12.082223   329 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1016 09:56:12.082227   329 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1016 09:56:12.082252   329 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1016 09:56:12.082257   329 net.cpp:157] Top shape: 1 2 960 (1920)
I1016 09:56:12.082258   329 net.cpp:165] Memory required for data: 1159756544
I1016 09:56:12.082260   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1016 09:56:12.082268   329 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1016 09:56:12.082271   329 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1016 09:56:12.082275   329 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1016 09:56:12.084038   329 net.cpp:150] Setting up conv15_2_mbox_loc
I1016 09:56:12.084049   329 net.cpp:157] Top shape: 4 24 3 4 (1152)
I1016 09:56:12.084051   329 net.cpp:165] Memory required for data: 1159761152
I1016 09:56:12.084058   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1016 09:56:12.084064   329 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1016 09:56:12.084067   329 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1016 09:56:12.084071   329 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1016 09:56:12.084172   329 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1016 09:56:12.084177   329 net.cpp:157] Top shape: 4 3 4 24 (1152)
I1016 09:56:12.084179   329 net.cpp:165] Memory required for data: 1159765760
I1016 09:56:12.084182   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1016 09:56:12.084187   329 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1016 09:56:12.084189   329 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1016 09:56:12.084194   329 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1016 09:56:12.084216   329 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1016 09:56:12.084220   329 net.cpp:157] Top shape: 4 288 (1152)
I1016 09:56:12.084223   329 net.cpp:165] Memory required for data: 1159770368
I1016 09:56:12.084225   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1016 09:56:12.084233   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1016 09:56:12.084236   329 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1016 09:56:12.084241   329 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1016 09:56:12.086068   329 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1016 09:56:12.086084   329 net.cpp:157] Top shape: 4 18 3 4 (864)
I1016 09:56:12.086086   329 net.cpp:165] Memory required for data: 1159773824
I1016 09:56:12.086096   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1016 09:56:12.086103   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1016 09:56:12.086108   329 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1016 09:56:12.086115   329 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1016 09:56:12.086282   329 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1016 09:56:12.086290   329 net.cpp:157] Top shape: 4 3 4 18 (864)
I1016 09:56:12.086292   329 net.cpp:165] Memory required for data: 1159777280
I1016 09:56:12.086295   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1016 09:56:12.086300   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1016 09:56:12.086303   329 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1016 09:56:12.086308   329 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1016 09:56:12.086347   329 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1016 09:56:12.086352   329 net.cpp:157] Top shape: 4 216 (864)
I1016 09:56:12.086354   329 net.cpp:165] Memory required for data: 1159780736
I1016 09:56:12.086356   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1016 09:56:12.086361   329 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1016 09:56:12.086364   329 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1016 09:56:12.086369   329 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1016 09:56:12.086374   329 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1016 09:56:12.086400   329 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1016 09:56:12.086405   329 net.cpp:157] Top shape: 1 2 288 (576)
I1016 09:56:12.086406   329 net.cpp:165] Memory required for data: 1159783040
I1016 09:56:12.086408   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1016 09:56:12.086416   329 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1016 09:56:12.086421   329 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1016 09:56:12.086426   329 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1016 09:56:12.088439   329 net.cpp:150] Setting up conv16_2_mbox_loc
I1016 09:56:12.088451   329 net.cpp:157] Top shape: 4 24 2 2 (384)
I1016 09:56:12.088454   329 net.cpp:165] Memory required for data: 1159784576
I1016 09:56:12.088459   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1016 09:56:12.088465   329 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1016 09:56:12.088469   329 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1016 09:56:12.088475   329 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1016 09:56:12.088575   329 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1016 09:56:12.088580   329 net.cpp:157] Top shape: 4 2 2 24 (384)
I1016 09:56:12.088582   329 net.cpp:165] Memory required for data: 1159786112
I1016 09:56:12.088584   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1016 09:56:12.088590   329 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1016 09:56:12.088593   329 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1016 09:56:12.088596   329 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1016 09:56:12.088619   329 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1016 09:56:12.088624   329 net.cpp:157] Top shape: 4 96 (384)
I1016 09:56:12.088625   329 net.cpp:165] Memory required for data: 1159787648
I1016 09:56:12.088627   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1016 09:56:12.088635   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1016 09:56:12.088639   329 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1016 09:56:12.088644   329 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1016 09:56:12.090417   329 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1016 09:56:12.090430   329 net.cpp:157] Top shape: 4 18 2 2 (288)
I1016 09:56:12.090431   329 net.cpp:165] Memory required for data: 1159788800
I1016 09:56:12.090437   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1016 09:56:12.090443   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1016 09:56:12.090447   329 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1016 09:56:12.090452   329 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1016 09:56:12.090553   329 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1016 09:56:12.090559   329 net.cpp:157] Top shape: 4 2 2 18 (288)
I1016 09:56:12.090560   329 net.cpp:165] Memory required for data: 1159789952
I1016 09:56:12.090564   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1016 09:56:12.090569   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1016 09:56:12.090571   329 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1016 09:56:12.090575   329 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1016 09:56:12.090600   329 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1016 09:56:12.090603   329 net.cpp:157] Top shape: 4 72 (288)
I1016 09:56:12.090605   329 net.cpp:165] Memory required for data: 1159791104
I1016 09:56:12.090607   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1016 09:56:12.090613   329 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1016 09:56:12.090616   329 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1016 09:56:12.090620   329 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1016 09:56:12.090625   329 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1016 09:56:12.090649   329 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1016 09:56:12.090653   329 net.cpp:157] Top shape: 1 2 96 (192)
I1016 09:56:12.090656   329 net.cpp:165] Memory required for data: 1159791872
I1016 09:56:12.090658   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1016 09:56:12.090665   329 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1016 09:56:12.090668   329 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1016 09:56:12.090675   329 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1016 09:56:12.092552   329 net.cpp:150] Setting up conv17_2_mbox_loc
I1016 09:56:12.092564   329 net.cpp:157] Top shape: 4 24 1 1 (96)
I1016 09:56:12.092566   329 net.cpp:165] Memory required for data: 1159792256
I1016 09:56:12.092572   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1016 09:56:12.092579   329 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1016 09:56:12.092582   329 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1016 09:56:12.092587   329 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1016 09:56:12.092689   329 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1016 09:56:12.092694   329 net.cpp:157] Top shape: 4 1 1 24 (96)
I1016 09:56:12.092696   329 net.cpp:165] Memory required for data: 1159792640
I1016 09:56:12.092698   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1016 09:56:12.092705   329 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1016 09:56:12.092708   329 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1016 09:56:12.092712   329 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1016 09:56:12.092736   329 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1016 09:56:12.092741   329 net.cpp:157] Top shape: 4 24 (96)
I1016 09:56:12.092743   329 net.cpp:165] Memory required for data: 1159793024
I1016 09:56:12.092746   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1016 09:56:12.092753   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1016 09:56:12.092756   329 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1016 09:56:12.092762   329 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1016 09:56:12.094512   329 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1016 09:56:12.094525   329 net.cpp:157] Top shape: 4 18 1 1 (72)
I1016 09:56:12.094528   329 net.cpp:165] Memory required for data: 1159793312
I1016 09:56:12.094533   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1016 09:56:12.094539   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1016 09:56:12.094542   329 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1016 09:56:12.094548   329 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1016 09:56:12.094651   329 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1016 09:56:12.094660   329 net.cpp:157] Top shape: 4 1 1 18 (72)
I1016 09:56:12.094662   329 net.cpp:165] Memory required for data: 1159793600
I1016 09:56:12.094666   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1016 09:56:12.094676   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1016 09:56:12.094678   329 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1016 09:56:12.094683   329 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1016 09:56:12.094708   329 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1016 09:56:12.094713   329 net.cpp:157] Top shape: 4 18 (72)
I1016 09:56:12.094715   329 net.cpp:165] Memory required for data: 1159793888
I1016 09:56:12.094717   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1016 09:56:12.094723   329 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1016 09:56:12.094727   329 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1016 09:56:12.094730   329 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1016 09:56:12.094736   329 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1016 09:56:12.094759   329 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1016 09:56:12.094764   329 net.cpp:157] Top shape: 1 2 24 (48)
I1016 09:56:12.094766   329 net.cpp:165] Memory required for data: 1159794080
I1016 09:56:12.094769   329 layer_factory.hpp:77] Creating layer mbox_loc
I1016 09:56:12.094775   329 net.cpp:100] Creating Layer mbox_loc
I1016 09:56:12.094779   329 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1016 09:56:12.094782   329 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1016 09:56:12.094786   329 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1016 09:56:12.094789   329 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1016 09:56:12.094792   329 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1016 09:56:12.094795   329 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1016 09:56:12.094799   329 net.cpp:408] mbox_loc -> mbox_loc
I1016 09:56:12.094825   329 net.cpp:150] Setting up mbox_loc
I1016 09:56:12.094828   329 net.cpp:157] Top shape: 4 12168 (48672)
I1016 09:56:12.094830   329 net.cpp:165] Memory required for data: 1159988768
I1016 09:56:12.094832   329 layer_factory.hpp:77] Creating layer mbox_conf
I1016 09:56:12.094838   329 net.cpp:100] Creating Layer mbox_conf
I1016 09:56:12.094841   329 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1016 09:56:12.094846   329 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1016 09:56:12.094848   329 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1016 09:56:12.094851   329 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1016 09:56:12.094854   329 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1016 09:56:12.094857   329 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1016 09:56:12.094861   329 net.cpp:408] mbox_conf -> mbox_conf
I1016 09:56:12.094882   329 net.cpp:150] Setting up mbox_conf
I1016 09:56:12.094887   329 net.cpp:157] Top shape: 4 9126 (36504)
I1016 09:56:12.094889   329 net.cpp:165] Memory required for data: 1160134784
I1016 09:56:12.094892   329 layer_factory.hpp:77] Creating layer mbox_priorbox
I1016 09:56:12.094895   329 net.cpp:100] Creating Layer mbox_priorbox
I1016 09:56:12.094898   329 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1016 09:56:12.094902   329 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1016 09:56:12.094905   329 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1016 09:56:12.094908   329 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1016 09:56:12.094911   329 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1016 09:56:12.094913   329 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1016 09:56:12.094918   329 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1016 09:56:12.094938   329 net.cpp:150] Setting up mbox_priorbox
I1016 09:56:12.094944   329 net.cpp:157] Top shape: 1 2 12168 (24336)
I1016 09:56:12.094945   329 net.cpp:165] Memory required for data: 1160232128
I1016 09:56:12.094947   329 layer_factory.hpp:77] Creating layer mbox_loss
I1016 09:56:12.094956   329 net.cpp:100] Creating Layer mbox_loss
I1016 09:56:12.094959   329 net.cpp:434] mbox_loss <- mbox_loc
I1016 09:56:12.094961   329 net.cpp:434] mbox_loss <- mbox_conf
I1016 09:56:12.094964   329 net.cpp:434] mbox_loss <- mbox_priorbox
I1016 09:56:12.094967   329 net.cpp:434] mbox_loss <- label
I1016 09:56:12.094971   329 net.cpp:408] mbox_loss -> mbox_loss
I1016 09:56:12.095023   329 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I1016 09:56:12.095108   329 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1016 09:56:12.095118   329 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1016 09:56:12.095962   329 net.cpp:150] Setting up mbox_loss
I1016 09:56:12.095973   329 net.cpp:157] Top shape: (1)
I1016 09:56:12.095975   329 net.cpp:160]     with loss weight 1
I1016 09:56:12.095983   329 net.cpp:165] Memory required for data: 1160232132
I1016 09:56:12.095985   329 layer_factory.hpp:77] Creating layer score_32
I1016 09:56:12.095994   329 net.cpp:100] Creating Layer score_32
I1016 09:56:12.095999   329 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1016 09:56:12.096004   329 net.cpp:408] score_32 -> score_32
I1016 09:56:12.097736   329 net.cpp:150] Setting up score_32
I1016 09:56:12.097748   329 net.cpp:157] Top shape: 4 2 10 15 (1200)
I1016 09:56:12.097750   329 net.cpp:165] Memory required for data: 1160236932
I1016 09:56:12.097756   329 layer_factory.hpp:77] Creating layer upscore_16
I1016 09:56:12.097764   329 net.cpp:100] Creating Layer upscore_16
I1016 09:56:12.097767   329 net.cpp:434] upscore_16 <- score_32
I1016 09:56:12.097771   329 net.cpp:408] upscore_16 -> upscore_16
I1016 09:56:12.097987   329 net.cpp:150] Setting up upscore_16
I1016 09:56:12.097996   329 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1016 09:56:12.097998   329 net.cpp:165] Memory required for data: 1160256132
I1016 09:56:12.098002   329 layer_factory.hpp:77] Creating layer score_16
I1016 09:56:12.098008   329 net.cpp:100] Creating Layer score_16
I1016 09:56:12.098012   329 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1016 09:56:12.098016   329 net.cpp:408] score_16 -> score_16
I1016 09:56:12.099867   329 net.cpp:150] Setting up score_16
I1016 09:56:12.099879   329 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1016 09:56:12.099882   329 net.cpp:165] Memory required for data: 1160275332
I1016 09:56:12.099889   329 layer_factory.hpp:77] Creating layer fuse_16
I1016 09:56:12.099894   329 net.cpp:100] Creating Layer fuse_16
I1016 09:56:12.099896   329 net.cpp:434] fuse_16 <- upscore_16
I1016 09:56:12.099900   329 net.cpp:434] fuse_16 <- score_16
I1016 09:56:12.099906   329 net.cpp:408] fuse_16 -> fuse_16
I1016 09:56:12.099946   329 net.cpp:150] Setting up fuse_16
I1016 09:56:12.099951   329 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1016 09:56:12.099953   329 net.cpp:165] Memory required for data: 1160294532
I1016 09:56:12.099956   329 layer_factory.hpp:77] Creating layer upscore_8
I1016 09:56:12.099963   329 net.cpp:100] Creating Layer upscore_8
I1016 09:56:12.099967   329 net.cpp:434] upscore_8 <- fuse_16
I1016 09:56:12.099975   329 net.cpp:408] upscore_8 -> upscore_8
I1016 09:56:12.100164   329 net.cpp:150] Setting up upscore_8
I1016 09:56:12.100172   329 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1016 09:56:12.100173   329 net.cpp:165] Memory required for data: 1160371332
I1016 09:56:12.100178   329 layer_factory.hpp:77] Creating layer score_8
I1016 09:56:12.100183   329 net.cpp:100] Creating Layer score_8
I1016 09:56:12.100185   329 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1016 09:56:12.100190   329 net.cpp:408] score_8 -> score_8
I1016 09:56:12.103679   329 net.cpp:150] Setting up score_8
I1016 09:56:12.103691   329 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1016 09:56:12.103694   329 net.cpp:165] Memory required for data: 1160448132
I1016 09:56:12.103699   329 layer_factory.hpp:77] Creating layer fuse_8
I1016 09:56:12.103706   329 net.cpp:100] Creating Layer fuse_8
I1016 09:56:12.103709   329 net.cpp:434] fuse_8 <- upscore_8
I1016 09:56:12.103713   329 net.cpp:434] fuse_8 <- score_8
I1016 09:56:12.103716   329 net.cpp:408] fuse_8 -> fuse_8
I1016 09:56:12.103745   329 net.cpp:150] Setting up fuse_8
I1016 09:56:12.103750   329 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1016 09:56:12.103752   329 net.cpp:165] Memory required for data: 1160524932
I1016 09:56:12.103755   329 layer_factory.hpp:77] Creating layer upscore_4
I1016 09:56:12.103761   329 net.cpp:100] Creating Layer upscore_4
I1016 09:56:12.103763   329 net.cpp:434] upscore_4 <- fuse_8
I1016 09:56:12.103768   329 net.cpp:408] upscore_4 -> upscore_4
I1016 09:56:12.103969   329 net.cpp:150] Setting up upscore_4
I1016 09:56:12.103976   329 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1016 09:56:12.103978   329 net.cpp:165] Memory required for data: 1160832132
I1016 09:56:12.103982   329 layer_factory.hpp:77] Creating layer score_4
I1016 09:56:12.103987   329 net.cpp:100] Creating Layer score_4
I1016 09:56:12.103991   329 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1016 09:56:12.103994   329 net.cpp:408] score_4 -> score_4
I1016 09:56:12.105916   329 net.cpp:150] Setting up score_4
I1016 09:56:12.105928   329 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1016 09:56:12.105931   329 net.cpp:165] Memory required for data: 1161139332
I1016 09:56:12.105937   329 layer_factory.hpp:77] Creating layer fuse_4
I1016 09:56:12.105942   329 net.cpp:100] Creating Layer fuse_4
I1016 09:56:12.105944   329 net.cpp:434] fuse_4 <- upscore_4
I1016 09:56:12.105947   329 net.cpp:434] fuse_4 <- score_4
I1016 09:56:12.105952   329 net.cpp:408] fuse_4 -> fuse_4
I1016 09:56:12.105980   329 net.cpp:150] Setting up fuse_4
I1016 09:56:12.105985   329 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1016 09:56:12.105988   329 net.cpp:165] Memory required for data: 1161446532
I1016 09:56:12.105989   329 layer_factory.hpp:77] Creating layer upscore
I1016 09:56:12.105996   329 net.cpp:100] Creating Layer upscore
I1016 09:56:12.105999   329 net.cpp:434] upscore <- fuse_4
I1016 09:56:12.106004   329 net.cpp:408] upscore -> upscore
I1016 09:56:12.106187   329 net.cpp:150] Setting up upscore
I1016 09:56:12.106194   329 net.cpp:157] Top shape: 4 2 331 491 (1300168)
I1016 09:56:12.106196   329 net.cpp:165] Memory required for data: 1166647204
I1016 09:56:12.106200   329 layer_factory.hpp:77] Creating layer score
I1016 09:56:12.106207   329 net.cpp:100] Creating Layer score
I1016 09:56:12.106209   329 net.cpp:434] score <- upscore
I1016 09:56:12.106212   329 net.cpp:434] score <- data_data_0_split_7
I1016 09:56:12.106216   329 net.cpp:408] score -> score
I1016 09:56:12.106240   329 net.cpp:150] Setting up score
I1016 09:56:12.106245   329 net.cpp:157] Top shape: 4 2 320 480 (1228800)
I1016 09:56:12.106246   329 net.cpp:165] Memory required for data: 1171562404
I1016 09:56:12.106250   329 layer_factory.hpp:77] Creating layer seg_loss
I1016 09:56:12.106256   329 net.cpp:100] Creating Layer seg_loss
I1016 09:56:12.106257   329 net.cpp:434] seg_loss <- score
I1016 09:56:12.106261   329 net.cpp:434] seg_loss <- label_seg
I1016 09:56:12.106264   329 net.cpp:408] seg_loss -> seg_loss
I1016 09:56:12.106271   329 layer_factory.hpp:77] Creating layer seg_loss
I1016 09:56:12.108772   329 net.cpp:150] Setting up seg_loss
I1016 09:56:12.108783   329 net.cpp:157] Top shape: (1)
I1016 09:56:12.108786   329 net.cpp:160]     with loss weight 1
I1016 09:56:12.108793   329 net.cpp:165] Memory required for data: 1171562408
I1016 09:56:12.108796   329 net.cpp:226] seg_loss needs backward computation.
I1016 09:56:12.108799   329 net.cpp:226] score needs backward computation.
I1016 09:56:12.108803   329 net.cpp:226] upscore needs backward computation.
I1016 09:56:12.108805   329 net.cpp:226] fuse_4 needs backward computation.
I1016 09:56:12.108808   329 net.cpp:226] score_4 needs backward computation.
I1016 09:56:12.108809   329 net.cpp:226] upscore_4 needs backward computation.
I1016 09:56:12.108813   329 net.cpp:226] fuse_8 needs backward computation.
I1016 09:56:12.108814   329 net.cpp:226] score_8 needs backward computation.
I1016 09:56:12.108817   329 net.cpp:226] upscore_8 needs backward computation.
I1016 09:56:12.108819   329 net.cpp:226] fuse_16 needs backward computation.
I1016 09:56:12.108822   329 net.cpp:226] score_16 needs backward computation.
I1016 09:56:12.108824   329 net.cpp:226] upscore_16 needs backward computation.
I1016 09:56:12.108827   329 net.cpp:226] score_32 needs backward computation.
I1016 09:56:12.108829   329 net.cpp:226] mbox_loss needs backward computation.
I1016 09:56:12.108834   329 net.cpp:228] mbox_priorbox does not need backward computation.
I1016 09:56:12.108839   329 net.cpp:226] mbox_conf needs backward computation.
I1016 09:56:12.108845   329 net.cpp:226] mbox_loc needs backward computation.
I1016 09:56:12.108850   329 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.108853   329 net.cpp:226] conv17_2_mbox_conf_flat needs backward computation.
I1016 09:56:12.108856   329 net.cpp:226] conv17_2_mbox_conf_perm needs backward computation.
I1016 09:56:12.108860   329 net.cpp:226] conv17_2_mbox_conf_new needs backward computation.
I1016 09:56:12.108862   329 net.cpp:226] conv17_2_mbox_loc_flat needs backward computation.
I1016 09:56:12.108865   329 net.cpp:226] conv17_2_mbox_loc_perm needs backward computation.
I1016 09:56:12.108868   329 net.cpp:226] conv17_2_mbox_loc needs backward computation.
I1016 09:56:12.108870   329 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.108875   329 net.cpp:226] conv16_2_mbox_conf_flat needs backward computation.
I1016 09:56:12.108878   329 net.cpp:226] conv16_2_mbox_conf_perm needs backward computation.
I1016 09:56:12.108881   329 net.cpp:226] conv16_2_mbox_conf_new needs backward computation.
I1016 09:56:12.108884   329 net.cpp:226] conv16_2_mbox_loc_flat needs backward computation.
I1016 09:56:12.108886   329 net.cpp:226] conv16_2_mbox_loc_perm needs backward computation.
I1016 09:56:12.108889   329 net.cpp:226] conv16_2_mbox_loc needs backward computation.
I1016 09:56:12.108892   329 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.108896   329 net.cpp:226] conv15_2_mbox_conf_flat needs backward computation.
I1016 09:56:12.108898   329 net.cpp:226] conv15_2_mbox_conf_perm needs backward computation.
I1016 09:56:12.108901   329 net.cpp:226] conv15_2_mbox_conf_new needs backward computation.
I1016 09:56:12.108904   329 net.cpp:226] conv15_2_mbox_loc_flat needs backward computation.
I1016 09:56:12.108907   329 net.cpp:226] conv15_2_mbox_loc_perm needs backward computation.
I1016 09:56:12.108911   329 net.cpp:226] conv15_2_mbox_loc needs backward computation.
I1016 09:56:12.108914   329 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.108917   329 net.cpp:226] conv14_2_mbox_conf_flat needs backward computation.
I1016 09:56:12.108920   329 net.cpp:226] conv14_2_mbox_conf_perm needs backward computation.
I1016 09:56:12.108923   329 net.cpp:226] conv14_2_mbox_conf_new needs backward computation.
I1016 09:56:12.108927   329 net.cpp:226] conv14_2_mbox_loc_flat needs backward computation.
I1016 09:56:12.108929   329 net.cpp:226] conv14_2_mbox_loc_perm needs backward computation.
I1016 09:56:12.108932   329 net.cpp:226] conv14_2_mbox_loc needs backward computation.
I1016 09:56:12.108934   329 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1016 09:56:12.108938   329 net.cpp:226] conv13_mbox_conf_flat needs backward computation.
I1016 09:56:12.108940   329 net.cpp:226] conv13_mbox_conf_perm needs backward computation.
I1016 09:56:12.108943   329 net.cpp:226] conv13_mbox_conf_new needs backward computation.
I1016 09:56:12.108947   329 net.cpp:226] conv13_mbox_loc_flat needs backward computation.
I1016 09:56:12.108950   329 net.cpp:226] conv13_mbox_loc_perm needs backward computation.
I1016 09:56:12.108953   329 net.cpp:226] conv13_mbox_loc needs backward computation.
I1016 09:56:12.108956   329 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1016 09:56:12.108959   329 net.cpp:226] conv11_mbox_conf_flat needs backward computation.
I1016 09:56:12.108963   329 net.cpp:226] conv11_mbox_conf_perm needs backward computation.
I1016 09:56:12.108964   329 net.cpp:226] conv11_mbox_conf_new needs backward computation.
I1016 09:56:12.108968   329 net.cpp:226] conv11_mbox_loc_flat needs backward computation.
I1016 09:56:12.108969   329 net.cpp:226] conv11_mbox_loc_perm needs backward computation.
I1016 09:56:12.108973   329 net.cpp:226] conv11_mbox_loc needs backward computation.
I1016 09:56:12.108975   329 net.cpp:226] conv17_2_conv17_2/relu_0_split needs backward computation.
I1016 09:56:12.108978   329 net.cpp:226] conv17_2/relu needs backward computation.
I1016 09:56:12.108980   329 net.cpp:226] conv17_2/scale needs backward computation.
I1016 09:56:12.108983   329 net.cpp:226] conv17_2/bn needs backward computation.
I1016 09:56:12.108985   329 net.cpp:226] conv17_2 needs backward computation.
I1016 09:56:12.108989   329 net.cpp:226] conv17_1/relu needs backward computation.
I1016 09:56:12.108990   329 net.cpp:226] conv17_1/scale needs backward computation.
I1016 09:56:12.108992   329 net.cpp:226] conv17_1/bn needs backward computation.
I1016 09:56:12.108994   329 net.cpp:226] conv17_1 needs backward computation.
I1016 09:56:12.108997   329 net.cpp:226] conv16_2_conv16_2/relu_0_split needs backward computation.
I1016 09:56:12.109000   329 net.cpp:226] conv16_2/relu needs backward computation.
I1016 09:56:12.109004   329 net.cpp:226] conv16_2/scale needs backward computation.
I1016 09:56:12.109006   329 net.cpp:226] conv16_2/bn needs backward computation.
I1016 09:56:12.109009   329 net.cpp:226] conv16_2 needs backward computation.
I1016 09:56:12.109010   329 net.cpp:226] conv16_1/relu needs backward computation.
I1016 09:56:12.109014   329 net.cpp:226] conv16_1/scale needs backward computation.
I1016 09:56:12.109015   329 net.cpp:226] conv16_1/bn needs backward computation.
I1016 09:56:12.109017   329 net.cpp:226] conv16_1 needs backward computation.
I1016 09:56:12.109020   329 net.cpp:226] conv15_2_conv15_2/relu_0_split needs backward computation.
I1016 09:56:12.109024   329 net.cpp:226] conv15_2/relu needs backward computation.
I1016 09:56:12.109025   329 net.cpp:226] conv15_2/scale needs backward computation.
I1016 09:56:12.109027   329 net.cpp:226] conv15_2/bn needs backward computation.
I1016 09:56:12.109030   329 net.cpp:226] conv15_2 needs backward computation.
I1016 09:56:12.109032   329 net.cpp:226] conv15_1/relu needs backward computation.
I1016 09:56:12.109035   329 net.cpp:226] conv15_1/scale needs backward computation.
I1016 09:56:12.109037   329 net.cpp:226] conv15_1/bn needs backward computation.
I1016 09:56:12.109040   329 net.cpp:226] conv15_1 needs backward computation.
I1016 09:56:12.109042   329 net.cpp:226] conv14_2_conv14_2/relu_0_split needs backward computation.
I1016 09:56:12.109045   329 net.cpp:226] conv14_2/relu needs backward computation.
I1016 09:56:12.109048   329 net.cpp:226] conv14_2/scale needs backward computation.
I1016 09:56:12.109050   329 net.cpp:226] conv14_2/bn needs backward computation.
I1016 09:56:12.109052   329 net.cpp:226] conv14_2 needs backward computation.
I1016 09:56:12.109055   329 net.cpp:226] conv14_1/relu needs backward computation.
I1016 09:56:12.109057   329 net.cpp:226] conv14_1/scale needs backward computation.
I1016 09:56:12.109060   329 net.cpp:226] conv14_1/bn needs backward computation.
I1016 09:56:12.109062   329 net.cpp:226] conv14_1 needs backward computation.
I1016 09:56:12.109064   329 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1016 09:56:12.109067   329 net.cpp:226] conv13/relu needs backward computation.
I1016 09:56:12.109071   329 net.cpp:226] conv13/scale needs backward computation.
I1016 09:56:12.109072   329 net.cpp:226] conv13/bn needs backward computation.
I1016 09:56:12.109074   329 net.cpp:226] conv13 needs backward computation.
I1016 09:56:12.109077   329 net.cpp:226] conv13/dw/relu needs backward computation.
I1016 09:56:12.109081   329 net.cpp:226] conv13/dw/scale needs backward computation.
I1016 09:56:12.109083   329 net.cpp:226] conv13/dw/bn needs backward computation.
I1016 09:56:12.109086   329 net.cpp:226] conv13/dw needs backward computation.
I1016 09:56:12.109087   329 net.cpp:226] conv12/relu needs backward computation.
I1016 09:56:12.109091   329 net.cpp:226] conv12/scale needs backward computation.
I1016 09:56:12.109092   329 net.cpp:226] conv12/bn needs backward computation.
I1016 09:56:12.109094   329 net.cpp:226] conv12 needs backward computation.
I1016 09:56:12.109097   329 net.cpp:226] conv12/dw/relu needs backward computation.
I1016 09:56:12.109099   329 net.cpp:226] conv12/dw/scale needs backward computation.
I1016 09:56:12.109102   329 net.cpp:226] conv12/dw/bn needs backward computation.
I1016 09:56:12.109104   329 net.cpp:226] conv12/dw needs backward computation.
I1016 09:56:12.109107   329 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1016 09:56:12.109109   329 net.cpp:226] conv11/relu needs backward computation.
I1016 09:56:12.109112   329 net.cpp:226] conv11/scale needs backward computation.
I1016 09:56:12.109114   329 net.cpp:226] conv11/bn needs backward computation.
I1016 09:56:12.109117   329 net.cpp:226] conv11 needs backward computation.
I1016 09:56:12.109119   329 net.cpp:226] conv11/dw/relu needs backward computation.
I1016 09:56:12.109122   329 net.cpp:226] conv11/dw/scale needs backward computation.
I1016 09:56:12.109123   329 net.cpp:226] conv11/dw/bn needs backward computation.
I1016 09:56:12.109125   329 net.cpp:226] conv11/dw needs backward computation.
I1016 09:56:12.109128   329 net.cpp:226] conv10/relu needs backward computation.
I1016 09:56:12.109130   329 net.cpp:226] conv10/scale needs backward computation.
I1016 09:56:12.109133   329 net.cpp:226] conv10/bn needs backward computation.
I1016 09:56:12.109135   329 net.cpp:226] conv10 needs backward computation.
I1016 09:56:12.109138   329 net.cpp:226] conv10/dw/relu needs backward computation.
I1016 09:56:12.109140   329 net.cpp:226] conv10/dw/scale needs backward computation.
I1016 09:56:12.109143   329 net.cpp:226] conv10/dw/bn needs backward computation.
I1016 09:56:12.109144   329 net.cpp:226] conv10/dw needs backward computation.
I1016 09:56:12.109148   329 net.cpp:226] conv9/relu needs backward computation.
I1016 09:56:12.109150   329 net.cpp:226] conv9/scale needs backward computation.
I1016 09:56:12.109153   329 net.cpp:226] conv9/bn needs backward computation.
I1016 09:56:12.109154   329 net.cpp:226] conv9 needs backward computation.
I1016 09:56:12.109158   329 net.cpp:226] conv9/dw/relu needs backward computation.
I1016 09:56:12.109159   329 net.cpp:226] conv9/dw/scale needs backward computation.
I1016 09:56:12.109163   329 net.cpp:226] conv9/dw/bn needs backward computation.
I1016 09:56:12.109164   329 net.cpp:226] conv9/dw needs backward computation.
I1016 09:56:12.109167   329 net.cpp:226] conv8/relu needs backward computation.
I1016 09:56:12.109169   329 net.cpp:226] conv8/scale needs backward computation.
I1016 09:56:12.109172   329 net.cpp:226] conv8/bn needs backward computation.
I1016 09:56:12.109174   329 net.cpp:226] conv8 needs backward computation.
I1016 09:56:12.109176   329 net.cpp:226] conv8/dw/relu needs backward computation.
I1016 09:56:12.109179   329 net.cpp:226] conv8/dw/scale needs backward computation.
I1016 09:56:12.109181   329 net.cpp:226] conv8/dw/bn needs backward computation.
I1016 09:56:12.109184   329 net.cpp:226] conv8/dw needs backward computation.
I1016 09:56:12.109186   329 net.cpp:226] conv7/relu needs backward computation.
I1016 09:56:12.109189   329 net.cpp:226] conv7/scale needs backward computation.
I1016 09:56:12.109190   329 net.cpp:226] conv7/bn needs backward computation.
I1016 09:56:12.109194   329 net.cpp:226] conv7 needs backward computation.
I1016 09:56:12.109195   329 net.cpp:226] conv7/dw/relu needs backward computation.
I1016 09:56:12.109199   329 net.cpp:226] conv7/dw/scale needs backward computation.
I1016 09:56:12.109200   329 net.cpp:226] conv7/dw/bn needs backward computation.
I1016 09:56:12.109202   329 net.cpp:226] conv7/dw needs backward computation.
I1016 09:56:12.109205   329 net.cpp:226] conv6/relu needs backward computation.
I1016 09:56:12.109208   329 net.cpp:226] conv6/scale needs backward computation.
I1016 09:56:12.109210   329 net.cpp:226] conv6/bn needs backward computation.
I1016 09:56:12.109212   329 net.cpp:226] conv6 needs backward computation.
I1016 09:56:12.109215   329 net.cpp:226] conv6/dw/relu needs backward computation.
I1016 09:56:12.109217   329 net.cpp:226] conv6/dw/scale needs backward computation.
I1016 09:56:12.109220   329 net.cpp:226] conv6/dw/bn needs backward computation.
I1016 09:56:12.109222   329 net.cpp:226] conv6/dw needs backward computation.
I1016 09:56:12.109225   329 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1016 09:56:12.109228   329 net.cpp:226] conv5/relu needs backward computation.
I1016 09:56:12.109231   329 net.cpp:226] conv5/scale needs backward computation.
I1016 09:56:12.109233   329 net.cpp:226] conv5/bn needs backward computation.
I1016 09:56:12.109236   329 net.cpp:226] conv5 needs backward computation.
I1016 09:56:12.109238   329 net.cpp:226] conv5/dw/relu needs backward computation.
I1016 09:56:12.109241   329 net.cpp:226] conv5/dw/scale needs backward computation.
I1016 09:56:12.109243   329 net.cpp:226] conv5/dw/bn needs backward computation.
I1016 09:56:12.109246   329 net.cpp:226] conv5/dw needs backward computation.
I1016 09:56:12.109248   329 net.cpp:226] conv4/relu needs backward computation.
I1016 09:56:12.109251   329 net.cpp:226] conv4/scale needs backward computation.
I1016 09:56:12.109252   329 net.cpp:226] conv4/bn needs backward computation.
I1016 09:56:12.109256   329 net.cpp:226] conv4 needs backward computation.
I1016 09:56:12.109258   329 net.cpp:226] conv4/dw/relu needs backward computation.
I1016 09:56:12.109261   329 net.cpp:226] conv4/dw/scale needs backward computation.
I1016 09:56:12.109262   329 net.cpp:226] conv4/dw/bn needs backward computation.
I1016 09:56:12.109264   329 net.cpp:226] conv4/dw needs backward computation.
I1016 09:56:12.109267   329 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1016 09:56:12.109271   329 net.cpp:226] conv3/relu needs backward computation.
I1016 09:56:12.109272   329 net.cpp:226] conv3/scale needs backward computation.
I1016 09:56:12.109274   329 net.cpp:226] conv3/bn needs backward computation.
I1016 09:56:12.109277   329 net.cpp:226] conv3 needs backward computation.
I1016 09:56:12.109279   329 net.cpp:226] conv3/dw/relu needs backward computation.
I1016 09:56:12.109282   329 net.cpp:226] conv3/dw/scale needs backward computation.
I1016 09:56:12.109284   329 net.cpp:226] conv3/dw/bn needs backward computation.
I1016 09:56:12.109287   329 net.cpp:226] conv3/dw needs backward computation.
I1016 09:56:12.109289   329 net.cpp:226] conv2/relu needs backward computation.
I1016 09:56:12.109292   329 net.cpp:226] conv2/scale needs backward computation.
I1016 09:56:12.109294   329 net.cpp:226] conv2/bn needs backward computation.
I1016 09:56:12.109297   329 net.cpp:226] conv2 needs backward computation.
I1016 09:56:12.109299   329 net.cpp:226] conv2/dw/relu needs backward computation.
I1016 09:56:12.109302   329 net.cpp:226] conv2/dw/scale needs backward computation.
I1016 09:56:12.109303   329 net.cpp:226] conv2/dw/bn needs backward computation.
I1016 09:56:12.109306   329 net.cpp:226] conv2/dw needs backward computation.
I1016 09:56:12.109308   329 net.cpp:226] conv1/relu needs backward computation.
I1016 09:56:12.109311   329 net.cpp:226] conv1/scale needs backward computation.
I1016 09:56:12.109313   329 net.cpp:226] conv1/bn needs backward computation.
I1016 09:56:12.109316   329 net.cpp:226] conv1 needs backward computation.
I1016 09:56:12.109318   329 net.cpp:226] conv1/dw/relu needs backward computation.
I1016 09:56:12.109320   329 net.cpp:226] conv1/dw/scale needs backward computation.
I1016 09:56:12.109323   329 net.cpp:226] conv1/dw/bn needs backward computation.
I1016 09:56:12.109325   329 net.cpp:226] conv1/dw needs backward computation.
I1016 09:56:12.109328   329 net.cpp:226] conv0/relu needs backward computation.
I1016 09:56:12.109330   329 net.cpp:226] conv0/scale needs backward computation.
I1016 09:56:12.109333   329 net.cpp:226] conv0/bn needs backward computation.
I1016 09:56:12.109335   329 net.cpp:226] conv0 needs backward computation.
I1016 09:56:12.109339   329 net.cpp:228] data_data_0_split does not need backward computation.
I1016 09:56:12.109342   329 net.cpp:228] data does not need backward computation.
I1016 09:56:12.109345   329 net.cpp:270] This network produces output mbox_loss
I1016 09:56:12.109349   329 net.cpp:270] This network produces output seg_loss
I1016 09:56:12.109438   329 net.cpp:283] Network initialization done.
I1016 09:56:12.110914   329 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_test.prototxt
I1016 09:56:12.110927   329 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 09:56:12.110932   329 solver.cpp:196] Creating test net (#0) specified by test_net file: proto/union/MobileNetSSD_test.prototxt
I1016 09:56:12.111817   329 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_conf_perm"
  type: "Permute"
  bottom: "conv13_mbox_conf"
  top: "conv13_mbox_conf_perm"
  permute_param {
    
I1016 09:56:12.112299   329 layer_factory.hpp:77] Creating layer data
I1016 09:56:12.112354   329 net.cpp:100] Creating Layer data
I1016 09:56:12.112361   329 net.cpp:408] data -> data
I1016 09:56:12.112370   329 net.cpp:408] data -> label
I1016 09:56:12.112375   329 net.cpp:408] data -> label_seg
I1016 09:56:12.112381   329 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1016 09:56:12.138903   381 db_lmdb.cpp:35] Opened lmdb lmdb/seg_test_lmdb
I1016 09:56:12.234846   329 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 1,3,320,480
I1016 09:56:12.240948   329 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1016 09:56:12.241006   329 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1016 09:56:12.241011   329 net.cpp:150] Setting up data
I1016 09:56:12.241019   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241024   329 net.cpp:157] Top shape: 1 1 2 8 (16)
I1016 09:56:12.241029   329 net.cpp:157] Top shape: 1 1 320 480 (153600)
I1016 09:56:12.241034   329 net.cpp:165] Memory required for data: 2457664
I1016 09:56:12.241041   329 layer_factory.hpp:77] Creating layer data_data_0_split
I1016 09:56:12.241071   329 net.cpp:100] Creating Layer data_data_0_split
I1016 09:56:12.241078   329 net.cpp:434] data_data_0_split <- data
I1016 09:56:12.241092   329 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1016 09:56:12.241102   329 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1016 09:56:12.241108   329 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1016 09:56:12.241113   329 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1016 09:56:12.241117   329 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1016 09:56:12.241124   329 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1016 09:56:12.241133   329 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1016 09:56:12.241140   329 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1016 09:56:12.241308   329 net.cpp:150] Setting up data_data_0_split
I1016 09:56:12.241317   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241322   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241324   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241328   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241330   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241334   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241339   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241343   329 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1016 09:56:12.241348   329 net.cpp:165] Memory required for data: 17203264
I1016 09:56:12.241351   329 layer_factory.hpp:77] Creating layer conv0
I1016 09:56:12.241365   329 net.cpp:100] Creating Layer conv0
I1016 09:56:12.241371   329 net.cpp:434] conv0 <- data_data_0_split_0
I1016 09:56:12.241381   329 net.cpp:408] conv0 -> conv0
I1016 09:56:12.243232   384 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1016 09:56:12.243618   329 net.cpp:150] Setting up conv0
I1016 09:56:12.243629   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.243633   329 net.cpp:165] Memory required for data: 22118464
I1016 09:56:12.243639   329 layer_factory.hpp:77] Creating layer conv0/bn
I1016 09:56:12.243647   329 net.cpp:100] Creating Layer conv0/bn
I1016 09:56:12.243652   329 net.cpp:434] conv0/bn <- conv0
I1016 09:56:12.243659   329 net.cpp:395] conv0/bn -> conv0 (in-place)
I1016 09:56:12.243922   329 net.cpp:150] Setting up conv0/bn
I1016 09:56:12.243932   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.243934   329 net.cpp:165] Memory required for data: 27033664
I1016 09:56:12.243944   329 layer_factory.hpp:77] Creating layer conv0/scale
I1016 09:56:12.243952   329 net.cpp:100] Creating Layer conv0/scale
I1016 09:56:12.243955   329 net.cpp:434] conv0/scale <- conv0
I1016 09:56:12.243959   329 net.cpp:395] conv0/scale -> conv0 (in-place)
I1016 09:56:12.244006   329 layer_factory.hpp:77] Creating layer conv0/scale
I1016 09:56:12.244181   329 net.cpp:150] Setting up conv0/scale
I1016 09:56:12.244189   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.244191   329 net.cpp:165] Memory required for data: 31948864
I1016 09:56:12.244196   329 layer_factory.hpp:77] Creating layer conv0/relu
I1016 09:56:12.244201   329 net.cpp:100] Creating Layer conv0/relu
I1016 09:56:12.244204   329 net.cpp:434] conv0/relu <- conv0
I1016 09:56:12.244208   329 net.cpp:395] conv0/relu -> conv0 (in-place)
I1016 09:56:12.244547   329 net.cpp:150] Setting up conv0/relu
I1016 09:56:12.244558   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.244562   329 net.cpp:165] Memory required for data: 36864064
I1016 09:56:12.244566   329 layer_factory.hpp:77] Creating layer conv1/dw
I1016 09:56:12.244576   329 net.cpp:100] Creating Layer conv1/dw
I1016 09:56:12.244580   329 net.cpp:434] conv1/dw <- conv0
I1016 09:56:12.244586   329 net.cpp:408] conv1/dw -> conv1/dw
I1016 09:56:12.244807   329 net.cpp:150] Setting up conv1/dw
I1016 09:56:12.244814   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.244818   329 net.cpp:165] Memory required for data: 41779264
I1016 09:56:12.244824   329 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1016 09:56:12.244829   329 net.cpp:100] Creating Layer conv1/dw/bn
I1016 09:56:12.244833   329 net.cpp:434] conv1/dw/bn <- conv1/dw
I1016 09:56:12.244838   329 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1016 09:56:12.245062   329 net.cpp:150] Setting up conv1/dw/bn
I1016 09:56:12.245071   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.245075   329 net.cpp:165] Memory required for data: 46694464
I1016 09:56:12.245085   329 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1016 09:56:12.245093   329 net.cpp:100] Creating Layer conv1/dw/scale
I1016 09:56:12.245096   329 net.cpp:434] conv1/dw/scale <- conv1/dw
I1016 09:56:12.245100   329 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1016 09:56:12.245149   329 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1016 09:56:12.245321   329 net.cpp:150] Setting up conv1/dw/scale
I1016 09:56:12.245328   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.245332   329 net.cpp:165] Memory required for data: 51609664
I1016 09:56:12.245338   329 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1016 09:56:12.245343   329 net.cpp:100] Creating Layer conv1/dw/relu
I1016 09:56:12.245347   329 net.cpp:434] conv1/dw/relu <- conv1/dw
I1016 09:56:12.245352   329 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1016 09:56:12.245684   329 net.cpp:150] Setting up conv1/dw/relu
I1016 09:56:12.245694   329 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1016 09:56:12.245698   329 net.cpp:165] Memory required for data: 56524864
I1016 09:56:12.245702   329 layer_factory.hpp:77] Creating layer conv1
I1016 09:56:12.245712   329 net.cpp:100] Creating Layer conv1
I1016 09:56:12.245714   329 net.cpp:434] conv1 <- conv1/dw
I1016 09:56:12.245718   329 net.cpp:408] conv1 -> conv1
I1016 09:56:12.247324   329 net.cpp:150] Setting up conv1
I1016 09:56:12.247337   329 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1016 09:56:12.247341   329 net.cpp:165] Memory required for data: 66355264
I1016 09:56:12.247349   329 layer_factory.hpp:77] Creating layer conv1/bn
I1016 09:56:12.247355   329 net.cpp:100] Creating Layer conv1/bn
I1016 09:56:12.247357   329 net.cpp:434] conv1/bn <- conv1
I1016 09:56:12.247362   329 net.cpp:395] conv1/bn -> conv1 (in-place)
I1016 09:56:12.247601   329 net.cpp:150] Setting up conv1/bn
I1016 09:56:12.247609   329 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1016 09:56:12.247612   329 net.cpp:165] Memory required for data: 76185664
I1016 09:56:12.247620   329 layer_factory.hpp:77] Creating layer conv1/scale
I1016 09:56:12.247627   329 net.cpp:100] Creating Layer conv1/scale
I1016 09:56:12.247630   329 net.cpp:434] conv1/scale <- conv1
I1016 09:56:12.247635   329 net.cpp:395] conv1/scale -> conv1 (in-place)
I1016 09:56:12.247683   329 layer_factory.hpp:77] Creating layer conv1/scale
I1016 09:56:12.247859   329 net.cpp:150] Setting up conv1/scale
I1016 09:56:12.247867   329 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1016 09:56:12.247870   329 net.cpp:165] Memory required for data: 86016064
I1016 09:56:12.247879   329 layer_factory.hpp:77] Creating layer conv1/relu
I1016 09:56:12.247886   329 net.cpp:100] Creating Layer conv1/relu
I1016 09:56:12.247889   329 net.cpp:434] conv1/relu <- conv1
I1016 09:56:12.247895   329 net.cpp:395] conv1/relu -> conv1 (in-place)
I1016 09:56:12.248555   329 net.cpp:150] Setting up conv1/relu
I1016 09:56:12.248569   329 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1016 09:56:12.248572   329 net.cpp:165] Memory required for data: 95846464
I1016 09:56:12.248576   329 layer_factory.hpp:77] Creating layer conv2/dw
I1016 09:56:12.248585   329 net.cpp:100] Creating Layer conv2/dw
I1016 09:56:12.248589   329 net.cpp:434] conv2/dw <- conv1
I1016 09:56:12.248595   329 net.cpp:408] conv2/dw -> conv2/dw
I1016 09:56:12.248821   329 net.cpp:150] Setting up conv2/dw
I1016 09:56:12.248831   329 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1016 09:56:12.248834   329 net.cpp:165] Memory required for data: 98304064
I1016 09:56:12.248841   329 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1016 09:56:12.248844   329 net.cpp:100] Creating Layer conv2/dw/bn
I1016 09:56:12.248847   329 net.cpp:434] conv2/dw/bn <- conv2/dw
I1016 09:56:12.248853   329 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1016 09:56:12.249066   329 net.cpp:150] Setting up conv2/dw/bn
I1016 09:56:12.249074   329 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1016 09:56:12.249078   329 net.cpp:165] Memory required for data: 100761664
I1016 09:56:12.249085   329 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1016 09:56:12.249094   329 net.cpp:100] Creating Layer conv2/dw/scale
I1016 09:56:12.249097   329 net.cpp:434] conv2/dw/scale <- conv2/dw
I1016 09:56:12.249101   329 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1016 09:56:12.249150   329 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1016 09:56:12.249285   329 net.cpp:150] Setting up conv2/dw/scale
I1016 09:56:12.249294   329 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1016 09:56:12.249296   329 net.cpp:165] Memory required for data: 103219264
I1016 09:56:12.249303   329 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1016 09:56:12.249308   329 net.cpp:100] Creating Layer conv2/dw/relu
I1016 09:56:12.249311   329 net.cpp:434] conv2/dw/relu <- conv2/dw
I1016 09:56:12.249316   329 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1016 09:56:12.249649   329 net.cpp:150] Setting up conv2/dw/relu
I1016 09:56:12.249658   329 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1016 09:56:12.249662   329 net.cpp:165] Memory required for data: 105676864
I1016 09:56:12.249666   329 layer_factory.hpp:77] Creating layer conv2
I1016 09:56:12.249675   329 net.cpp:100] Creating Layer conv2
I1016 09:56:12.249677   329 net.cpp:434] conv2 <- conv2/dw
I1016 09:56:12.249683   329 net.cpp:408] conv2 -> conv2
I1016 09:56:12.251313   329 net.cpp:150] Setting up conv2
I1016 09:56:12.251332   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.251335   329 net.cpp:165] Memory required for data: 110592064
I1016 09:56:12.251343   329 layer_factory.hpp:77] Creating layer conv2/bn
I1016 09:56:12.251348   329 net.cpp:100] Creating Layer conv2/bn
I1016 09:56:12.251351   329 net.cpp:434] conv2/bn <- conv2
I1016 09:56:12.251355   329 net.cpp:395] conv2/bn -> conv2 (in-place)
I1016 09:56:12.251566   329 net.cpp:150] Setting up conv2/bn
I1016 09:56:12.251574   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.251579   329 net.cpp:165] Memory required for data: 115507264
I1016 09:56:12.251585   329 layer_factory.hpp:77] Creating layer conv2/scale
I1016 09:56:12.251591   329 net.cpp:100] Creating Layer conv2/scale
I1016 09:56:12.251595   329 net.cpp:434] conv2/scale <- conv2
I1016 09:56:12.251600   329 net.cpp:395] conv2/scale -> conv2 (in-place)
I1016 09:56:12.251648   329 layer_factory.hpp:77] Creating layer conv2/scale
I1016 09:56:12.251780   329 net.cpp:150] Setting up conv2/scale
I1016 09:56:12.251791   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.251794   329 net.cpp:165] Memory required for data: 120422464
I1016 09:56:12.251801   329 layer_factory.hpp:77] Creating layer conv2/relu
I1016 09:56:12.251804   329 net.cpp:100] Creating Layer conv2/relu
I1016 09:56:12.251808   329 net.cpp:434] conv2/relu <- conv2
I1016 09:56:12.251813   329 net.cpp:395] conv2/relu -> conv2 (in-place)
I1016 09:56:12.252148   329 net.cpp:150] Setting up conv2/relu
I1016 09:56:12.252158   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.252162   329 net.cpp:165] Memory required for data: 125337664
I1016 09:56:12.252166   329 layer_factory.hpp:77] Creating layer conv3/dw
I1016 09:56:12.252173   329 net.cpp:100] Creating Layer conv3/dw
I1016 09:56:12.252177   329 net.cpp:434] conv3/dw <- conv2
I1016 09:56:12.252184   329 net.cpp:408] conv3/dw -> conv3/dw
I1016 09:56:12.252400   329 net.cpp:150] Setting up conv3/dw
I1016 09:56:12.252409   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.252413   329 net.cpp:165] Memory required for data: 130252864
I1016 09:56:12.252418   329 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1016 09:56:12.252424   329 net.cpp:100] Creating Layer conv3/dw/bn
I1016 09:56:12.252427   329 net.cpp:434] conv3/dw/bn <- conv3/dw
I1016 09:56:12.252432   329 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1016 09:56:12.252631   329 net.cpp:150] Setting up conv3/dw/bn
I1016 09:56:12.252640   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.252642   329 net.cpp:165] Memory required for data: 135168064
I1016 09:56:12.252652   329 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1016 09:56:12.252660   329 net.cpp:100] Creating Layer conv3/dw/scale
I1016 09:56:12.252663   329 net.cpp:434] conv3/dw/scale <- conv3/dw
I1016 09:56:12.252668   329 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1016 09:56:12.252710   329 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1016 09:56:12.252842   329 net.cpp:150] Setting up conv3/dw/scale
I1016 09:56:12.252852   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.252856   329 net.cpp:165] Memory required for data: 140083264
I1016 09:56:12.252861   329 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1016 09:56:12.252866   329 net.cpp:100] Creating Layer conv3/dw/relu
I1016 09:56:12.252871   329 net.cpp:434] conv3/dw/relu <- conv3/dw
I1016 09:56:12.252876   329 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1016 09:56:12.253548   329 net.cpp:150] Setting up conv3/dw/relu
I1016 09:56:12.253561   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.253566   329 net.cpp:165] Memory required for data: 144998464
I1016 09:56:12.253569   329 layer_factory.hpp:77] Creating layer conv3
I1016 09:56:12.253577   329 net.cpp:100] Creating Layer conv3
I1016 09:56:12.253582   329 net.cpp:434] conv3 <- conv3/dw
I1016 09:56:12.253588   329 net.cpp:408] conv3 -> conv3
I1016 09:56:12.255306   329 net.cpp:150] Setting up conv3
I1016 09:56:12.255322   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.255326   329 net.cpp:165] Memory required for data: 149913664
I1016 09:56:12.255332   329 layer_factory.hpp:77] Creating layer conv3/bn
I1016 09:56:12.255339   329 net.cpp:100] Creating Layer conv3/bn
I1016 09:56:12.255343   329 net.cpp:434] conv3/bn <- conv3
I1016 09:56:12.255349   329 net.cpp:395] conv3/bn -> conv3 (in-place)
I1016 09:56:12.255666   329 net.cpp:150] Setting up conv3/bn
I1016 09:56:12.255681   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.255686   329 net.cpp:165] Memory required for data: 154828864
I1016 09:56:12.255695   329 layer_factory.hpp:77] Creating layer conv3/scale
I1016 09:56:12.255704   329 net.cpp:100] Creating Layer conv3/scale
I1016 09:56:12.255709   329 net.cpp:434] conv3/scale <- conv3
I1016 09:56:12.255715   329 net.cpp:395] conv3/scale -> conv3 (in-place)
I1016 09:56:12.255771   329 layer_factory.hpp:77] Creating layer conv3/scale
I1016 09:56:12.255923   329 net.cpp:150] Setting up conv3/scale
I1016 09:56:12.255930   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.255934   329 net.cpp:165] Memory required for data: 159744064
I1016 09:56:12.255940   329 layer_factory.hpp:77] Creating layer conv3/relu
I1016 09:56:12.255947   329 net.cpp:100] Creating Layer conv3/relu
I1016 09:56:12.255951   329 net.cpp:434] conv3/relu <- conv3
I1016 09:56:12.255956   329 net.cpp:395] conv3/relu -> conv3 (in-place)
I1016 09:56:12.256357   329 net.cpp:150] Setting up conv3/relu
I1016 09:56:12.256368   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.256371   329 net.cpp:165] Memory required for data: 164659264
I1016 09:56:12.256373   329 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1016 09:56:12.256378   329 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1016 09:56:12.256383   329 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1016 09:56:12.256391   329 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1016 09:56:12.256399   329 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1016 09:56:12.256458   329 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1016 09:56:12.256464   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.256466   329 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1016 09:56:12.256469   329 net.cpp:165] Memory required for data: 174489664
I1016 09:56:12.256474   329 layer_factory.hpp:77] Creating layer conv4/dw
I1016 09:56:12.256484   329 net.cpp:100] Creating Layer conv4/dw
I1016 09:56:12.256487   329 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1016 09:56:12.256494   329 net.cpp:408] conv4/dw -> conv4/dw
I1016 09:56:12.256775   329 net.cpp:150] Setting up conv4/dw
I1016 09:56:12.256788   329 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1016 09:56:12.256791   329 net.cpp:165] Memory required for data: 175718464
I1016 09:56:12.256796   329 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1016 09:56:12.256803   329 net.cpp:100] Creating Layer conv4/dw/bn
I1016 09:56:12.256806   329 net.cpp:434] conv4/dw/bn <- conv4/dw
I1016 09:56:12.256809   329 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1016 09:56:12.257068   329 net.cpp:150] Setting up conv4/dw/bn
I1016 09:56:12.257077   329 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1016 09:56:12.257081   329 net.cpp:165] Memory required for data: 176947264
I1016 09:56:12.257086   329 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1016 09:56:12.257091   329 net.cpp:100] Creating Layer conv4/dw/scale
I1016 09:56:12.257094   329 net.cpp:434] conv4/dw/scale <- conv4/dw
I1016 09:56:12.257100   329 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1016 09:56:12.257155   329 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1016 09:56:12.257306   329 net.cpp:150] Setting up conv4/dw/scale
I1016 09:56:12.257315   329 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1016 09:56:12.257319   329 net.cpp:165] Memory required for data: 178176064
I1016 09:56:12.257326   329 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1016 09:56:12.257333   329 net.cpp:100] Creating Layer conv4/dw/relu
I1016 09:56:12.257338   329 net.cpp:434] conv4/dw/relu <- conv4/dw
I1016 09:56:12.257341   329 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1016 09:56:12.257736   329 net.cpp:150] Setting up conv4/dw/relu
I1016 09:56:12.257750   329 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1016 09:56:12.257753   329 net.cpp:165] Memory required for data: 179404864
I1016 09:56:12.257756   329 layer_factory.hpp:77] Creating layer conv4
I1016 09:56:12.257763   329 net.cpp:100] Creating Layer conv4
I1016 09:56:12.257766   329 net.cpp:434] conv4 <- conv4/dw
I1016 09:56:12.257771   329 net.cpp:408] conv4 -> conv4
I1016 09:56:12.260713   329 net.cpp:150] Setting up conv4
I1016 09:56:12.260727   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.260730   329 net.cpp:165] Memory required for data: 181862464
I1016 09:56:12.260735   329 layer_factory.hpp:77] Creating layer conv4/bn
I1016 09:56:12.260740   329 net.cpp:100] Creating Layer conv4/bn
I1016 09:56:12.260742   329 net.cpp:434] conv4/bn <- conv4
I1016 09:56:12.260747   329 net.cpp:395] conv4/bn -> conv4 (in-place)
I1016 09:56:12.260941   329 net.cpp:150] Setting up conv4/bn
I1016 09:56:12.260948   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.260951   329 net.cpp:165] Memory required for data: 184320064
I1016 09:56:12.260957   329 layer_factory.hpp:77] Creating layer conv4/scale
I1016 09:56:12.260962   329 net.cpp:100] Creating Layer conv4/scale
I1016 09:56:12.260964   329 net.cpp:434] conv4/scale <- conv4
I1016 09:56:12.260968   329 net.cpp:395] conv4/scale -> conv4 (in-place)
I1016 09:56:12.261005   329 layer_factory.hpp:77] Creating layer conv4/scale
I1016 09:56:12.261112   329 net.cpp:150] Setting up conv4/scale
I1016 09:56:12.261119   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.261121   329 net.cpp:165] Memory required for data: 186777664
I1016 09:56:12.261126   329 layer_factory.hpp:77] Creating layer conv4/relu
I1016 09:56:12.261131   329 net.cpp:100] Creating Layer conv4/relu
I1016 09:56:12.261132   329 net.cpp:434] conv4/relu <- conv4
I1016 09:56:12.261137   329 net.cpp:395] conv4/relu -> conv4 (in-place)
I1016 09:56:12.262116   329 net.cpp:150] Setting up conv4/relu
I1016 09:56:12.262128   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.262130   329 net.cpp:165] Memory required for data: 189235264
I1016 09:56:12.262133   329 layer_factory.hpp:77] Creating layer conv5/dw
I1016 09:56:12.262140   329 net.cpp:100] Creating Layer conv5/dw
I1016 09:56:12.262143   329 net.cpp:434] conv5/dw <- conv4
I1016 09:56:12.262150   329 net.cpp:408] conv5/dw -> conv5/dw
I1016 09:56:12.262373   329 net.cpp:150] Setting up conv5/dw
I1016 09:56:12.262382   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.262383   329 net.cpp:165] Memory required for data: 191692864
I1016 09:56:12.262388   329 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1016 09:56:12.262392   329 net.cpp:100] Creating Layer conv5/dw/bn
I1016 09:56:12.262395   329 net.cpp:434] conv5/dw/bn <- conv5/dw
I1016 09:56:12.262398   329 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1016 09:56:12.262578   329 net.cpp:150] Setting up conv5/dw/bn
I1016 09:56:12.262585   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.262588   329 net.cpp:165] Memory required for data: 194150464
I1016 09:56:12.262593   329 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1016 09:56:12.262598   329 net.cpp:100] Creating Layer conv5/dw/scale
I1016 09:56:12.262599   329 net.cpp:434] conv5/dw/scale <- conv5/dw
I1016 09:56:12.262603   329 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1016 09:56:12.262640   329 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1016 09:56:12.262748   329 net.cpp:150] Setting up conv5/dw/scale
I1016 09:56:12.262753   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.262754   329 net.cpp:165] Memory required for data: 196608064
I1016 09:56:12.262758   329 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1016 09:56:12.262763   329 net.cpp:100] Creating Layer conv5/dw/relu
I1016 09:56:12.262765   329 net.cpp:434] conv5/dw/relu <- conv5/dw
I1016 09:56:12.262768   329 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1016 09:56:12.263094   329 net.cpp:150] Setting up conv5/dw/relu
I1016 09:56:12.263103   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.263105   329 net.cpp:165] Memory required for data: 199065664
I1016 09:56:12.263108   329 layer_factory.hpp:77] Creating layer conv5
I1016 09:56:12.263114   329 net.cpp:100] Creating Layer conv5
I1016 09:56:12.263116   329 net.cpp:434] conv5 <- conv5/dw
I1016 09:56:12.263121   329 net.cpp:408] conv5 -> conv5
I1016 09:56:12.265238   329 net.cpp:150] Setting up conv5
I1016 09:56:12.265249   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.265252   329 net.cpp:165] Memory required for data: 201523264
I1016 09:56:12.265256   329 layer_factory.hpp:77] Creating layer conv5/bn
I1016 09:56:12.265261   329 net.cpp:100] Creating Layer conv5/bn
I1016 09:56:12.265264   329 net.cpp:434] conv5/bn <- conv5
I1016 09:56:12.265269   329 net.cpp:395] conv5/bn -> conv5 (in-place)
I1016 09:56:12.265460   329 net.cpp:150] Setting up conv5/bn
I1016 09:56:12.265467   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.265470   329 net.cpp:165] Memory required for data: 203980864
I1016 09:56:12.265475   329 layer_factory.hpp:77] Creating layer conv5/scale
I1016 09:56:12.265480   329 net.cpp:100] Creating Layer conv5/scale
I1016 09:56:12.265481   329 net.cpp:434] conv5/scale <- conv5
I1016 09:56:12.265486   329 net.cpp:395] conv5/scale -> conv5 (in-place)
I1016 09:56:12.265523   329 layer_factory.hpp:77] Creating layer conv5/scale
I1016 09:56:12.265631   329 net.cpp:150] Setting up conv5/scale
I1016 09:56:12.265636   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.265638   329 net.cpp:165] Memory required for data: 206438464
I1016 09:56:12.265650   329 layer_factory.hpp:77] Creating layer conv5/relu
I1016 09:56:12.265653   329 net.cpp:100] Creating Layer conv5/relu
I1016 09:56:12.265656   329 net.cpp:434] conv5/relu <- conv5
I1016 09:56:12.265660   329 net.cpp:395] conv5/relu -> conv5 (in-place)
I1016 09:56:12.265998   329 net.cpp:150] Setting up conv5/relu
I1016 09:56:12.266007   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.266010   329 net.cpp:165] Memory required for data: 208896064
I1016 09:56:12.266012   329 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1016 09:56:12.266017   329 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1016 09:56:12.266021   329 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1016 09:56:12.266024   329 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1016 09:56:12.266029   329 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1016 09:56:12.266072   329 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1016 09:56:12.266077   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.266080   329 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1016 09:56:12.266083   329 net.cpp:165] Memory required for data: 213811264
I1016 09:56:12.266084   329 layer_factory.hpp:77] Creating layer conv6/dw
I1016 09:56:12.266091   329 net.cpp:100] Creating Layer conv6/dw
I1016 09:56:12.266094   329 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1016 09:56:12.266098   329 net.cpp:408] conv6/dw -> conv6/dw
I1016 09:56:12.266309   329 net.cpp:150] Setting up conv6/dw
I1016 09:56:12.266316   329 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1016 09:56:12.266319   329 net.cpp:165] Memory required for data: 214425664
I1016 09:56:12.266322   329 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1016 09:56:12.266326   329 net.cpp:100] Creating Layer conv6/dw/bn
I1016 09:56:12.266330   329 net.cpp:434] conv6/dw/bn <- conv6/dw
I1016 09:56:12.266332   329 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1016 09:56:12.266525   329 net.cpp:150] Setting up conv6/dw/bn
I1016 09:56:12.266531   329 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1016 09:56:12.266533   329 net.cpp:165] Memory required for data: 215040064
I1016 09:56:12.266539   329 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1016 09:56:12.266544   329 net.cpp:100] Creating Layer conv6/dw/scale
I1016 09:56:12.266546   329 net.cpp:434] conv6/dw/scale <- conv6/dw
I1016 09:56:12.266551   329 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1016 09:56:12.266587   329 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1016 09:56:12.266736   329 net.cpp:150] Setting up conv6/dw/scale
I1016 09:56:12.266743   329 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1016 09:56:12.266746   329 net.cpp:165] Memory required for data: 215654464
I1016 09:56:12.266753   329 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1016 09:56:12.266759   329 net.cpp:100] Creating Layer conv6/dw/relu
I1016 09:56:12.266762   329 net.cpp:434] conv6/dw/relu <- conv6/dw
I1016 09:56:12.266767   329 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1016 09:56:12.267098   329 net.cpp:150] Setting up conv6/dw/relu
I1016 09:56:12.267107   329 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1016 09:56:12.267110   329 net.cpp:165] Memory required for data: 216268864
I1016 09:56:12.267112   329 layer_factory.hpp:77] Creating layer conv6
I1016 09:56:12.267119   329 net.cpp:100] Creating Layer conv6
I1016 09:56:12.267122   329 net.cpp:434] conv6 <- conv6/dw
I1016 09:56:12.267127   329 net.cpp:408] conv6 -> conv6
I1016 09:56:12.269805   329 net.cpp:150] Setting up conv6
I1016 09:56:12.269827   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.269830   329 net.cpp:165] Memory required for data: 217497664
I1016 09:56:12.269836   329 layer_factory.hpp:77] Creating layer conv6/bn
I1016 09:56:12.269842   329 net.cpp:100] Creating Layer conv6/bn
I1016 09:56:12.269845   329 net.cpp:434] conv6/bn <- conv6
I1016 09:56:12.269850   329 net.cpp:395] conv6/bn -> conv6 (in-place)
I1016 09:56:12.270053   329 net.cpp:150] Setting up conv6/bn
I1016 09:56:12.270061   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.270062   329 net.cpp:165] Memory required for data: 218726464
I1016 09:56:12.270067   329 layer_factory.hpp:77] Creating layer conv6/scale
I1016 09:56:12.270073   329 net.cpp:100] Creating Layer conv6/scale
I1016 09:56:12.270076   329 net.cpp:434] conv6/scale <- conv6
I1016 09:56:12.270079   329 net.cpp:395] conv6/scale -> conv6 (in-place)
I1016 09:56:12.270121   329 layer_factory.hpp:77] Creating layer conv6/scale
I1016 09:56:12.270229   329 net.cpp:150] Setting up conv6/scale
I1016 09:56:12.270234   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.270236   329 net.cpp:165] Memory required for data: 219955264
I1016 09:56:12.270241   329 layer_factory.hpp:77] Creating layer conv6/relu
I1016 09:56:12.270244   329 net.cpp:100] Creating Layer conv6/relu
I1016 09:56:12.270247   329 net.cpp:434] conv6/relu <- conv6
I1016 09:56:12.270251   329 net.cpp:395] conv6/relu -> conv6 (in-place)
I1016 09:56:12.270920   329 net.cpp:150] Setting up conv6/relu
I1016 09:56:12.270932   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.270934   329 net.cpp:165] Memory required for data: 221184064
I1016 09:56:12.270937   329 layer_factory.hpp:77] Creating layer conv7/dw
I1016 09:56:12.270946   329 net.cpp:100] Creating Layer conv7/dw
I1016 09:56:12.270948   329 net.cpp:434] conv7/dw <- conv6
I1016 09:56:12.270952   329 net.cpp:408] conv7/dw -> conv7/dw
I1016 09:56:12.271193   329 net.cpp:150] Setting up conv7/dw
I1016 09:56:12.271200   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.271203   329 net.cpp:165] Memory required for data: 222412864
I1016 09:56:12.271206   329 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1016 09:56:12.271210   329 net.cpp:100] Creating Layer conv7/dw/bn
I1016 09:56:12.271214   329 net.cpp:434] conv7/dw/bn <- conv7/dw
I1016 09:56:12.271216   329 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1016 09:56:12.271407   329 net.cpp:150] Setting up conv7/dw/bn
I1016 09:56:12.271414   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.271415   329 net.cpp:165] Memory required for data: 223641664
I1016 09:56:12.271421   329 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1016 09:56:12.271426   329 net.cpp:100] Creating Layer conv7/dw/scale
I1016 09:56:12.271428   329 net.cpp:434] conv7/dw/scale <- conv7/dw
I1016 09:56:12.271432   329 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1016 09:56:12.271471   329 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1016 09:56:12.271580   329 net.cpp:150] Setting up conv7/dw/scale
I1016 09:56:12.271587   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.271589   329 net.cpp:165] Memory required for data: 224870464
I1016 09:56:12.271594   329 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1016 09:56:12.271597   329 net.cpp:100] Creating Layer conv7/dw/relu
I1016 09:56:12.271600   329 net.cpp:434] conv7/dw/relu <- conv7/dw
I1016 09:56:12.271603   329 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1016 09:56:12.271927   329 net.cpp:150] Setting up conv7/dw/relu
I1016 09:56:12.271936   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.271939   329 net.cpp:165] Memory required for data: 226099264
I1016 09:56:12.271941   329 layer_factory.hpp:77] Creating layer conv7
I1016 09:56:12.271948   329 net.cpp:100] Creating Layer conv7
I1016 09:56:12.271951   329 net.cpp:434] conv7 <- conv7/dw
I1016 09:56:12.271955   329 net.cpp:408] conv7 -> conv7
I1016 09:56:12.276427   329 net.cpp:150] Setting up conv7
I1016 09:56:12.276440   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.276443   329 net.cpp:165] Memory required for data: 227328064
I1016 09:56:12.276448   329 layer_factory.hpp:77] Creating layer conv7/bn
I1016 09:56:12.276453   329 net.cpp:100] Creating Layer conv7/bn
I1016 09:56:12.276456   329 net.cpp:434] conv7/bn <- conv7
I1016 09:56:12.276460   329 net.cpp:395] conv7/bn -> conv7 (in-place)
I1016 09:56:12.276669   329 net.cpp:150] Setting up conv7/bn
I1016 09:56:12.276676   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.276679   329 net.cpp:165] Memory required for data: 228556864
I1016 09:56:12.276684   329 layer_factory.hpp:77] Creating layer conv7/scale
I1016 09:56:12.276690   329 net.cpp:100] Creating Layer conv7/scale
I1016 09:56:12.276693   329 net.cpp:434] conv7/scale <- conv7
I1016 09:56:12.276696   329 net.cpp:395] conv7/scale -> conv7 (in-place)
I1016 09:56:12.276739   329 layer_factory.hpp:77] Creating layer conv7/scale
I1016 09:56:12.276856   329 net.cpp:150] Setting up conv7/scale
I1016 09:56:12.276862   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.276865   329 net.cpp:165] Memory required for data: 229785664
I1016 09:56:12.276870   329 layer_factory.hpp:77] Creating layer conv7/relu
I1016 09:56:12.276875   329 net.cpp:100] Creating Layer conv7/relu
I1016 09:56:12.276876   329 net.cpp:434] conv7/relu <- conv7
I1016 09:56:12.276880   329 net.cpp:395] conv7/relu -> conv7 (in-place)
I1016 09:56:12.277272   329 net.cpp:150] Setting up conv7/relu
I1016 09:56:12.277283   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.277285   329 net.cpp:165] Memory required for data: 231014464
I1016 09:56:12.277288   329 layer_factory.hpp:77] Creating layer conv8/dw
I1016 09:56:12.277303   329 net.cpp:100] Creating Layer conv8/dw
I1016 09:56:12.277307   329 net.cpp:434] conv8/dw <- conv7
I1016 09:56:12.277312   329 net.cpp:408] conv8/dw -> conv8/dw
I1016 09:56:12.277552   329 net.cpp:150] Setting up conv8/dw
I1016 09:56:12.277559   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.277562   329 net.cpp:165] Memory required for data: 232243264
I1016 09:56:12.277566   329 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1016 09:56:12.277570   329 net.cpp:100] Creating Layer conv8/dw/bn
I1016 09:56:12.277573   329 net.cpp:434] conv8/dw/bn <- conv8/dw
I1016 09:56:12.277577   329 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1016 09:56:12.277772   329 net.cpp:150] Setting up conv8/dw/bn
I1016 09:56:12.277779   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.277781   329 net.cpp:165] Memory required for data: 233472064
I1016 09:56:12.277786   329 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1016 09:56:12.277791   329 net.cpp:100] Creating Layer conv8/dw/scale
I1016 09:56:12.277793   329 net.cpp:434] conv8/dw/scale <- conv8/dw
I1016 09:56:12.277798   329 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1016 09:56:12.277846   329 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1016 09:56:12.277967   329 net.cpp:150] Setting up conv8/dw/scale
I1016 09:56:12.277974   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.277976   329 net.cpp:165] Memory required for data: 234700864
I1016 09:56:12.277981   329 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1016 09:56:12.277984   329 net.cpp:100] Creating Layer conv8/dw/relu
I1016 09:56:12.277987   329 net.cpp:434] conv8/dw/relu <- conv8/dw
I1016 09:56:12.277992   329 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1016 09:56:12.278702   329 net.cpp:150] Setting up conv8/dw/relu
I1016 09:56:12.278712   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.278714   329 net.cpp:165] Memory required for data: 235929664
I1016 09:56:12.278717   329 layer_factory.hpp:77] Creating layer conv8
I1016 09:56:12.278726   329 net.cpp:100] Creating Layer conv8
I1016 09:56:12.278730   329 net.cpp:434] conv8 <- conv8/dw
I1016 09:56:12.278735   329 net.cpp:408] conv8 -> conv8
I1016 09:56:12.283406   329 net.cpp:150] Setting up conv8
I1016 09:56:12.283433   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.283437   329 net.cpp:165] Memory required for data: 237158464
I1016 09:56:12.283447   329 layer_factory.hpp:77] Creating layer conv8/bn
I1016 09:56:12.283457   329 net.cpp:100] Creating Layer conv8/bn
I1016 09:56:12.283463   329 net.cpp:434] conv8/bn <- conv8
I1016 09:56:12.283470   329 net.cpp:395] conv8/bn -> conv8 (in-place)
I1016 09:56:12.283753   329 net.cpp:150] Setting up conv8/bn
I1016 09:56:12.283761   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.283766   329 net.cpp:165] Memory required for data: 238387264
I1016 09:56:12.283773   329 layer_factory.hpp:77] Creating layer conv8/scale
I1016 09:56:12.283783   329 net.cpp:100] Creating Layer conv8/scale
I1016 09:56:12.283787   329 net.cpp:434] conv8/scale <- conv8
I1016 09:56:12.283792   329 net.cpp:395] conv8/scale -> conv8 (in-place)
I1016 09:56:12.283849   329 layer_factory.hpp:77] Creating layer conv8/scale
I1016 09:56:12.284003   329 net.cpp:150] Setting up conv8/scale
I1016 09:56:12.284009   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.284013   329 net.cpp:165] Memory required for data: 239616064
I1016 09:56:12.284018   329 layer_factory.hpp:77] Creating layer conv8/relu
I1016 09:56:12.284026   329 net.cpp:100] Creating Layer conv8/relu
I1016 09:56:12.284030   329 net.cpp:434] conv8/relu <- conv8
I1016 09:56:12.284035   329 net.cpp:395] conv8/relu -> conv8 (in-place)
I1016 09:56:12.284549   329 net.cpp:150] Setting up conv8/relu
I1016 09:56:12.284559   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.284562   329 net.cpp:165] Memory required for data: 240844864
I1016 09:56:12.284566   329 layer_factory.hpp:77] Creating layer conv9/dw
I1016 09:56:12.284577   329 net.cpp:100] Creating Layer conv9/dw
I1016 09:56:12.284581   329 net.cpp:434] conv9/dw <- conv8
I1016 09:56:12.284588   329 net.cpp:408] conv9/dw -> conv9/dw
I1016 09:56:12.284924   329 net.cpp:150] Setting up conv9/dw
I1016 09:56:12.284931   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.284935   329 net.cpp:165] Memory required for data: 242073664
I1016 09:56:12.284940   329 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1016 09:56:12.284945   329 net.cpp:100] Creating Layer conv9/dw/bn
I1016 09:56:12.284950   329 net.cpp:434] conv9/dw/bn <- conv9/dw
I1016 09:56:12.284955   329 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1016 09:56:12.285223   329 net.cpp:150] Setting up conv9/dw/bn
I1016 09:56:12.285229   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.285231   329 net.cpp:165] Memory required for data: 243302464
I1016 09:56:12.285236   329 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1016 09:56:12.285241   329 net.cpp:100] Creating Layer conv9/dw/scale
I1016 09:56:12.285244   329 net.cpp:434] conv9/dw/scale <- conv9/dw
I1016 09:56:12.285249   329 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1016 09:56:12.285300   329 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1016 09:56:12.285423   329 net.cpp:150] Setting up conv9/dw/scale
I1016 09:56:12.285431   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.285434   329 net.cpp:165] Memory required for data: 244531264
I1016 09:56:12.285439   329 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1016 09:56:12.285445   329 net.cpp:100] Creating Layer conv9/dw/relu
I1016 09:56:12.285449   329 net.cpp:434] conv9/dw/relu <- conv9/dw
I1016 09:56:12.285451   329 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1016 09:56:12.286016   329 net.cpp:150] Setting up conv9/dw/relu
I1016 09:56:12.286032   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.286036   329 net.cpp:165] Memory required for data: 245760064
I1016 09:56:12.286041   329 layer_factory.hpp:77] Creating layer conv9
I1016 09:56:12.286051   329 net.cpp:100] Creating Layer conv9
I1016 09:56:12.286056   329 net.cpp:434] conv9 <- conv9/dw
I1016 09:56:12.286075   329 net.cpp:408] conv9 -> conv9
I1016 09:56:12.291384   329 net.cpp:150] Setting up conv9
I1016 09:56:12.291399   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.291400   329 net.cpp:165] Memory required for data: 246988864
I1016 09:56:12.291405   329 layer_factory.hpp:77] Creating layer conv9/bn
I1016 09:56:12.291411   329 net.cpp:100] Creating Layer conv9/bn
I1016 09:56:12.291414   329 net.cpp:434] conv9/bn <- conv9
I1016 09:56:12.291419   329 net.cpp:395] conv9/bn -> conv9 (in-place)
I1016 09:56:12.291726   329 net.cpp:150] Setting up conv9/bn
I1016 09:56:12.291738   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.291743   329 net.cpp:165] Memory required for data: 248217664
I1016 09:56:12.291751   329 layer_factory.hpp:77] Creating layer conv9/scale
I1016 09:56:12.291759   329 net.cpp:100] Creating Layer conv9/scale
I1016 09:56:12.291761   329 net.cpp:434] conv9/scale <- conv9
I1016 09:56:12.291765   329 net.cpp:395] conv9/scale -> conv9 (in-place)
I1016 09:56:12.291827   329 layer_factory.hpp:77] Creating layer conv9/scale
I1016 09:56:12.292019   329 net.cpp:150] Setting up conv9/scale
I1016 09:56:12.292030   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.292034   329 net.cpp:165] Memory required for data: 249446464
I1016 09:56:12.292042   329 layer_factory.hpp:77] Creating layer conv9/relu
I1016 09:56:12.292048   329 net.cpp:100] Creating Layer conv9/relu
I1016 09:56:12.292052   329 net.cpp:434] conv9/relu <- conv9
I1016 09:56:12.292057   329 net.cpp:395] conv9/relu -> conv9 (in-place)
I1016 09:56:12.292867   329 net.cpp:150] Setting up conv9/relu
I1016 09:56:12.292881   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.292882   329 net.cpp:165] Memory required for data: 250675264
I1016 09:56:12.292886   329 layer_factory.hpp:77] Creating layer conv10/dw
I1016 09:56:12.292894   329 net.cpp:100] Creating Layer conv10/dw
I1016 09:56:12.292897   329 net.cpp:434] conv10/dw <- conv9
I1016 09:56:12.292902   329 net.cpp:408] conv10/dw -> conv10/dw
I1016 09:56:12.293243   329 net.cpp:150] Setting up conv10/dw
I1016 09:56:12.293252   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.293254   329 net.cpp:165] Memory required for data: 251904064
I1016 09:56:12.293258   329 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1016 09:56:12.293263   329 net.cpp:100] Creating Layer conv10/dw/bn
I1016 09:56:12.293265   329 net.cpp:434] conv10/dw/bn <- conv10/dw
I1016 09:56:12.293270   329 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1016 09:56:12.293566   329 net.cpp:150] Setting up conv10/dw/bn
I1016 09:56:12.293575   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.293577   329 net.cpp:165] Memory required for data: 253132864
I1016 09:56:12.293582   329 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1016 09:56:12.293587   329 net.cpp:100] Creating Layer conv10/dw/scale
I1016 09:56:12.293591   329 net.cpp:434] conv10/dw/scale <- conv10/dw
I1016 09:56:12.293596   329 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1016 09:56:12.293653   329 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1016 09:56:12.293859   329 net.cpp:150] Setting up conv10/dw/scale
I1016 09:56:12.293871   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.293875   329 net.cpp:165] Memory required for data: 254361664
I1016 09:56:12.293880   329 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1016 09:56:12.293885   329 net.cpp:100] Creating Layer conv10/dw/relu
I1016 09:56:12.293887   329 net.cpp:434] conv10/dw/relu <- conv10/dw
I1016 09:56:12.293893   329 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1016 09:56:12.294333   329 net.cpp:150] Setting up conv10/dw/relu
I1016 09:56:12.294343   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.294347   329 net.cpp:165] Memory required for data: 255590464
I1016 09:56:12.294348   329 layer_factory.hpp:77] Creating layer conv10
I1016 09:56:12.294356   329 net.cpp:100] Creating Layer conv10
I1016 09:56:12.294359   329 net.cpp:434] conv10 <- conv10/dw
I1016 09:56:12.294365   329 net.cpp:408] conv10 -> conv10
I1016 09:56:12.298154   329 net.cpp:150] Setting up conv10
I1016 09:56:12.298169   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.298172   329 net.cpp:165] Memory required for data: 256819264
I1016 09:56:12.298177   329 layer_factory.hpp:77] Creating layer conv10/bn
I1016 09:56:12.298182   329 net.cpp:100] Creating Layer conv10/bn
I1016 09:56:12.298184   329 net.cpp:434] conv10/bn <- conv10
I1016 09:56:12.298189   329 net.cpp:395] conv10/bn -> conv10 (in-place)
I1016 09:56:12.298502   329 net.cpp:150] Setting up conv10/bn
I1016 09:56:12.298511   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.298514   329 net.cpp:165] Memory required for data: 258048064
I1016 09:56:12.298521   329 layer_factory.hpp:77] Creating layer conv10/scale
I1016 09:56:12.298526   329 net.cpp:100] Creating Layer conv10/scale
I1016 09:56:12.298527   329 net.cpp:434] conv10/scale <- conv10
I1016 09:56:12.298533   329 net.cpp:395] conv10/scale -> conv10 (in-place)
I1016 09:56:12.298596   329 layer_factory.hpp:77] Creating layer conv10/scale
I1016 09:56:12.298796   329 net.cpp:150] Setting up conv10/scale
I1016 09:56:12.298805   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.298807   329 net.cpp:165] Memory required for data: 259276864
I1016 09:56:12.298811   329 layer_factory.hpp:77] Creating layer conv10/relu
I1016 09:56:12.298816   329 net.cpp:100] Creating Layer conv10/relu
I1016 09:56:12.298818   329 net.cpp:434] conv10/relu <- conv10
I1016 09:56:12.298823   329 net.cpp:395] conv10/relu -> conv10 (in-place)
I1016 09:56:12.299294   329 net.cpp:150] Setting up conv10/relu
I1016 09:56:12.299309   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.299312   329 net.cpp:165] Memory required for data: 260505664
I1016 09:56:12.299316   329 layer_factory.hpp:77] Creating layer conv11/dw
I1016 09:56:12.299329   329 net.cpp:100] Creating Layer conv11/dw
I1016 09:56:12.299334   329 net.cpp:434] conv11/dw <- conv10
I1016 09:56:12.299341   329 net.cpp:408] conv11/dw -> conv11/dw
I1016 09:56:12.299734   329 net.cpp:150] Setting up conv11/dw
I1016 09:56:12.299748   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.299752   329 net.cpp:165] Memory required for data: 261734464
I1016 09:56:12.299758   329 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1016 09:56:12.299765   329 net.cpp:100] Creating Layer conv11/dw/bn
I1016 09:56:12.299769   329 net.cpp:434] conv11/dw/bn <- conv11/dw
I1016 09:56:12.299777   329 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1016 09:56:12.300107   329 net.cpp:150] Setting up conv11/dw/bn
I1016 09:56:12.300117   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.300122   329 net.cpp:165] Memory required for data: 262963264
I1016 09:56:12.300148   329 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1016 09:56:12.300158   329 net.cpp:100] Creating Layer conv11/dw/scale
I1016 09:56:12.300163   329 net.cpp:434] conv11/dw/scale <- conv11/dw
I1016 09:56:12.300169   329 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1016 09:56:12.300237   329 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1016 09:56:12.300427   329 net.cpp:150] Setting up conv11/dw/scale
I1016 09:56:12.300438   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.300441   329 net.cpp:165] Memory required for data: 264192064
I1016 09:56:12.300449   329 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1016 09:56:12.300457   329 net.cpp:100] Creating Layer conv11/dw/relu
I1016 09:56:12.300459   329 net.cpp:434] conv11/dw/relu <- conv11/dw
I1016 09:56:12.300467   329 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1016 09:56:12.301051   329 net.cpp:150] Setting up conv11/dw/relu
I1016 09:56:12.301064   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.301069   329 net.cpp:165] Memory required for data: 265420864
I1016 09:56:12.301072   329 layer_factory.hpp:77] Creating layer conv11
I1016 09:56:12.301084   329 net.cpp:100] Creating Layer conv11
I1016 09:56:12.301089   329 net.cpp:434] conv11 <- conv11/dw
I1016 09:56:12.301095   329 net.cpp:408] conv11 -> conv11
I1016 09:56:12.305981   329 net.cpp:150] Setting up conv11
I1016 09:56:12.305996   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.305999   329 net.cpp:165] Memory required for data: 266649664
I1016 09:56:12.306004   329 layer_factory.hpp:77] Creating layer conv11/bn
I1016 09:56:12.306008   329 net.cpp:100] Creating Layer conv11/bn
I1016 09:56:12.306011   329 net.cpp:434] conv11/bn <- conv11
I1016 09:56:12.306017   329 net.cpp:395] conv11/bn -> conv11 (in-place)
I1016 09:56:12.306340   329 net.cpp:150] Setting up conv11/bn
I1016 09:56:12.306349   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.306352   329 net.cpp:165] Memory required for data: 267878464
I1016 09:56:12.306358   329 layer_factory.hpp:77] Creating layer conv11/scale
I1016 09:56:12.306363   329 net.cpp:100] Creating Layer conv11/scale
I1016 09:56:12.306366   329 net.cpp:434] conv11/scale <- conv11
I1016 09:56:12.306371   329 net.cpp:395] conv11/scale -> conv11 (in-place)
I1016 09:56:12.306428   329 layer_factory.hpp:77] Creating layer conv11/scale
I1016 09:56:12.306620   329 net.cpp:150] Setting up conv11/scale
I1016 09:56:12.306632   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.306637   329 net.cpp:165] Memory required for data: 269107264
I1016 09:56:12.306643   329 layer_factory.hpp:77] Creating layer conv11/relu
I1016 09:56:12.306648   329 net.cpp:100] Creating Layer conv11/relu
I1016 09:56:12.306651   329 net.cpp:434] conv11/relu <- conv11
I1016 09:56:12.306656   329 net.cpp:395] conv11/relu -> conv11 (in-place)
I1016 09:56:12.307497   329 net.cpp:150] Setting up conv11/relu
I1016 09:56:12.307509   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307512   329 net.cpp:165] Memory required for data: 270336064
I1016 09:56:12.307514   329 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1016 09:56:12.307523   329 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1016 09:56:12.307525   329 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1016 09:56:12.307530   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1016 09:56:12.307538   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1016 09:56:12.307543   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1016 09:56:12.307548   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1016 09:56:12.307551   329 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1016 09:56:12.307695   329 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1016 09:56:12.307708   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307711   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307713   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307716   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307719   329 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1016 09:56:12.307721   329 net.cpp:165] Memory required for data: 276480064
I1016 09:56:12.307723   329 layer_factory.hpp:77] Creating layer conv12/dw
I1016 09:56:12.307732   329 net.cpp:100] Creating Layer conv12/dw
I1016 09:56:12.307735   329 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1016 09:56:12.307742   329 net.cpp:408] conv12/dw -> conv12/dw
I1016 09:56:12.308137   329 net.cpp:150] Setting up conv12/dw
I1016 09:56:12.308146   329 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1016 09:56:12.308149   329 net.cpp:165] Memory required for data: 276787264
I1016 09:56:12.308154   329 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1016 09:56:12.308161   329 net.cpp:100] Creating Layer conv12/dw/bn
I1016 09:56:12.308166   329 net.cpp:434] conv12/dw/bn <- conv12/dw
I1016 09:56:12.308172   329 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1016 09:56:12.308522   329 net.cpp:150] Setting up conv12/dw/bn
I1016 09:56:12.308531   329 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1016 09:56:12.308534   329 net.cpp:165] Memory required for data: 277094464
I1016 09:56:12.308539   329 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1016 09:56:12.308544   329 net.cpp:100] Creating Layer conv12/dw/scale
I1016 09:56:12.308547   329 net.cpp:434] conv12/dw/scale <- conv12/dw
I1016 09:56:12.308552   329 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1016 09:56:12.308607   329 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1016 09:56:12.308806   329 net.cpp:150] Setting up conv12/dw/scale
I1016 09:56:12.308817   329 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1016 09:56:12.308822   329 net.cpp:165] Memory required for data: 277401664
I1016 09:56:12.308830   329 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1016 09:56:12.308835   329 net.cpp:100] Creating Layer conv12/dw/relu
I1016 09:56:12.308836   329 net.cpp:434] conv12/dw/relu <- conv12/dw
I1016 09:56:12.308840   329 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1016 09:56:12.309295   329 net.cpp:150] Setting up conv12/dw/relu
I1016 09:56:12.309305   329 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1016 09:56:12.309307   329 net.cpp:165] Memory required for data: 277708864
I1016 09:56:12.309310   329 layer_factory.hpp:77] Creating layer conv12
I1016 09:56:12.309319   329 net.cpp:100] Creating Layer conv12
I1016 09:56:12.309321   329 net.cpp:434] conv12 <- conv12/dw
I1016 09:56:12.309327   329 net.cpp:408] conv12 -> conv12
I1016 09:56:12.315918   329 net.cpp:150] Setting up conv12
I1016 09:56:12.315930   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.315933   329 net.cpp:165] Memory required for data: 278323264
I1016 09:56:12.315937   329 layer_factory.hpp:77] Creating layer conv12/bn
I1016 09:56:12.315943   329 net.cpp:100] Creating Layer conv12/bn
I1016 09:56:12.315948   329 net.cpp:434] conv12/bn <- conv12
I1016 09:56:12.315951   329 net.cpp:395] conv12/bn -> conv12 (in-place)
I1016 09:56:12.316196   329 net.cpp:150] Setting up conv12/bn
I1016 09:56:12.316205   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.316207   329 net.cpp:165] Memory required for data: 278937664
I1016 09:56:12.316213   329 layer_factory.hpp:77] Creating layer conv12/scale
I1016 09:56:12.316220   329 net.cpp:100] Creating Layer conv12/scale
I1016 09:56:12.316222   329 net.cpp:434] conv12/scale <- conv12
I1016 09:56:12.316226   329 net.cpp:395] conv12/scale -> conv12 (in-place)
I1016 09:56:12.316267   329 layer_factory.hpp:77] Creating layer conv12/scale
I1016 09:56:12.316387   329 net.cpp:150] Setting up conv12/scale
I1016 09:56:12.316395   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.316396   329 net.cpp:165] Memory required for data: 279552064
I1016 09:56:12.316401   329 layer_factory.hpp:77] Creating layer conv12/relu
I1016 09:56:12.316406   329 net.cpp:100] Creating Layer conv12/relu
I1016 09:56:12.316409   329 net.cpp:434] conv12/relu <- conv12
I1016 09:56:12.316412   329 net.cpp:395] conv12/relu -> conv12 (in-place)
I1016 09:56:12.316800   329 net.cpp:150] Setting up conv12/relu
I1016 09:56:12.316810   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.316812   329 net.cpp:165] Memory required for data: 280166464
I1016 09:56:12.316815   329 layer_factory.hpp:77] Creating layer conv13/dw
I1016 09:56:12.316823   329 net.cpp:100] Creating Layer conv13/dw
I1016 09:56:12.316825   329 net.cpp:434] conv13/dw <- conv12
I1016 09:56:12.316830   329 net.cpp:408] conv13/dw -> conv13/dw
I1016 09:56:12.317113   329 net.cpp:150] Setting up conv13/dw
I1016 09:56:12.317121   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.317122   329 net.cpp:165] Memory required for data: 280780864
I1016 09:56:12.317126   329 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1016 09:56:12.317131   329 net.cpp:100] Creating Layer conv13/dw/bn
I1016 09:56:12.317133   329 net.cpp:434] conv13/dw/bn <- conv13/dw
I1016 09:56:12.317138   329 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1016 09:56:12.317337   329 net.cpp:150] Setting up conv13/dw/bn
I1016 09:56:12.317342   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.317344   329 net.cpp:165] Memory required for data: 281395264
I1016 09:56:12.317349   329 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1016 09:56:12.317354   329 net.cpp:100] Creating Layer conv13/dw/scale
I1016 09:56:12.317358   329 net.cpp:434] conv13/dw/scale <- conv13/dw
I1016 09:56:12.317363   329 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1016 09:56:12.317400   329 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1016 09:56:12.317520   329 net.cpp:150] Setting up conv13/dw/scale
I1016 09:56:12.317526   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.317528   329 net.cpp:165] Memory required for data: 282009664
I1016 09:56:12.317533   329 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1016 09:56:12.317538   329 net.cpp:100] Creating Layer conv13/dw/relu
I1016 09:56:12.317539   329 net.cpp:434] conv13/dw/relu <- conv13/dw
I1016 09:56:12.317544   329 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1016 09:56:12.318279   329 net.cpp:150] Setting up conv13/dw/relu
I1016 09:56:12.318291   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.318295   329 net.cpp:165] Memory required for data: 282624064
I1016 09:56:12.318296   329 layer_factory.hpp:77] Creating layer conv13
I1016 09:56:12.318305   329 net.cpp:100] Creating Layer conv13
I1016 09:56:12.318308   329 net.cpp:434] conv13 <- conv13/dw
I1016 09:56:12.318315   329 net.cpp:408] conv13 -> conv13
I1016 09:56:12.329684   329 net.cpp:150] Setting up conv13
I1016 09:56:12.329704   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.329706   329 net.cpp:165] Memory required for data: 283238464
I1016 09:56:12.329712   329 layer_factory.hpp:77] Creating layer conv13/bn
I1016 09:56:12.329720   329 net.cpp:100] Creating Layer conv13/bn
I1016 09:56:12.329725   329 net.cpp:434] conv13/bn <- conv13
I1016 09:56:12.329731   329 net.cpp:395] conv13/bn -> conv13 (in-place)
I1016 09:56:12.329970   329 net.cpp:150] Setting up conv13/bn
I1016 09:56:12.329977   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.329980   329 net.cpp:165] Memory required for data: 283852864
I1016 09:56:12.329987   329 layer_factory.hpp:77] Creating layer conv13/scale
I1016 09:56:12.329993   329 net.cpp:100] Creating Layer conv13/scale
I1016 09:56:12.329995   329 net.cpp:434] conv13/scale <- conv13
I1016 09:56:12.330001   329 net.cpp:395] conv13/scale -> conv13 (in-place)
I1016 09:56:12.330042   329 layer_factory.hpp:77] Creating layer conv13/scale
I1016 09:56:12.330165   329 net.cpp:150] Setting up conv13/scale
I1016 09:56:12.330171   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330173   329 net.cpp:165] Memory required for data: 284467264
I1016 09:56:12.330178   329 layer_factory.hpp:77] Creating layer conv13/relu
I1016 09:56:12.330183   329 net.cpp:100] Creating Layer conv13/relu
I1016 09:56:12.330185   329 net.cpp:434] conv13/relu <- conv13
I1016 09:56:12.330189   329 net.cpp:395] conv13/relu -> conv13 (in-place)
I1016 09:56:12.330582   329 net.cpp:150] Setting up conv13/relu
I1016 09:56:12.330591   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330593   329 net.cpp:165] Memory required for data: 285081664
I1016 09:56:12.330596   329 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1016 09:56:12.330601   329 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1016 09:56:12.330605   329 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1016 09:56:12.330610   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1016 09:56:12.330618   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1016 09:56:12.330623   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1016 09:56:12.330627   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1016 09:56:12.330631   329 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1016 09:56:12.330716   329 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1016 09:56:12.330723   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330725   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330729   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330730   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330734   329 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1016 09:56:12.330735   329 net.cpp:165] Memory required for data: 288153664
I1016 09:56:12.330737   329 layer_factory.hpp:77] Creating layer conv14_1
I1016 09:56:12.330745   329 net.cpp:100] Creating Layer conv14_1
I1016 09:56:12.330749   329 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1016 09:56:12.330752   329 net.cpp:408] conv14_1 -> conv14_1
I1016 09:56:12.334825   329 net.cpp:150] Setting up conv14_1
I1016 09:56:12.334837   329 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1016 09:56:12.334841   329 net.cpp:165] Memory required for data: 288307264
I1016 09:56:12.334846   329 layer_factory.hpp:77] Creating layer conv14_1/bn
I1016 09:56:12.334849   329 net.cpp:100] Creating Layer conv14_1/bn
I1016 09:56:12.334852   329 net.cpp:434] conv14_1/bn <- conv14_1
I1016 09:56:12.334858   329 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1016 09:56:12.335067   329 net.cpp:150] Setting up conv14_1/bn
I1016 09:56:12.335074   329 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1016 09:56:12.335077   329 net.cpp:165] Memory required for data: 288460864
I1016 09:56:12.335083   329 layer_factory.hpp:77] Creating layer conv14_1/scale
I1016 09:56:12.335088   329 net.cpp:100] Creating Layer conv14_1/scale
I1016 09:56:12.335091   329 net.cpp:434] conv14_1/scale <- conv14_1
I1016 09:56:12.335095   329 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1016 09:56:12.335139   329 layer_factory.hpp:77] Creating layer conv14_1/scale
I1016 09:56:12.335263   329 net.cpp:150] Setting up conv14_1/scale
I1016 09:56:12.335269   329 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1016 09:56:12.335271   329 net.cpp:165] Memory required for data: 288614464
I1016 09:56:12.335276   329 layer_factory.hpp:77] Creating layer conv14_1/relu
I1016 09:56:12.335283   329 net.cpp:100] Creating Layer conv14_1/relu
I1016 09:56:12.335285   329 net.cpp:434] conv14_1/relu <- conv14_1
I1016 09:56:12.335289   329 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1016 09:56:12.335681   329 net.cpp:150] Setting up conv14_1/relu
I1016 09:56:12.335691   329 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1016 09:56:12.335693   329 net.cpp:165] Memory required for data: 288768064
I1016 09:56:12.335696   329 layer_factory.hpp:77] Creating layer conv14_2
I1016 09:56:12.335707   329 net.cpp:100] Creating Layer conv14_2
I1016 09:56:12.335711   329 net.cpp:434] conv14_2 <- conv14_1
I1016 09:56:12.335717   329 net.cpp:408] conv14_2 -> conv14_2
I1016 09:56:12.348106   329 net.cpp:150] Setting up conv14_2
I1016 09:56:12.348125   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.348129   329 net.cpp:165] Memory required for data: 288849984
I1016 09:56:12.348134   329 layer_factory.hpp:77] Creating layer conv14_2/bn
I1016 09:56:12.348143   329 net.cpp:100] Creating Layer conv14_2/bn
I1016 09:56:12.348147   329 net.cpp:434] conv14_2/bn <- conv14_2
I1016 09:56:12.348152   329 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1016 09:56:12.348414   329 net.cpp:150] Setting up conv14_2/bn
I1016 09:56:12.348421   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.348424   329 net.cpp:165] Memory required for data: 288931904
I1016 09:56:12.348433   329 layer_factory.hpp:77] Creating layer conv14_2/scale
I1016 09:56:12.348439   329 net.cpp:100] Creating Layer conv14_2/scale
I1016 09:56:12.348443   329 net.cpp:434] conv14_2/scale <- conv14_2
I1016 09:56:12.348446   329 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1016 09:56:12.348491   329 layer_factory.hpp:77] Creating layer conv14_2/scale
I1016 09:56:12.348628   329 net.cpp:150] Setting up conv14_2/scale
I1016 09:56:12.348635   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.348639   329 net.cpp:165] Memory required for data: 289013824
I1016 09:56:12.348642   329 layer_factory.hpp:77] Creating layer conv14_2/relu
I1016 09:56:12.348647   329 net.cpp:100] Creating Layer conv14_2/relu
I1016 09:56:12.348649   329 net.cpp:434] conv14_2/relu <- conv14_2
I1016 09:56:12.348654   329 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1016 09:56:12.349404   329 net.cpp:150] Setting up conv14_2/relu
I1016 09:56:12.349417   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.349419   329 net.cpp:165] Memory required for data: 289095744
I1016 09:56:12.349422   329 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1016 09:56:12.349428   329 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1016 09:56:12.349431   329 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1016 09:56:12.349437   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1016 09:56:12.349443   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1016 09:56:12.349448   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1016 09:56:12.349452   329 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1016 09:56:12.349536   329 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1016 09:56:12.349542   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.349545   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.349548   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.349550   329 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1016 09:56:12.349552   329 net.cpp:165] Memory required for data: 289423424
I1016 09:56:12.349555   329 layer_factory.hpp:77] Creating layer conv15_1
I1016 09:56:12.349563   329 net.cpp:100] Creating Layer conv15_1
I1016 09:56:12.349566   329 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1016 09:56:12.349575   329 net.cpp:408] conv15_1 -> conv15_1
I1016 09:56:12.352712   329 net.cpp:150] Setting up conv15_1
I1016 09:56:12.352725   329 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1016 09:56:12.352728   329 net.cpp:165] Memory required for data: 289443904
I1016 09:56:12.352733   329 layer_factory.hpp:77] Creating layer conv15_1/bn
I1016 09:56:12.352741   329 net.cpp:100] Creating Layer conv15_1/bn
I1016 09:56:12.352744   329 net.cpp:434] conv15_1/bn <- conv15_1
I1016 09:56:12.352751   329 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1016 09:56:12.352963   329 net.cpp:150] Setting up conv15_1/bn
I1016 09:56:12.352970   329 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1016 09:56:12.352972   329 net.cpp:165] Memory required for data: 289464384
I1016 09:56:12.352978   329 layer_factory.hpp:77] Creating layer conv15_1/scale
I1016 09:56:12.352983   329 net.cpp:100] Creating Layer conv15_1/scale
I1016 09:56:12.352986   329 net.cpp:434] conv15_1/scale <- conv15_1
I1016 09:56:12.352989   329 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1016 09:56:12.353031   329 layer_factory.hpp:77] Creating layer conv15_1/scale
I1016 09:56:12.353155   329 net.cpp:150] Setting up conv15_1/scale
I1016 09:56:12.353160   329 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1016 09:56:12.353163   329 net.cpp:165] Memory required for data: 289484864
I1016 09:56:12.353166   329 layer_factory.hpp:77] Creating layer conv15_1/relu
I1016 09:56:12.353171   329 net.cpp:100] Creating Layer conv15_1/relu
I1016 09:56:12.353173   329 net.cpp:434] conv15_1/relu <- conv15_1
I1016 09:56:12.353178   329 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1016 09:56:12.353577   329 net.cpp:150] Setting up conv15_1/relu
I1016 09:56:12.353587   329 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1016 09:56:12.353590   329 net.cpp:165] Memory required for data: 289505344
I1016 09:56:12.353592   329 layer_factory.hpp:77] Creating layer conv15_2
I1016 09:56:12.353600   329 net.cpp:100] Creating Layer conv15_2
I1016 09:56:12.353605   329 net.cpp:434] conv15_2 <- conv15_1
I1016 09:56:12.353610   329 net.cpp:408] conv15_2 -> conv15_2
I1016 09:56:12.358808   329 net.cpp:150] Setting up conv15_2
I1016 09:56:12.358820   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.358824   329 net.cpp:165] Memory required for data: 289517632
I1016 09:56:12.358827   329 layer_factory.hpp:77] Creating layer conv15_2/bn
I1016 09:56:12.358855   329 net.cpp:100] Creating Layer conv15_2/bn
I1016 09:56:12.358858   329 net.cpp:434] conv15_2/bn <- conv15_2
I1016 09:56:12.358863   329 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1016 09:56:12.359088   329 net.cpp:150] Setting up conv15_2/bn
I1016 09:56:12.359097   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359098   329 net.cpp:165] Memory required for data: 289529920
I1016 09:56:12.359104   329 layer_factory.hpp:77] Creating layer conv15_2/scale
I1016 09:56:12.359112   329 net.cpp:100] Creating Layer conv15_2/scale
I1016 09:56:12.359115   329 net.cpp:434] conv15_2/scale <- conv15_2
I1016 09:56:12.359119   329 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1016 09:56:12.359163   329 layer_factory.hpp:77] Creating layer conv15_2/scale
I1016 09:56:12.359287   329 net.cpp:150] Setting up conv15_2/scale
I1016 09:56:12.359294   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359297   329 net.cpp:165] Memory required for data: 289542208
I1016 09:56:12.359302   329 layer_factory.hpp:77] Creating layer conv15_2/relu
I1016 09:56:12.359306   329 net.cpp:100] Creating Layer conv15_2/relu
I1016 09:56:12.359309   329 net.cpp:434] conv15_2/relu <- conv15_2
I1016 09:56:12.359313   329 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1016 09:56:12.359714   329 net.cpp:150] Setting up conv15_2/relu
I1016 09:56:12.359725   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359727   329 net.cpp:165] Memory required for data: 289554496
I1016 09:56:12.359730   329 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1016 09:56:12.359735   329 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1016 09:56:12.359738   329 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1016 09:56:12.359745   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1016 09:56:12.359751   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1016 09:56:12.359756   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1016 09:56:12.359761   329 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1016 09:56:12.359848   329 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1016 09:56:12.359853   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359856   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359858   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359861   329 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1016 09:56:12.359863   329 net.cpp:165] Memory required for data: 289603648
I1016 09:56:12.359865   329 layer_factory.hpp:77] Creating layer conv16_1
I1016 09:56:12.359874   329 net.cpp:100] Creating Layer conv16_1
I1016 09:56:12.359876   329 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1016 09:56:12.359881   329 net.cpp:408] conv16_1 -> conv16_1
I1016 09:56:12.362897   329 net.cpp:150] Setting up conv16_1
I1016 09:56:12.362910   329 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1016 09:56:12.362913   329 net.cpp:165] Memory required for data: 289609792
I1016 09:56:12.362918   329 layer_factory.hpp:77] Creating layer conv16_1/bn
I1016 09:56:12.362923   329 net.cpp:100] Creating Layer conv16_1/bn
I1016 09:56:12.362926   329 net.cpp:434] conv16_1/bn <- conv16_1
I1016 09:56:12.362931   329 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1016 09:56:12.363152   329 net.cpp:150] Setting up conv16_1/bn
I1016 09:56:12.363160   329 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1016 09:56:12.363162   329 net.cpp:165] Memory required for data: 289615936
I1016 09:56:12.363168   329 layer_factory.hpp:77] Creating layer conv16_1/scale
I1016 09:56:12.363173   329 net.cpp:100] Creating Layer conv16_1/scale
I1016 09:56:12.363176   329 net.cpp:434] conv16_1/scale <- conv16_1
I1016 09:56:12.363180   329 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1016 09:56:12.363224   329 layer_factory.hpp:77] Creating layer conv16_1/scale
I1016 09:56:12.363371   329 net.cpp:150] Setting up conv16_1/scale
I1016 09:56:12.363379   329 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1016 09:56:12.363381   329 net.cpp:165] Memory required for data: 289622080
I1016 09:56:12.363389   329 layer_factory.hpp:77] Creating layer conv16_1/relu
I1016 09:56:12.363394   329 net.cpp:100] Creating Layer conv16_1/relu
I1016 09:56:12.363399   329 net.cpp:434] conv16_1/relu <- conv16_1
I1016 09:56:12.363401   329 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1016 09:56:12.363811   329 net.cpp:150] Setting up conv16_1/relu
I1016 09:56:12.363821   329 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1016 09:56:12.363826   329 net.cpp:165] Memory required for data: 289628224
I1016 09:56:12.363829   329 layer_factory.hpp:77] Creating layer conv16_2
I1016 09:56:12.363840   329 net.cpp:100] Creating Layer conv16_2
I1016 09:56:12.363843   329 net.cpp:434] conv16_2 <- conv16_1
I1016 09:56:12.363849   329 net.cpp:408] conv16_2 -> conv16_2
I1016 09:56:12.368727   329 net.cpp:150] Setting up conv16_2
I1016 09:56:12.368742   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.368746   329 net.cpp:165] Memory required for data: 289632320
I1016 09:56:12.368753   329 layer_factory.hpp:77] Creating layer conv16_2/bn
I1016 09:56:12.368762   329 net.cpp:100] Creating Layer conv16_2/bn
I1016 09:56:12.368765   329 net.cpp:434] conv16_2/bn <- conv16_2
I1016 09:56:12.368772   329 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1016 09:56:12.369007   329 net.cpp:150] Setting up conv16_2/bn
I1016 09:56:12.369016   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.369020   329 net.cpp:165] Memory required for data: 289636416
I1016 09:56:12.369027   329 layer_factory.hpp:77] Creating layer conv16_2/scale
I1016 09:56:12.369035   329 net.cpp:100] Creating Layer conv16_2/scale
I1016 09:56:12.369040   329 net.cpp:434] conv16_2/scale <- conv16_2
I1016 09:56:12.369043   329 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1016 09:56:12.369098   329 layer_factory.hpp:77] Creating layer conv16_2/scale
I1016 09:56:12.369238   329 net.cpp:150] Setting up conv16_2/scale
I1016 09:56:12.369246   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.369249   329 net.cpp:165] Memory required for data: 289640512
I1016 09:56:12.369256   329 layer_factory.hpp:77] Creating layer conv16_2/relu
I1016 09:56:12.369261   329 net.cpp:100] Creating Layer conv16_2/relu
I1016 09:56:12.369264   329 net.cpp:434] conv16_2/relu <- conv16_2
I1016 09:56:12.369269   329 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1016 09:56:12.370095   329 net.cpp:150] Setting up conv16_2/relu
I1016 09:56:12.370108   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.370112   329 net.cpp:165] Memory required for data: 289644608
I1016 09:56:12.370117   329 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1016 09:56:12.370123   329 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1016 09:56:12.370127   329 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1016 09:56:12.370134   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1016 09:56:12.370143   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1016 09:56:12.370149   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1016 09:56:12.370154   329 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1016 09:56:12.370249   329 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1016 09:56:12.370256   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.370261   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.370265   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.370267   329 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1016 09:56:12.370270   329 net.cpp:165] Memory required for data: 289660992
I1016 09:56:12.370271   329 layer_factory.hpp:77] Creating layer conv17_1
I1016 09:56:12.370281   329 net.cpp:100] Creating Layer conv17_1
I1016 09:56:12.370285   329 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1016 09:56:12.370290   329 net.cpp:408] conv17_1 -> conv17_1
I1016 09:56:12.372246   329 net.cpp:150] Setting up conv17_1
I1016 09:56:12.372258   329 net.cpp:157] Top shape: 1 64 2 2 (256)
I1016 09:56:12.372262   329 net.cpp:165] Memory required for data: 289662016
I1016 09:56:12.372268   329 layer_factory.hpp:77] Creating layer conv17_1/bn
I1016 09:56:12.372275   329 net.cpp:100] Creating Layer conv17_1/bn
I1016 09:56:12.372279   329 net.cpp:434] conv17_1/bn <- conv17_1
I1016 09:56:12.372285   329 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1016 09:56:12.372531   329 net.cpp:150] Setting up conv17_1/bn
I1016 09:56:12.372540   329 net.cpp:157] Top shape: 1 64 2 2 (256)
I1016 09:56:12.372543   329 net.cpp:165] Memory required for data: 289663040
I1016 09:56:12.372551   329 layer_factory.hpp:77] Creating layer conv17_1/scale
I1016 09:56:12.372557   329 net.cpp:100] Creating Layer conv17_1/scale
I1016 09:56:12.372560   329 net.cpp:434] conv17_1/scale <- conv17_1
I1016 09:56:12.372566   329 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1016 09:56:12.372619   329 layer_factory.hpp:77] Creating layer conv17_1/scale
I1016 09:56:12.372773   329 net.cpp:150] Setting up conv17_1/scale
I1016 09:56:12.372781   329 net.cpp:157] Top shape: 1 64 2 2 (256)
I1016 09:56:12.372784   329 net.cpp:165] Memory required for data: 289664064
I1016 09:56:12.372792   329 layer_factory.hpp:77] Creating layer conv17_1/relu
I1016 09:56:12.372797   329 net.cpp:100] Creating Layer conv17_1/relu
I1016 09:56:12.372800   329 net.cpp:434] conv17_1/relu <- conv17_1
I1016 09:56:12.372807   329 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1016 09:56:12.373211   329 net.cpp:150] Setting up conv17_1/relu
I1016 09:56:12.373221   329 net.cpp:157] Top shape: 1 64 2 2 (256)
I1016 09:56:12.373225   329 net.cpp:165] Memory required for data: 289665088
I1016 09:56:12.373229   329 layer_factory.hpp:77] Creating layer conv17_2
I1016 09:56:12.373239   329 net.cpp:100] Creating Layer conv17_2
I1016 09:56:12.373242   329 net.cpp:434] conv17_2 <- conv17_1
I1016 09:56:12.373250   329 net.cpp:408] conv17_2 -> conv17_2
I1016 09:56:12.375619   329 net.cpp:150] Setting up conv17_2
I1016 09:56:12.375633   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.375636   329 net.cpp:165] Memory required for data: 289665600
I1016 09:56:12.375643   329 layer_factory.hpp:77] Creating layer conv17_2/bn
I1016 09:56:12.375649   329 net.cpp:100] Creating Layer conv17_2/bn
I1016 09:56:12.375653   329 net.cpp:434] conv17_2/bn <- conv17_2
I1016 09:56:12.375658   329 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1016 09:56:12.375893   329 net.cpp:150] Setting up conv17_2/bn
I1016 09:56:12.375901   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.375905   329 net.cpp:165] Memory required for data: 289666112
I1016 09:56:12.375912   329 layer_factory.hpp:77] Creating layer conv17_2/scale
I1016 09:56:12.375918   329 net.cpp:100] Creating Layer conv17_2/scale
I1016 09:56:12.375921   329 net.cpp:434] conv17_2/scale <- conv17_2
I1016 09:56:12.375928   329 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1016 09:56:12.375977   329 layer_factory.hpp:77] Creating layer conv17_2/scale
I1016 09:56:12.376121   329 net.cpp:150] Setting up conv17_2/scale
I1016 09:56:12.376128   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.376132   329 net.cpp:165] Memory required for data: 289666624
I1016 09:56:12.376138   329 layer_factory.hpp:77] Creating layer conv17_2/relu
I1016 09:56:12.376142   329 net.cpp:100] Creating Layer conv17_2/relu
I1016 09:56:12.376145   329 net.cpp:434] conv17_2/relu <- conv17_2
I1016 09:56:12.376152   329 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1016 09:56:12.376559   329 net.cpp:150] Setting up conv17_2/relu
I1016 09:56:12.376570   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.376574   329 net.cpp:165] Memory required for data: 289667136
I1016 09:56:12.376577   329 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1016 09:56:12.376585   329 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1016 09:56:12.376587   329 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1016 09:56:12.376595   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1016 09:56:12.376602   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1016 09:56:12.376607   329 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1016 09:56:12.376683   329 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1016 09:56:12.376689   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.376693   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.376694   329 net.cpp:157] Top shape: 1 128 1 1 (128)
I1016 09:56:12.376696   329 net.cpp:165] Memory required for data: 289668672
I1016 09:56:12.376698   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1016 09:56:12.376708   329 net.cpp:100] Creating Layer conv11_mbox_loc
I1016 09:56:12.376710   329 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1016 09:56:12.376716   329 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1016 09:56:12.378644   329 net.cpp:150] Setting up conv11_mbox_loc
I1016 09:56:12.378659   329 net.cpp:157] Top shape: 1 12 20 30 (7200)
I1016 09:56:12.378662   329 net.cpp:165] Memory required for data: 289697472
I1016 09:56:12.378670   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1016 09:56:12.378679   329 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1016 09:56:12.378684   329 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1016 09:56:12.378690   329 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1016 09:56:12.378829   329 net.cpp:150] Setting up conv11_mbox_loc_perm
I1016 09:56:12.378839   329 net.cpp:157] Top shape: 1 20 30 12 (7200)
I1016 09:56:12.378841   329 net.cpp:165] Memory required for data: 289726272
I1016 09:56:12.378845   329 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1016 09:56:12.378852   329 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1016 09:56:12.378855   329 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1016 09:56:12.378860   329 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1016 09:56:12.378892   329 net.cpp:150] Setting up conv11_mbox_loc_flat
I1016 09:56:12.378897   329 net.cpp:157] Top shape: 1 7200 (7200)
I1016 09:56:12.378901   329 net.cpp:165] Memory required for data: 289755072
I1016 09:56:12.378904   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1016 09:56:12.378916   329 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1016 09:56:12.378921   329 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1016 09:56:12.378927   329 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1016 09:56:12.381366   329 net.cpp:150] Setting up conv11_mbox_conf_new
I1016 09:56:12.381381   329 net.cpp:157] Top shape: 1 9 20 30 (5400)
I1016 09:56:12.381386   329 net.cpp:165] Memory required for data: 289776672
I1016 09:56:12.381393   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1016 09:56:12.381399   329 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1016 09:56:12.381402   329 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1016 09:56:12.381408   329 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1016 09:56:12.381551   329 net.cpp:150] Setting up conv11_mbox_conf_perm
I1016 09:56:12.381561   329 net.cpp:157] Top shape: 1 20 30 9 (5400)
I1016 09:56:12.381563   329 net.cpp:165] Memory required for data: 289798272
I1016 09:56:12.381567   329 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1016 09:56:12.381572   329 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1016 09:56:12.381575   329 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1016 09:56:12.381580   329 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1016 09:56:12.381611   329 net.cpp:150] Setting up conv11_mbox_conf_flat
I1016 09:56:12.381618   329 net.cpp:157] Top shape: 1 5400 (5400)
I1016 09:56:12.381619   329 net.cpp:165] Memory required for data: 289819872
I1016 09:56:12.381621   329 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1016 09:56:12.381630   329 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1016 09:56:12.381634   329 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1016 09:56:12.381640   329 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1016 09:56:12.381649   329 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1016 09:56:12.381681   329 net.cpp:150] Setting up conv11_mbox_priorbox
I1016 09:56:12.381686   329 net.cpp:157] Top shape: 1 2 7200 (14400)
I1016 09:56:12.381688   329 net.cpp:165] Memory required for data: 289877472
I1016 09:56:12.381691   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1016 09:56:12.381703   329 net.cpp:100] Creating Layer conv13_mbox_loc
I1016 09:56:12.381708   329 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1016 09:56:12.381713   329 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1016 09:56:12.384745   329 net.cpp:150] Setting up conv13_mbox_loc
I1016 09:56:12.384758   329 net.cpp:157] Top shape: 1 24 10 15 (3600)
I1016 09:56:12.384763   329 net.cpp:165] Memory required for data: 289891872
I1016 09:56:12.384770   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1016 09:56:12.384778   329 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1016 09:56:12.384780   329 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1016 09:56:12.384786   329 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1016 09:56:12.384932   329 net.cpp:150] Setting up conv13_mbox_loc_perm
I1016 09:56:12.384940   329 net.cpp:157] Top shape: 1 10 15 24 (3600)
I1016 09:56:12.384944   329 net.cpp:165] Memory required for data: 289906272
I1016 09:56:12.384948   329 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1016 09:56:12.384953   329 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1016 09:56:12.384958   329 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1016 09:56:12.384961   329 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1016 09:56:12.384994   329 net.cpp:150] Setting up conv13_mbox_loc_flat
I1016 09:56:12.384999   329 net.cpp:157] Top shape: 1 3600 (3600)
I1016 09:56:12.385001   329 net.cpp:165] Memory required for data: 289920672
I1016 09:56:12.385004   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1016 09:56:12.385012   329 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1016 09:56:12.385016   329 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1016 09:56:12.385025   329 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1016 09:56:12.387264   329 net.cpp:150] Setting up conv13_mbox_conf_new
I1016 09:56:12.387279   329 net.cpp:157] Top shape: 1 18 10 15 (2700)
I1016 09:56:12.387282   329 net.cpp:165] Memory required for data: 289931472
I1016 09:56:12.387290   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1016 09:56:12.387297   329 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1016 09:56:12.387300   329 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1016 09:56:12.387307   329 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1016 09:56:12.387446   329 net.cpp:150] Setting up conv13_mbox_conf_perm
I1016 09:56:12.387455   329 net.cpp:157] Top shape: 1 10 15 18 (2700)
I1016 09:56:12.387459   329 net.cpp:165] Memory required for data: 289942272
I1016 09:56:12.387462   329 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1016 09:56:12.387470   329 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1016 09:56:12.387473   329 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1016 09:56:12.387480   329 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1016 09:56:12.387513   329 net.cpp:150] Setting up conv13_mbox_conf_flat
I1016 09:56:12.387519   329 net.cpp:157] Top shape: 1 2700 (2700)
I1016 09:56:12.387521   329 net.cpp:165] Memory required for data: 289953072
I1016 09:56:12.387524   329 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1016 09:56:12.387532   329 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1016 09:56:12.387536   329 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1016 09:56:12.387539   329 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1016 09:56:12.387544   329 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1016 09:56:12.387578   329 net.cpp:150] Setting up conv13_mbox_priorbox
I1016 09:56:12.387583   329 net.cpp:157] Top shape: 1 2 3600 (7200)
I1016 09:56:12.387584   329 net.cpp:165] Memory required for data: 289981872
I1016 09:56:12.387588   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1016 09:56:12.387595   329 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1016 09:56:12.387598   329 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1016 09:56:12.387605   329 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1016 09:56:12.389576   329 net.cpp:150] Setting up conv14_2_mbox_loc
I1016 09:56:12.389588   329 net.cpp:157] Top shape: 1 24 5 8 (960)
I1016 09:56:12.389592   329 net.cpp:165] Memory required for data: 289985712
I1016 09:56:12.389600   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1016 09:56:12.389609   329 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1016 09:56:12.389613   329 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1016 09:56:12.389621   329 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1016 09:56:12.389762   329 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1016 09:56:12.389772   329 net.cpp:157] Top shape: 1 5 8 24 (960)
I1016 09:56:12.389775   329 net.cpp:165] Memory required for data: 289989552
I1016 09:56:12.389780   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1016 09:56:12.389784   329 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1016 09:56:12.389787   329 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1016 09:56:12.389794   329 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1016 09:56:12.389832   329 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1016 09:56:12.389842   329 net.cpp:157] Top shape: 1 960 (960)
I1016 09:56:12.389844   329 net.cpp:165] Memory required for data: 289993392
I1016 09:56:12.389847   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1016 09:56:12.389855   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1016 09:56:12.389860   329 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1016 09:56:12.389866   329 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1016 09:56:12.391808   329 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1016 09:56:12.391820   329 net.cpp:157] Top shape: 1 18 5 8 (720)
I1016 09:56:12.391824   329 net.cpp:165] Memory required for data: 289996272
I1016 09:56:12.391832   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1016 09:56:12.391839   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1016 09:56:12.391841   329 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1016 09:56:12.391851   329 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1016 09:56:12.391990   329 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1016 09:56:12.391999   329 net.cpp:157] Top shape: 1 5 8 18 (720)
I1016 09:56:12.392002   329 net.cpp:165] Memory required for data: 289999152
I1016 09:56:12.392006   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1016 09:56:12.392011   329 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1016 09:56:12.392014   329 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1016 09:56:12.392021   329 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1016 09:56:12.392060   329 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1016 09:56:12.392068   329 net.cpp:157] Top shape: 1 720 (720)
I1016 09:56:12.392071   329 net.cpp:165] Memory required for data: 290002032
I1016 09:56:12.392073   329 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1016 09:56:12.392079   329 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1016 09:56:12.392084   329 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1016 09:56:12.392087   329 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1016 09:56:12.392093   329 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1016 09:56:12.392128   329 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1016 09:56:12.392134   329 net.cpp:157] Top shape: 1 2 960 (1920)
I1016 09:56:12.392135   329 net.cpp:165] Memory required for data: 290009712
I1016 09:56:12.392138   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1016 09:56:12.392146   329 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1016 09:56:12.392149   329 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1016 09:56:12.392156   329 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1016 09:56:12.394102   329 net.cpp:150] Setting up conv15_2_mbox_loc
I1016 09:56:12.394114   329 net.cpp:157] Top shape: 1 24 3 4 (288)
I1016 09:56:12.394119   329 net.cpp:165] Memory required for data: 290010864
I1016 09:56:12.394126   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1016 09:56:12.394135   329 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1016 09:56:12.394138   329 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1016 09:56:12.394145   329 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1016 09:56:12.394284   329 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1016 09:56:12.394291   329 net.cpp:157] Top shape: 1 3 4 24 (288)
I1016 09:56:12.394295   329 net.cpp:165] Memory required for data: 290012016
I1016 09:56:12.394299   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1016 09:56:12.394305   329 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1016 09:56:12.394309   329 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1016 09:56:12.394315   329 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1016 09:56:12.394346   329 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1016 09:56:12.394353   329 net.cpp:157] Top shape: 1 288 (288)
I1016 09:56:12.394356   329 net.cpp:165] Memory required for data: 290013168
I1016 09:56:12.394359   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1016 09:56:12.394369   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1016 09:56:12.394373   329 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1016 09:56:12.394379   329 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1016 09:56:12.396286   329 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1016 09:56:12.396297   329 net.cpp:157] Top shape: 1 18 3 4 (216)
I1016 09:56:12.396301   329 net.cpp:165] Memory required for data: 290014032
I1016 09:56:12.396309   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1016 09:56:12.396317   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1016 09:56:12.396322   329 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1016 09:56:12.396329   329 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1016 09:56:12.396469   329 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1016 09:56:12.396478   329 net.cpp:157] Top shape: 1 3 4 18 (216)
I1016 09:56:12.396481   329 net.cpp:165] Memory required for data: 290014896
I1016 09:56:12.396486   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1016 09:56:12.396492   329 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1016 09:56:12.396494   329 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1016 09:56:12.396502   329 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1016 09:56:12.396534   329 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1016 09:56:12.396541   329 net.cpp:157] Top shape: 1 216 (216)
I1016 09:56:12.396543   329 net.cpp:165] Memory required for data: 290015760
I1016 09:56:12.396546   329 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1016 09:56:12.396553   329 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1016 09:56:12.396559   329 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1016 09:56:12.396562   329 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1016 09:56:12.396567   329 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1016 09:56:12.396600   329 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1016 09:56:12.396605   329 net.cpp:157] Top shape: 1 2 288 (576)
I1016 09:56:12.396607   329 net.cpp:165] Memory required for data: 290018064
I1016 09:56:12.396610   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1016 09:56:12.396620   329 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1016 09:56:12.396622   329 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1016 09:56:12.396628   329 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1016 09:56:12.398613   329 net.cpp:150] Setting up conv16_2_mbox_loc
I1016 09:56:12.398627   329 net.cpp:157] Top shape: 1 24 2 2 (96)
I1016 09:56:12.398630   329 net.cpp:165] Memory required for data: 290018448
I1016 09:56:12.398638   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1016 09:56:12.398645   329 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1016 09:56:12.398648   329 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1016 09:56:12.398655   329 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1016 09:56:12.398797   329 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1016 09:56:12.398805   329 net.cpp:157] Top shape: 1 2 2 24 (96)
I1016 09:56:12.398808   329 net.cpp:165] Memory required for data: 290018832
I1016 09:56:12.398811   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1016 09:56:12.398818   329 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1016 09:56:12.398820   329 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1016 09:56:12.398828   329 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1016 09:56:12.398859   329 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1016 09:56:12.398865   329 net.cpp:157] Top shape: 1 96 (96)
I1016 09:56:12.398869   329 net.cpp:165] Memory required for data: 290019216
I1016 09:56:12.398872   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1016 09:56:12.398882   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1016 09:56:12.398886   329 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1016 09:56:12.398895   329 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1016 09:56:12.400846   329 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1016 09:56:12.400861   329 net.cpp:157] Top shape: 1 18 2 2 (72)
I1016 09:56:12.400863   329 net.cpp:165] Memory required for data: 290019504
I1016 09:56:12.400872   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1016 09:56:12.400882   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1016 09:56:12.400885   329 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1016 09:56:12.400890   329 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1016 09:56:12.401031   329 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1016 09:56:12.401039   329 net.cpp:157] Top shape: 1 2 2 18 (72)
I1016 09:56:12.401043   329 net.cpp:165] Memory required for data: 290019792
I1016 09:56:12.401046   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1016 09:56:12.401055   329 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1016 09:56:12.401060   329 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1016 09:56:12.401064   329 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1016 09:56:12.401099   329 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1016 09:56:12.401105   329 net.cpp:157] Top shape: 1 72 (72)
I1016 09:56:12.401109   329 net.cpp:165] Memory required for data: 290020080
I1016 09:56:12.401113   329 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1016 09:56:12.401120   329 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1016 09:56:12.401124   329 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1016 09:56:12.401127   329 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1016 09:56:12.401134   329 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1016 09:56:12.401168   329 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1016 09:56:12.401173   329 net.cpp:157] Top shape: 1 2 96 (192)
I1016 09:56:12.401176   329 net.cpp:165] Memory required for data: 290020848
I1016 09:56:12.401180   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1016 09:56:12.401191   329 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1016 09:56:12.401196   329 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1016 09:56:12.401203   329 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1016 09:56:12.403661   329 net.cpp:150] Setting up conv17_2_mbox_loc
I1016 09:56:12.403672   329 net.cpp:157] Top shape: 1 24 1 1 (24)
I1016 09:56:12.403677   329 net.cpp:165] Memory required for data: 290020944
I1016 09:56:12.403686   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1016 09:56:12.403693   329 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1016 09:56:12.403697   329 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1016 09:56:12.403703   329 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1016 09:56:12.403846   329 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1016 09:56:12.403854   329 net.cpp:157] Top shape: 1 1 1 24 (24)
I1016 09:56:12.403857   329 net.cpp:165] Memory required for data: 290021040
I1016 09:56:12.403861   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1016 09:56:12.403868   329 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1016 09:56:12.403870   329 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1016 09:56:12.403877   329 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1016 09:56:12.403908   329 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1016 09:56:12.403913   329 net.cpp:157] Top shape: 1 24 (24)
I1016 09:56:12.403914   329 net.cpp:165] Memory required for data: 290021136
I1016 09:56:12.403918   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1016 09:56:12.403929   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1016 09:56:12.403934   329 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1016 09:56:12.403941   329 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1016 09:56:12.406805   329 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1016 09:56:12.406817   329 net.cpp:157] Top shape: 1 18 1 1 (18)
I1016 09:56:12.406821   329 net.cpp:165] Memory required for data: 290021208
I1016 09:56:12.406829   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1016 09:56:12.406844   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1016 09:56:12.406848   329 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1016 09:56:12.406854   329 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1016 09:56:12.406997   329 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1016 09:56:12.407006   329 net.cpp:157] Top shape: 1 1 1 18 (18)
I1016 09:56:12.407011   329 net.cpp:165] Memory required for data: 290021280
I1016 09:56:12.407014   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1016 09:56:12.407019   329 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1016 09:56:12.407022   329 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1016 09:56:12.407029   329 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1016 09:56:12.407060   329 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1016 09:56:12.407066   329 net.cpp:157] Top shape: 1 18 (18)
I1016 09:56:12.407068   329 net.cpp:165] Memory required for data: 290021352
I1016 09:56:12.407070   329 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1016 09:56:12.407076   329 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1016 09:56:12.407078   329 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1016 09:56:12.407083   329 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1016 09:56:12.407088   329 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1016 09:56:12.407117   329 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1016 09:56:12.407121   329 net.cpp:157] Top shape: 1 2 24 (48)
I1016 09:56:12.407124   329 net.cpp:165] Memory required for data: 290021544
I1016 09:56:12.407126   329 layer_factory.hpp:77] Creating layer mbox_loc
I1016 09:56:12.407131   329 net.cpp:100] Creating Layer mbox_loc
I1016 09:56:12.407135   329 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1016 09:56:12.407138   329 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1016 09:56:12.407142   329 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1016 09:56:12.407146   329 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1016 09:56:12.407148   329 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1016 09:56:12.407151   329 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1016 09:56:12.407156   329 net.cpp:408] mbox_loc -> mbox_loc
I1016 09:56:12.407191   329 net.cpp:150] Setting up mbox_loc
I1016 09:56:12.407198   329 net.cpp:157] Top shape: 1 12168 (12168)
I1016 09:56:12.407202   329 net.cpp:165] Memory required for data: 290070216
I1016 09:56:12.407205   329 layer_factory.hpp:77] Creating layer mbox_conf
I1016 09:56:12.407212   329 net.cpp:100] Creating Layer mbox_conf
I1016 09:56:12.407215   329 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1016 09:56:12.407220   329 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1016 09:56:12.407224   329 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1016 09:56:12.407228   329 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1016 09:56:12.407232   329 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1016 09:56:12.407238   329 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1016 09:56:12.407241   329 net.cpp:408] mbox_conf -> mbox_conf
I1016 09:56:12.407272   329 net.cpp:150] Setting up mbox_conf
I1016 09:56:12.407277   329 net.cpp:157] Top shape: 1 9126 (9126)
I1016 09:56:12.407281   329 net.cpp:165] Memory required for data: 290106720
I1016 09:56:12.407285   329 layer_factory.hpp:77] Creating layer mbox_priorbox
I1016 09:56:12.407289   329 net.cpp:100] Creating Layer mbox_priorbox
I1016 09:56:12.407292   329 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1016 09:56:12.407295   329 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1016 09:56:12.407299   329 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1016 09:56:12.407301   329 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1016 09:56:12.407305   329 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1016 09:56:12.407306   329 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1016 09:56:12.407310   329 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1016 09:56:12.407343   329 net.cpp:150] Setting up mbox_priorbox
I1016 09:56:12.407351   329 net.cpp:157] Top shape: 1 2 12168 (24336)
I1016 09:56:12.407353   329 net.cpp:165] Memory required for data: 290204064
I1016 09:56:12.407357   329 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I1016 09:56:12.407366   329 net.cpp:100] Creating Layer mbox_conf_reshape
I1016 09:56:12.407369   329 net.cpp:434] mbox_conf_reshape <- mbox_conf
I1016 09:56:12.407377   329 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I1016 09:56:12.407413   329 net.cpp:150] Setting up mbox_conf_reshape
I1016 09:56:12.407418   329 net.cpp:157] Top shape: 1 3042 3 (9126)
I1016 09:56:12.407421   329 net.cpp:165] Memory required for data: 290240568
I1016 09:56:12.407424   329 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I1016 09:56:12.407433   329 net.cpp:100] Creating Layer mbox_conf_softmax
I1016 09:56:12.407436   329 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I1016 09:56:12.407441   329 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I1016 09:56:12.408325   329 net.cpp:150] Setting up mbox_conf_softmax
I1016 09:56:12.408339   329 net.cpp:157] Top shape: 1 3042 3 (9126)
I1016 09:56:12.408341   329 net.cpp:165] Memory required for data: 290277072
I1016 09:56:12.408346   329 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I1016 09:56:12.408352   329 net.cpp:100] Creating Layer mbox_conf_flatten
I1016 09:56:12.408356   329 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I1016 09:56:12.408362   329 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I1016 09:56:12.408397   329 net.cpp:150] Setting up mbox_conf_flatten
I1016 09:56:12.408402   329 net.cpp:157] Top shape: 1 9126 (9126)
I1016 09:56:12.408406   329 net.cpp:165] Memory required for data: 290313576
I1016 09:56:12.408409   329 layer_factory.hpp:77] Creating layer detection_out
I1016 09:56:12.408421   329 net.cpp:100] Creating Layer detection_out
I1016 09:56:12.408424   329 net.cpp:434] detection_out <- mbox_loc
I1016 09:56:12.408432   329 net.cpp:434] detection_out <- mbox_conf_flatten
I1016 09:56:12.408434   329 net.cpp:434] detection_out <- mbox_priorbox
I1016 09:56:12.408442   329 net.cpp:408] detection_out -> detection_out
I1016 09:56:12.408521   329 net.cpp:150] Setting up detection_out
I1016 09:56:12.408527   329 net.cpp:157] Top shape: 1 1 1 7 (7)
I1016 09:56:12.408529   329 net.cpp:165] Memory required for data: 290313604
I1016 09:56:12.408531   329 layer_factory.hpp:77] Creating layer detection_eval
I1016 09:56:12.408538   329 net.cpp:100] Creating Layer detection_eval
I1016 09:56:12.408542   329 net.cpp:434] detection_eval <- detection_out
I1016 09:56:12.408547   329 net.cpp:434] detection_eval <- label
I1016 09:56:12.408553   329 net.cpp:408] detection_eval -> detection_eval
I1016 09:56:12.408614   329 net.cpp:150] Setting up detection_eval
I1016 09:56:12.408622   329 net.cpp:157] Top shape: 1 1 3 5 (15)
I1016 09:56:12.408624   329 net.cpp:165] Memory required for data: 290313664
I1016 09:56:12.408627   329 layer_factory.hpp:77] Creating layer score_32
I1016 09:56:12.408634   329 net.cpp:100] Creating Layer score_32
I1016 09:56:12.408638   329 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1016 09:56:12.408643   329 net.cpp:408] score_32 -> score_32
I1016 09:56:12.410619   329 net.cpp:150] Setting up score_32
I1016 09:56:12.410635   329 net.cpp:157] Top shape: 1 2 10 15 (300)
I1016 09:56:12.410640   329 net.cpp:165] Memory required for data: 290314864
I1016 09:56:12.410648   329 layer_factory.hpp:77] Creating layer upscore_16
I1016 09:56:12.410656   329 net.cpp:100] Creating Layer upscore_16
I1016 09:56:12.410660   329 net.cpp:434] upscore_16 <- score_32
I1016 09:56:12.410668   329 net.cpp:408] upscore_16 -> upscore_16
I1016 09:56:12.410923   329 net.cpp:150] Setting up upscore_16
I1016 09:56:12.410931   329 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1016 09:56:12.410935   329 net.cpp:165] Memory required for data: 290319664
I1016 09:56:12.410940   329 layer_factory.hpp:77] Creating layer score_16
I1016 09:56:12.410946   329 net.cpp:100] Creating Layer score_16
I1016 09:56:12.410950   329 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1016 09:56:12.410959   329 net.cpp:408] score_16 -> score_16
I1016 09:56:12.413218   329 net.cpp:150] Setting up score_16
I1016 09:56:12.413230   329 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1016 09:56:12.413234   329 net.cpp:165] Memory required for data: 290324464
I1016 09:56:12.413242   329 layer_factory.hpp:77] Creating layer fuse_16
I1016 09:56:12.413251   329 net.cpp:100] Creating Layer fuse_16
I1016 09:56:12.413254   329 net.cpp:434] fuse_16 <- upscore_16
I1016 09:56:12.413257   329 net.cpp:434] fuse_16 <- score_16
I1016 09:56:12.413261   329 net.cpp:408] fuse_16 -> fuse_16
I1016 09:56:12.413321   329 net.cpp:150] Setting up fuse_16
I1016 09:56:12.413331   329 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1016 09:56:12.413333   329 net.cpp:165] Memory required for data: 290329264
I1016 09:56:12.413336   329 layer_factory.hpp:77] Creating layer upscore_8
I1016 09:56:12.413341   329 net.cpp:100] Creating Layer upscore_8
I1016 09:56:12.413343   329 net.cpp:434] upscore_8 <- fuse_16
I1016 09:56:12.413348   329 net.cpp:408] upscore_8 -> upscore_8
I1016 09:56:12.413594   329 net.cpp:150] Setting up upscore_8
I1016 09:56:12.413604   329 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1016 09:56:12.413606   329 net.cpp:165] Memory required for data: 290348464
I1016 09:56:12.413609   329 layer_factory.hpp:77] Creating layer score_8
I1016 09:56:12.413615   329 net.cpp:100] Creating Layer score_8
I1016 09:56:12.413619   329 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1016 09:56:12.413625   329 net.cpp:408] score_8 -> score_8
I1016 09:56:12.415925   329 net.cpp:150] Setting up score_8
I1016 09:56:12.415936   329 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1016 09:56:12.415940   329 net.cpp:165] Memory required for data: 290367664
I1016 09:56:12.415946   329 layer_factory.hpp:77] Creating layer fuse_8
I1016 09:56:12.415951   329 net.cpp:100] Creating Layer fuse_8
I1016 09:56:12.415954   329 net.cpp:434] fuse_8 <- upscore_8
I1016 09:56:12.415958   329 net.cpp:434] fuse_8 <- score_8
I1016 09:56:12.415962   329 net.cpp:408] fuse_8 -> fuse_8
I1016 09:56:12.415994   329 net.cpp:150] Setting up fuse_8
I1016 09:56:12.415999   329 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1016 09:56:12.416002   329 net.cpp:165] Memory required for data: 290386864
I1016 09:56:12.416003   329 layer_factory.hpp:77] Creating layer upscore_4
I1016 09:56:12.416009   329 net.cpp:100] Creating Layer upscore_4
I1016 09:56:12.416013   329 net.cpp:434] upscore_4 <- fuse_8
I1016 09:56:12.416016   329 net.cpp:408] upscore_4 -> upscore_4
I1016 09:56:12.416281   329 net.cpp:150] Setting up upscore_4
I1016 09:56:12.416290   329 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1016 09:56:12.416293   329 net.cpp:165] Memory required for data: 290463664
I1016 09:56:12.416298   329 layer_factory.hpp:77] Creating layer score_4
I1016 09:56:12.416309   329 net.cpp:100] Creating Layer score_4
I1016 09:56:12.416313   329 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1016 09:56:12.416321   329 net.cpp:408] score_4 -> score_4
I1016 09:56:12.418244   329 net.cpp:150] Setting up score_4
I1016 09:56:12.418256   329 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1016 09:56:12.418259   329 net.cpp:165] Memory required for data: 290540464
I1016 09:56:12.418267   329 layer_factory.hpp:77] Creating layer fuse_4
I1016 09:56:12.418275   329 net.cpp:100] Creating Layer fuse_4
I1016 09:56:12.418280   329 net.cpp:434] fuse_4 <- upscore_4
I1016 09:56:12.418285   329 net.cpp:434] fuse_4 <- score_4
I1016 09:56:12.418290   329 net.cpp:408] fuse_4 -> fuse_4
I1016 09:56:12.418336   329 net.cpp:150] Setting up fuse_4
I1016 09:56:12.418345   329 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1016 09:56:12.418349   329 net.cpp:165] Memory required for data: 290617264
I1016 09:56:12.418352   329 layer_factory.hpp:77] Creating layer upscore
I1016 09:56:12.418362   329 net.cpp:100] Creating Layer upscore
I1016 09:56:12.418367   329 net.cpp:434] upscore <- fuse_4
I1016 09:56:12.418372   329 net.cpp:408] upscore -> upscore
I1016 09:56:12.418637   329 net.cpp:150] Setting up upscore
I1016 09:56:12.418645   329 net.cpp:157] Top shape: 1 2 331 491 (325042)
I1016 09:56:12.418648   329 net.cpp:165] Memory required for data: 291917432
I1016 09:56:12.418653   329 layer_factory.hpp:77] Creating layer score
I1016 09:56:12.418661   329 net.cpp:100] Creating Layer score
I1016 09:56:12.418668   329 net.cpp:434] score <- upscore
I1016 09:56:12.418673   329 net.cpp:434] score <- data_data_0_split_7
I1016 09:56:12.418678   329 net.cpp:408] score -> score
I1016 09:56:12.418720   329 net.cpp:150] Setting up score
I1016 09:56:12.418728   329 net.cpp:157] Top shape: 1 2 320 480 (307200)
I1016 09:56:12.418732   329 net.cpp:165] Memory required for data: 293146232
I1016 09:56:12.418735   329 layer_factory.hpp:77] Creating layer seg_loss
I1016 09:56:12.418741   329 net.cpp:100] Creating Layer seg_loss
I1016 09:56:12.418745   329 net.cpp:434] seg_loss <- score
I1016 09:56:12.418751   329 net.cpp:434] seg_loss <- label_seg
I1016 09:56:12.418758   329 net.cpp:408] seg_loss -> seg_loss
I1016 09:56:12.418769   329 layer_factory.hpp:77] Creating layer seg_loss
I1016 09:56:12.420382   329 net.cpp:150] Setting up seg_loss
I1016 09:56:12.420397   329 net.cpp:157] Top shape: (1)
I1016 09:56:12.420398   329 net.cpp:160]     with loss weight 1
I1016 09:56:12.420405   329 net.cpp:165] Memory required for data: 293146236
I1016 09:56:12.420408   329 net.cpp:226] seg_loss needs backward computation.
I1016 09:56:12.420413   329 net.cpp:226] score needs backward computation.
I1016 09:56:12.420414   329 net.cpp:226] upscore needs backward computation.
I1016 09:56:12.420418   329 net.cpp:226] fuse_4 needs backward computation.
I1016 09:56:12.420420   329 net.cpp:226] score_4 needs backward computation.
I1016 09:56:12.420423   329 net.cpp:226] upscore_4 needs backward computation.
I1016 09:56:12.420425   329 net.cpp:226] fuse_8 needs backward computation.
I1016 09:56:12.420429   329 net.cpp:226] score_8 needs backward computation.
I1016 09:56:12.420433   329 net.cpp:226] upscore_8 needs backward computation.
I1016 09:56:12.420437   329 net.cpp:226] fuse_16 needs backward computation.
I1016 09:56:12.420441   329 net.cpp:226] score_16 needs backward computation.
I1016 09:56:12.420445   329 net.cpp:226] upscore_16 needs backward computation.
I1016 09:56:12.420450   329 net.cpp:226] score_32 needs backward computation.
I1016 09:56:12.420454   329 net.cpp:228] detection_eval does not need backward computation.
I1016 09:56:12.420459   329 net.cpp:228] detection_out does not need backward computation.
I1016 09:56:12.420464   329 net.cpp:228] mbox_conf_flatten does not need backward computation.
I1016 09:56:12.420469   329 net.cpp:228] mbox_conf_softmax does not need backward computation.
I1016 09:56:12.420472   329 net.cpp:228] mbox_conf_reshape does not need backward computation.
I1016 09:56:12.420476   329 net.cpp:228] mbox_priorbox does not need backward computation.
I1016 09:56:12.420482   329 net.cpp:228] mbox_conf does not need backward computation.
I1016 09:56:12.420486   329 net.cpp:228] mbox_loc does not need backward computation.
I1016 09:56:12.420492   329 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.420495   329 net.cpp:228] conv17_2_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420500   329 net.cpp:228] conv17_2_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420505   329 net.cpp:228] conv17_2_mbox_conf_new does not need backward computation.
I1016 09:56:12.420508   329 net.cpp:228] conv17_2_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420513   329 net.cpp:228] conv17_2_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420517   329 net.cpp:228] conv17_2_mbox_loc does not need backward computation.
I1016 09:56:12.420522   329 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.420527   329 net.cpp:228] conv16_2_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420532   329 net.cpp:228] conv16_2_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420536   329 net.cpp:228] conv16_2_mbox_conf_new does not need backward computation.
I1016 09:56:12.420539   329 net.cpp:228] conv16_2_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420542   329 net.cpp:228] conv16_2_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420544   329 net.cpp:228] conv16_2_mbox_loc does not need backward computation.
I1016 09:56:12.420547   329 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.420552   329 net.cpp:228] conv15_2_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420557   329 net.cpp:228] conv15_2_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420562   329 net.cpp:228] conv15_2_mbox_conf_new does not need backward computation.
I1016 09:56:12.420567   329 net.cpp:228] conv15_2_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420570   329 net.cpp:228] conv15_2_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420575   329 net.cpp:228] conv15_2_mbox_loc does not need backward computation.
I1016 09:56:12.420579   329 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1016 09:56:12.420584   329 net.cpp:228] conv14_2_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420588   329 net.cpp:228] conv14_2_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420590   329 net.cpp:228] conv14_2_mbox_conf_new does not need backward computation.
I1016 09:56:12.420593   329 net.cpp:228] conv14_2_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420595   329 net.cpp:228] conv14_2_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420598   329 net.cpp:228] conv14_2_mbox_loc does not need backward computation.
I1016 09:56:12.420603   329 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1016 09:56:12.420610   329 net.cpp:228] conv13_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420615   329 net.cpp:228] conv13_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420620   329 net.cpp:228] conv13_mbox_conf_new does not need backward computation.
I1016 09:56:12.420625   329 net.cpp:228] conv13_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420629   329 net.cpp:228] conv13_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420634   329 net.cpp:228] conv13_mbox_loc does not need backward computation.
I1016 09:56:12.420639   329 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1016 09:56:12.420644   329 net.cpp:228] conv11_mbox_conf_flat does not need backward computation.
I1016 09:56:12.420648   329 net.cpp:228] conv11_mbox_conf_perm does not need backward computation.
I1016 09:56:12.420652   329 net.cpp:228] conv11_mbox_conf_new does not need backward computation.
I1016 09:56:12.420656   329 net.cpp:228] conv11_mbox_loc_flat does not need backward computation.
I1016 09:56:12.420661   329 net.cpp:228] conv11_mbox_loc_perm does not need backward computation.
I1016 09:56:12.420665   329 net.cpp:228] conv11_mbox_loc does not need backward computation.
I1016 09:56:12.420670   329 net.cpp:228] conv17_2_conv17_2/relu_0_split does not need backward computation.
I1016 09:56:12.420672   329 net.cpp:228] conv17_2/relu does not need backward computation.
I1016 09:56:12.420675   329 net.cpp:228] conv17_2/scale does not need backward computation.
I1016 09:56:12.420678   329 net.cpp:228] conv17_2/bn does not need backward computation.
I1016 09:56:12.420680   329 net.cpp:228] conv17_2 does not need backward computation.
I1016 09:56:12.420682   329 net.cpp:228] conv17_1/relu does not need backward computation.
I1016 09:56:12.420686   329 net.cpp:228] conv17_1/scale does not need backward computation.
I1016 09:56:12.420687   329 net.cpp:228] conv17_1/bn does not need backward computation.
I1016 09:56:12.420691   329 net.cpp:228] conv17_1 does not need backward computation.
I1016 09:56:12.420693   329 net.cpp:228] conv16_2_conv16_2/relu_0_split does not need backward computation.
I1016 09:56:12.420698   329 net.cpp:228] conv16_2/relu does not need backward computation.
I1016 09:56:12.420702   329 net.cpp:228] conv16_2/scale does not need backward computation.
I1016 09:56:12.420706   329 net.cpp:228] conv16_2/bn does not need backward computation.
I1016 09:56:12.420711   329 net.cpp:228] conv16_2 does not need backward computation.
I1016 09:56:12.420716   329 net.cpp:228] conv16_1/relu does not need backward computation.
I1016 09:56:12.420718   329 net.cpp:228] conv16_1/scale does not need backward computation.
I1016 09:56:12.420722   329 net.cpp:228] conv16_1/bn does not need backward computation.
I1016 09:56:12.420727   329 net.cpp:228] conv16_1 does not need backward computation.
I1016 09:56:12.420729   329 net.cpp:228] conv15_2_conv15_2/relu_0_split does not need backward computation.
I1016 09:56:12.420734   329 net.cpp:228] conv15_2/relu does not need backward computation.
I1016 09:56:12.420737   329 net.cpp:228] conv15_2/scale does not need backward computation.
I1016 09:56:12.420738   329 net.cpp:228] conv15_2/bn does not need backward computation.
I1016 09:56:12.420742   329 net.cpp:228] conv15_2 does not need backward computation.
I1016 09:56:12.420743   329 net.cpp:228] conv15_1/relu does not need backward computation.
I1016 09:56:12.420747   329 net.cpp:228] conv15_1/scale does not need backward computation.
I1016 09:56:12.420749   329 net.cpp:228] conv15_1/bn does not need backward computation.
I1016 09:56:12.420754   329 net.cpp:228] conv15_1 does not need backward computation.
I1016 09:56:12.420758   329 net.cpp:228] conv14_2_conv14_2/relu_0_split does not need backward computation.
I1016 09:56:12.420763   329 net.cpp:228] conv14_2/relu does not need backward computation.
I1016 09:56:12.420766   329 net.cpp:228] conv14_2/scale does not need backward computation.
I1016 09:56:12.420770   329 net.cpp:228] conv14_2/bn does not need backward computation.
I1016 09:56:12.420774   329 net.cpp:228] conv14_2 does not need backward computation.
I1016 09:56:12.420778   329 net.cpp:228] conv14_1/relu does not need backward computation.
I1016 09:56:12.420783   329 net.cpp:228] conv14_1/scale does not need backward computation.
I1016 09:56:12.420785   329 net.cpp:228] conv14_1/bn does not need backward computation.
I1016 09:56:12.420789   329 net.cpp:228] conv14_1 does not need backward computation.
I1016 09:56:12.420791   329 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1016 09:56:12.420794   329 net.cpp:226] conv13/relu needs backward computation.
I1016 09:56:12.420796   329 net.cpp:226] conv13/scale needs backward computation.
I1016 09:56:12.420799   329 net.cpp:226] conv13/bn needs backward computation.
I1016 09:56:12.420801   329 net.cpp:226] conv13 needs backward computation.
I1016 09:56:12.420805   329 net.cpp:226] conv13/dw/relu needs backward computation.
I1016 09:56:12.420810   329 net.cpp:226] conv13/dw/scale needs backward computation.
I1016 09:56:12.420814   329 net.cpp:226] conv13/dw/bn needs backward computation.
I1016 09:56:12.420817   329 net.cpp:226] conv13/dw needs backward computation.
I1016 09:56:12.420821   329 net.cpp:226] conv12/relu needs backward computation.
I1016 09:56:12.420825   329 net.cpp:226] conv12/scale needs backward computation.
I1016 09:56:12.420828   329 net.cpp:226] conv12/bn needs backward computation.
I1016 09:56:12.420832   329 net.cpp:226] conv12 needs backward computation.
I1016 09:56:12.420836   329 net.cpp:226] conv12/dw/relu needs backward computation.
I1016 09:56:12.420840   329 net.cpp:226] conv12/dw/scale needs backward computation.
I1016 09:56:12.420845   329 net.cpp:226] conv12/dw/bn needs backward computation.
I1016 09:56:12.420848   329 net.cpp:226] conv12/dw needs backward computation.
I1016 09:56:12.420852   329 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1016 09:56:12.420857   329 net.cpp:226] conv11/relu needs backward computation.
I1016 09:56:12.420861   329 net.cpp:226] conv11/scale needs backward computation.
I1016 09:56:12.420864   329 net.cpp:226] conv11/bn needs backward computation.
I1016 09:56:12.420866   329 net.cpp:226] conv11 needs backward computation.
I1016 09:56:12.420869   329 net.cpp:226] conv11/dw/relu needs backward computation.
I1016 09:56:12.420871   329 net.cpp:226] conv11/dw/scale needs backward computation.
I1016 09:56:12.420874   329 net.cpp:226] conv11/dw/bn needs backward computation.
I1016 09:56:12.420876   329 net.cpp:226] conv11/dw needs backward computation.
I1016 09:56:12.420879   329 net.cpp:226] conv10/relu needs backward computation.
I1016 09:56:12.420881   329 net.cpp:226] conv10/scale needs backward computation.
I1016 09:56:12.420883   329 net.cpp:226] conv10/bn needs backward computation.
I1016 09:56:12.420886   329 net.cpp:226] conv10 needs backward computation.
I1016 09:56:12.420889   329 net.cpp:226] conv10/dw/relu needs backward computation.
I1016 09:56:12.420893   329 net.cpp:226] conv10/dw/scale needs backward computation.
I1016 09:56:12.420897   329 net.cpp:226] conv10/dw/bn needs backward computation.
I1016 09:56:12.420900   329 net.cpp:226] conv10/dw needs backward computation.
I1016 09:56:12.420905   329 net.cpp:226] conv9/relu needs backward computation.
I1016 09:56:12.420909   329 net.cpp:226] conv9/scale needs backward computation.
I1016 09:56:12.420913   329 net.cpp:226] conv9/bn needs backward computation.
I1016 09:56:12.420917   329 net.cpp:226] conv9 needs backward computation.
I1016 09:56:12.420922   329 net.cpp:226] conv9/dw/relu needs backward computation.
I1016 09:56:12.420923   329 net.cpp:226] conv9/dw/scale needs backward computation.
I1016 09:56:12.420925   329 net.cpp:226] conv9/dw/bn needs backward computation.
I1016 09:56:12.420928   329 net.cpp:226] conv9/dw needs backward computation.
I1016 09:56:12.420931   329 net.cpp:226] conv8/relu needs backward computation.
I1016 09:56:12.420933   329 net.cpp:226] conv8/scale needs backward computation.
I1016 09:56:12.420935   329 net.cpp:226] conv8/bn needs backward computation.
I1016 09:56:12.420938   329 net.cpp:226] conv8 needs backward computation.
I1016 09:56:12.420940   329 net.cpp:226] conv8/dw/relu needs backward computation.
I1016 09:56:12.420943   329 net.cpp:226] conv8/dw/scale needs backward computation.
I1016 09:56:12.420946   329 net.cpp:226] conv8/dw/bn needs backward computation.
I1016 09:56:12.420950   329 net.cpp:226] conv8/dw needs backward computation.
I1016 09:56:12.420954   329 net.cpp:226] conv7/relu needs backward computation.
I1016 09:56:12.420958   329 net.cpp:226] conv7/scale needs backward computation.
I1016 09:56:12.420963   329 net.cpp:226] conv7/bn needs backward computation.
I1016 09:56:12.420965   329 net.cpp:226] conv7 needs backward computation.
I1016 09:56:12.420969   329 net.cpp:226] conv7/dw/relu needs backward computation.
I1016 09:56:12.420975   329 net.cpp:226] conv7/dw/scale needs backward computation.
I1016 09:56:12.420979   329 net.cpp:226] conv7/dw/bn needs backward computation.
I1016 09:56:12.420984   329 net.cpp:226] conv7/dw needs backward computation.
I1016 09:56:12.420987   329 net.cpp:226] conv6/relu needs backward computation.
I1016 09:56:12.420991   329 net.cpp:226] conv6/scale needs backward computation.
I1016 09:56:12.420995   329 net.cpp:226] conv6/bn needs backward computation.
I1016 09:56:12.421000   329 net.cpp:226] conv6 needs backward computation.
I1016 09:56:12.421003   329 net.cpp:226] conv6/dw/relu needs backward computation.
I1016 09:56:12.421005   329 net.cpp:226] conv6/dw/scale needs backward computation.
I1016 09:56:12.421007   329 net.cpp:226] conv6/dw/bn needs backward computation.
I1016 09:56:12.421010   329 net.cpp:226] conv6/dw needs backward computation.
I1016 09:56:12.421013   329 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1016 09:56:12.421015   329 net.cpp:226] conv5/relu needs backward computation.
I1016 09:56:12.421018   329 net.cpp:226] conv5/scale needs backward computation.
I1016 09:56:12.421020   329 net.cpp:226] conv5/bn needs backward computation.
I1016 09:56:12.421022   329 net.cpp:226] conv5 needs backward computation.
I1016 09:56:12.421025   329 net.cpp:226] conv5/dw/relu needs backward computation.
I1016 09:56:12.421027   329 net.cpp:226] conv5/dw/scale needs backward computation.
I1016 09:56:12.421030   329 net.cpp:226] conv5/dw/bn needs backward computation.
I1016 09:56:12.421034   329 net.cpp:226] conv5/dw needs backward computation.
I1016 09:56:12.421038   329 net.cpp:226] conv4/relu needs backward computation.
I1016 09:56:12.421042   329 net.cpp:226] conv4/scale needs backward computation.
I1016 09:56:12.421046   329 net.cpp:226] conv4/bn needs backward computation.
I1016 09:56:12.421049   329 net.cpp:226] conv4 needs backward computation.
I1016 09:56:12.421054   329 net.cpp:226] conv4/dw/relu needs backward computation.
I1016 09:56:12.421057   329 net.cpp:226] conv4/dw/scale needs backward computation.
I1016 09:56:12.421061   329 net.cpp:226] conv4/dw/bn needs backward computation.
I1016 09:56:12.421064   329 net.cpp:226] conv4/dw needs backward computation.
I1016 09:56:12.421067   329 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1016 09:56:12.421069   329 net.cpp:226] conv3/relu needs backward computation.
I1016 09:56:12.421072   329 net.cpp:226] conv3/scale needs backward computation.
I1016 09:56:12.421074   329 net.cpp:226] conv3/bn needs backward computation.
I1016 09:56:12.421077   329 net.cpp:226] conv3 needs backward computation.
I1016 09:56:12.421079   329 net.cpp:226] conv3/dw/relu needs backward computation.
I1016 09:56:12.421082   329 net.cpp:226] conv3/dw/scale needs backward computation.
I1016 09:56:12.421084   329 net.cpp:226] conv3/dw/bn needs backward computation.
I1016 09:56:12.421087   329 net.cpp:226] conv3/dw needs backward computation.
I1016 09:56:12.421090   329 net.cpp:226] conv2/relu needs backward computation.
I1016 09:56:12.421094   329 net.cpp:226] conv2/scale needs backward computation.
I1016 09:56:12.421097   329 net.cpp:226] conv2/bn needs backward computation.
I1016 09:56:12.421102   329 net.cpp:226] conv2 needs backward computation.
I1016 09:56:12.421106   329 net.cpp:226] conv2/dw/relu needs backward computation.
I1016 09:56:12.421109   329 net.cpp:226] conv2/dw/scale needs backward computation.
I1016 09:56:12.421113   329 net.cpp:226] conv2/dw/bn needs backward computation.
I1016 09:56:12.421118   329 net.cpp:226] conv2/dw needs backward computation.
I1016 09:56:12.421121   329 net.cpp:226] conv1/relu needs backward computation.
I1016 09:56:12.421124   329 net.cpp:226] conv1/scale needs backward computation.
I1016 09:56:12.421126   329 net.cpp:226] conv1/bn needs backward computation.
I1016 09:56:12.421128   329 net.cpp:226] conv1 needs backward computation.
I1016 09:56:12.421131   329 net.cpp:226] conv1/dw/relu needs backward computation.
I1016 09:56:12.421133   329 net.cpp:226] conv1/dw/scale needs backward computation.
I1016 09:56:12.421136   329 net.cpp:226] conv1/dw/bn needs backward computation.
I1016 09:56:12.421139   329 net.cpp:226] conv1/dw needs backward computation.
I1016 09:56:12.421141   329 net.cpp:226] conv0/relu needs backward computation.
I1016 09:56:12.421144   329 net.cpp:226] conv0/scale needs backward computation.
I1016 09:56:12.421147   329 net.cpp:226] conv0/bn needs backward computation.
I1016 09:56:12.421151   329 net.cpp:226] conv0 needs backward computation.
I1016 09:56:12.421159   329 net.cpp:228] data_data_0_split does not need backward computation.
I1016 09:56:12.421164   329 net.cpp:228] data does not need backward computation.
I1016 09:56:12.421167   329 net.cpp:270] This network produces output detection_eval
I1016 09:56:12.421172   329 net.cpp:270] This network produces output seg_loss
I1016 09:56:12.421290   329 net.cpp:283] Network initialization done.
I1016 09:56:12.421712   329 solver.cpp:75] Solver scaffolding done.
I1016 09:56:13.155438   329 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: pretrained/mobilenet_iter_73000.caffemodel
I1016 09:56:13.155495   329 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 09:56:13.161934   329 net.cpp:761] Ignoring source layer conv11_mbox_conf
I1016 09:56:13.161991   329 net.cpp:761] Ignoring source layer conv13_mbox_conf
I1016 09:56:13.162022   329 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I1016 09:56:13.162042   329 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I1016 09:56:13.162058   329 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I1016 09:56:13.162071   329 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I1016 09:56:13.687222   329 solver.cpp:243] Iteration 0, loss = 106489
I1016 09:56:13.687252   329 solver.cpp:259]     Train net output #0: mbox_loss = 21.0959 (* 1 = 21.0959 loss)
I1016 09:56:13.687258   329 solver.cpp:259]     Train net output #1: seg_loss = 106467 (* 1 = 106467 loss)
I1016 09:56:13.687263   329 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I1016 09:56:16.280249   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 09:57:13.677191   329 solver.cpp:243] Iteration 100, loss = 23743.6
I1016 09:57:13.677224   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.43008 (* 1 = 8.43008 loss)
I1016 09:57:13.677230   329 solver.cpp:259]     Train net output #1: seg_loss = 22441.1 (* 1 = 22441.1 loss)
I1016 09:57:13.677235   329 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I1016 09:58:14.642251   329 solver.cpp:243] Iteration 200, loss = 22752.2
I1016 09:58:14.642305   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.4808 (* 1 = 12.4808 loss)
I1016 09:58:14.642313   329 solver.cpp:259]     Train net output #1: seg_loss = 18608.4 (* 1 = 18608.4 loss)
I1016 09:58:14.642318   329 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I1016 09:59:16.763223   329 solver.cpp:243] Iteration 300, loss = 23852.2
I1016 09:59:16.763257   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.15609 (* 1 = 5.15609 loss)
I1016 09:59:16.763262   329 solver.cpp:259]     Train net output #1: seg_loss = 26969.1 (* 1 = 26969.1 loss)
I1016 09:59:16.763268   329 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I1016 10:00:19.368682   329 solver.cpp:243] Iteration 400, loss = 22919
I1016 10:00:19.368731   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.31905 (* 1 = 5.31905 loss)
I1016 10:00:19.368737   329 solver.cpp:259]     Train net output #1: seg_loss = 27237.8 (* 1 = 27237.8 loss)
I1016 10:00:19.368743   329 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I1016 10:01:21.749097   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_500.caffemodel
I1016 10:01:22.107306   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_500.solverstate
I1016 10:01:22.786448   329 solver.cpp:243] Iteration 500, loss = 15853.6
I1016 10:01:22.786479   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.77384 (* 1 = 8.77384 loss)
I1016 10:01:22.786486   329 solver.cpp:259]     Train net output #1: seg_loss = 19600.5 (* 1 = 19600.5 loss)
I1016 10:01:22.786492   329 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I1016 10:02:24.599300   329 solver.cpp:243] Iteration 600, loss = 18150.4
I1016 10:02:24.599336   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.94589 (* 1 = 8.94589 loss)
I1016 10:02:24.599342   329 solver.cpp:259]     Train net output #1: seg_loss = 13085.9 (* 1 = 13085.9 loss)
I1016 10:02:24.599349   329 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I1016 10:03:25.299816   329 solver.cpp:243] Iteration 700, loss = 11732.6
I1016 10:03:25.299863   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.00261 (* 1 = 8.00261 loss)
I1016 10:03:25.299870   329 solver.cpp:259]     Train net output #1: seg_loss = 12183.8 (* 1 = 12183.8 loss)
I1016 10:03:25.299875   329 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I1016 10:04:27.524046   329 solver.cpp:243] Iteration 800, loss = 47414.4
I1016 10:04:27.524085   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.52372 (* 1 = 7.52372 loss)
I1016 10:04:27.524091   329 solver.cpp:259]     Train net output #1: seg_loss = 13774.7 (* 1 = 13774.7 loss)
I1016 10:04:27.524096   329 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I1016 10:05:29.424240   329 solver.cpp:243] Iteration 900, loss = 34132.2
I1016 10:05:29.424273   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.64061 (* 1 = 7.64061 loss)
I1016 10:05:29.424279   329 solver.cpp:259]     Train net output #1: seg_loss = 26873.4 (* 1 = 26873.4 loss)
I1016 10:05:29.424284   329 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I1016 10:06:31.106794   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1000.caffemodel
I1016 10:06:31.429388   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1000.solverstate
I1016 10:06:32.032810   329 solver.cpp:243] Iteration 1000, loss = 15434.3
I1016 10:06:32.032842   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.36203 (* 1 = 7.36203 loss)
I1016 10:06:32.032850   329 solver.cpp:259]     Train net output #1: seg_loss = 29058.5 (* 1 = 29058.5 loss)
I1016 10:06:32.032855   329 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I1016 10:06:38.067224   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:07:33.211817   329 solver.cpp:243] Iteration 1100, loss = 15193.1
I1016 10:07:33.211851   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.83876 (* 1 = 4.83876 loss)
I1016 10:07:33.211858   329 solver.cpp:259]     Train net output #1: seg_loss = 12766.4 (* 1 = 12766.4 loss)
I1016 10:07:33.211863   329 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I1016 10:08:34.838627   329 solver.cpp:243] Iteration 1200, loss = 15050.8
I1016 10:08:34.838660   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.38071 (* 1 = 7.38071 loss)
I1016 10:08:34.838665   329 solver.cpp:259]     Train net output #1: seg_loss = 11380.4 (* 1 = 11380.4 loss)
I1016 10:08:34.838671   329 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I1016 10:09:35.940376   329 solver.cpp:243] Iteration 1300, loss = 16132.4
I1016 10:09:35.940410   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.3636 (* 1 = 12.3636 loss)
I1016 10:09:35.940416   329 solver.cpp:259]     Train net output #1: seg_loss = 22799.7 (* 1 = 22799.7 loss)
I1016 10:09:35.940423   329 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I1016 10:10:37.536008   329 solver.cpp:243] Iteration 1400, loss = 14384.4
I1016 10:10:37.536056   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.60768 (* 1 = 4.60768 loss)
I1016 10:10:37.536063   329 solver.cpp:259]     Train net output #1: seg_loss = 16421.8 (* 1 = 16421.8 loss)
I1016 10:10:37.536069   329 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I1016 10:11:39.732997   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1500.caffemodel
I1016 10:11:40.492368   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1500.solverstate
I1016 10:11:41.064437   329 solver.cpp:243] Iteration 1500, loss = 15951.5
I1016 10:11:41.064476   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.58517 (* 1 = 5.58517 loss)
I1016 10:11:41.064486   329 solver.cpp:259]     Train net output #1: seg_loss = 21910 (* 1 = 21910 loss)
I1016 10:11:41.064505   329 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I1016 10:12:42.477752   329 solver.cpp:243] Iteration 1600, loss = 40766.7
I1016 10:12:42.477787   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.37994 (* 1 = 4.37994 loss)
I1016 10:12:42.477795   329 solver.cpp:259]     Train net output #1: seg_loss = 8998.54 (* 1 = 8998.54 loss)
I1016 10:12:42.477818   329 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I1016 10:13:44.440284   329 solver.cpp:243] Iteration 1700, loss = 13312.2
I1016 10:13:44.440326   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.52994 (* 1 = 6.52994 loss)
I1016 10:13:44.440335   329 solver.cpp:259]     Train net output #1: seg_loss = 9668.58 (* 1 = 9668.58 loss)
I1016 10:13:44.440343   329 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I1016 10:14:44.793515   329 solver.cpp:243] Iteration 1800, loss = 11761.4
I1016 10:14:44.793550   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.40693 (* 1 = 7.40693 loss)
I1016 10:14:44.793556   329 solver.cpp:259]     Train net output #1: seg_loss = 21432 (* 1 = 21432 loss)
I1016 10:14:44.793561   329 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I1016 10:15:46.783022   329 solver.cpp:243] Iteration 1900, loss = 18098.3
I1016 10:15:46.783059   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.18776 (* 1 = 6.18776 loss)
I1016 10:15:46.783066   329 solver.cpp:259]     Train net output #1: seg_loss = 27880.4 (* 1 = 27880.4 loss)
I1016 10:15:46.783071   329 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I1016 10:16:47.993723   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2000.caffemodel
I1016 10:16:48.792631   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2000.solverstate
I1016 10:16:49.454011   329 solver.cpp:243] Iteration 2000, loss = 19110
I1016 10:16:49.454043   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.04205 (* 1 = 8.04205 loss)
I1016 10:16:49.454049   329 solver.cpp:259]     Train net output #1: seg_loss = 18342.7 (* 1 = 18342.7 loss)
I1016 10:16:49.454056   329 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I1016 10:17:00.617660   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:17:50.862820   329 solver.cpp:243] Iteration 2100, loss = 12791.6
I1016 10:17:50.862854   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.98495 (* 1 = 5.98495 loss)
I1016 10:17:50.862860   329 solver.cpp:259]     Train net output #1: seg_loss = 12840.2 (* 1 = 12840.2 loss)
I1016 10:17:50.862865   329 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I1016 10:18:52.307016   329 solver.cpp:243] Iteration 2200, loss = 16042.7
I1016 10:18:52.307052   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.75301 (* 1 = 5.75301 loss)
I1016 10:18:52.307061   329 solver.cpp:259]     Train net output #1: seg_loss = 15160.4 (* 1 = 15160.4 loss)
I1016 10:18:52.307070   329 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I1016 10:19:53.743597   329 solver.cpp:243] Iteration 2300, loss = 13246.8
I1016 10:19:53.743628   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.39926 (* 1 = 6.39926 loss)
I1016 10:19:53.743634   329 solver.cpp:259]     Train net output #1: seg_loss = 8735.92 (* 1 = 8735.92 loss)
I1016 10:19:53.743640   329 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I1016 10:20:55.591473   329 solver.cpp:243] Iteration 2400, loss = 15378.6
I1016 10:20:55.591506   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.881 (* 1 = 10.881 loss)
I1016 10:20:55.591512   329 solver.cpp:259]     Train net output #1: seg_loss = 9880.03 (* 1 = 9880.03 loss)
I1016 10:20:55.591518   329 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I1016 10:21:57.466836   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2500.caffemodel
I1016 10:21:57.716585   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2500.solverstate
I1016 10:21:58.299561   329 solver.cpp:243] Iteration 2500, loss = 41501.2
I1016 10:21:58.299597   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.5104 (* 1 = 10.5104 loss)
I1016 10:21:58.299602   329 solver.cpp:259]     Train net output #1: seg_loss = 10359.8 (* 1 = 10359.8 loss)
I1016 10:21:58.299608   329 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I1016 10:23:01.641934   329 solver.cpp:243] Iteration 2600, loss = 12752
I1016 10:23:01.641968   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.98904 (* 1 = 5.98904 loss)
I1016 10:23:01.641974   329 solver.cpp:259]     Train net output #1: seg_loss = 12986.5 (* 1 = 12986.5 loss)
I1016 10:23:01.641980   329 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I1016 10:24:03.990658   329 solver.cpp:243] Iteration 2700, loss = 15700.3
I1016 10:24:03.990706   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.67324 (* 1 = 5.67324 loss)
I1016 10:24:03.990712   329 solver.cpp:259]     Train net output #1: seg_loss = 12635.8 (* 1 = 12635.8 loss)
I1016 10:24:03.990718   329 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I1016 10:25:05.095755   329 solver.cpp:243] Iteration 2800, loss = 9362.68
I1016 10:25:05.095805   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.0317 (* 1 = 8.0317 loss)
I1016 10:25:05.095811   329 solver.cpp:259]     Train net output #1: seg_loss = 11428 (* 1 = 11428 loss)
I1016 10:25:05.095816   329 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I1016 10:26:05.703815   329 solver.cpp:243] Iteration 2900, loss = 12178
I1016 10:26:05.703864   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.2364 (* 1 = 12.2364 loss)
I1016 10:26:05.703871   329 solver.cpp:259]     Train net output #1: seg_loss = 10934.7 (* 1 = 10934.7 loss)
I1016 10:26:05.703876   329 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I1016 10:27:07.485178   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3000.caffemodel
I1016 10:27:07.710474   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3000.solverstate
I1016 10:27:08.295655   329 solver.cpp:243] Iteration 3000, loss = 75151
I1016 10:27:08.295698   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.82507 (* 1 = 6.82507 loss)
I1016 10:27:08.295704   329 solver.cpp:259]     Train net output #1: seg_loss = 18021.8 (* 1 = 18021.8 loss)
I1016 10:27:08.295711   329 sgd_solver.cpp:138] Iteration 3000, lr = 0.0005
I1016 10:27:22.352550   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:28:10.157009   329 solver.cpp:243] Iteration 3100, loss = 14433.5
I1016 10:28:10.157058   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.59979 (* 1 = 9.59979 loss)
I1016 10:28:10.157063   329 solver.cpp:259]     Train net output #1: seg_loss = 12725 (* 1 = 12725 loss)
I1016 10:28:10.157069   329 sgd_solver.cpp:138] Iteration 3100, lr = 0.0005
I1016 10:29:12.674489   329 solver.cpp:243] Iteration 3200, loss = 10791.6
I1016 10:29:12.674525   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.66508 (* 1 = 6.66508 loss)
I1016 10:29:12.674530   329 solver.cpp:259]     Train net output #1: seg_loss = 8855.1 (* 1 = 8855.1 loss)
I1016 10:29:12.674536   329 sgd_solver.cpp:138] Iteration 3200, lr = 0.0005
I1016 10:30:13.739151   329 solver.cpp:243] Iteration 3300, loss = 13525.6
I1016 10:30:13.739198   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.40629 (* 1 = 6.40629 loss)
I1016 10:30:13.739205   329 solver.cpp:259]     Train net output #1: seg_loss = 6551.44 (* 1 = 6551.44 loss)
I1016 10:30:13.739210   329 sgd_solver.cpp:138] Iteration 3300, lr = 0.0005
I1016 10:31:14.015748   329 solver.cpp:243] Iteration 3400, loss = 10624.4
I1016 10:31:14.015799   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.10147 (* 1 = 8.10147 loss)
I1016 10:31:14.015805   329 solver.cpp:259]     Train net output #1: seg_loss = 9765.14 (* 1 = 9765.14 loss)
I1016 10:31:14.015812   329 sgd_solver.cpp:138] Iteration 3400, lr = 0.0005
I1016 10:32:13.627966   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3500.caffemodel
I1016 10:32:14.419349   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3500.solverstate
I1016 10:32:14.986141   329 solver.cpp:243] Iteration 3500, loss = 15872
I1016 10:32:14.986191   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.4902 (* 1 = 11.4902 loss)
I1016 10:32:14.986217   329 solver.cpp:259]     Train net output #1: seg_loss = 71843.2 (* 1 = 71843.2 loss)
I1016 10:32:14.986225   329 sgd_solver.cpp:138] Iteration 3500, lr = 0.0005
I1016 10:33:13.501816   329 solver.cpp:243] Iteration 3600, loss = 9188.02
I1016 10:33:13.501870   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.64057 (* 1 = 6.64057 loss)
I1016 10:33:13.501879   329 solver.cpp:259]     Train net output #1: seg_loss = 8744.09 (* 1 = 8744.09 loss)
I1016 10:33:13.501888   329 sgd_solver.cpp:138] Iteration 3600, lr = 0.0005
I1016 10:34:13.497642   329 solver.cpp:243] Iteration 3700, loss = 11670.9
I1016 10:34:13.497690   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.12202 (* 1 = 7.12202 loss)
I1016 10:34:13.497696   329 solver.cpp:259]     Train net output #1: seg_loss = 12901.2 (* 1 = 12901.2 loss)
I1016 10:34:13.497702   329 sgd_solver.cpp:138] Iteration 3700, lr = 0.0005
I1016 10:35:12.997653   329 solver.cpp:243] Iteration 3800, loss = 12923
I1016 10:35:12.997702   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.231 (* 1 = 10.231 loss)
I1016 10:35:12.997709   329 solver.cpp:259]     Train net output #1: seg_loss = 11460.1 (* 1 = 11460.1 loss)
I1016 10:35:12.997715   329 sgd_solver.cpp:138] Iteration 3800, lr = 0.0005
I1016 10:36:11.900550   329 solver.cpp:243] Iteration 3900, loss = 8935.71
I1016 10:36:11.900599   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.47771 (* 1 = 5.47771 loss)
I1016 10:36:11.900605   329 solver.cpp:259]     Train net output #1: seg_loss = 7819.56 (* 1 = 7819.56 loss)
I1016 10:36:11.900612   329 sgd_solver.cpp:138] Iteration 3900, lr = 0.0005
I1016 10:37:09.855458   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4000.caffemodel
I1016 10:37:10.095618   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4000.solverstate
I1016 10:37:10.288841   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 10:37:16.246366   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:38:49.088776   329 solver.cpp:243] Iteration 4000, loss = 10297.9
I1016 10:38:49.088816   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.96229 (* 1 = 8.96229 loss)
I1016 10:38:49.088822   329 solver.cpp:259]     Train net output #1: seg_loss = 10288.9 (* 1 = 10288.9 loss)
I1016 10:38:49.088829   329 sgd_solver.cpp:138] Iteration 4000, lr = 0.0005
I1016 10:39:47.409677   329 solver.cpp:243] Iteration 4100, loss = 8639.54
I1016 10:39:47.409727   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.47427 (* 1 = 5.47427 loss)
I1016 10:39:47.409734   329 solver.cpp:259]     Train net output #1: seg_loss = 8045.77 (* 1 = 8045.77 loss)
I1016 10:39:47.409739   329 sgd_solver.cpp:138] Iteration 4100, lr = 0.0005
I1016 10:40:47.155189   329 solver.cpp:243] Iteration 4200, loss = 11876.2
I1016 10:40:47.155239   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.29405 (* 1 = 8.29405 loss)
I1016 10:40:47.155246   329 solver.cpp:259]     Train net output #1: seg_loss = 11505 (* 1 = 11505 loss)
I1016 10:40:47.155251   329 sgd_solver.cpp:138] Iteration 4200, lr = 0.0005
I1016 10:41:47.905882   329 solver.cpp:243] Iteration 4300, loss = 8680.08
I1016 10:41:47.905915   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.08554 (* 1 = 5.08554 loss)
I1016 10:41:47.905921   329 solver.cpp:259]     Train net output #1: seg_loss = 10798.3 (* 1 = 10798.3 loss)
I1016 10:41:47.905926   329 sgd_solver.cpp:138] Iteration 4300, lr = 0.0005
I1016 10:42:47.903182   329 solver.cpp:243] Iteration 4400, loss = 9152.61
I1016 10:42:47.903230   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.38782 (* 1 = 4.38782 loss)
I1016 10:42:47.903236   329 solver.cpp:259]     Train net output #1: seg_loss = 9444.78 (* 1 = 9444.78 loss)
I1016 10:42:47.903244   329 sgd_solver.cpp:138] Iteration 4400, lr = 0.0005
I1016 10:43:46.255012   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4500.caffemodel
I1016 10:43:46.473419   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4500.solverstate
I1016 10:43:47.576431   329 solver.cpp:243] Iteration 4500, loss = 7472.02
I1016 10:43:47.576464   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.28009 (* 1 = 8.28009 loss)
I1016 10:43:47.576470   329 solver.cpp:259]     Train net output #1: seg_loss = 9223.55 (* 1 = 9223.55 loss)
I1016 10:43:47.576476   329 sgd_solver.cpp:138] Iteration 4500, lr = 0.0005
I1016 10:44:13.014693   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:44:47.281031   329 solver.cpp:243] Iteration 4600, loss = 9378.37
I1016 10:44:47.281081   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.84864 (* 1 = 8.84864 loss)
I1016 10:44:47.281087   329 solver.cpp:259]     Train net output #1: seg_loss = 7922.26 (* 1 = 7922.26 loss)
I1016 10:44:47.281093   329 sgd_solver.cpp:138] Iteration 4600, lr = 0.0005
I1016 10:45:46.645619   329 solver.cpp:243] Iteration 4700, loss = 26534.2
I1016 10:45:46.645668   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.82478 (* 1 = 7.82478 loss)
I1016 10:45:46.645674   329 solver.cpp:259]     Train net output #1: seg_loss = 11455.4 (* 1 = 11455.4 loss)
I1016 10:45:46.645680   329 sgd_solver.cpp:138] Iteration 4700, lr = 0.0005
I1016 10:46:46.888648   329 solver.cpp:243] Iteration 4800, loss = 21343.1
I1016 10:46:46.888696   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.61848 (* 1 = 4.61848 loss)
I1016 10:46:46.888702   329 solver.cpp:259]     Train net output #1: seg_loss = 8376.53 (* 1 = 8376.53 loss)
I1016 10:46:46.888710   329 sgd_solver.cpp:138] Iteration 4800, lr = 0.0005
I1016 10:47:48.744453   329 solver.cpp:243] Iteration 4900, loss = 9874.35
I1016 10:47:48.744499   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.49954 (* 1 = 7.49954 loss)
I1016 10:47:48.744506   329 solver.cpp:259]     Train net output #1: seg_loss = 15532.8 (* 1 = 15532.8 loss)
I1016 10:47:48.744513   329 sgd_solver.cpp:138] Iteration 4900, lr = 0.0005
I1016 10:48:47.624482   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5000.caffemodel
I1016 10:48:47.845346   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5000.solverstate
I1016 10:48:48.988553   329 solver.cpp:243] Iteration 5000, loss = 10426
I1016 10:48:48.988601   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.14544 (* 1 = 5.14544 loss)
I1016 10:48:48.988608   329 solver.cpp:259]     Train net output #1: seg_loss = 8610.46 (* 1 = 8610.46 loss)
I1016 10:48:48.988613   329 sgd_solver.cpp:138] Iteration 5000, lr = 0.0005
I1016 10:49:46.909430   329 solver.cpp:243] Iteration 5100, loss = 10110.6
I1016 10:49:46.909481   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.7086 (* 1 = 8.7086 loss)
I1016 10:49:46.909487   329 solver.cpp:259]     Train net output #1: seg_loss = 12921.6 (* 1 = 12921.6 loss)
I1016 10:49:46.909492   329 sgd_solver.cpp:138] Iteration 5100, lr = 0.0005
I1016 10:50:46.287689   329 solver.cpp:243] Iteration 5200, loss = 163891
I1016 10:50:46.287739   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.54486 (* 1 = 5.54486 loss)
I1016 10:50:46.287745   329 solver.cpp:259]     Train net output #1: seg_loss = 80806.1 (* 1 = 80806.1 loss)
I1016 10:50:46.287751   329 sgd_solver.cpp:138] Iteration 5200, lr = 0.0005
I1016 10:51:46.170752   329 solver.cpp:243] Iteration 5300, loss = 12038.4
I1016 10:51:46.170800   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.0043 (* 1 = 8.0043 loss)
I1016 10:51:46.170807   329 solver.cpp:259]     Train net output #1: seg_loss = 8541.73 (* 1 = 8541.73 loss)
I1016 10:51:46.170814   329 sgd_solver.cpp:138] Iteration 5300, lr = 0.0005
I1016 10:52:45.907727   329 solver.cpp:243] Iteration 5400, loss = 8945.32
I1016 10:52:45.907774   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.53339 (* 1 = 5.53339 loss)
I1016 10:52:45.907781   329 solver.cpp:259]     Train net output #1: seg_loss = 9151.29 (* 1 = 9151.29 loss)
I1016 10:52:45.907786   329 sgd_solver.cpp:138] Iteration 5400, lr = 0.0005
I1016 10:53:44.389983   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5500.caffemodel
I1016 10:53:44.622859   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5500.solverstate
I1016 10:53:45.189407   329 solver.cpp:243] Iteration 5500, loss = 7995.7
I1016 10:53:45.189441   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.22171 (* 1 = 6.22171 loss)
I1016 10:53:45.189448   329 solver.cpp:259]     Train net output #1: seg_loss = 7353.39 (* 1 = 7353.39 loss)
I1016 10:53:45.189453   329 sgd_solver.cpp:138] Iteration 5500, lr = 0.0005
I1016 10:54:14.892202   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 10:54:43.067163   329 solver.cpp:243] Iteration 5600, loss = 9445.19
I1016 10:54:43.067214   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.46789 (* 1 = 9.46789 loss)
I1016 10:54:43.067220   329 solver.cpp:259]     Train net output #1: seg_loss = 11221.1 (* 1 = 11221.1 loss)
I1016 10:54:43.067227   329 sgd_solver.cpp:138] Iteration 5600, lr = 0.0005
I1016 10:55:42.786381   329 solver.cpp:243] Iteration 5700, loss = 55352.1
I1016 10:55:42.786414   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.85999 (* 1 = 6.85999 loss)
I1016 10:55:42.786420   329 solver.cpp:259]     Train net output #1: seg_loss = 194294 (* 1 = 194294 loss)
I1016 10:55:42.786427   329 sgd_solver.cpp:138] Iteration 5700, lr = 0.0005
I1016 10:56:42.294970   329 solver.cpp:243] Iteration 5800, loss = 19844.8
I1016 10:56:42.295002   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.89943 (* 1 = 4.89943 loss)
I1016 10:56:42.295008   329 solver.cpp:259]     Train net output #1: seg_loss = 8467.26 (* 1 = 8467.26 loss)
I1016 10:56:42.295015   329 sgd_solver.cpp:138] Iteration 5800, lr = 0.0005
I1016 10:57:42.486104   329 solver.cpp:243] Iteration 5900, loss = 16844.1
I1016 10:57:42.486135   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.60177 (* 1 = 6.60177 loss)
I1016 10:57:42.486141   329 solver.cpp:259]     Train net output #1: seg_loss = 8505.04 (* 1 = 8505.04 loss)
I1016 10:57:42.486148   329 sgd_solver.cpp:138] Iteration 5900, lr = 0.0005
I1016 10:58:41.145802   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6000.caffemodel
I1016 10:58:41.365267   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6000.solverstate
I1016 10:58:41.947317   329 solver.cpp:243] Iteration 6000, loss = 11945.5
I1016 10:58:41.947353   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.45177 (* 1 = 8.45177 loss)
I1016 10:58:41.947360   329 solver.cpp:259]     Train net output #1: seg_loss = 13571.7 (* 1 = 13571.7 loss)
I1016 10:58:41.947365   329 sgd_solver.cpp:138] Iteration 6000, lr = 0.0005
I1016 10:59:40.568047   329 solver.cpp:243] Iteration 6100, loss = 7702.93
I1016 10:59:40.568081   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.55548 (* 1 = 6.55548 loss)
I1016 10:59:40.568087   329 solver.cpp:259]     Train net output #1: seg_loss = 11216 (* 1 = 11216 loss)
I1016 10:59:40.568094   329 sgd_solver.cpp:138] Iteration 6100, lr = 0.0005
I1016 11:00:39.640725   329 solver.cpp:243] Iteration 6200, loss = 15876.9
I1016 11:00:39.640761   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.1425 (* 1 = 10.1425 loss)
I1016 11:00:39.640767   329 solver.cpp:259]     Train net output #1: seg_loss = 6925.35 (* 1 = 6925.35 loss)
I1016 11:00:39.640774   329 sgd_solver.cpp:138] Iteration 6200, lr = 0.0005
I1016 11:01:38.850888   329 solver.cpp:243] Iteration 6300, loss = 10647.7
I1016 11:01:38.850924   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.27138 (* 1 = 8.27138 loss)
I1016 11:01:38.850930   329 solver.cpp:259]     Train net output #1: seg_loss = 8268.43 (* 1 = 8268.43 loss)
I1016 11:01:38.850937   329 sgd_solver.cpp:138] Iteration 6300, lr = 0.0005
I1016 11:02:38.690718   329 solver.cpp:243] Iteration 6400, loss = 8189.59
I1016 11:02:38.690754   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.02742 (* 1 = 8.02742 loss)
I1016 11:02:38.690760   329 solver.cpp:259]     Train net output #1: seg_loss = 8091.87 (* 1 = 8091.87 loss)
I1016 11:02:38.690766   329 sgd_solver.cpp:138] Iteration 6400, lr = 0.0005
I1016 11:03:37.900513   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6500.caffemodel
I1016 11:03:38.130224   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6500.solverstate
I1016 11:03:38.692997   329 solver.cpp:243] Iteration 6500, loss = 10454.3
I1016 11:03:38.693032   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.07975 (* 1 = 9.07975 loss)
I1016 11:03:38.693037   329 solver.cpp:259]     Train net output #1: seg_loss = 9806.1 (* 1 = 9806.1 loss)
I1016 11:03:38.693044   329 sgd_solver.cpp:138] Iteration 6500, lr = 0.0005
I1016 11:04:10.915676   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:04:37.405700   329 solver.cpp:243] Iteration 6600, loss = 7943.01
I1016 11:04:37.405735   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.66217 (* 1 = 9.66217 loss)
I1016 11:04:37.405741   329 solver.cpp:259]     Train net output #1: seg_loss = 9184 (* 1 = 9184 loss)
I1016 11:04:37.405747   329 sgd_solver.cpp:138] Iteration 6600, lr = 0.0005
I1016 11:05:35.768798   329 solver.cpp:243] Iteration 6700, loss = 16237.3
I1016 11:05:35.768832   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.5764 (* 1 = 11.5764 loss)
I1016 11:05:35.768839   329 solver.cpp:259]     Train net output #1: seg_loss = 6729.34 (* 1 = 6729.34 loss)
I1016 11:05:35.768844   329 sgd_solver.cpp:138] Iteration 6700, lr = 0.0005
I1016 11:06:35.420015   329 solver.cpp:243] Iteration 6800, loss = 7841.36
I1016 11:06:35.420048   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.68924 (* 1 = 8.68924 loss)
I1016 11:06:35.420054   329 solver.cpp:259]     Train net output #1: seg_loss = 7751.22 (* 1 = 7751.22 loss)
I1016 11:06:35.420059   329 sgd_solver.cpp:138] Iteration 6800, lr = 0.0005
I1016 11:07:36.063535   329 solver.cpp:243] Iteration 6900, loss = 10821.2
I1016 11:07:36.063585   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.5529 (* 1 = 10.5529 loss)
I1016 11:07:36.063591   329 solver.cpp:259]     Train net output #1: seg_loss = 9998.65 (* 1 = 9998.65 loss)
I1016 11:07:36.063611   329 sgd_solver.cpp:138] Iteration 6900, lr = 0.0005
I1016 11:08:47.661617   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7000.caffemodel
I1016 11:08:47.880347   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7000.solverstate
I1016 11:08:48.771097   329 solver.cpp:243] Iteration 7000, loss = 7776.77
I1016 11:08:48.771129   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.81148 (* 1 = 4.81148 loss)
I1016 11:08:48.771136   329 solver.cpp:259]     Train net output #1: seg_loss = 7435.95 (* 1 = 7435.95 loss)
I1016 11:08:48.771142   329 sgd_solver.cpp:138] Iteration 7000, lr = 0.0005
I1016 11:10:16.835712   329 solver.cpp:243] Iteration 7100, loss = 7152.72
I1016 11:10:16.835743   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.35373 (* 1 = 5.35373 loss)
I1016 11:10:16.835749   329 solver.cpp:259]     Train net output #1: seg_loss = 6167.09 (* 1 = 6167.09 loss)
I1016 11:10:16.835755   329 sgd_solver.cpp:138] Iteration 7100, lr = 0.0005
I1016 11:11:20.932679   329 solver.cpp:243] Iteration 7200, loss = 5988.99
I1016 11:11:20.932731   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.40607 (* 1 = 7.40607 loss)
I1016 11:11:20.932740   329 solver.cpp:259]     Train net output #1: seg_loss = 4950.59 (* 1 = 4950.59 loss)
I1016 11:11:20.932749   329 sgd_solver.cpp:138] Iteration 7200, lr = 0.0005
I1016 11:12:21.252130   329 solver.cpp:243] Iteration 7300, loss = 9909.48
I1016 11:12:21.252178   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.1518 (* 1 = 12.1518 loss)
I1016 11:12:21.252184   329 solver.cpp:259]     Train net output #1: seg_loss = 9692.6 (* 1 = 9692.6 loss)
I1016 11:12:21.252190   329 sgd_solver.cpp:138] Iteration 7300, lr = 0.0005
I1016 11:13:21.395468   329 solver.cpp:243] Iteration 7400, loss = 13592
I1016 11:13:21.395519   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.51224 (* 1 = 7.51224 loss)
I1016 11:13:21.395524   329 solver.cpp:259]     Train net output #1: seg_loss = 66327.4 (* 1 = 66327.4 loss)
I1016 11:13:21.395530   329 sgd_solver.cpp:138] Iteration 7400, lr = 0.0005
I1016 11:14:21.587004   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7500.caffemodel
I1016 11:14:21.813731   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7500.solverstate
I1016 11:14:22.942095   329 solver.cpp:243] Iteration 7500, loss = 8335.09
I1016 11:14:22.942131   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.79603 (* 1 = 6.79603 loss)
I1016 11:14:22.942137   329 solver.cpp:259]     Train net output #1: seg_loss = 8900.13 (* 1 = 8900.13 loss)
I1016 11:14:22.942142   329 sgd_solver.cpp:138] Iteration 7500, lr = 0.0005
I1016 11:15:24.094532   329 solver.cpp:243] Iteration 7600, loss = 7764.85
I1016 11:15:24.094581   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.424 (* 1 = 12.424 loss)
I1016 11:15:24.094588   329 solver.cpp:259]     Train net output #1: seg_loss = 5324.95 (* 1 = 5324.95 loss)
I1016 11:15:24.094594   329 sgd_solver.cpp:138] Iteration 7600, lr = 0.0005
I1016 11:16:24.192528   329 solver.cpp:243] Iteration 7700, loss = 8224.91
I1016 11:16:24.192561   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.87176 (* 1 = 7.87176 loss)
I1016 11:16:24.192567   329 solver.cpp:259]     Train net output #1: seg_loss = 9482.06 (* 1 = 9482.06 loss)
I1016 11:16:24.192572   329 sgd_solver.cpp:138] Iteration 7700, lr = 0.0005
I1016 11:16:47.890099   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:17:24.275507   329 solver.cpp:243] Iteration 7800, loss = 6692.58
I1016 11:17:24.275540   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.28936 (* 1 = 7.28936 loss)
I1016 11:17:24.275547   329 solver.cpp:259]     Train net output #1: seg_loss = 6298.43 (* 1 = 6298.43 loss)
I1016 11:17:24.275552   329 sgd_solver.cpp:138] Iteration 7800, lr = 0.0005
I1016 11:18:24.915992   329 solver.cpp:243] Iteration 7900, loss = 6385.61
I1016 11:18:24.916040   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.93197 (* 1 = 8.93197 loss)
I1016 11:18:24.916046   329 solver.cpp:259]     Train net output #1: seg_loss = 6396.29 (* 1 = 6396.29 loss)
I1016 11:18:24.916052   329 sgd_solver.cpp:138] Iteration 7900, lr = 0.0005
I1016 11:19:25.393319   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8000.caffemodel
I1016 11:19:25.637725   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8000.solverstate
I1016 11:19:26.379896   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 11:21:04.826930   329 solver.cpp:243] Iteration 8000, loss = 11123.8
I1016 11:21:04.826961   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.2961 (* 1 = 8.2961 loss)
I1016 11:21:04.826969   329 solver.cpp:259]     Train net output #1: seg_loss = 11115.5 (* 1 = 11115.5 loss)
I1016 11:21:04.826975   329 sgd_solver.cpp:138] Iteration 8000, lr = 0.0005
I1016 11:22:05.989990   329 solver.cpp:243] Iteration 8100, loss = 17206.4
I1016 11:22:05.990029   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.4682 (* 1 = 6.4682 loss)
I1016 11:22:05.990036   329 solver.cpp:259]     Train net output #1: seg_loss = 8035.6 (* 1 = 8035.6 loss)
I1016 11:22:05.990042   329 sgd_solver.cpp:138] Iteration 8100, lr = 0.0005
I1016 11:23:06.144917   329 solver.cpp:243] Iteration 8200, loss = 6940.91
I1016 11:23:06.144968   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.45241 (* 1 = 7.45241 loss)
I1016 11:23:06.144974   329 solver.cpp:259]     Train net output #1: seg_loss = 6807.04 (* 1 = 6807.04 loss)
I1016 11:23:06.144980   329 sgd_solver.cpp:138] Iteration 8200, lr = 0.0005
I1016 11:23:36.114620   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:24:05.306258   329 solver.cpp:243] Iteration 8300, loss = 5965.18
I1016 11:24:05.306306   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78266 (* 1 = 6.78266 loss)
I1016 11:24:05.306313   329 solver.cpp:259]     Train net output #1: seg_loss = 6429.78 (* 1 = 6429.78 loss)
I1016 11:24:05.306318   329 sgd_solver.cpp:138] Iteration 8300, lr = 0.0005
I1016 11:25:06.178614   329 solver.cpp:243] Iteration 8400, loss = 6758.69
I1016 11:25:06.178649   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.97912 (* 1 = 5.97912 loss)
I1016 11:25:06.178655   329 solver.cpp:259]     Train net output #1: seg_loss = 5808.03 (* 1 = 5808.03 loss)
I1016 11:25:06.178661   329 sgd_solver.cpp:138] Iteration 8400, lr = 0.0005
I1016 11:26:09.328969   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8500.caffemodel
I1016 11:26:09.592725   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8500.solverstate
I1016 11:26:10.212038   329 solver.cpp:243] Iteration 8500, loss = 9504.06
I1016 11:26:10.212074   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.90862 (* 1 = 5.90862 loss)
I1016 11:26:10.212083   329 solver.cpp:259]     Train net output #1: seg_loss = 10245.8 (* 1 = 10245.8 loss)
I1016 11:26:10.212102   329 sgd_solver.cpp:138] Iteration 8500, lr = 0.0005
I1016 11:27:32.787494   329 solver.cpp:243] Iteration 8600, loss = 9018.37
I1016 11:27:32.787540   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.55221 (* 1 = 9.55221 loss)
I1016 11:27:32.787546   329 solver.cpp:259]     Train net output #1: seg_loss = 13586.4 (* 1 = 13586.4 loss)
I1016 11:27:32.787552   329 sgd_solver.cpp:138] Iteration 8600, lr = 0.0005
I1016 11:28:33.129770   329 solver.cpp:243] Iteration 8700, loss = 8189.14
I1016 11:28:33.129803   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.60198 (* 1 = 8.60198 loss)
I1016 11:28:33.129809   329 solver.cpp:259]     Train net output #1: seg_loss = 7128.38 (* 1 = 7128.38 loss)
I1016 11:28:33.129815   329 sgd_solver.cpp:138] Iteration 8700, lr = 0.0005
I1016 11:29:33.355715   329 solver.cpp:243] Iteration 8800, loss = 7094.72
I1016 11:29:33.355748   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.9656 (* 1 = 6.9656 loss)
I1016 11:29:33.355754   329 solver.cpp:259]     Train net output #1: seg_loss = 6101.9 (* 1 = 6101.9 loss)
I1016 11:29:33.355760   329 sgd_solver.cpp:138] Iteration 8800, lr = 0.0005
I1016 11:30:33.470363   329 solver.cpp:243] Iteration 8900, loss = 11696.3
I1016 11:30:33.470396   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67074 (* 1 = 7.67074 loss)
I1016 11:30:33.470402   329 solver.cpp:259]     Train net output #1: seg_loss = 17954.8 (* 1 = 17954.8 loss)
I1016 11:30:33.470407   329 sgd_solver.cpp:138] Iteration 8900, lr = 0.0005
I1016 11:31:33.643911   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9000.caffemodel
I1016 11:31:34.418193   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9000.solverstate
I1016 11:31:35.055408   329 solver.cpp:243] Iteration 9000, loss = 15901.2
I1016 11:31:35.055451   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.68382 (* 1 = 5.68382 loss)
I1016 11:31:35.055457   329 solver.cpp:259]     Train net output #1: seg_loss = 11337.9 (* 1 = 11337.9 loss)
I1016 11:31:35.055462   329 sgd_solver.cpp:138] Iteration 9000, lr = 0.0005
I1016 11:32:35.570899   329 solver.cpp:243] Iteration 9100, loss = 7427.66
I1016 11:32:35.570947   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.45415 (* 1 = 5.45415 loss)
I1016 11:32:35.570952   329 solver.cpp:259]     Train net output #1: seg_loss = 5729.97 (* 1 = 5729.97 loss)
I1016 11:32:35.570958   329 sgd_solver.cpp:138] Iteration 9100, lr = 0.0005
I1016 11:33:36.539917   329 solver.cpp:243] Iteration 9200, loss = 8085.61
I1016 11:33:36.539952   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.68281 (* 1 = 7.68281 loss)
I1016 11:33:36.539958   329 solver.cpp:259]     Train net output #1: seg_loss = 9517.11 (* 1 = 9517.11 loss)
I1016 11:33:36.539963   329 sgd_solver.cpp:138] Iteration 9200, lr = 0.0005
I1016 11:34:36.665844   329 solver.cpp:243] Iteration 9300, loss = 5520.31
I1016 11:34:36.665877   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.39027 (* 1 = 9.39027 loss)
I1016 11:34:36.665884   329 solver.cpp:259]     Train net output #1: seg_loss = 6771.89 (* 1 = 6771.89 loss)
I1016 11:34:36.665889   329 sgd_solver.cpp:138] Iteration 9300, lr = 0.0005
I1016 11:35:16.019990   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:35:35.456068   329 solver.cpp:243] Iteration 9400, loss = 10897.9
I1016 11:35:35.456115   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.87521 (* 1 = 7.87521 loss)
I1016 11:35:35.456120   329 solver.cpp:259]     Train net output #1: seg_loss = 17862.6 (* 1 = 17862.6 loss)
I1016 11:35:35.456126   329 sgd_solver.cpp:138] Iteration 9400, lr = 0.0005
I1016 11:36:35.096156   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9500.caffemodel
I1016 11:36:35.352778   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9500.solverstate
I1016 11:36:35.913352   329 solver.cpp:243] Iteration 9500, loss = 9541.98
I1016 11:36:35.913388   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.15856 (* 1 = 8.15856 loss)
I1016 11:36:35.913398   329 solver.cpp:259]     Train net output #1: seg_loss = 5553.74 (* 1 = 5553.74 loss)
I1016 11:36:35.913419   329 sgd_solver.cpp:138] Iteration 9500, lr = 0.0005
I1016 11:37:36.381718   329 solver.cpp:243] Iteration 9600, loss = 8316.24
I1016 11:37:36.381752   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.56372 (* 1 = 6.56372 loss)
I1016 11:37:36.381758   329 solver.cpp:259]     Train net output #1: seg_loss = 10162.9 (* 1 = 10162.9 loss)
I1016 11:37:36.381764   329 sgd_solver.cpp:138] Iteration 9600, lr = 0.0005
I1016 11:38:38.572988   329 solver.cpp:243] Iteration 9700, loss = 6841.66
I1016 11:38:38.573022   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.62155 (* 1 = 9.62155 loss)
I1016 11:38:38.573031   329 solver.cpp:259]     Train net output #1: seg_loss = 7577.32 (* 1 = 7577.32 loss)
I1016 11:38:38.573055   329 sgd_solver.cpp:138] Iteration 9700, lr = 0.0005
I1016 11:39:39.786065   329 solver.cpp:243] Iteration 9800, loss = 7576.14
I1016 11:39:39.786099   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.91194 (* 1 = 5.91194 loss)
I1016 11:39:39.786105   329 solver.cpp:259]     Train net output #1: seg_loss = 8996.68 (* 1 = 8996.68 loss)
I1016 11:39:39.786111   329 sgd_solver.cpp:138] Iteration 9800, lr = 0.0005
I1016 11:40:40.683773   329 solver.cpp:243] Iteration 9900, loss = 6264.83
I1016 11:40:40.683836   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.2116 (* 1 = 5.2116 loss)
I1016 11:40:40.683842   329 solver.cpp:259]     Train net output #1: seg_loss = 5264.99 (* 1 = 5264.99 loss)
I1016 11:40:40.683848   329 sgd_solver.cpp:138] Iteration 9900, lr = 0.0005
I1016 11:41:42.704558   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10000.caffemodel
I1016 11:41:42.998023   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10000.solverstate
I1016 11:41:43.615696   329 solver.cpp:243] Iteration 10000, loss = 6181.42
I1016 11:41:43.615730   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.9378 (* 1 = 5.9378 loss)
I1016 11:41:43.615736   329 solver.cpp:259]     Train net output #1: seg_loss = 5900.07 (* 1 = 5900.07 loss)
I1016 11:41:43.615742   329 sgd_solver.cpp:138] Iteration 10000, lr = 0.0005
I1016 11:42:45.745175   329 solver.cpp:243] Iteration 10100, loss = 6097.83
I1016 11:42:45.745206   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.28271 (* 1 = 4.28271 loss)
I1016 11:42:45.745213   329 solver.cpp:259]     Train net output #1: seg_loss = 5903.94 (* 1 = 5903.94 loss)
I1016 11:42:45.745218   329 sgd_solver.cpp:138] Iteration 10100, lr = 0.0005
I1016 11:43:48.635028   329 solver.cpp:243] Iteration 10200, loss = 8291.96
I1016 11:43:48.635066   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.4427 (* 1 = 7.4427 loss)
I1016 11:43:48.635072   329 solver.cpp:259]     Train net output #1: seg_loss = 13821.7 (* 1 = 13821.7 loss)
I1016 11:43:48.635078   329 sgd_solver.cpp:138] Iteration 10200, lr = 0.0005
I1016 11:44:50.491255   329 solver.cpp:243] Iteration 10300, loss = 6858.21
I1016 11:44:50.491289   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.9621 (* 1 = 10.9621 loss)
I1016 11:44:50.491298   329 solver.cpp:259]     Train net output #1: seg_loss = 6931.24 (* 1 = 6931.24 loss)
I1016 11:44:50.491307   329 sgd_solver.cpp:138] Iteration 10300, lr = 0.0005
I1016 11:45:34.156505   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:45:52.000932   329 solver.cpp:243] Iteration 10400, loss = 5983.17
I1016 11:45:52.000982   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.99656 (* 1 = 6.99656 loss)
I1016 11:45:52.000986   329 solver.cpp:259]     Train net output #1: seg_loss = 6491.42 (* 1 = 6491.42 loss)
I1016 11:45:52.000993   329 sgd_solver.cpp:138] Iteration 10400, lr = 0.0005
I1016 11:46:52.896373   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10500.caffemodel
I1016 11:46:53.196300   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10500.solverstate
I1016 11:46:53.835840   329 solver.cpp:243] Iteration 10500, loss = 9135.69
I1016 11:46:53.835875   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.12671 (* 1 = 7.12671 loss)
I1016 11:46:53.835881   329 solver.cpp:259]     Train net output #1: seg_loss = 5769.25 (* 1 = 5769.25 loss)
I1016 11:46:53.835887   329 sgd_solver.cpp:138] Iteration 10500, lr = 0.0005
I1016 11:47:55.923663   329 solver.cpp:243] Iteration 10600, loss = 5605.71
I1016 11:47:55.923696   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.31842 (* 1 = 5.31842 loss)
I1016 11:47:55.923702   329 solver.cpp:259]     Train net output #1: seg_loss = 4907.9 (* 1 = 4907.9 loss)
I1016 11:47:55.923707   329 sgd_solver.cpp:138] Iteration 10600, lr = 0.0005
I1016 11:48:57.977383   329 solver.cpp:243] Iteration 10700, loss = 8118.62
I1016 11:48:57.977416   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.20712 (* 1 = 9.20712 loss)
I1016 11:48:57.977422   329 solver.cpp:259]     Train net output #1: seg_loss = 8380.79 (* 1 = 8380.79 loss)
I1016 11:48:57.977428   329 sgd_solver.cpp:138] Iteration 10700, lr = 0.0005
I1016 11:50:00.700475   329 solver.cpp:243] Iteration 10800, loss = 5599.65
I1016 11:50:00.700507   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.9332 (* 1 = 4.9332 loss)
I1016 11:50:00.700516   329 solver.cpp:259]     Train net output #1: seg_loss = 5922.11 (* 1 = 5922.11 loss)
I1016 11:50:00.700525   329 sgd_solver.cpp:138] Iteration 10800, lr = 0.0005
I1016 11:51:02.665030   329 solver.cpp:243] Iteration 10900, loss = 5786.8
I1016 11:51:02.665067   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.20527 (* 1 = 9.20527 loss)
I1016 11:51:02.665073   329 solver.cpp:259]     Train net output #1: seg_loss = 5373.67 (* 1 = 5373.67 loss)
I1016 11:51:02.665079   329 sgd_solver.cpp:138] Iteration 10900, lr = 0.0005
I1016 11:52:02.959877   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11000.caffemodel
I1016 11:52:03.433306   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11000.solverstate
I1016 11:52:04.071317   329 solver.cpp:243] Iteration 11000, loss = 4750.11
I1016 11:52:04.071352   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.30508 (* 1 = 6.30508 loss)
I1016 11:52:04.071358   329 solver.cpp:259]     Train net output #1: seg_loss = 4531.6 (* 1 = 4531.6 loss)
I1016 11:52:04.071365   329 sgd_solver.cpp:138] Iteration 11000, lr = 0.0005
I1016 11:53:06.746899   329 solver.cpp:243] Iteration 11100, loss = 6196.42
I1016 11:53:06.746938   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.32685 (* 1 = 8.32685 loss)
I1016 11:53:06.746944   329 solver.cpp:259]     Train net output #1: seg_loss = 4329.88 (* 1 = 4329.88 loss)
I1016 11:53:06.746950   329 sgd_solver.cpp:138] Iteration 11100, lr = 0.0005
I1016 11:54:08.929682   329 solver.cpp:243] Iteration 11200, loss = 8377.84
I1016 11:54:08.929716   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.93714 (* 1 = 6.93714 loss)
I1016 11:54:08.929721   329 solver.cpp:259]     Train net output #1: seg_loss = 6941.35 (* 1 = 6941.35 loss)
I1016 11:54:08.929728   329 sgd_solver.cpp:138] Iteration 11200, lr = 0.0005
I1016 11:55:11.954550   329 solver.cpp:243] Iteration 11300, loss = 11086.5
I1016 11:55:11.954581   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.99949 (* 1 = 5.99949 loss)
I1016 11:55:11.954587   329 solver.cpp:259]     Train net output #1: seg_loss = 26746.6 (* 1 = 26746.6 loss)
I1016 11:55:11.954593   329 sgd_solver.cpp:138] Iteration 11300, lr = 0.0005
I1016 11:55:59.855294   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 11:56:13.738385   329 solver.cpp:243] Iteration 11400, loss = 5684.44
I1016 11:56:13.738421   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.84576 (* 1 = 6.84576 loss)
I1016 11:56:13.738428   329 solver.cpp:259]     Train net output #1: seg_loss = 9130.49 (* 1 = 9130.49 loss)
I1016 11:56:13.738435   329 sgd_solver.cpp:138] Iteration 11400, lr = 0.0005
I1016 11:57:15.215097   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11500.caffemodel
I1016 11:57:15.680286   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11500.solverstate
I1016 11:57:16.341317   329 solver.cpp:243] Iteration 11500, loss = 14801.6
I1016 11:57:16.341351   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.34043 (* 1 = 6.34043 loss)
I1016 11:57:16.341356   329 solver.cpp:259]     Train net output #1: seg_loss = 5447.23 (* 1 = 5447.23 loss)
I1016 11:57:16.341363   329 sgd_solver.cpp:138] Iteration 11500, lr = 0.0005
I1016 11:58:17.207326   329 solver.cpp:243] Iteration 11600, loss = 6480.07
I1016 11:58:17.207360   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.9787 (* 1 = 11.9787 loss)
I1016 11:58:17.207365   329 solver.cpp:259]     Train net output #1: seg_loss = 7740.62 (* 1 = 7740.62 loss)
I1016 11:58:17.207371   329 sgd_solver.cpp:138] Iteration 11600, lr = 0.0005
I1016 11:59:19.432452   329 solver.cpp:243] Iteration 11700, loss = 6190.58
I1016 11:59:19.432490   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.79796 (* 1 = 6.79796 loss)
I1016 11:59:19.432497   329 solver.cpp:259]     Train net output #1: seg_loss = 8168.95 (* 1 = 8168.95 loss)
I1016 11:59:19.432502   329 sgd_solver.cpp:138] Iteration 11700, lr = 0.0005
I1016 12:00:22.336026   329 solver.cpp:243] Iteration 11800, loss = 13417.6
I1016 12:00:22.336060   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.1168 (* 1 = 4.1168 loss)
I1016 12:00:22.336066   329 solver.cpp:259]     Train net output #1: seg_loss = 5610.98 (* 1 = 5610.98 loss)
I1016 12:00:22.336071   329 sgd_solver.cpp:138] Iteration 11800, lr = 0.0005
I1016 12:01:24.863931   329 solver.cpp:243] Iteration 11900, loss = 5941.04
I1016 12:01:24.863965   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.69098 (* 1 = 5.69098 loss)
I1016 12:01:24.863973   329 solver.cpp:259]     Train net output #1: seg_loss = 7496.01 (* 1 = 7496.01 loss)
I1016 12:01:24.863996   329 sgd_solver.cpp:138] Iteration 11900, lr = 0.0005
I1016 12:02:26.276648   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12000.caffemodel
I1016 12:02:26.657299   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12000.solverstate
I1016 12:02:26.938448   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 12:03:43.926730   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:04:07.236577   329 solver.cpp:243] Iteration 12000, loss = 5933.59
I1016 12:04:07.236609   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.50372 (* 1 = 5.50372 loss)
I1016 12:04:07.236615   329 solver.cpp:259]     Train net output #1: seg_loss = 5928.09 (* 1 = 5928.09 loss)
I1016 12:04:07.236621   329 sgd_solver.cpp:138] Iteration 12000, lr = 0.0005
I1016 12:05:06.541726   329 solver.cpp:243] Iteration 12100, loss = 7266.83
I1016 12:05:06.541759   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.41384 (* 1 = 9.41384 loss)
I1016 12:05:06.541765   329 solver.cpp:259]     Train net output #1: seg_loss = 8253.97 (* 1 = 8253.97 loss)
I1016 12:05:06.541771   329 sgd_solver.cpp:138] Iteration 12100, lr = 0.0005
I1016 12:06:08.707029   329 solver.cpp:243] Iteration 12200, loss = 7190.28
I1016 12:06:08.707077   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.00525 (* 1 = 6.00525 loss)
I1016 12:06:08.707082   329 solver.cpp:259]     Train net output #1: seg_loss = 18539.5 (* 1 = 18539.5 loss)
I1016 12:06:08.707088   329 sgd_solver.cpp:138] Iteration 12200, lr = 0.0005
I1016 12:07:10.480016   329 solver.cpp:243] Iteration 12300, loss = 8926.44
I1016 12:07:10.480051   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.23304 (* 1 = 5.23304 loss)
I1016 12:07:10.480057   329 solver.cpp:259]     Train net output #1: seg_loss = 5314.62 (* 1 = 5314.62 loss)
I1016 12:07:10.480062   329 sgd_solver.cpp:138] Iteration 12300, lr = 0.0005
I1016 12:08:12.844952   329 solver.cpp:243] Iteration 12400, loss = 11518.7
I1016 12:08:12.844985   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.52184 (* 1 = 5.52184 loss)
I1016 12:08:12.844991   329 solver.cpp:259]     Train net output #1: seg_loss = 6373.57 (* 1 = 6373.57 loss)
I1016 12:08:12.844997   329 sgd_solver.cpp:138] Iteration 12400, lr = 0.0005
I1016 12:09:13.381724   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12500.caffemodel
I1016 12:09:13.632591   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12500.solverstate
I1016 12:09:14.250165   329 solver.cpp:243] Iteration 12500, loss = 6981.79
I1016 12:09:14.250198   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.76746 (* 1 = 8.76746 loss)
I1016 12:09:14.250208   329 solver.cpp:259]     Train net output #1: seg_loss = 6828.5 (* 1 = 6828.5 loss)
I1016 12:09:14.250216   329 sgd_solver.cpp:138] Iteration 12500, lr = 0.0005
I1016 12:10:14.867743   329 solver.cpp:243] Iteration 12600, loss = 5150.85
I1016 12:10:14.867775   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.43215 (* 1 = 5.43215 loss)
I1016 12:10:14.867782   329 solver.cpp:259]     Train net output #1: seg_loss = 5665.3 (* 1 = 5665.3 loss)
I1016 12:10:14.867789   329 sgd_solver.cpp:138] Iteration 12600, lr = 0.0005
I1016 12:11:16.281126   329 solver.cpp:243] Iteration 12700, loss = 16499.1
I1016 12:11:16.281157   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.8384 (* 1 = 10.8384 loss)
I1016 12:11:16.281164   329 solver.cpp:259]     Train net output #1: seg_loss = 6186.88 (* 1 = 6186.88 loss)
I1016 12:11:16.281169   329 sgd_solver.cpp:138] Iteration 12700, lr = 0.0005
I1016 12:12:17.857031   329 solver.cpp:243] Iteration 12800, loss = 5789.05
I1016 12:12:17.857064   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.44881 (* 1 = 8.44881 loss)
I1016 12:12:17.857069   329 solver.cpp:259]     Train net output #1: seg_loss = 7138.7 (* 1 = 7138.7 loss)
I1016 12:12:17.857075   329 sgd_solver.cpp:138] Iteration 12800, lr = 0.0005
I1016 12:13:15.904455   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:13:20.157210   329 solver.cpp:243] Iteration 12900, loss = 5627.12
I1016 12:13:20.157258   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.06796 (* 1 = 6.06796 loss)
I1016 12:13:20.157264   329 solver.cpp:259]     Train net output #1: seg_loss = 5551.09 (* 1 = 5551.09 loss)
I1016 12:13:20.157270   329 sgd_solver.cpp:138] Iteration 12900, lr = 0.0005
I1016 12:14:21.720373   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13000.caffemodel
I1016 12:14:22.062059   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13000.solverstate
I1016 12:14:22.663635   329 solver.cpp:243] Iteration 13000, loss = 6651.83
I1016 12:14:22.663681   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.31402 (* 1 = 8.31402 loss)
I1016 12:14:22.663686   329 solver.cpp:259]     Train net output #1: seg_loss = 5827.02 (* 1 = 5827.02 loss)
I1016 12:14:22.663693   329 sgd_solver.cpp:138] Iteration 13000, lr = 0.0005
I1016 12:15:23.365959   329 solver.cpp:243] Iteration 13100, loss = 5343.31
I1016 12:15:23.365990   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.08554 (* 1 = 7.08554 loss)
I1016 12:15:23.365996   329 solver.cpp:259]     Train net output #1: seg_loss = 5631.84 (* 1 = 5631.84 loss)
I1016 12:15:23.366003   329 sgd_solver.cpp:138] Iteration 13100, lr = 0.0005
I1016 12:16:24.009618   329 solver.cpp:243] Iteration 13200, loss = 9642.13
I1016 12:16:24.009652   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.88443 (* 1 = 4.88443 loss)
I1016 12:16:24.009658   329 solver.cpp:259]     Train net output #1: seg_loss = 5847.78 (* 1 = 5847.78 loss)
I1016 12:16:24.009663   329 sgd_solver.cpp:138] Iteration 13200, lr = 0.0005
I1016 12:17:26.015280   329 solver.cpp:243] Iteration 13300, loss = 5355.57
I1016 12:17:26.015311   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.0753 (* 1 = 10.0753 loss)
I1016 12:17:26.015317   329 solver.cpp:259]     Train net output #1: seg_loss = 7041.9 (* 1 = 7041.9 loss)
I1016 12:17:26.015323   329 sgd_solver.cpp:138] Iteration 13300, lr = 0.0005
I1016 12:18:28.023054   329 solver.cpp:243] Iteration 13400, loss = 6878.26
I1016 12:18:28.023089   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.17006 (* 1 = 9.17006 loss)
I1016 12:18:28.023097   329 solver.cpp:259]     Train net output #1: seg_loss = 9659.54 (* 1 = 9659.54 loss)
I1016 12:18:28.023102   329 sgd_solver.cpp:138] Iteration 13400, lr = 0.0005
I1016 12:19:29.638270   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13500.caffemodel
I1016 12:19:29.929361   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13500.solverstate
I1016 12:19:30.497247   329 solver.cpp:243] Iteration 13500, loss = 5385.78
I1016 12:19:30.497280   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.73827 (* 1 = 5.73827 loss)
I1016 12:19:30.497287   329 solver.cpp:259]     Train net output #1: seg_loss = 5372.25 (* 1 = 5372.25 loss)
I1016 12:19:30.497292   329 sgd_solver.cpp:138] Iteration 13500, lr = 0.0005
I1016 12:20:31.555687   329 solver.cpp:243] Iteration 13600, loss = 5312.29
I1016 12:20:31.555721   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.26295 (* 1 = 7.26295 loss)
I1016 12:20:31.555727   329 solver.cpp:259]     Train net output #1: seg_loss = 3690.93 (* 1 = 3690.93 loss)
I1016 12:20:31.555732   329 sgd_solver.cpp:138] Iteration 13600, lr = 0.0005
I1016 12:21:32.046445   329 solver.cpp:243] Iteration 13700, loss = 4553.17
I1016 12:21:32.046478   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.27575 (* 1 = 5.27575 loss)
I1016 12:21:32.046484   329 solver.cpp:259]     Train net output #1: seg_loss = 4709 (* 1 = 4709 loss)
I1016 12:21:32.046491   329 sgd_solver.cpp:138] Iteration 13700, lr = 0.0005
I1016 12:22:34.000321   329 solver.cpp:243] Iteration 13800, loss = 6023.38
I1016 12:22:34.000355   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.81036 (* 1 = 9.81036 loss)
I1016 12:22:34.000360   329 solver.cpp:259]     Train net output #1: seg_loss = 8746.6 (* 1 = 8746.6 loss)
I1016 12:22:34.000366   329 sgd_solver.cpp:138] Iteration 13800, lr = 0.0005
I1016 12:23:33.587229   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:23:35.361346   329 solver.cpp:243] Iteration 13900, loss = 4702.58
I1016 12:23:35.361377   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.03485 (* 1 = 3.03485 loss)
I1016 12:23:35.361383   329 solver.cpp:259]     Train net output #1: seg_loss = 5281.43 (* 1 = 5281.43 loss)
I1016 12:23:35.361389   329 sgd_solver.cpp:138] Iteration 13900, lr = 0.0005
I1016 12:24:37.154739   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14000.caffemodel
I1016 12:24:37.465617   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14000.solverstate
I1016 12:24:38.083838   329 solver.cpp:243] Iteration 14000, loss = 6783.08
I1016 12:24:38.083884   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.65929 (* 1 = 6.65929 loss)
I1016 12:24:38.083889   329 solver.cpp:259]     Train net output #1: seg_loss = 4392.16 (* 1 = 4392.16 loss)
I1016 12:24:38.083895   329 sgd_solver.cpp:138] Iteration 14000, lr = 0.0005
I1016 12:25:39.479806   329 solver.cpp:243] Iteration 14100, loss = 6463.45
I1016 12:25:39.479854   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.60305 (* 1 = 6.60305 loss)
I1016 12:25:39.479861   329 solver.cpp:259]     Train net output #1: seg_loss = 5320.5 (* 1 = 5320.5 loss)
I1016 12:25:39.479866   329 sgd_solver.cpp:138] Iteration 14100, lr = 0.0005
I1016 12:26:40.772330   329 solver.cpp:243] Iteration 14200, loss = 6161.13
I1016 12:26:40.772377   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.76079 (* 1 = 8.76079 loss)
I1016 12:26:40.772383   329 solver.cpp:259]     Train net output #1: seg_loss = 8734.75 (* 1 = 8734.75 loss)
I1016 12:26:40.772389   329 sgd_solver.cpp:138] Iteration 14200, lr = 0.0005
I1016 12:27:41.560544   329 solver.cpp:243] Iteration 14300, loss = 5369.04
I1016 12:27:41.560576   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.65606 (* 1 = 8.65606 loss)
I1016 12:27:41.560583   329 solver.cpp:259]     Train net output #1: seg_loss = 5235.56 (* 1 = 5235.56 loss)
I1016 12:27:41.560590   329 sgd_solver.cpp:138] Iteration 14300, lr = 0.0005
I1016 12:28:43.329504   329 solver.cpp:243] Iteration 14400, loss = 4642.08
I1016 12:28:43.329538   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.59801 (* 1 = 6.59801 loss)
I1016 12:28:43.329547   329 solver.cpp:259]     Train net output #1: seg_loss = 5685.48 (* 1 = 5685.48 loss)
I1016 12:28:43.329571   329 sgd_solver.cpp:138] Iteration 14400, lr = 0.0005
I1016 12:29:44.946225   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14500.caffemodel
I1016 12:29:45.238674   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14500.solverstate
I1016 12:29:45.846285   329 solver.cpp:243] Iteration 14500, loss = 5823.14
I1016 12:29:45.846319   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.19023 (* 1 = 8.19023 loss)
I1016 12:29:45.846328   329 solver.cpp:259]     Train net output #1: seg_loss = 7329.4 (* 1 = 7329.4 loss)
I1016 12:29:45.846338   329 sgd_solver.cpp:138] Iteration 14500, lr = 0.0005
I1016 12:30:47.624217   329 solver.cpp:243] Iteration 14600, loss = 5672.58
I1016 12:30:47.624250   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.68849 (* 1 = 7.68849 loss)
I1016 12:30:47.624258   329 solver.cpp:259]     Train net output #1: seg_loss = 4945.35 (* 1 = 4945.35 loss)
I1016 12:30:47.624281   329 sgd_solver.cpp:138] Iteration 14600, lr = 0.0005
I1016 12:31:48.878196   329 solver.cpp:243] Iteration 14700, loss = 4908.98
I1016 12:31:48.878232   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.1416 (* 1 = 7.1416 loss)
I1016 12:31:48.878240   329 solver.cpp:259]     Train net output #1: seg_loss = 6241.04 (* 1 = 6241.04 loss)
I1016 12:31:48.878248   329 sgd_solver.cpp:138] Iteration 14700, lr = 0.0005
I1016 12:32:49.200372   329 solver.cpp:243] Iteration 14800, loss = 4493.87
I1016 12:32:49.200407   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.73493 (* 1 = 7.73493 loss)
I1016 12:32:49.200415   329 solver.cpp:259]     Train net output #1: seg_loss = 3540.73 (* 1 = 3540.73 loss)
I1016 12:32:49.200438   329 sgd_solver.cpp:138] Iteration 14800, lr = 0.0005
I1016 12:33:51.362912   329 solver.cpp:243] Iteration 14900, loss = 5325.45
I1016 12:33:51.362960   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.10574 (* 1 = 5.10574 loss)
I1016 12:33:51.362967   329 solver.cpp:259]     Train net output #1: seg_loss = 6202.02 (* 1 = 6202.02 loss)
I1016 12:33:51.362972   329 sgd_solver.cpp:138] Iteration 14900, lr = 0.0005
I1016 12:33:52.035324   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:34:52.413334   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15000.caffemodel
I1016 12:34:52.704324   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15000.solverstate
I1016 12:34:53.331583   329 solver.cpp:243] Iteration 15000, loss = 6872.81
I1016 12:34:53.331615   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.1405 (* 1 = 5.1405 loss)
I1016 12:34:53.331621   329 solver.cpp:259]     Train net output #1: seg_loss = 6363.75 (* 1 = 6363.75 loss)
I1016 12:34:53.331627   329 sgd_solver.cpp:138] Iteration 15000, lr = 0.0005
I1016 12:35:55.448649   329 solver.cpp:243] Iteration 15100, loss = 6605.52
I1016 12:35:55.448707   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.54966 (* 1 = 3.54966 loss)
I1016 12:35:55.448716   329 solver.cpp:259]     Train net output #1: seg_loss = 3898.51 (* 1 = 3898.51 loss)
I1016 12:35:55.448724   329 sgd_solver.cpp:138] Iteration 15100, lr = 0.0005
I1016 12:36:56.733194   329 solver.cpp:243] Iteration 15200, loss = 6295.79
I1016 12:36:56.733242   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.13724 (* 1 = 5.13724 loss)
I1016 12:36:56.733248   329 solver.cpp:259]     Train net output #1: seg_loss = 5483.38 (* 1 = 5483.38 loss)
I1016 12:36:56.733254   329 sgd_solver.cpp:138] Iteration 15200, lr = 0.0005
I1016 12:37:57.765023   329 solver.cpp:243] Iteration 15300, loss = 5606.88
I1016 12:37:57.765060   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.35104 (* 1 = 7.35104 loss)
I1016 12:37:57.765066   329 solver.cpp:259]     Train net output #1: seg_loss = 3135.04 (* 1 = 3135.04 loss)
I1016 12:37:57.765074   329 sgd_solver.cpp:138] Iteration 15300, lr = 0.0005
I1016 12:38:58.901300   329 solver.cpp:243] Iteration 15400, loss = 8845.89
I1016 12:38:58.901331   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.60543 (* 1 = 9.60543 loss)
I1016 12:38:58.901337   329 solver.cpp:259]     Train net output #1: seg_loss = 8831.64 (* 1 = 8831.64 loss)
I1016 12:38:58.901343   329 sgd_solver.cpp:138] Iteration 15400, lr = 0.0005
I1016 12:39:59.935820   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15500.caffemodel
I1016 12:40:00.282279   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15500.solverstate
I1016 12:40:00.898459   329 solver.cpp:243] Iteration 15500, loss = 6567.81
I1016 12:40:00.898502   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.89988 (* 1 = 5.89988 loss)
I1016 12:40:00.898509   329 solver.cpp:259]     Train net output #1: seg_loss = 6103.74 (* 1 = 6103.74 loss)
I1016 12:40:00.898515   329 sgd_solver.cpp:138] Iteration 15500, lr = 0.0005
I1016 12:41:02.724287   329 solver.cpp:243] Iteration 15600, loss = 6061.85
I1016 12:41:02.724334   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.4179 (* 1 = 8.4179 loss)
I1016 12:41:02.724339   329 solver.cpp:259]     Train net output #1: seg_loss = 5705.33 (* 1 = 5705.33 loss)
I1016 12:41:02.724345   329 sgd_solver.cpp:138] Iteration 15600, lr = 0.0005
I1016 12:42:04.683758   329 solver.cpp:243] Iteration 15700, loss = 6334.6
I1016 12:42:04.683789   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.70675 (* 1 = 7.70675 loss)
I1016 12:42:04.683795   329 solver.cpp:259]     Train net output #1: seg_loss = 6638.96 (* 1 = 6638.96 loss)
I1016 12:42:04.683801   329 sgd_solver.cpp:138] Iteration 15700, lr = 0.0005
I1016 12:43:06.504572   329 solver.cpp:243] Iteration 15800, loss = 4146.49
I1016 12:43:06.504621   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.04722 (* 1 = 8.04722 loss)
I1016 12:43:06.504627   329 solver.cpp:259]     Train net output #1: seg_loss = 4325.51 (* 1 = 4325.51 loss)
I1016 12:43:06.504633   329 sgd_solver.cpp:138] Iteration 15800, lr = 0.0005
I1016 12:44:08.136936   329 solver.cpp:243] Iteration 15900, loss = 5928.93
I1016 12:44:08.136968   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.26898 (* 1 = 6.26898 loss)
I1016 12:44:08.136973   329 solver.cpp:259]     Train net output #1: seg_loss = 11691.1 (* 1 = 11691.1 loss)
I1016 12:44:08.136979   329 sgd_solver.cpp:138] Iteration 15900, lr = 0.0005
I1016 12:44:11.963002   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:45:09.972918   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_16000.caffemodel
I1016 12:45:10.357465   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_16000.solverstate
I1016 12:45:10.644815   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 12:46:51.653188   329 solver.cpp:243] Iteration 16000, loss = 6147.84
I1016 12:46:51.653221   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.25548 (* 1 = 6.25548 loss)
I1016 12:46:51.653228   329 solver.cpp:259]     Train net output #1: seg_loss = 6141.59 (* 1 = 6141.59 loss)
I1016 12:46:51.653234   329 sgd_solver.cpp:138] Iteration 16000, lr = 0.0005
I1016 12:47:53.032800   329 solver.cpp:243] Iteration 16100, loss = 5900.92
I1016 12:47:53.032850   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.52953 (* 1 = 5.52953 loss)
I1016 12:47:53.032857   329 solver.cpp:259]     Train net output #1: seg_loss = 4640.15 (* 1 = 4640.15 loss)
I1016 12:47:53.032881   329 sgd_solver.cpp:138] Iteration 16100, lr = 0.0005
I1016 12:48:55.671165   329 solver.cpp:243] Iteration 16200, loss = 4878.08
I1016 12:48:55.671202   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.11397 (* 1 = 7.11397 loss)
I1016 12:48:55.671211   329 solver.cpp:259]     Train net output #1: seg_loss = 3770.47 (* 1 = 3770.47 loss)
I1016 12:48:55.671219   329 sgd_solver.cpp:138] Iteration 16200, lr = 0.0005
I1016 12:49:57.698799   329 solver.cpp:243] Iteration 16300, loss = 5869.71
I1016 12:49:57.698832   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.88379 (* 1 = 5.88379 loss)
I1016 12:49:57.698840   329 solver.cpp:259]     Train net output #1: seg_loss = 7828.86 (* 1 = 7828.86 loss)
I1016 12:49:57.698849   329 sgd_solver.cpp:138] Iteration 16300, lr = 0.0005
I1016 12:50:58.621486   329 solver.cpp:243] Iteration 16400, loss = 5082.3
I1016 12:50:58.621533   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.34854 (* 1 = 8.34854 loss)
I1016 12:50:58.621556   329 solver.cpp:259]     Train net output #1: seg_loss = 4645.25 (* 1 = 4645.25 loss)
I1016 12:50:58.621562   329 sgd_solver.cpp:138] Iteration 16400, lr = 0.0005
I1016 12:51:08.208412   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 12:51:59.617813   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_16500.caffemodel
I1016 12:51:59.963373   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_16500.solverstate
I1016 12:52:00.630424   329 solver.cpp:243] Iteration 16500, loss = 5228.06
I1016 12:52:00.630470   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.6662 (* 1 = 12.6662 loss)
I1016 12:52:00.630476   329 solver.cpp:259]     Train net output #1: seg_loss = 4013.7 (* 1 = 4013.7 loss)
I1016 12:52:00.630482   329 sgd_solver.cpp:138] Iteration 16500, lr = 0.0005
I1016 12:53:01.569358   329 solver.cpp:243] Iteration 16600, loss = 4527.58
I1016 12:53:01.569406   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.73883 (* 1 = 4.73883 loss)
I1016 12:53:01.569412   329 solver.cpp:259]     Train net output #1: seg_loss = 3495.63 (* 1 = 3495.63 loss)
I1016 12:53:01.569418   329 sgd_solver.cpp:138] Iteration 16600, lr = 0.0005
I1016 12:54:03.617429   329 solver.cpp:243] Iteration 16700, loss = 7086.56
I1016 12:54:03.617478   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.26188 (* 1 = 6.26188 loss)
I1016 12:54:03.617485   329 solver.cpp:259]     Train net output #1: seg_loss = 9050.46 (* 1 = 9050.46 loss)
I1016 12:54:03.617489   329 sgd_solver.cpp:138] Iteration 16700, lr = 0.0005
I1016 12:55:05.271104   329 solver.cpp:243] Iteration 16800, loss = 4897.9
I1016 12:55:05.271153   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.89454 (* 1 = 5.89454 loss)
I1016 12:55:05.271159   329 solver.cpp:259]     Train net output #1: seg_loss = 4105.77 (* 1 = 4105.77 loss)
I1016 12:55:05.271165   329 sgd_solver.cpp:138] Iteration 16800, lr = 0.0005
I1016 12:56:06.239414   329 solver.cpp:243] Iteration 16900, loss = 5346.15
I1016 12:56:06.239446   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.2683 (* 1 = 6.2683 loss)
I1016 12:56:06.239452   329 solver.cpp:259]     Train net output #1: seg_loss = 6148.89 (* 1 = 6148.89 loss)
I1016 12:56:06.239459   329 sgd_solver.cpp:138] Iteration 16900, lr = 0.0005
I1016 12:57:06.253001   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_17000.caffemodel
I1016 12:57:06.558511   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_17000.solverstate
I1016 12:57:07.171954   329 solver.cpp:243] Iteration 17000, loss = 8202.46
I1016 12:57:07.171986   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.2822 (* 1 = 5.2822 loss)
I1016 12:57:07.171993   329 solver.cpp:259]     Train net output #1: seg_loss = 6359.13 (* 1 = 6359.13 loss)
I1016 12:57:07.171999   329 sgd_solver.cpp:138] Iteration 17000, lr = 0.0005
I1016 12:58:08.525820   329 solver.cpp:243] Iteration 17100, loss = 4394.15
I1016 12:58:08.525871   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.46359 (* 1 = 4.46359 loss)
I1016 12:58:08.525878   329 solver.cpp:259]     Train net output #1: seg_loss = 3632.95 (* 1 = 3632.95 loss)
I1016 12:58:08.525883   329 sgd_solver.cpp:138] Iteration 17100, lr = 0.0005
I1016 12:59:09.504981   329 solver.cpp:243] Iteration 17200, loss = 6139.46
I1016 12:59:09.505014   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.6424 (* 1 = 11.6424 loss)
I1016 12:59:09.505022   329 solver.cpp:259]     Train net output #1: seg_loss = 4643.16 (* 1 = 4643.16 loss)
I1016 12:59:09.505028   329 sgd_solver.cpp:138] Iteration 17200, lr = 0.0005
I1016 13:00:09.819999   329 solver.cpp:243] Iteration 17300, loss = 4383
I1016 13:00:09.820046   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.4098 (* 1 = 10.4098 loss)
I1016 13:00:09.820053   329 solver.cpp:259]     Train net output #1: seg_loss = 4190.75 (* 1 = 4190.75 loss)
I1016 13:00:09.820060   329 sgd_solver.cpp:138] Iteration 17300, lr = 0.0005
I1016 13:01:09.138376   329 solver.cpp:243] Iteration 17400, loss = 4791.76
I1016 13:01:09.138432   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.98824 (* 1 = 4.98824 loss)
I1016 13:01:09.138437   329 solver.cpp:259]     Train net output #1: seg_loss = 4565.39 (* 1 = 4565.39 loss)
I1016 13:01:09.138443   329 sgd_solver.cpp:138] Iteration 17400, lr = 0.0005
I1016 13:01:21.568094   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:02:07.108870   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_17500.caffemodel
I1016 13:02:07.422636   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_17500.solverstate
I1016 13:02:08.034298   329 solver.cpp:243] Iteration 17500, loss = 3881.84
I1016 13:02:08.034346   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.87886 (* 1 = 5.87886 loss)
I1016 13:02:08.034353   329 solver.cpp:259]     Train net output #1: seg_loss = 3206.39 (* 1 = 3206.39 loss)
I1016 13:02:08.034358   329 sgd_solver.cpp:138] Iteration 17500, lr = 0.0005
I1016 13:03:07.667985   329 solver.cpp:243] Iteration 17600, loss = 5178.2
I1016 13:03:07.668040   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.42502 (* 1 = 6.42502 loss)
I1016 13:03:07.668047   329 solver.cpp:259]     Train net output #1: seg_loss = 5836.53 (* 1 = 5836.53 loss)
I1016 13:03:07.668053   329 sgd_solver.cpp:138] Iteration 17600, lr = 0.0005
I1016 13:04:07.249078   329 solver.cpp:243] Iteration 17700, loss = 7191.09
I1016 13:04:07.249128   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.05314 (* 1 = 6.05314 loss)
I1016 13:04:07.249135   329 solver.cpp:259]     Train net output #1: seg_loss = 12212.3 (* 1 = 12212.3 loss)
I1016 13:04:07.249141   329 sgd_solver.cpp:138] Iteration 17700, lr = 0.0005
I1016 13:05:07.339370   329 solver.cpp:243] Iteration 17800, loss = 5807.94
I1016 13:05:07.339404   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.29916 (* 1 = 5.29916 loss)
I1016 13:05:07.339411   329 solver.cpp:259]     Train net output #1: seg_loss = 5954.9 (* 1 = 5954.9 loss)
I1016 13:05:07.339417   329 sgd_solver.cpp:138] Iteration 17800, lr = 0.0005
I1016 13:06:06.588621   329 solver.cpp:243] Iteration 17900, loss = 4290.79
I1016 13:06:06.588671   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.57233 (* 1 = 8.57233 loss)
I1016 13:06:06.588677   329 solver.cpp:259]     Train net output #1: seg_loss = 6099.93 (* 1 = 6099.93 loss)
I1016 13:06:06.588683   329 sgd_solver.cpp:138] Iteration 17900, lr = 0.0005
I1016 13:07:05.372508   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_18000.caffemodel
I1016 13:07:05.636342   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_18000.solverstate
I1016 13:07:06.209924   329 solver.cpp:243] Iteration 18000, loss = 11894.7
I1016 13:07:06.209957   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.49446 (* 1 = 5.49446 loss)
I1016 13:07:06.209964   329 solver.cpp:259]     Train net output #1: seg_loss = 5791.78 (* 1 = 5791.78 loss)
I1016 13:07:06.209969   329 sgd_solver.cpp:138] Iteration 18000, lr = 0.0005
I1016 13:08:04.672683   329 solver.cpp:243] Iteration 18100, loss = 5375.86
I1016 13:08:04.672734   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.72708 (* 1 = 6.72708 loss)
I1016 13:08:04.672739   329 solver.cpp:259]     Train net output #1: seg_loss = 6529.05 (* 1 = 6529.05 loss)
I1016 13:08:04.672746   329 sgd_solver.cpp:138] Iteration 18100, lr = 0.0005
I1016 13:09:04.306140   329 solver.cpp:243] Iteration 18200, loss = 4275.4
I1016 13:09:04.306205   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.25151 (* 1 = 3.25151 loss)
I1016 13:09:04.306210   329 solver.cpp:259]     Train net output #1: seg_loss = 1887.54 (* 1 = 1887.54 loss)
I1016 13:09:04.306216   329 sgd_solver.cpp:138] Iteration 18200, lr = 0.0005
I1016 13:10:04.288409   329 solver.cpp:243] Iteration 18300, loss = 10932.9
I1016 13:10:04.288460   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.54914 (* 1 = 4.54914 loss)
I1016 13:10:04.288465   329 solver.cpp:259]     Train net output #1: seg_loss = 6304.05 (* 1 = 6304.05 loss)
I1016 13:10:04.288471   329 sgd_solver.cpp:138] Iteration 18300, lr = 0.0005
I1016 13:11:03.988050   329 solver.cpp:243] Iteration 18400, loss = 4528.17
I1016 13:11:03.988101   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.3021 (* 1 = 7.3021 loss)
I1016 13:11:03.988106   329 solver.cpp:259]     Train net output #1: seg_loss = 8139.56 (* 1 = 8139.56 loss)
I1016 13:11:03.988113   329 sgd_solver.cpp:138] Iteration 18400, lr = 0.0005
I1016 13:11:20.007843   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:12:02.476086   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_18500.caffemodel
I1016 13:12:03.202183   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_18500.solverstate
I1016 13:12:03.771999   329 solver.cpp:243] Iteration 18500, loss = 4601.13
I1016 13:12:03.772037   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.1751 (* 1 = 9.1751 loss)
I1016 13:12:03.772045   329 solver.cpp:259]     Train net output #1: seg_loss = 3279.96 (* 1 = 3279.96 loss)
I1016 13:12:03.772063   329 sgd_solver.cpp:138] Iteration 18500, lr = 0.0005
I1016 13:13:01.168876   329 solver.cpp:243] Iteration 18600, loss = 5762.09
I1016 13:13:01.168926   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.80083 (* 1 = 6.80083 loss)
I1016 13:13:01.168931   329 solver.cpp:259]     Train net output #1: seg_loss = 8019.63 (* 1 = 8019.63 loss)
I1016 13:13:01.168938   329 sgd_solver.cpp:138] Iteration 18600, lr = 0.0005
I1016 13:14:00.921887   329 solver.cpp:243] Iteration 18700, loss = 4568.87
I1016 13:14:00.921921   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.85394 (* 1 = 8.85394 loss)
I1016 13:14:00.921926   329 solver.cpp:259]     Train net output #1: seg_loss = 4097.78 (* 1 = 4097.78 loss)
I1016 13:14:00.921932   329 sgd_solver.cpp:138] Iteration 18700, lr = 0.0005
I1016 13:15:00.442813   329 solver.cpp:243] Iteration 18800, loss = 4848.31
I1016 13:15:00.442864   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.22683 (* 1 = 5.22683 loss)
I1016 13:15:00.442870   329 solver.cpp:259]     Train net output #1: seg_loss = 3880.81 (* 1 = 3880.81 loss)
I1016 13:15:00.442876   329 sgd_solver.cpp:138] Iteration 18800, lr = 0.0005
I1016 13:16:00.687135   329 solver.cpp:243] Iteration 18900, loss = 7258.76
I1016 13:16:00.687187   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.15605 (* 1 = 3.15605 loss)
I1016 13:16:00.687193   329 solver.cpp:259]     Train net output #1: seg_loss = 8152.66 (* 1 = 8152.66 loss)
I1016 13:16:00.687199   329 sgd_solver.cpp:138] Iteration 18900, lr = 0.0005
I1016 13:16:59.217545   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_19000.caffemodel
I1016 13:17:00.032758   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_19000.solverstate
I1016 13:17:00.588738   329 solver.cpp:243] Iteration 19000, loss = 9377.61
I1016 13:17:00.588788   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.72811 (* 1 = 5.72811 loss)
I1016 13:17:00.588794   329 solver.cpp:259]     Train net output #1: seg_loss = 4999.63 (* 1 = 4999.63 loss)
I1016 13:17:00.588800   329 sgd_solver.cpp:138] Iteration 19000, lr = 0.0005
I1016 13:17:59.031167   329 solver.cpp:243] Iteration 19100, loss = 5618.1
I1016 13:17:59.031214   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.9064 (* 1 = 5.9064 loss)
I1016 13:17:59.031221   329 solver.cpp:259]     Train net output #1: seg_loss = 4461.39 (* 1 = 4461.39 loss)
I1016 13:17:59.031227   329 sgd_solver.cpp:138] Iteration 19100, lr = 0.0005
I1016 13:18:58.211599   329 solver.cpp:243] Iteration 19200, loss = 9548.54
I1016 13:18:58.211633   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.5623 (* 1 = 7.5623 loss)
I1016 13:18:58.211639   329 solver.cpp:259]     Train net output #1: seg_loss = 7902.92 (* 1 = 7902.92 loss)
I1016 13:18:58.211645   329 sgd_solver.cpp:138] Iteration 19200, lr = 0.0005
I1016 13:19:57.478595   329 solver.cpp:243] Iteration 19300, loss = 4866.79
I1016 13:19:57.478646   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.43846 (* 1 = 5.43846 loss)
I1016 13:19:57.478652   329 solver.cpp:259]     Train net output #1: seg_loss = 4334.6 (* 1 = 4334.6 loss)
I1016 13:19:57.478657   329 sgd_solver.cpp:138] Iteration 19300, lr = 0.0005
I1016 13:20:57.423517   329 solver.cpp:243] Iteration 19400, loss = 5097.14
I1016 13:20:57.423554   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.16412 (* 1 = 4.16412 loss)
I1016 13:20:57.423563   329 solver.cpp:259]     Train net output #1: seg_loss = 4809.1 (* 1 = 4809.1 loss)
I1016 13:20:57.423570   329 sgd_solver.cpp:138] Iteration 19400, lr = 0.0005
I1016 13:21:19.955523   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:21:56.710103   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_19500.caffemodel
I1016 13:21:57.545624   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_19500.solverstate
I1016 13:21:58.128365   329 solver.cpp:243] Iteration 19500, loss = 5780.34
I1016 13:21:58.128399   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.7328 (* 1 = 6.7328 loss)
I1016 13:21:58.128408   329 solver.cpp:259]     Train net output #1: seg_loss = 5789.31 (* 1 = 5789.31 loss)
I1016 13:21:58.128415   329 sgd_solver.cpp:138] Iteration 19500, lr = 0.0005
I1016 13:22:56.322176   329 solver.cpp:243] Iteration 19600, loss = 4635.17
I1016 13:22:56.322227   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.36408 (* 1 = 5.36408 loss)
I1016 13:22:56.322233   329 solver.cpp:259]     Train net output #1: seg_loss = 5068.51 (* 1 = 5068.51 loss)
I1016 13:22:56.322239   329 sgd_solver.cpp:138] Iteration 19600, lr = 0.0005
I1016 13:23:54.700954   329 solver.cpp:243] Iteration 19700, loss = 6348.45
I1016 13:23:54.701006   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.50925 (* 1 = 6.50925 loss)
I1016 13:23:54.701012   329 solver.cpp:259]     Train net output #1: seg_loss = 8542.3 (* 1 = 8542.3 loss)
I1016 13:23:54.701019   329 sgd_solver.cpp:138] Iteration 19700, lr = 0.0005
I1016 13:24:54.297466   329 solver.cpp:243] Iteration 19800, loss = 4118.82
I1016 13:24:54.297518   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.00369 (* 1 = 6.00369 loss)
I1016 13:24:54.297524   329 solver.cpp:259]     Train net output #1: seg_loss = 3996.37 (* 1 = 3996.37 loss)
I1016 13:24:54.297529   329 sgd_solver.cpp:138] Iteration 19800, lr = 0.0005
I1016 13:25:54.013528   329 solver.cpp:243] Iteration 19900, loss = 4770.7
I1016 13:25:54.013577   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.07459 (* 1 = 7.07459 loss)
I1016 13:25:54.013583   329 solver.cpp:259]     Train net output #1: seg_loss = 6786.55 (* 1 = 6786.55 loss)
I1016 13:25:54.013589   329 sgd_solver.cpp:138] Iteration 19900, lr = 0.0005
I1016 13:26:53.481017   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_20000.caffemodel
I1016 13:26:54.252949   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_20000.solverstate
I1016 13:26:54.501001   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 13:28:21.228639   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:28:32.151355   329 solver.cpp:243] Iteration 20000, loss = 3881.81
I1016 13:28:32.151393   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.91442 (* 1 = 5.91442 loss)
I1016 13:28:32.151399   329 solver.cpp:259]     Train net output #1: seg_loss = 3875.9 (* 1 = 3875.9 loss)
I1016 13:28:32.151404   329 sgd_solver.cpp:47] MultiStep Status: Iteration 20000, step = 1
I1016 13:28:32.151408   329 sgd_solver.cpp:138] Iteration 20000, lr = 0.00025
I1016 13:29:30.521677   329 solver.cpp:243] Iteration 20100, loss = 4312.33
I1016 13:29:30.521713   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.79097 (* 1 = 4.79097 loss)
I1016 13:29:30.521720   329 solver.cpp:259]     Train net output #1: seg_loss = 4532.48 (* 1 = 4532.48 loss)
I1016 13:29:30.521728   329 sgd_solver.cpp:138] Iteration 20100, lr = 0.00025
I1016 13:30:29.216579   329 solver.cpp:243] Iteration 20200, loss = 3996.14
I1016 13:30:29.216615   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.85977 (* 1 = 7.85977 loss)
I1016 13:30:29.216624   329 solver.cpp:259]     Train net output #1: seg_loss = 3185 (* 1 = 3185 loss)
I1016 13:30:29.216647   329 sgd_solver.cpp:138] Iteration 20200, lr = 0.00025
I1016 13:31:29.141659   329 solver.cpp:243] Iteration 20300, loss = 4985.98
I1016 13:31:29.141697   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.83389 (* 1 = 6.83389 loss)
I1016 13:31:29.141706   329 solver.cpp:259]     Train net output #1: seg_loss = 4013.25 (* 1 = 4013.25 loss)
I1016 13:31:29.141729   329 sgd_solver.cpp:138] Iteration 20300, lr = 0.00025
I1016 13:32:28.697444   329 solver.cpp:243] Iteration 20400, loss = 3621.78
I1016 13:32:28.697484   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.61998 (* 1 = 7.61998 loss)
I1016 13:32:28.697494   329 solver.cpp:259]     Train net output #1: seg_loss = 3747.57 (* 1 = 3747.57 loss)
I1016 13:32:28.697516   329 sgd_solver.cpp:138] Iteration 20400, lr = 0.00025
I1016 13:33:28.462327   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_20500.caffemodel
I1016 13:33:28.771194   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_20500.solverstate
I1016 13:33:29.339128   329 solver.cpp:243] Iteration 20500, loss = 5309.58
I1016 13:33:29.339171   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.07863 (* 1 = 3.07863 loss)
I1016 13:33:29.339179   329 solver.cpp:259]     Train net output #1: seg_loss = 3470.4 (* 1 = 3470.4 loss)
I1016 13:33:29.339184   329 sgd_solver.cpp:138] Iteration 20500, lr = 0.00025
I1016 13:34:28.728658   329 solver.cpp:243] Iteration 20600, loss = 4329.79
I1016 13:34:28.728690   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.91467 (* 1 = 5.91467 loss)
I1016 13:34:28.728696   329 solver.cpp:259]     Train net output #1: seg_loss = 4417.63 (* 1 = 4417.63 loss)
I1016 13:34:28.728703   329 sgd_solver.cpp:138] Iteration 20600, lr = 0.00025
I1016 13:35:27.986352   329 solver.cpp:243] Iteration 20700, loss = 4619.39
I1016 13:35:27.986404   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.18775 (* 1 = 4.18775 loss)
I1016 13:35:27.986410   329 solver.cpp:259]     Train net output #1: seg_loss = 6318.37 (* 1 = 6318.37 loss)
I1016 13:35:27.986416   329 sgd_solver.cpp:138] Iteration 20700, lr = 0.00025
I1016 13:36:26.612545   329 solver.cpp:243] Iteration 20800, loss = 4140.04
I1016 13:36:26.612594   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.5213 (* 1 = 10.5213 loss)
I1016 13:36:26.612601   329 solver.cpp:259]     Train net output #1: seg_loss = 4407.87 (* 1 = 4407.87 loss)
I1016 13:36:26.612607   329 sgd_solver.cpp:138] Iteration 20800, lr = 0.00025
I1016 13:37:26.184154   329 solver.cpp:243] Iteration 20900, loss = 3713.81
I1016 13:37:26.184192   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.46551 (* 1 = 7.46551 loss)
I1016 13:37:26.184201   329 solver.cpp:259]     Train net output #1: seg_loss = 2904.43 (* 1 = 2904.43 loss)
I1016 13:37:26.184208   329 sgd_solver.cpp:138] Iteration 20900, lr = 0.00025
I1016 13:37:59.117333   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:38:25.644383   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_21000.caffemodel
I1016 13:38:26.374372   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_21000.solverstate
I1016 13:38:26.955624   329 solver.cpp:243] Iteration 21000, loss = 4435.32
I1016 13:38:26.955669   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.57902 (* 1 = 8.57902 loss)
I1016 13:38:26.955675   329 solver.cpp:259]     Train net output #1: seg_loss = 4345.73 (* 1 = 4345.73 loss)
I1016 13:38:26.955682   329 sgd_solver.cpp:138] Iteration 21000, lr = 0.00025
I1016 13:39:26.244364   329 solver.cpp:243] Iteration 21100, loss = 4077.19
I1016 13:39:26.244415   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.7223 (* 1 = 10.7223 loss)
I1016 13:39:26.244421   329 solver.cpp:259]     Train net output #1: seg_loss = 3719.12 (* 1 = 3719.12 loss)
I1016 13:39:26.244427   329 sgd_solver.cpp:138] Iteration 21100, lr = 0.00025
I1016 13:40:25.311213   329 solver.cpp:243] Iteration 21200, loss = 3977.04
I1016 13:40:25.311260   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.89835 (* 1 = 5.89835 loss)
I1016 13:40:25.311267   329 solver.cpp:259]     Train net output #1: seg_loss = 4053.43 (* 1 = 4053.43 loss)
I1016 13:40:25.311273   329 sgd_solver.cpp:138] Iteration 21200, lr = 0.00025
I1016 13:41:23.547109   329 solver.cpp:243] Iteration 21300, loss = 3993.59
I1016 13:41:23.547159   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.65108 (* 1 = 4.65108 loss)
I1016 13:41:23.547165   329 solver.cpp:259]     Train net output #1: seg_loss = 4091.6 (* 1 = 4091.6 loss)
I1016 13:41:23.547171   329 sgd_solver.cpp:138] Iteration 21300, lr = 0.00025
I1016 13:42:23.429476   329 solver.cpp:243] Iteration 21400, loss = 4152.62
I1016 13:42:23.429509   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.01246 (* 1 = 9.01246 loss)
I1016 13:42:23.429515   329 solver.cpp:259]     Train net output #1: seg_loss = 4365.74 (* 1 = 4365.74 loss)
I1016 13:42:23.429522   329 sgd_solver.cpp:138] Iteration 21400, lr = 0.00025
I1016 13:43:22.366992   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_21500.caffemodel
I1016 13:43:23.180126   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_21500.solverstate
I1016 13:43:23.746409   329 solver.cpp:243] Iteration 21500, loss = 5151.5
I1016 13:43:23.746459   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.1687 (* 1 = 7.1687 loss)
I1016 13:43:23.746464   329 solver.cpp:259]     Train net output #1: seg_loss = 4968.38 (* 1 = 4968.38 loss)
I1016 13:43:23.746470   329 sgd_solver.cpp:138] Iteration 21500, lr = 0.00025
I1016 13:44:23.259788   329 solver.cpp:243] Iteration 21600, loss = 3574.97
I1016 13:44:23.259840   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.14595 (* 1 = 9.14595 loss)
I1016 13:44:23.259846   329 solver.cpp:259]     Train net output #1: seg_loss = 3306.61 (* 1 = 3306.61 loss)
I1016 13:44:23.259852   329 sgd_solver.cpp:138] Iteration 21600, lr = 0.00025
I1016 13:45:22.365021   329 solver.cpp:243] Iteration 21700, loss = 4956.76
I1016 13:45:22.365070   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.42588 (* 1 = 5.42588 loss)
I1016 13:45:22.365077   329 solver.cpp:259]     Train net output #1: seg_loss = 5414.56 (* 1 = 5414.56 loss)
I1016 13:45:22.365082   329 sgd_solver.cpp:138] Iteration 21700, lr = 0.00025
I1016 13:46:21.383222   329 solver.cpp:243] Iteration 21800, loss = 4557.51
I1016 13:46:21.383273   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.25039 (* 1 = 6.25039 loss)
I1016 13:46:21.383278   329 solver.cpp:259]     Train net output #1: seg_loss = 3206.02 (* 1 = 3206.02 loss)
I1016 13:46:21.383285   329 sgd_solver.cpp:138] Iteration 21800, lr = 0.00025
I1016 13:47:20.420846   329 solver.cpp:243] Iteration 21900, loss = 5672.05
I1016 13:47:20.420897   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.66793 (* 1 = 7.66793 loss)
I1016 13:47:20.420902   329 solver.cpp:259]     Train net output #1: seg_loss = 5677.12 (* 1 = 5677.12 loss)
I1016 13:47:20.420908   329 sgd_solver.cpp:138] Iteration 21900, lr = 0.00025
I1016 13:47:59.108146   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:48:19.292985   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_22000.caffemodel
I1016 13:48:19.533272   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_22000.solverstate
I1016 13:48:20.529422   329 solver.cpp:243] Iteration 22000, loss = 4265.35
I1016 13:48:20.529471   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.30291 (* 1 = 7.30291 loss)
I1016 13:48:20.529477   329 solver.cpp:259]     Train net output #1: seg_loss = 3231.44 (* 1 = 3231.44 loss)
I1016 13:48:20.529484   329 sgd_solver.cpp:138] Iteration 22000, lr = 0.00025
I1016 13:49:19.774816   329 solver.cpp:243] Iteration 22100, loss = 4505.99
I1016 13:49:19.774868   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.73155 (* 1 = 3.73155 loss)
I1016 13:49:19.774873   329 solver.cpp:259]     Train net output #1: seg_loss = 4433.57 (* 1 = 4433.57 loss)
I1016 13:49:19.774879   329 sgd_solver.cpp:138] Iteration 22100, lr = 0.00025
I1016 13:50:19.579205   329 solver.cpp:243] Iteration 22200, loss = 5008.85
I1016 13:50:19.579255   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.09231 (* 1 = 9.09231 loss)
I1016 13:50:19.579262   329 solver.cpp:259]     Train net output #1: seg_loss = 5675.48 (* 1 = 5675.48 loss)
I1016 13:50:19.579267   329 sgd_solver.cpp:138] Iteration 22200, lr = 0.00025
I1016 13:51:18.636795   329 solver.cpp:243] Iteration 22300, loss = 3405.19
I1016 13:51:18.636845   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.20739 (* 1 = 7.20739 loss)
I1016 13:51:18.636852   329 solver.cpp:259]     Train net output #1: seg_loss = 3987.88 (* 1 = 3987.88 loss)
I1016 13:51:18.636857   329 sgd_solver.cpp:138] Iteration 22300, lr = 0.00025
I1016 13:52:16.895148   329 solver.cpp:243] Iteration 22400, loss = 4185.34
I1016 13:52:16.895197   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.37827 (* 1 = 6.37827 loss)
I1016 13:52:16.895203   329 solver.cpp:259]     Train net output #1: seg_loss = 3576.15 (* 1 = 3576.15 loss)
I1016 13:52:16.895210   329 sgd_solver.cpp:138] Iteration 22400, lr = 0.00025
I1016 13:53:16.048118   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_22500.caffemodel
I1016 13:53:16.890982   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_22500.solverstate
I1016 13:53:17.464964   329 solver.cpp:243] Iteration 22500, loss = 4387.09
I1016 13:53:17.465009   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.56772 (* 1 = 4.56772 loss)
I1016 13:53:17.465015   329 solver.cpp:259]     Train net output #1: seg_loss = 3179.7 (* 1 = 3179.7 loss)
I1016 13:53:17.465021   329 sgd_solver.cpp:138] Iteration 22500, lr = 0.00025
I1016 13:54:16.321741   329 solver.cpp:243] Iteration 22600, loss = 4373.71
I1016 13:54:16.321792   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.89158 (* 1 = 6.89158 loss)
I1016 13:54:16.321799   329 solver.cpp:259]     Train net output #1: seg_loss = 5046.45 (* 1 = 5046.45 loss)
I1016 13:54:16.321805   329 sgd_solver.cpp:138] Iteration 22600, lr = 0.00025
I1016 13:55:16.508234   329 solver.cpp:243] Iteration 22700, loss = 4212.79
I1016 13:55:16.508282   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.36753 (* 1 = 6.36753 loss)
I1016 13:55:16.508288   329 solver.cpp:259]     Train net output #1: seg_loss = 4791.55 (* 1 = 4791.55 loss)
I1016 13:55:16.508293   329 sgd_solver.cpp:138] Iteration 22700, lr = 0.00025
I1016 13:56:15.475594   329 solver.cpp:243] Iteration 22800, loss = 4400.63
I1016 13:56:15.475643   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.84178 (* 1 = 5.84178 loss)
I1016 13:56:15.475649   329 solver.cpp:259]     Train net output #1: seg_loss = 5068.64 (* 1 = 5068.64 loss)
I1016 13:56:15.475656   329 sgd_solver.cpp:138] Iteration 22800, lr = 0.00025
I1016 13:57:14.227553   329 solver.cpp:243] Iteration 22900, loss = 4070.26
I1016 13:57:14.227600   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.00979 (* 1 = 5.00979 loss)
I1016 13:57:14.227607   329 solver.cpp:259]     Train net output #1: seg_loss = 3370.15 (* 1 = 3370.15 loss)
I1016 13:57:14.227612   329 sgd_solver.cpp:138] Iteration 22900, lr = 0.00025
I1016 13:57:59.323369   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 13:58:14.099975   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_23000.caffemodel
I1016 13:58:14.933029   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_23000.solverstate
I1016 13:58:15.509939   329 solver.cpp:243] Iteration 23000, loss = 4788.59
I1016 13:58:15.509970   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.45705 (* 1 = 6.45705 loss)
I1016 13:58:15.509976   329 solver.cpp:259]     Train net output #1: seg_loss = 3867.1 (* 1 = 3867.1 loss)
I1016 13:58:15.509982   329 sgd_solver.cpp:138] Iteration 23000, lr = 0.00025
I1016 13:59:15.526931   329 solver.cpp:243] Iteration 23100, loss = 3610.98
I1016 13:59:15.526968   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.81121 (* 1 = 6.81121 loss)
I1016 13:59:15.526973   329 solver.cpp:259]     Train net output #1: seg_loss = 2547.75 (* 1 = 2547.75 loss)
I1016 13:59:15.526978   329 sgd_solver.cpp:138] Iteration 23100, lr = 0.00025
I1016 14:00:16.829530   329 solver.cpp:243] Iteration 23200, loss = 4416.25
I1016 14:00:16.829578   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.18976 (* 1 = 6.18976 loss)
I1016 14:00:16.829584   329 solver.cpp:259]     Train net output #1: seg_loss = 4604.41 (* 1 = 4604.41 loss)
I1016 14:00:16.829591   329 sgd_solver.cpp:138] Iteration 23200, lr = 0.00025
I1016 14:01:16.893976   329 solver.cpp:243] Iteration 23300, loss = 4021.36
I1016 14:01:16.894009   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.219 (* 1 = 12.219 loss)
I1016 14:01:16.894016   329 solver.cpp:259]     Train net output #1: seg_loss = 3960.81 (* 1 = 3960.81 loss)
I1016 14:01:16.894021   329 sgd_solver.cpp:138] Iteration 23300, lr = 0.00025
I1016 14:02:16.189795   329 solver.cpp:243] Iteration 23400, loss = 3740.68
I1016 14:02:16.189846   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.0562 (* 1 = 7.0562 loss)
I1016 14:02:16.189852   329 solver.cpp:259]     Train net output #1: seg_loss = 3527.39 (* 1 = 3527.39 loss)
I1016 14:02:16.189858   329 sgd_solver.cpp:138] Iteration 23400, lr = 0.00025
I1016 14:03:14.372769   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_23500.caffemodel
I1016 14:03:14.602625   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_23500.solverstate
I1016 14:03:15.162528   329 solver.cpp:243] Iteration 23500, loss = 5706.15
I1016 14:03:15.162572   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.47311 (* 1 = 8.47311 loss)
I1016 14:03:15.162578   329 solver.cpp:259]     Train net output #1: seg_loss = 3146.25 (* 1 = 3146.25 loss)
I1016 14:03:15.162585   329 sgd_solver.cpp:138] Iteration 23500, lr = 0.00025
I1016 14:04:14.770249   329 solver.cpp:243] Iteration 23600, loss = 3598.45
I1016 14:04:14.770298   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.06899 (* 1 = 6.06899 loss)
I1016 14:04:14.770303   329 solver.cpp:259]     Train net output #1: seg_loss = 3194.32 (* 1 = 3194.32 loss)
I1016 14:04:14.770309   329 sgd_solver.cpp:138] Iteration 23600, lr = 0.00025
I1016 14:05:14.727486   329 solver.cpp:243] Iteration 23700, loss = 4541.45
I1016 14:05:14.727520   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.4054 (* 1 = 8.4054 loss)
I1016 14:05:14.727526   329 solver.cpp:259]     Train net output #1: seg_loss = 4194.01 (* 1 = 4194.01 loss)
I1016 14:05:14.727533   329 sgd_solver.cpp:138] Iteration 23700, lr = 0.00025
I1016 14:06:14.808239   329 solver.cpp:243] Iteration 23800, loss = 3471.81
I1016 14:06:14.808286   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.44671 (* 1 = 5.44671 loss)
I1016 14:06:14.808292   329 solver.cpp:259]     Train net output #1: seg_loss = 3724.83 (* 1 = 3724.83 loss)
I1016 14:06:14.808298   329 sgd_solver.cpp:138] Iteration 23800, lr = 0.00025
I1016 14:07:14.084643   329 solver.cpp:243] Iteration 23900, loss = 3963.94
I1016 14:07:14.084691   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.36638 (* 1 = 8.36638 loss)
I1016 14:07:14.084697   329 solver.cpp:259]     Train net output #1: seg_loss = 4770.37 (* 1 = 4770.37 loss)
I1016 14:07:14.084702   329 sgd_solver.cpp:138] Iteration 23900, lr = 0.00025
I1016 14:08:02.907263   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:08:12.080528   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_24000.caffemodel
I1016 14:08:12.328086   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_24000.solverstate
I1016 14:08:12.525009   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 14:09:51.585027   329 solver.cpp:243] Iteration 24000, loss = 4057
I1016 14:09:51.585060   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.31954 (* 1 = 3.31954 loss)
I1016 14:09:51.585065   329 solver.cpp:259]     Train net output #1: seg_loss = 4053.68 (* 1 = 4053.68 loss)
I1016 14:09:51.585072   329 sgd_solver.cpp:138] Iteration 24000, lr = 0.00025
I1016 14:10:50.229321   329 solver.cpp:243] Iteration 24100, loss = 4309.49
I1016 14:10:50.229369   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.76418 (* 1 = 8.76418 loss)
I1016 14:10:50.229375   329 solver.cpp:259]     Train net output #1: seg_loss = 5237.56 (* 1 = 5237.56 loss)
I1016 14:10:50.229382   329 sgd_solver.cpp:138] Iteration 24100, lr = 0.00025
I1016 14:11:49.791610   329 solver.cpp:243] Iteration 24200, loss = 4436.16
I1016 14:11:49.791641   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.87305 (* 1 = 5.87305 loss)
I1016 14:11:49.791647   329 solver.cpp:259]     Train net output #1: seg_loss = 3964.22 (* 1 = 3964.22 loss)
I1016 14:11:49.791653   329 sgd_solver.cpp:138] Iteration 24200, lr = 0.00025
I1016 14:12:50.116163   329 solver.cpp:243] Iteration 24300, loss = 3543.52
I1016 14:12:50.116211   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.89215 (* 1 = 5.89215 loss)
I1016 14:12:50.116217   329 solver.cpp:259]     Train net output #1: seg_loss = 3327.5 (* 1 = 3327.5 loss)
I1016 14:12:50.116223   329 sgd_solver.cpp:138] Iteration 24300, lr = 0.00025
I1016 14:13:49.561780   329 solver.cpp:243] Iteration 24400, loss = 3351.59
I1016 14:13:49.561815   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.73926 (* 1 = 8.73926 loss)
I1016 14:13:49.561828   329 solver.cpp:259]     Train net output #1: seg_loss = 2901.32 (* 1 = 2901.32 loss)
I1016 14:13:49.561837   329 sgd_solver.cpp:138] Iteration 24400, lr = 0.00025
I1016 14:14:45.515874   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:14:48.475353   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_24500.caffemodel
I1016 14:14:48.822767   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_24500.solverstate
I1016 14:14:49.466830   329 solver.cpp:243] Iteration 24500, loss = 5783.73
I1016 14:14:49.466881   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.3239 (* 1 = 10.3239 loss)
I1016 14:14:49.466887   329 solver.cpp:259]     Train net output #1: seg_loss = 3873.88 (* 1 = 3873.88 loss)
I1016 14:14:49.466893   329 sgd_solver.cpp:138] Iteration 24500, lr = 0.00025
I1016 14:15:48.140058   329 solver.cpp:243] Iteration 24600, loss = 4098.18
I1016 14:15:48.140105   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.3971 (* 1 = 7.3971 loss)
I1016 14:15:48.140111   329 solver.cpp:259]     Train net output #1: seg_loss = 3788.18 (* 1 = 3788.18 loss)
I1016 14:15:48.140117   329 sgd_solver.cpp:138] Iteration 24600, lr = 0.00025
I1016 14:16:47.709600   329 solver.cpp:243] Iteration 24700, loss = 3605.19
I1016 14:16:47.709632   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.43196 (* 1 = 4.43196 loss)
I1016 14:16:47.709638   329 solver.cpp:259]     Train net output #1: seg_loss = 4105.06 (* 1 = 4105.06 loss)
I1016 14:16:47.709645   329 sgd_solver.cpp:138] Iteration 24700, lr = 0.00025
I1016 14:17:48.287453   329 solver.cpp:243] Iteration 24800, loss = 5115.89
I1016 14:17:48.287500   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.61289 (* 1 = 6.61289 loss)
I1016 14:17:48.287506   329 solver.cpp:259]     Train net output #1: seg_loss = 5173.91 (* 1 = 5173.91 loss)
I1016 14:17:48.287513   329 sgd_solver.cpp:138] Iteration 24800, lr = 0.00025
I1016 14:18:48.630729   329 solver.cpp:243] Iteration 24900, loss = 3387.39
I1016 14:18:48.630775   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.87079 (* 1 = 4.87079 loss)
I1016 14:18:48.630781   329 solver.cpp:259]     Train net output #1: seg_loss = 3735.81 (* 1 = 3735.81 loss)
I1016 14:18:48.630786   329 sgd_solver.cpp:138] Iteration 24900, lr = 0.00025
I1016 14:19:47.801012   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_25000.caffemodel
I1016 14:19:48.104799   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_25000.solverstate
I1016 14:19:48.700964   329 solver.cpp:243] Iteration 25000, loss = 3401.25
I1016 14:19:48.701012   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.62648 (* 1 = 9.62648 loss)
I1016 14:19:48.701019   329 solver.cpp:259]     Train net output #1: seg_loss = 3240.75 (* 1 = 3240.75 loss)
I1016 14:19:48.701025   329 sgd_solver.cpp:138] Iteration 25000, lr = 0.00025
I1016 14:20:46.858080   329 solver.cpp:243] Iteration 25100, loss = 3819.32
I1016 14:20:46.858112   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.08293 (* 1 = 8.08293 loss)
I1016 14:20:46.858119   329 solver.cpp:259]     Train net output #1: seg_loss = 3419.24 (* 1 = 3419.24 loss)
I1016 14:20:46.858124   329 sgd_solver.cpp:138] Iteration 25100, lr = 0.00025
I1016 14:21:47.125221   329 solver.cpp:243] Iteration 25200, loss = 3610.42
I1016 14:21:47.125255   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.37465 (* 1 = 8.37465 loss)
I1016 14:21:47.125262   329 solver.cpp:259]     Train net output #1: seg_loss = 4609.42 (* 1 = 4609.42 loss)
I1016 14:21:47.125267   329 sgd_solver.cpp:138] Iteration 25200, lr = 0.00025
I1016 14:22:46.921813   329 solver.cpp:243] Iteration 25300, loss = 3310.75
I1016 14:22:46.921851   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.38198 (* 1 = 5.38198 loss)
I1016 14:22:46.921857   329 solver.cpp:259]     Train net output #1: seg_loss = 3673.09 (* 1 = 3673.09 loss)
I1016 14:22:46.921864   329 sgd_solver.cpp:138] Iteration 25300, lr = 0.00025
I1016 14:23:47.352741   329 solver.cpp:243] Iteration 25400, loss = 4444.92
I1016 14:23:47.352787   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.88852 (* 1 = 5.88852 loss)
I1016 14:23:47.352793   329 solver.cpp:259]     Train net output #1: seg_loss = 5114.65 (* 1 = 5114.65 loss)
I1016 14:23:47.352799   329 sgd_solver.cpp:138] Iteration 25400, lr = 0.00025
I1016 14:24:45.921764   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_25500.caffemodel
I1016 14:24:46.694612   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_25500.solverstate
I1016 14:24:47.255590   329 solver.cpp:243] Iteration 25500, loss = 4659.9
I1016 14:24:47.255636   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.7322 (* 1 = 6.7322 loss)
I1016 14:24:47.255642   329 solver.cpp:259]     Train net output #1: seg_loss = 4353.8 (* 1 = 4353.8 loss)
I1016 14:24:47.255648   329 sgd_solver.cpp:138] Iteration 25500, lr = 0.00025
I1016 14:24:49.620609   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:25:45.677217   329 solver.cpp:243] Iteration 25600, loss = 3559.35
I1016 14:25:45.677265   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.6132 (* 1 = 8.6132 loss)
I1016 14:25:45.677271   329 solver.cpp:259]     Train net output #1: seg_loss = 3773.13 (* 1 = 3773.13 loss)
I1016 14:25:45.677278   329 sgd_solver.cpp:138] Iteration 25600, lr = 0.00025
I1016 14:26:45.081624   329 solver.cpp:243] Iteration 25700, loss = 7352.76
I1016 14:26:45.081686   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.76002 (* 1 = 8.76002 loss)
I1016 14:26:45.081691   329 solver.cpp:259]     Train net output #1: seg_loss = 14260.9 (* 1 = 14260.9 loss)
I1016 14:26:45.081698   329 sgd_solver.cpp:138] Iteration 25700, lr = 0.00025
I1016 14:27:44.497918   329 solver.cpp:243] Iteration 25800, loss = 3503.92
I1016 14:27:44.497951   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.67924 (* 1 = 4.67924 loss)
I1016 14:27:44.497957   329 solver.cpp:259]     Train net output #1: seg_loss = 2843.71 (* 1 = 2843.71 loss)
I1016 14:27:44.497963   329 sgd_solver.cpp:138] Iteration 25800, lr = 0.00025
I1016 14:28:44.636278   329 solver.cpp:243] Iteration 25900, loss = 3780.45
I1016 14:28:44.636325   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.05489 (* 1 = 4.05489 loss)
I1016 14:28:44.636332   329 solver.cpp:259]     Train net output #1: seg_loss = 3809.96 (* 1 = 3809.96 loss)
I1016 14:28:44.636337   329 sgd_solver.cpp:138] Iteration 25900, lr = 0.00025
I1016 14:29:44.093858   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_26000.caffemodel
I1016 14:29:44.837195   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_26000.solverstate
I1016 14:29:45.448278   329 solver.cpp:243] Iteration 26000, loss = 4884.84
I1016 14:29:45.448310   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.36763 (* 1 = 6.36763 loss)
I1016 14:29:45.448318   329 solver.cpp:259]     Train net output #1: seg_loss = 5229 (* 1 = 5229 loss)
I1016 14:29:45.448323   329 sgd_solver.cpp:138] Iteration 26000, lr = 0.00025
I1016 14:30:43.838052   329 solver.cpp:243] Iteration 26100, loss = 3623.18
I1016 14:30:43.838083   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.2028 (* 1 = 9.2028 loss)
I1016 14:30:43.838090   329 solver.cpp:259]     Train net output #1: seg_loss = 2696.8 (* 1 = 2696.8 loss)
I1016 14:30:43.838096   329 sgd_solver.cpp:138] Iteration 26100, lr = 0.00025
I1016 14:31:42.418334   329 solver.cpp:243] Iteration 26200, loss = 4786.27
I1016 14:31:42.418368   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.79847 (* 1 = 8.79847 loss)
I1016 14:31:42.418377   329 solver.cpp:259]     Train net output #1: seg_loss = 6277.53 (* 1 = 6277.53 loss)
I1016 14:31:42.418400   329 sgd_solver.cpp:138] Iteration 26200, lr = 0.00025
I1016 14:32:42.239589   329 solver.cpp:243] Iteration 26300, loss = 3502.18
I1016 14:32:42.239624   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.06326 (* 1 = 5.06326 loss)
I1016 14:32:42.239634   329 solver.cpp:259]     Train net output #1: seg_loss = 4179 (* 1 = 4179 loss)
I1016 14:32:42.239655   329 sgd_solver.cpp:138] Iteration 26300, lr = 0.00025
I1016 14:33:42.177143   329 solver.cpp:243] Iteration 26400, loss = 3841.07
I1016 14:33:42.177178   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67144 (* 1 = 7.67144 loss)
I1016 14:33:42.177186   329 solver.cpp:259]     Train net output #1: seg_loss = 2628.8 (* 1 = 2628.8 loss)
I1016 14:33:42.177209   329 sgd_solver.cpp:138] Iteration 26400, lr = 0.00025
I1016 14:34:41.789189   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_26500.caffemodel
I1016 14:34:42.012570   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_26500.solverstate
I1016 14:34:42.563541   329 solver.cpp:243] Iteration 26500, loss = 3592.34
I1016 14:34:42.563585   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.53554 (* 1 = 4.53554 loss)
I1016 14:34:42.563591   329 solver.cpp:259]     Train net output #1: seg_loss = 3215.03 (* 1 = 3215.03 loss)
I1016 14:34:42.563597   329 sgd_solver.cpp:138] Iteration 26500, lr = 0.00025
I1016 14:34:49.640533   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:35:41.671130   329 solver.cpp:243] Iteration 26600, loss = 3883.06
I1016 14:35:41.671177   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.74981 (* 1 = 3.74981 loss)
I1016 14:35:41.671183   329 solver.cpp:259]     Train net output #1: seg_loss = 2360.18 (* 1 = 2360.18 loss)
I1016 14:35:41.671190   329 sgd_solver.cpp:138] Iteration 26600, lr = 0.00025
I1016 14:36:40.404131   329 solver.cpp:243] Iteration 26700, loss = 3468.15
I1016 14:36:40.404177   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.178 (* 1 = 7.178 loss)
I1016 14:36:40.404184   329 solver.cpp:259]     Train net output #1: seg_loss = 4232.97 (* 1 = 4232.97 loss)
I1016 14:36:40.404189   329 sgd_solver.cpp:138] Iteration 26700, lr = 0.00025
I1016 14:37:40.195518   329 solver.cpp:243] Iteration 26800, loss = 3746.5
I1016 14:37:40.195554   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.5577 (* 1 = 6.5577 loss)
I1016 14:37:40.195578   329 solver.cpp:259]     Train net output #1: seg_loss = 4485.13 (* 1 = 4485.13 loss)
I1016 14:37:40.195586   329 sgd_solver.cpp:138] Iteration 26800, lr = 0.00025
I1016 14:38:39.534195   329 solver.cpp:243] Iteration 26900, loss = 3144.35
I1016 14:38:39.534243   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.15019 (* 1 = 9.15019 loss)
I1016 14:38:39.534250   329 solver.cpp:259]     Train net output #1: seg_loss = 3890.22 (* 1 = 3890.22 loss)
I1016 14:38:39.534255   329 sgd_solver.cpp:138] Iteration 26900, lr = 0.00025
I1016 14:39:39.210003   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_27000.caffemodel
I1016 14:39:39.971871   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_27000.solverstate
I1016 14:39:40.534096   329 solver.cpp:243] Iteration 27000, loss = 4829.32
I1016 14:39:40.534127   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.18278 (* 1 = 5.18278 loss)
I1016 14:39:40.534133   329 solver.cpp:259]     Train net output #1: seg_loss = 2988.96 (* 1 = 2988.96 loss)
I1016 14:39:40.534139   329 sgd_solver.cpp:138] Iteration 27000, lr = 0.00025
I1016 14:40:39.454535   329 solver.cpp:243] Iteration 27100, loss = 4204.74
I1016 14:40:39.454581   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.35146 (* 1 = 6.35146 loss)
I1016 14:40:39.454587   329 solver.cpp:259]     Train net output #1: seg_loss = 4915.56 (* 1 = 4915.56 loss)
I1016 14:40:39.454593   329 sgd_solver.cpp:138] Iteration 27100, lr = 0.00025
I1016 14:41:38.822016   329 solver.cpp:243] Iteration 27200, loss = 3524.98
I1016 14:41:38.822048   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.1501 (* 1 = 5.1501 loss)
I1016 14:41:38.822053   329 solver.cpp:259]     Train net output #1: seg_loss = 4921.1 (* 1 = 4921.1 loss)
I1016 14:41:38.822059   329 sgd_solver.cpp:138] Iteration 27200, lr = 0.00025
I1016 14:42:37.436240   329 solver.cpp:243] Iteration 27300, loss = 3601.03
I1016 14:42:37.436288   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.8657 (* 1 = 10.8657 loss)
I1016 14:42:37.436295   329 solver.cpp:259]     Train net output #1: seg_loss = 3876 (* 1 = 3876 loss)
I1016 14:42:37.436300   329 sgd_solver.cpp:138] Iteration 27300, lr = 0.00025
I1016 14:43:37.106117   329 solver.cpp:243] Iteration 27400, loss = 3176.71
I1016 14:43:37.106149   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.46704 (* 1 = 6.46704 loss)
I1016 14:43:37.106154   329 solver.cpp:259]     Train net output #1: seg_loss = 4329.03 (* 1 = 4329.03 loss)
I1016 14:43:37.106160   329 sgd_solver.cpp:138] Iteration 27400, lr = 0.00025
I1016 14:44:36.506199   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_27500.caffemodel
I1016 14:44:37.324642   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_27500.solverstate
I1016 14:44:37.892007   329 solver.cpp:243] Iteration 27500, loss = 4557.41
I1016 14:44:37.892056   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.62554 (* 1 = 8.62554 loss)
I1016 14:44:37.892062   329 solver.cpp:259]     Train net output #1: seg_loss = 4107.74 (* 1 = 4107.74 loss)
I1016 14:44:37.892068   329 sgd_solver.cpp:138] Iteration 27500, lr = 0.00025
I1016 14:44:50.423075   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:45:37.301508   329 solver.cpp:243] Iteration 27600, loss = 3339.42
I1016 14:45:37.301554   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.26161 (* 1 = 7.26161 loss)
I1016 14:45:37.301560   329 solver.cpp:259]     Train net output #1: seg_loss = 3636.04 (* 1 = 3636.04 loss)
I1016 14:45:37.301566   329 sgd_solver.cpp:138] Iteration 27600, lr = 0.00025
I1016 14:46:36.579808   329 solver.cpp:243] Iteration 27700, loss = 3494.37
I1016 14:46:36.579855   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.49879 (* 1 = 7.49879 loss)
I1016 14:46:36.579861   329 solver.cpp:259]     Train net output #1: seg_loss = 3185.96 (* 1 = 3185.96 loss)
I1016 14:46:36.579867   329 sgd_solver.cpp:138] Iteration 27700, lr = 0.00025
I1016 14:47:34.897943   329 solver.cpp:243] Iteration 27800, loss = 3403.58
I1016 14:47:34.897977   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.59163 (* 1 = 6.59163 loss)
I1016 14:47:34.897984   329 solver.cpp:259]     Train net output #1: seg_loss = 4093.55 (* 1 = 4093.55 loss)
I1016 14:47:34.897989   329 sgd_solver.cpp:138] Iteration 27800, lr = 0.00025
I1016 14:48:34.879873   329 solver.cpp:243] Iteration 27900, loss = 3577.87
I1016 14:48:34.879921   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.90865 (* 1 = 6.90865 loss)
I1016 14:48:34.879927   329 solver.cpp:259]     Train net output #1: seg_loss = 3533.41 (* 1 = 3533.41 loss)
I1016 14:48:34.879933   329 sgd_solver.cpp:138] Iteration 27900, lr = 0.00025
I1016 14:49:33.913386   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_28000.caffemodel
I1016 14:49:34.156462   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_28000.solverstate
I1016 14:49:34.392743   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 14:51:12.001708   329 solver.cpp:243] Iteration 28000, loss = 3872.56
I1016 14:51:12.001741   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.57686 (* 1 = 6.57686 loss)
I1016 14:51:12.001750   329 solver.cpp:259]     Train net output #1: seg_loss = 3865.98 (* 1 = 3865.98 loss)
I1016 14:51:12.001758   329 sgd_solver.cpp:138] Iteration 28000, lr = 0.00025
I1016 14:51:30.403779   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 14:52:11.353601   329 solver.cpp:243] Iteration 28100, loss = 2987.83
I1016 14:52:11.353651   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.43281 (* 1 = 5.43281 loss)
I1016 14:52:11.353655   329 solver.cpp:259]     Train net output #1: seg_loss = 3425.49 (* 1 = 3425.49 loss)
I1016 14:52:11.353662   329 sgd_solver.cpp:138] Iteration 28100, lr = 0.00025
I1016 14:53:10.709125   329 solver.cpp:243] Iteration 28200, loss = 4237.11
I1016 14:53:10.709162   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.90863 (* 1 = 7.90863 loss)
I1016 14:53:10.709172   329 solver.cpp:259]     Train net output #1: seg_loss = 4696.4 (* 1 = 4696.4 loss)
I1016 14:53:10.709194   329 sgd_solver.cpp:138] Iteration 28200, lr = 0.00025
I1016 14:54:09.959828   329 solver.cpp:243] Iteration 28300, loss = 4194.52
I1016 14:54:09.959863   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.75157 (* 1 = 6.75157 loss)
I1016 14:54:09.959872   329 solver.cpp:259]     Train net output #1: seg_loss = 6339.89 (* 1 = 6339.89 loss)
I1016 14:54:09.959895   329 sgd_solver.cpp:138] Iteration 28300, lr = 0.00025
I1016 14:55:09.019909   329 solver.cpp:243] Iteration 28400, loss = 5801.98
I1016 14:55:09.019944   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.68446 (* 1 = 6.68446 loss)
I1016 14:55:09.019953   329 solver.cpp:259]     Train net output #1: seg_loss = 7354.09 (* 1 = 7354.09 loss)
I1016 14:55:09.019976   329 sgd_solver.cpp:138] Iteration 28400, lr = 0.00025
I1016 14:56:07.910645   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_28500.caffemodel
I1016 14:56:08.177970   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_28500.solverstate
I1016 14:56:08.785957   329 solver.cpp:243] Iteration 28500, loss = 3370.1
I1016 14:56:08.785990   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.56768 (* 1 = 7.56768 loss)
I1016 14:56:08.785996   329 solver.cpp:259]     Train net output #1: seg_loss = 3683.02 (* 1 = 3683.02 loss)
I1016 14:56:08.786003   329 sgd_solver.cpp:138] Iteration 28500, lr = 0.00025
I1016 14:57:08.630307   329 solver.cpp:243] Iteration 28600, loss = 4250.43
I1016 14:57:08.630373   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.64452 (* 1 = 5.64452 loss)
I1016 14:57:08.630379   329 solver.cpp:259]     Train net output #1: seg_loss = 4243.27 (* 1 = 4243.27 loss)
I1016 14:57:08.630386   329 sgd_solver.cpp:138] Iteration 28600, lr = 0.00025
I1016 14:58:08.674046   329 solver.cpp:243] Iteration 28700, loss = 4280.92
I1016 14:58:08.674080   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.79725 (* 1 = 5.79725 loss)
I1016 14:58:08.674089   329 solver.cpp:259]     Train net output #1: seg_loss = 5071.36 (* 1 = 5071.36 loss)
I1016 14:58:08.674098   329 sgd_solver.cpp:138] Iteration 28700, lr = 0.00025
I1016 14:59:07.847115   329 solver.cpp:243] Iteration 28800, loss = 2913.92
I1016 14:59:07.847163   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.7113 (* 1 = 4.7113 loss)
I1016 14:59:07.847169   329 solver.cpp:259]     Train net output #1: seg_loss = 3330.24 (* 1 = 3330.24 loss)
I1016 14:59:07.847175   329 sgd_solver.cpp:138] Iteration 28800, lr = 0.00025
I1016 15:00:06.369282   329 solver.cpp:243] Iteration 28900, loss = 3914.96
I1016 15:00:06.369329   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.46727 (* 1 = 4.46727 loss)
I1016 15:00:06.369335   329 solver.cpp:259]     Train net output #1: seg_loss = 3206.7 (* 1 = 3206.7 loss)
I1016 15:00:06.369341   329 sgd_solver.cpp:138] Iteration 28900, lr = 0.00025
I1016 15:01:05.781883   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_29000.caffemodel
I1016 15:01:06.565251   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_29000.solverstate
I1016 15:01:07.136466   329 solver.cpp:243] Iteration 29000, loss = 3618.74
I1016 15:01:07.136509   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.97863 (* 1 = 4.97863 loss)
I1016 15:01:07.136515   329 solver.cpp:259]     Train net output #1: seg_loss = 3324.02 (* 1 = 3324.02 loss)
I1016 15:01:07.136521   329 sgd_solver.cpp:138] Iteration 29000, lr = 0.00025
I1016 15:01:29.546927   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:02:06.034435   329 solver.cpp:243] Iteration 29100, loss = 3655.73
I1016 15:02:06.034482   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.43379 (* 1 = 8.43379 loss)
I1016 15:02:06.034488   329 solver.cpp:259]     Train net output #1: seg_loss = 3874.43 (* 1 = 3874.43 loss)
I1016 15:02:06.034493   329 sgd_solver.cpp:138] Iteration 29100, lr = 0.00025
I1016 15:03:06.383927   329 solver.cpp:243] Iteration 29200, loss = 3709.92
I1016 15:03:06.383960   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.1052 (* 1 = 8.1052 loss)
I1016 15:03:06.383965   329 solver.cpp:259]     Train net output #1: seg_loss = 4289.71 (* 1 = 4289.71 loss)
I1016 15:03:06.383972   329 sgd_solver.cpp:138] Iteration 29200, lr = 0.00025
I1016 15:04:05.622578   329 solver.cpp:243] Iteration 29300, loss = 4230.33
I1016 15:04:05.622627   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.94705 (* 1 = 8.94705 loss)
I1016 15:04:05.622632   329 solver.cpp:259]     Train net output #1: seg_loss = 4742.4 (* 1 = 4742.4 loss)
I1016 15:04:05.622637   329 sgd_solver.cpp:138] Iteration 29300, lr = 0.00025
I1016 15:05:04.512151   329 solver.cpp:243] Iteration 29400, loss = 3828.35
I1016 15:05:04.512198   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.41954 (* 1 = 7.41954 loss)
I1016 15:05:04.512204   329 solver.cpp:259]     Train net output #1: seg_loss = 4130.08 (* 1 = 4130.08 loss)
I1016 15:05:04.512210   329 sgd_solver.cpp:138] Iteration 29400, lr = 0.00025
I1016 15:06:03.538210   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_29500.caffemodel
I1016 15:06:03.781777   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_29500.solverstate
I1016 15:06:04.899477   329 solver.cpp:243] Iteration 29500, loss = 4801.1
I1016 15:06:04.899511   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.49911 (* 1 = 4.49911 loss)
I1016 15:06:04.899518   329 solver.cpp:259]     Train net output #1: seg_loss = 3666 (* 1 = 3666 loss)
I1016 15:06:04.899523   329 sgd_solver.cpp:138] Iteration 29500, lr = 0.00025
I1016 15:07:03.594085   329 solver.cpp:243] Iteration 29600, loss = 3253.62
I1016 15:07:03.594117   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.02579 (* 1 = 7.02579 loss)
I1016 15:07:03.594125   329 solver.cpp:259]     Train net output #1: seg_loss = 2976.16 (* 1 = 2976.16 loss)
I1016 15:07:03.594130   329 sgd_solver.cpp:138] Iteration 29600, lr = 0.00025
I1016 15:08:03.641314   329 solver.cpp:243] Iteration 29700, loss = 4026.36
I1016 15:08:03.641361   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.00081 (* 1 = 5.00081 loss)
I1016 15:08:03.641367   329 solver.cpp:259]     Train net output #1: seg_loss = 6379.51 (* 1 = 6379.51 loss)
I1016 15:08:03.641373   329 sgd_solver.cpp:138] Iteration 29700, lr = 0.00025
I1016 15:09:03.519181   329 solver.cpp:243] Iteration 29800, loss = 3538.15
I1016 15:09:03.519227   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.87172 (* 1 = 6.87172 loss)
I1016 15:09:03.519234   329 solver.cpp:259]     Train net output #1: seg_loss = 3216.35 (* 1 = 3216.35 loss)
I1016 15:09:03.519240   329 sgd_solver.cpp:138] Iteration 29800, lr = 0.00025
I1016 15:10:02.639542   329 solver.cpp:243] Iteration 29900, loss = 3416.76
I1016 15:10:02.639591   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.76755 (* 1 = 7.76755 loss)
I1016 15:10:02.639597   329 solver.cpp:259]     Train net output #1: seg_loss = 2930.33 (* 1 = 2930.33 loss)
I1016 15:10:02.639603   329 sgd_solver.cpp:138] Iteration 29900, lr = 0.00025
I1016 15:11:00.744928   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_30000.caffemodel
I1016 15:11:00.968585   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_30000.solverstate
I1016 15:11:01.528131   329 solver.cpp:243] Iteration 30000, loss = 5588.52
I1016 15:11:01.528177   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.7998 (* 1 = 6.7998 loss)
I1016 15:11:01.528182   329 solver.cpp:259]     Train net output #1: seg_loss = 3268.42 (* 1 = 3268.42 loss)
I1016 15:11:01.528188   329 sgd_solver.cpp:138] Iteration 30000, lr = 0.00025
I1016 15:11:29.157374   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:12:01.116076   329 solver.cpp:243] Iteration 30100, loss = 3253.53
I1016 15:12:01.116124   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.89753 (* 1 = 5.89753 loss)
I1016 15:12:01.116130   329 solver.cpp:259]     Train net output #1: seg_loss = 2679.22 (* 1 = 2679.22 loss)
I1016 15:12:01.116137   329 sgd_solver.cpp:138] Iteration 30100, lr = 0.00025
I1016 15:13:00.901437   329 solver.cpp:243] Iteration 30200, loss = 4417.73
I1016 15:13:00.901484   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.79445 (* 1 = 6.79445 loss)
I1016 15:13:00.901490   329 solver.cpp:259]     Train net output #1: seg_loss = 3693.75 (* 1 = 3693.75 loss)
I1016 15:13:00.901496   329 sgd_solver.cpp:138] Iteration 30200, lr = 0.00025
I1016 15:14:01.084671   329 solver.cpp:243] Iteration 30300, loss = 2996.57
I1016 15:14:01.084703   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.01852 (* 1 = 6.01852 loss)
I1016 15:14:01.084709   329 solver.cpp:259]     Train net output #1: seg_loss = 2575.99 (* 1 = 2575.99 loss)
I1016 15:14:01.084717   329 sgd_solver.cpp:138] Iteration 30300, lr = 0.00025
I1016 15:15:00.365972   329 solver.cpp:243] Iteration 30400, loss = 3455.64
I1016 15:15:00.366005   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.57317 (* 1 = 4.57317 loss)
I1016 15:15:00.366011   329 solver.cpp:259]     Train net output #1: seg_loss = 4156.41 (* 1 = 4156.41 loss)
I1016 15:15:00.366017   329 sgd_solver.cpp:138] Iteration 30400, lr = 0.00025
I1016 15:15:58.281867   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_30500.caffemodel
I1016 15:15:58.529345   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_30500.solverstate
I1016 15:15:59.081964   329 solver.cpp:243] Iteration 30500, loss = 2992.38
I1016 15:15:59.081995   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.66073 (* 1 = 4.66073 loss)
I1016 15:15:59.082002   329 solver.cpp:259]     Train net output #1: seg_loss = 3602.94 (* 1 = 3602.94 loss)
I1016 15:15:59.082008   329 sgd_solver.cpp:138] Iteration 30500, lr = 0.00025
I1016 15:16:58.619267   329 solver.cpp:243] Iteration 30600, loss = 3866.36
I1016 15:16:58.619316   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.51884 (* 1 = 7.51884 loss)
I1016 15:16:58.619323   329 solver.cpp:259]     Train net output #1: seg_loss = 2374.18 (* 1 = 2374.18 loss)
I1016 15:16:58.619328   329 sgd_solver.cpp:138] Iteration 30600, lr = 0.00025
I1016 15:17:58.080622   329 solver.cpp:243] Iteration 30700, loss = 3728.02
I1016 15:17:58.080669   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.29044 (* 1 = 8.29044 loss)
I1016 15:17:58.080677   329 solver.cpp:259]     Train net output #1: seg_loss = 2860.18 (* 1 = 2860.18 loss)
I1016 15:17:58.080682   329 sgd_solver.cpp:138] Iteration 30700, lr = 0.00025
I1016 15:18:58.433324   329 solver.cpp:243] Iteration 30800, loss = 3141.87
I1016 15:18:58.433372   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.11124 (* 1 = 6.11124 loss)
I1016 15:18:58.433378   329 solver.cpp:259]     Train net output #1: seg_loss = 3210.72 (* 1 = 3210.72 loss)
I1016 15:18:58.433383   329 sgd_solver.cpp:138] Iteration 30800, lr = 0.00025
I1016 15:19:57.777902   329 solver.cpp:243] Iteration 30900, loss = 3031.65
I1016 15:19:57.777935   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.54726 (* 1 = 8.54726 loss)
I1016 15:19:57.777941   329 solver.cpp:259]     Train net output #1: seg_loss = 2379.59 (* 1 = 2379.59 loss)
I1016 15:19:57.777946   329 sgd_solver.cpp:138] Iteration 30900, lr = 0.00025
I1016 15:20:56.680227   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_31000.caffemodel
I1016 15:20:57.508419   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_31000.solverstate
I1016 15:20:58.088495   329 solver.cpp:243] Iteration 31000, loss = 6119.07
I1016 15:20:58.088539   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.6281 (* 1 = 6.6281 loss)
I1016 15:20:58.088546   329 solver.cpp:259]     Train net output #1: seg_loss = 4307.16 (* 1 = 4307.16 loss)
I1016 15:20:58.088551   329 sgd_solver.cpp:138] Iteration 31000, lr = 0.00025
I1016 15:21:28.452186   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:21:56.089315   329 solver.cpp:243] Iteration 31100, loss = 3755.01
I1016 15:21:56.089349   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.9096 (* 1 = 9.9096 loss)
I1016 15:21:56.089355   329 solver.cpp:259]     Train net output #1: seg_loss = 3169.93 (* 1 = 3169.93 loss)
I1016 15:21:56.089361   329 sgd_solver.cpp:138] Iteration 31100, lr = 0.00025
I1016 15:22:55.506733   329 solver.cpp:243] Iteration 31200, loss = 3267.99
I1016 15:22:55.506764   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.26502 (* 1 = 4.26502 loss)
I1016 15:22:55.506770   329 solver.cpp:259]     Train net output #1: seg_loss = 3466.55 (* 1 = 3466.55 loss)
I1016 15:22:55.506777   329 sgd_solver.cpp:138] Iteration 31200, lr = 0.00025
I1016 15:23:55.667007   329 solver.cpp:243] Iteration 31300, loss = 4559.59
I1016 15:23:55.667039   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.63729 (* 1 = 7.63729 loss)
I1016 15:23:55.667045   329 solver.cpp:259]     Train net output #1: seg_loss = 3520.17 (* 1 = 3520.17 loss)
I1016 15:23:55.667052   329 sgd_solver.cpp:138] Iteration 31300, lr = 0.00025
I1016 15:24:55.729490   329 solver.cpp:243] Iteration 31400, loss = 3037.23
I1016 15:24:55.729522   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.21388 (* 1 = 4.21388 loss)
I1016 15:24:55.729528   329 solver.cpp:259]     Train net output #1: seg_loss = 2994.15 (* 1 = 2994.15 loss)
I1016 15:24:55.729534   329 sgd_solver.cpp:138] Iteration 31400, lr = 0.00025
I1016 15:25:54.509055   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_31500.caffemodel
I1016 15:25:54.760838   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_31500.solverstate
I1016 15:25:55.348948   329 solver.cpp:243] Iteration 31500, loss = 3049.1
I1016 15:25:55.348980   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.18656 (* 1 = 4.18656 loss)
I1016 15:25:55.348986   329 solver.cpp:259]     Train net output #1: seg_loss = 3331.14 (* 1 = 3331.14 loss)
I1016 15:25:55.348992   329 sgd_solver.cpp:138] Iteration 31500, lr = 0.00025
I1016 15:26:53.422183   329 solver.cpp:243] Iteration 31600, loss = 3532.97
I1016 15:26:53.422215   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.49145 (* 1 = 7.49145 loss)
I1016 15:26:53.422221   329 solver.cpp:259]     Train net output #1: seg_loss = 3841.47 (* 1 = 3841.47 loss)
I1016 15:26:53.422227   329 sgd_solver.cpp:138] Iteration 31600, lr = 0.00025
I1016 15:27:53.346781   329 solver.cpp:243] Iteration 31700, loss = 3149.67
I1016 15:27:53.346827   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.755 (* 1 = 7.755 loss)
I1016 15:27:53.346832   329 solver.cpp:259]     Train net output #1: seg_loss = 3760.21 (* 1 = 3760.21 loss)
I1016 15:27:53.346838   329 sgd_solver.cpp:138] Iteration 31700, lr = 0.00025
I1016 15:28:53.094568   329 solver.cpp:243] Iteration 31800, loss = 2972
I1016 15:28:53.094614   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.27543 (* 1 = 3.27543 loss)
I1016 15:28:53.094621   329 solver.cpp:259]     Train net output #1: seg_loss = 4008.49 (* 1 = 4008.49 loss)
I1016 15:28:53.094626   329 sgd_solver.cpp:138] Iteration 31800, lr = 0.00025
I1016 15:29:53.555399   329 solver.cpp:243] Iteration 31900, loss = 3764.91
I1016 15:29:53.555446   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.48001 (* 1 = 8.48001 loss)
I1016 15:29:53.555452   329 solver.cpp:259]     Train net output #1: seg_loss = 5876.55 (* 1 = 5876.55 loss)
I1016 15:29:53.555457   329 sgd_solver.cpp:138] Iteration 31900, lr = 0.00025
I1016 15:30:52.303822   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_32000.caffemodel
I1016 15:30:52.539027   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_32000.solverstate
I1016 15:30:52.723420   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 15:31:03.892223   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:32:31.695575   329 solver.cpp:243] Iteration 32000, loss = 3919.72
I1016 15:32:31.695607   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.11 (* 1 = 10.11 loss)
I1016 15:32:31.695613   329 solver.cpp:259]     Train net output #1: seg_loss = 3909.61 (* 1 = 3909.61 loss)
I1016 15:32:31.695619   329 sgd_solver.cpp:138] Iteration 32000, lr = 0.00025
I1016 15:33:29.939493   329 solver.cpp:243] Iteration 32100, loss = 3484.86
I1016 15:33:29.939543   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.0847 (* 1 = 9.0847 loss)
I1016 15:33:29.939550   329 solver.cpp:259]     Train net output #1: seg_loss = 3301.79 (* 1 = 3301.79 loss)
I1016 15:33:29.939555   329 sgd_solver.cpp:138] Iteration 32100, lr = 0.00025
I1016 15:34:29.487838   329 solver.cpp:243] Iteration 32200, loss = 5619.02
I1016 15:34:29.487887   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.60156 (* 1 = 8.60156 loss)
I1016 15:34:29.487893   329 solver.cpp:259]     Train net output #1: seg_loss = 7005.86 (* 1 = 7005.86 loss)
I1016 15:34:29.487900   329 sgd_solver.cpp:138] Iteration 32200, lr = 0.00025
I1016 15:35:29.340049   329 solver.cpp:243] Iteration 32300, loss = 3408.96
I1016 15:35:29.340080   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.15223 (* 1 = 5.15223 loss)
I1016 15:35:29.340086   329 solver.cpp:259]     Train net output #1: seg_loss = 3000.95 (* 1 = 3000.95 loss)
I1016 15:35:29.340092   329 sgd_solver.cpp:138] Iteration 32300, lr = 0.00025
I1016 15:36:29.751380   329 solver.cpp:243] Iteration 32400, loss = 3583.69
I1016 15:36:29.751430   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.44099 (* 1 = 4.44099 loss)
I1016 15:36:29.751435   329 solver.cpp:259]     Train net output #1: seg_loss = 3169.47 (* 1 = 3169.47 loss)
I1016 15:36:29.751441   329 sgd_solver.cpp:138] Iteration 32400, lr = 0.00025
I1016 15:37:29.601424   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_32500.caffemodel
I1016 15:37:29.938364   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_32500.solverstate
I1016 15:37:30.561281   329 solver.cpp:243] Iteration 32500, loss = 4308.92
I1016 15:37:30.561323   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.63535 (* 1 = 7.63535 loss)
I1016 15:37:30.561331   329 solver.cpp:259]     Train net output #1: seg_loss = 3842.37 (* 1 = 3842.37 loss)
I1016 15:37:30.561336   329 sgd_solver.cpp:138] Iteration 32500, lr = 0.00025
I1016 15:38:11.247066   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:38:29.499524   329 solver.cpp:243] Iteration 32600, loss = 3305.68
I1016 15:38:29.499575   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.88356 (* 1 = 7.88356 loss)
I1016 15:38:29.499581   329 solver.cpp:259]     Train net output #1: seg_loss = 3254.31 (* 1 = 3254.31 loss)
I1016 15:38:29.499588   329 sgd_solver.cpp:138] Iteration 32600, lr = 0.00025
I1016 15:39:28.019490   329 solver.cpp:243] Iteration 32700, loss = 4280.29
I1016 15:39:28.019538   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.82039 (* 1 = 9.82039 loss)
I1016 15:39:28.019546   329 solver.cpp:259]     Train net output #1: seg_loss = 6589.65 (* 1 = 6589.65 loss)
I1016 15:39:28.019551   329 sgd_solver.cpp:138] Iteration 32700, lr = 0.00025
I1016 15:40:27.780736   329 solver.cpp:243] Iteration 32800, loss = 3121.61
I1016 15:40:27.780771   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.78507 (* 1 = 7.78507 loss)
I1016 15:40:27.780776   329 solver.cpp:259]     Train net output #1: seg_loss = 3229.85 (* 1 = 3229.85 loss)
I1016 15:40:27.780782   329 sgd_solver.cpp:138] Iteration 32800, lr = 0.00025
I1016 15:41:27.628648   329 solver.cpp:243] Iteration 32900, loss = 3752.93
I1016 15:41:27.628695   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.23109 (* 1 = 7.23109 loss)
I1016 15:41:27.628702   329 solver.cpp:259]     Train net output #1: seg_loss = 3761.21 (* 1 = 3761.21 loss)
I1016 15:41:27.628708   329 sgd_solver.cpp:138] Iteration 32900, lr = 0.00025
I1016 15:42:27.249573   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_33000.caffemodel
I1016 15:42:28.069916   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_33000.solverstate
I1016 15:42:28.624383   329 solver.cpp:243] Iteration 33000, loss = 3459.85
I1016 15:42:28.624416   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.98634 (* 1 = 4.98634 loss)
I1016 15:42:28.624423   329 solver.cpp:259]     Train net output #1: seg_loss = 3184.12 (* 1 = 3184.12 loss)
I1016 15:42:28.624430   329 sgd_solver.cpp:138] Iteration 33000, lr = 0.00025
I1016 15:43:27.176030   329 solver.cpp:243] Iteration 33100, loss = 3779.65
I1016 15:43:27.176075   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.23734 (* 1 = 5.23734 loss)
I1016 15:43:27.176081   329 solver.cpp:259]     Train net output #1: seg_loss = 3121.99 (* 1 = 3121.99 loss)
I1016 15:43:27.176087   329 sgd_solver.cpp:138] Iteration 33100, lr = 0.00025
I1016 15:44:25.880297   329 solver.cpp:243] Iteration 33200, loss = 3060.5
I1016 15:44:25.880345   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.33131 (* 1 = 8.33131 loss)
I1016 15:44:25.880352   329 solver.cpp:259]     Train net output #1: seg_loss = 2855.75 (* 1 = 2855.75 loss)
I1016 15:44:25.880357   329 sgd_solver.cpp:138] Iteration 33200, lr = 0.00025
I1016 15:45:25.596650   329 solver.cpp:243] Iteration 33300, loss = 3341.67
I1016 15:45:25.596698   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.42943 (* 1 = 7.42943 loss)
I1016 15:45:25.596704   329 solver.cpp:259]     Train net output #1: seg_loss = 3892.38 (* 1 = 3892.38 loss)
I1016 15:45:25.596710   329 sgd_solver.cpp:138] Iteration 33300, lr = 0.00025
I1016 15:46:24.953809   329 solver.cpp:243] Iteration 33400, loss = 2778.85
I1016 15:46:24.953858   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.55938 (* 1 = 5.55938 loss)
I1016 15:46:24.953866   329 solver.cpp:259]     Train net output #1: seg_loss = 3377.69 (* 1 = 3377.69 loss)
I1016 15:46:24.953871   329 sgd_solver.cpp:138] Iteration 33400, lr = 0.00025
I1016 15:47:24.728278   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_33500.caffemodel
I1016 15:47:24.952541   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_33500.solverstate
I1016 15:47:25.508162   329 solver.cpp:243] Iteration 33500, loss = 4299.36
I1016 15:47:25.508211   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.84578 (* 1 = 6.84578 loss)
I1016 15:47:25.508216   329 solver.cpp:259]     Train net output #1: seg_loss = 2990.3 (* 1 = 2990.3 loss)
I1016 15:47:25.508222   329 sgd_solver.cpp:138] Iteration 33500, lr = 0.00025
I1016 15:48:10.942622   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:48:24.976810   329 solver.cpp:243] Iteration 33600, loss = 3253.59
I1016 15:48:24.976843   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.07699 (* 1 = 6.07699 loss)
I1016 15:48:24.976850   329 solver.cpp:259]     Train net output #1: seg_loss = 2885.28 (* 1 = 2885.28 loss)
I1016 15:48:24.976855   329 sgd_solver.cpp:138] Iteration 33600, lr = 0.00025
I1016 15:49:24.202970   329 solver.cpp:243] Iteration 33700, loss = 3057.72
I1016 15:49:24.203003   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.80304 (* 1 = 6.80304 loss)
I1016 15:49:24.203009   329 solver.cpp:259]     Train net output #1: seg_loss = 4088.1 (* 1 = 4088.1 loss)
I1016 15:49:24.203016   329 sgd_solver.cpp:138] Iteration 33700, lr = 0.00025
I1016 15:50:22.906950   329 solver.cpp:243] Iteration 33800, loss = 3674.46
I1016 15:50:22.906983   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.99059 (* 1 = 7.99059 loss)
I1016 15:50:22.906988   329 solver.cpp:259]     Train net output #1: seg_loss = 3256.57 (* 1 = 3256.57 loss)
I1016 15:50:22.906994   329 sgd_solver.cpp:138] Iteration 33800, lr = 0.00025
I1016 15:51:22.590934   329 solver.cpp:243] Iteration 33900, loss = 2891.42
I1016 15:51:22.590966   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.89494 (* 1 = 6.89494 loss)
I1016 15:51:22.590972   329 solver.cpp:259]     Train net output #1: seg_loss = 2531.54 (* 1 = 2531.54 loss)
I1016 15:51:22.590978   329 sgd_solver.cpp:138] Iteration 33900, lr = 0.00025
I1016 15:52:22.075960   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_34000.caffemodel
I1016 15:52:22.926175   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_34000.solverstate
I1016 15:52:23.499279   329 solver.cpp:243] Iteration 34000, loss = 3750.78
I1016 15:52:23.499310   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.59235 (* 1 = 7.59235 loss)
I1016 15:52:23.499317   329 solver.cpp:259]     Train net output #1: seg_loss = 3292.6 (* 1 = 3292.6 loss)
I1016 15:52:23.499323   329 sgd_solver.cpp:138] Iteration 34000, lr = 0.00025
I1016 15:53:22.799907   329 solver.cpp:243] Iteration 34100, loss = 2979.16
I1016 15:53:22.799954   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.88106 (* 1 = 7.88106 loss)
I1016 15:53:22.799960   329 solver.cpp:259]     Train net output #1: seg_loss = 3395.53 (* 1 = 3395.53 loss)
I1016 15:53:22.799966   329 sgd_solver.cpp:138] Iteration 34100, lr = 0.00025
I1016 15:54:21.966969   329 solver.cpp:243] Iteration 34200, loss = 3415.96
I1016 15:54:21.967017   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.44776 (* 1 = 9.44776 loss)
I1016 15:54:21.967025   329 solver.cpp:259]     Train net output #1: seg_loss = 2902.94 (* 1 = 2902.94 loss)
I1016 15:54:21.967030   329 sgd_solver.cpp:138] Iteration 34200, lr = 0.00025
I1016 15:55:20.254087   329 solver.cpp:243] Iteration 34300, loss = 3035.42
I1016 15:55:20.254127   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.57326 (* 1 = 4.57326 loss)
I1016 15:55:20.254133   329 solver.cpp:259]     Train net output #1: seg_loss = 2578.08 (* 1 = 2578.08 loss)
I1016 15:55:20.254139   329 sgd_solver.cpp:138] Iteration 34300, lr = 0.00025
I1016 15:56:20.247129   329 solver.cpp:243] Iteration 34400, loss = 3277.45
I1016 15:56:20.247164   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.62636 (* 1 = 8.62636 loss)
I1016 15:56:20.247172   329 solver.cpp:259]     Train net output #1: seg_loss = 3788.12 (* 1 = 3788.12 loss)
I1016 15:56:20.247195   329 sgd_solver.cpp:138] Iteration 34400, lr = 0.00025
I1016 15:57:19.416867   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_34500.caffemodel
I1016 15:57:19.645694   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_34500.solverstate
I1016 15:57:20.215903   329 solver.cpp:243] Iteration 34500, loss = 3824.26
I1016 15:57:20.215950   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.71189 (* 1 = 4.71189 loss)
I1016 15:57:20.215956   329 solver.cpp:259]     Train net output #1: seg_loss = 3009.53 (* 1 = 3009.53 loss)
I1016 15:57:20.215962   329 sgd_solver.cpp:138] Iteration 34500, lr = 0.00025
I1016 15:58:10.331707   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 15:58:20.866466   329 solver.cpp:243] Iteration 34600, loss = 2710.51
I1016 15:58:20.866513   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.07899 (* 1 = 5.07899 loss)
I1016 15:58:20.866519   329 solver.cpp:259]     Train net output #1: seg_loss = 2119.29 (* 1 = 2119.29 loss)
I1016 15:58:20.866525   329 sgd_solver.cpp:138] Iteration 34600, lr = 0.00025
I1016 15:59:20.269132   329 solver.cpp:243] Iteration 34700, loss = 3502.3
I1016 15:59:20.269179   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.27336 (* 1 = 9.27336 loss)
I1016 15:59:20.269186   329 solver.cpp:259]     Train net output #1: seg_loss = 3814.59 (* 1 = 3814.59 loss)
I1016 15:59:20.269191   329 sgd_solver.cpp:138] Iteration 34700, lr = 0.00025
I1016 16:00:20.743611   329 solver.cpp:243] Iteration 34800, loss = 4035.83
I1016 16:00:20.743660   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.43678 (* 1 = 7.43678 loss)
I1016 16:00:20.743666   329 solver.cpp:259]     Train net output #1: seg_loss = 4404.73 (* 1 = 4404.73 loss)
I1016 16:00:20.743672   329 sgd_solver.cpp:138] Iteration 34800, lr = 0.00025
I1016 16:01:20.843057   329 solver.cpp:243] Iteration 34900, loss = 4814.6
I1016 16:01:20.843092   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.92929 (* 1 = 9.92929 loss)
I1016 16:01:20.843116   329 solver.cpp:259]     Train net output #1: seg_loss = 7294.22 (* 1 = 7294.22 loss)
I1016 16:01:20.843124   329 sgd_solver.cpp:138] Iteration 34900, lr = 0.00025
I1016 16:02:21.762027   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_35000.caffemodel
I1016 16:02:22.609498   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_35000.solverstate
I1016 16:02:23.254010   329 solver.cpp:243] Iteration 35000, loss = 2987.19
I1016 16:02:23.254041   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.08953 (* 1 = 5.08953 loss)
I1016 16:02:23.254047   329 solver.cpp:259]     Train net output #1: seg_loss = 2644.15 (* 1 = 2644.15 loss)
I1016 16:02:23.254053   329 sgd_solver.cpp:138] Iteration 35000, lr = 0.00025
I1016 16:03:23.848819   329 solver.cpp:243] Iteration 35100, loss = 3795.73
I1016 16:03:23.848851   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.49756 (* 1 = 6.49756 loss)
I1016 16:03:23.848857   329 solver.cpp:259]     Train net output #1: seg_loss = 4468.01 (* 1 = 4468.01 loss)
I1016 16:03:23.848863   329 sgd_solver.cpp:138] Iteration 35100, lr = 0.00025
I1016 16:04:25.671638   329 solver.cpp:243] Iteration 35200, loss = 3597.35
I1016 16:04:25.671674   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14521 (* 1 = 7.14521 loss)
I1016 16:04:25.671699   329 solver.cpp:259]     Train net output #1: seg_loss = 3449.65 (* 1 = 3449.65 loss)
I1016 16:04:25.671706   329 sgd_solver.cpp:138] Iteration 35200, lr = 0.00025
I1016 16:05:26.142076   329 solver.cpp:243] Iteration 35300, loss = 2660.4
I1016 16:05:26.142108   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.01118 (* 1 = 5.01118 loss)
I1016 16:05:26.142114   329 solver.cpp:259]     Train net output #1: seg_loss = 2426.91 (* 1 = 2426.91 loss)
I1016 16:05:26.142120   329 sgd_solver.cpp:138] Iteration 35300, lr = 0.00025
I1016 16:06:24.417080   329 solver.cpp:243] Iteration 35400, loss = 3414
I1016 16:06:24.417129   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.77978 (* 1 = 8.77978 loss)
I1016 16:06:24.417135   329 solver.cpp:259]     Train net output #1: seg_loss = 2974.74 (* 1 = 2974.74 loss)
I1016 16:06:24.417141   329 sgd_solver.cpp:138] Iteration 35400, lr = 0.00025
I1016 16:07:24.106252   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_35500.caffemodel
I1016 16:07:24.349856   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_35500.solverstate
I1016 16:07:24.901960   329 solver.cpp:243] Iteration 35500, loss = 3127.01
I1016 16:07:24.901991   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.25384 (* 1 = 6.25384 loss)
I1016 16:07:24.901998   329 solver.cpp:259]     Train net output #1: seg_loss = 3650.75 (* 1 = 3650.75 loss)
I1016 16:07:24.902005   329 sgd_solver.cpp:138] Iteration 35500, lr = 0.00025
I1016 16:08:18.817221   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:08:24.194200   329 solver.cpp:243] Iteration 35600, loss = 3132.89
I1016 16:08:24.194249   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.49058 (* 1 = 8.49058 loss)
I1016 16:08:24.194257   329 solver.cpp:259]     Train net output #1: seg_loss = 4281.88 (* 1 = 4281.88 loss)
I1016 16:08:24.194262   329 sgd_solver.cpp:138] Iteration 35600, lr = 0.00025
I1016 16:09:24.275679   329 solver.cpp:243] Iteration 35700, loss = 3356.3
I1016 16:09:24.275728   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.98181 (* 1 = 9.98181 loss)
I1016 16:09:24.275735   329 solver.cpp:259]     Train net output #1: seg_loss = 3919.16 (* 1 = 3919.16 loss)
I1016 16:09:24.275741   329 sgd_solver.cpp:138] Iteration 35700, lr = 0.00025
I1016 16:10:24.632117   329 solver.cpp:243] Iteration 35800, loss = 3864.64
I1016 16:10:24.632149   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.45324 (* 1 = 7.45324 loss)
I1016 16:10:24.632156   329 solver.cpp:259]     Train net output #1: seg_loss = 3285.68 (* 1 = 3285.68 loss)
I1016 16:10:24.632163   329 sgd_solver.cpp:138] Iteration 35800, lr = 0.00025
I1016 16:11:23.797080   329 solver.cpp:243] Iteration 35900, loss = 3237.01
I1016 16:11:23.797127   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.2288 (* 1 = 4.2288 loss)
I1016 16:11:23.797133   329 solver.cpp:259]     Train net output #1: seg_loss = 2390.76 (* 1 = 2390.76 loss)
I1016 16:11:23.797139   329 sgd_solver.cpp:138] Iteration 35900, lr = 0.00025
I1016 16:12:23.336601   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_36000.caffemodel
I1016 16:12:24.180464   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_36000.solverstate
I1016 16:12:24.411695   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 16:14:02.445817   329 solver.cpp:243] Iteration 36000, loss = 3773.41
I1016 16:14:02.445852   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.19153 (* 1 = 9.19153 loss)
I1016 16:14:02.445859   329 solver.cpp:259]     Train net output #1: seg_loss = 3764.22 (* 1 = 3764.22 loss)
I1016 16:14:02.445865   329 sgd_solver.cpp:138] Iteration 36000, lr = 0.00025
I1016 16:15:00.852500   329 solver.cpp:243] Iteration 36100, loss = 3088.65
I1016 16:15:00.852532   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14449 (* 1 = 7.14449 loss)
I1016 16:15:00.852540   329 solver.cpp:259]     Train net output #1: seg_loss = 3320.75 (* 1 = 3320.75 loss)
I1016 16:15:00.852546   329 sgd_solver.cpp:138] Iteration 36100, lr = 0.00025
I1016 16:15:01.514014   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:16:00.908021   329 solver.cpp:243] Iteration 36200, loss = 3667.75
I1016 16:16:00.908069   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.63751 (* 1 = 4.63751 loss)
I1016 16:16:00.908076   329 solver.cpp:259]     Train net output #1: seg_loss = 5606.89 (* 1 = 5606.89 loss)
I1016 16:16:00.908082   329 sgd_solver.cpp:138] Iteration 36200, lr = 0.00025
I1016 16:17:00.859728   329 solver.cpp:243] Iteration 36300, loss = 3310.95
I1016 16:17:00.859760   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.71053 (* 1 = 6.71053 loss)
I1016 16:17:00.859766   329 solver.cpp:259]     Train net output #1: seg_loss = 3250.72 (* 1 = 3250.72 loss)
I1016 16:17:00.859771   329 sgd_solver.cpp:138] Iteration 36300, lr = 0.00025
I1016 16:18:00.124541   329 solver.cpp:243] Iteration 36400, loss = 3330.41
I1016 16:18:00.124578   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.92593 (* 1 = 5.92593 loss)
I1016 16:18:00.124585   329 solver.cpp:259]     Train net output #1: seg_loss = 3032.89 (* 1 = 3032.89 loss)
I1016 16:18:00.124591   329 sgd_solver.cpp:138] Iteration 36400, lr = 0.00025
I1016 16:18:58.170958   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_36500.caffemodel
I1016 16:18:58.482717   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_36500.solverstate
I1016 16:18:59.116972   329 solver.cpp:243] Iteration 36500, loss = 5804.54
I1016 16:18:59.117004   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.58871 (* 1 = 7.58871 loss)
I1016 16:18:59.117013   329 solver.cpp:259]     Train net output #1: seg_loss = 5746.85 (* 1 = 5746.85 loss)
I1016 16:18:59.117022   329 sgd_solver.cpp:138] Iteration 36500, lr = 0.00025
I1016 16:19:58.529237   329 solver.cpp:243] Iteration 36600, loss = 3000.99
I1016 16:19:58.529273   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.33204 (* 1 = 6.33204 loss)
I1016 16:19:58.529280   329 solver.cpp:259]     Train net output #1: seg_loss = 2835.79 (* 1 = 2835.79 loss)
I1016 16:19:58.529304   329 sgd_solver.cpp:138] Iteration 36600, lr = 0.00025
I1016 16:20:58.364696   329 solver.cpp:243] Iteration 36700, loss = 3762.12
I1016 16:20:58.364745   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.24653 (* 1 = 6.24653 loss)
I1016 16:20:58.364751   329 solver.cpp:259]     Train net output #1: seg_loss = 3912.56 (* 1 = 3912.56 loss)
I1016 16:20:58.364758   329 sgd_solver.cpp:138] Iteration 36700, lr = 0.00025
I1016 16:21:58.648296   329 solver.cpp:243] Iteration 36800, loss = 2771.19
I1016 16:21:58.648329   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.72718 (* 1 = 3.72718 loss)
I1016 16:21:58.648334   329 solver.cpp:259]     Train net output #1: seg_loss = 2758.42 (* 1 = 2758.42 loss)
I1016 16:21:58.648339   329 sgd_solver.cpp:138] Iteration 36800, lr = 0.00025
I1016 16:22:58.000685   329 solver.cpp:243] Iteration 36900, loss = 3142.01
I1016 16:22:58.000717   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.5246 (* 1 = 11.5246 loss)
I1016 16:22:58.000723   329 solver.cpp:259]     Train net output #1: seg_loss = 3596.12 (* 1 = 3596.12 loss)
I1016 16:22:58.000730   329 sgd_solver.cpp:138] Iteration 36900, lr = 0.00025
I1016 16:23:56.029167   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_37000.caffemodel
I1016 16:23:56.798264   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_37000.solverstate
I1016 16:23:57.368012   329 solver.cpp:243] Iteration 37000, loss = 2744.32
I1016 16:23:57.368057   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.28542 (* 1 = 8.28542 loss)
I1016 16:23:57.368063   329 solver.cpp:259]     Train net output #1: seg_loss = 3100.73 (* 1 = 3100.73 loss)
I1016 16:23:57.368069   329 sgd_solver.cpp:138] Iteration 37000, lr = 0.00025
I1016 16:24:56.222167   329 solver.cpp:243] Iteration 37100, loss = 3710.71
I1016 16:24:56.222227   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.20974 (* 1 = 7.20974 loss)
I1016 16:24:56.222234   329 solver.cpp:259]     Train net output #1: seg_loss = 2797.52 (* 1 = 2797.52 loss)
I1016 16:24:56.222239   329 sgd_solver.cpp:138] Iteration 37100, lr = 0.00025
I1016 16:25:01.625223   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:25:55.650286   329 solver.cpp:243] Iteration 37200, loss = 3406.18
I1016 16:25:55.650319   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.36732 (* 1 = 5.36732 loss)
I1016 16:25:55.650326   329 solver.cpp:259]     Train net output #1: seg_loss = 4313.82 (* 1 = 4313.82 loss)
I1016 16:25:55.650331   329 sgd_solver.cpp:138] Iteration 37200, lr = 0.00025
I1016 16:26:56.025816   329 solver.cpp:243] Iteration 37300, loss = 2801.26
I1016 16:26:56.025867   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.47578 (* 1 = 4.47578 loss)
I1016 16:26:56.025873   329 solver.cpp:259]     Train net output #1: seg_loss = 2938.39 (* 1 = 2938.39 loss)
I1016 16:26:56.025879   329 sgd_solver.cpp:138] Iteration 37300, lr = 0.00025
I1016 16:27:55.388928   329 solver.cpp:243] Iteration 37400, loss = 2841.53
I1016 16:27:55.388975   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.79172 (* 1 = 7.79172 loss)
I1016 16:27:55.388981   329 solver.cpp:259]     Train net output #1: seg_loss = 2014.13 (* 1 = 2014.13 loss)
I1016 16:27:55.388988   329 sgd_solver.cpp:138] Iteration 37400, lr = 0.00025
I1016 16:28:54.217103   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_37500.caffemodel
I1016 16:28:54.966862   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_37500.solverstate
I1016 16:28:55.534567   329 solver.cpp:243] Iteration 37500, loss = 4894.63
I1016 16:28:55.534612   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.98355 (* 1 = 5.98355 loss)
I1016 16:28:55.534618   329 solver.cpp:259]     Train net output #1: seg_loss = 3776.98 (* 1 = 3776.98 loss)
I1016 16:28:55.534624   329 sgd_solver.cpp:138] Iteration 37500, lr = 0.00025
I1016 16:29:53.512823   329 solver.cpp:243] Iteration 37600, loss = 3500.14
I1016 16:29:53.512869   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.3146 (* 1 = 6.3146 loss)
I1016 16:29:53.512874   329 solver.cpp:259]     Train net output #1: seg_loss = 3040.55 (* 1 = 3040.55 loss)
I1016 16:29:53.512881   329 sgd_solver.cpp:138] Iteration 37600, lr = 0.00025
I1016 16:30:53.002339   329 solver.cpp:243] Iteration 37700, loss = 3018.99
I1016 16:30:53.002372   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.53364 (* 1 = 5.53364 loss)
I1016 16:30:53.002377   329 solver.cpp:259]     Train net output #1: seg_loss = 2463.18 (* 1 = 2463.18 loss)
I1016 16:30:53.002384   329 sgd_solver.cpp:138] Iteration 37700, lr = 0.00025
I1016 16:31:53.606027   329 solver.cpp:243] Iteration 37800, loss = 4679.78
I1016 16:31:53.606060   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.31618 (* 1 = 8.31618 loss)
I1016 16:31:53.606065   329 solver.cpp:259]     Train net output #1: seg_loss = 6106.76 (* 1 = 6106.76 loss)
I1016 16:31:53.606072   329 sgd_solver.cpp:138] Iteration 37800, lr = 0.00025
I1016 16:32:53.788928   329 solver.cpp:243] Iteration 37900, loss = 2732.24
I1016 16:32:53.788976   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.33139 (* 1 = 4.33139 loss)
I1016 16:32:53.788982   329 solver.cpp:259]     Train net output #1: seg_loss = 2372.69 (* 1 = 2372.69 loss)
I1016 16:32:53.788990   329 sgd_solver.cpp:138] Iteration 37900, lr = 0.00025
I1016 16:33:53.528872   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_38000.caffemodel
I1016 16:33:54.410770   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_38000.solverstate
I1016 16:33:55.025319   329 solver.cpp:243] Iteration 38000, loss = 2791.6
I1016 16:33:55.025363   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.36107 (* 1 = 6.36107 loss)
I1016 16:33:55.025369   329 solver.cpp:259]     Train net output #1: seg_loss = 2350.69 (* 1 = 2350.69 loss)
I1016 16:33:55.025374   329 sgd_solver.cpp:138] Iteration 38000, lr = 0.00025
I1016 16:34:53.543866   329 solver.cpp:243] Iteration 38100, loss = 3157.11
I1016 16:34:53.543900   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.64533 (* 1 = 4.64533 loss)
I1016 16:34:53.543905   329 solver.cpp:259]     Train net output #1: seg_loss = 3833.04 (* 1 = 3833.04 loss)
I1016 16:34:53.543911   329 sgd_solver.cpp:138] Iteration 38100, lr = 0.00025
I1016 16:35:05.863466   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:35:54.192502   329 solver.cpp:243] Iteration 38200, loss = 3093.95
I1016 16:35:54.192533   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.02068 (* 1 = 7.02068 loss)
I1016 16:35:54.192538   329 solver.cpp:259]     Train net output #1: seg_loss = 2536.27 (* 1 = 2536.27 loss)
I1016 16:35:54.192543   329 sgd_solver.cpp:138] Iteration 38200, lr = 0.00025
I1016 16:36:55.335275   329 solver.cpp:243] Iteration 38300, loss = 2585.9
I1016 16:36:55.335307   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.13141 (* 1 = 6.13141 loss)
I1016 16:36:55.335314   329 solver.cpp:259]     Train net output #1: seg_loss = 731.784 (* 1 = 731.784 loss)
I1016 16:36:55.335319   329 sgd_solver.cpp:138] Iteration 38300, lr = 0.00025
I1016 16:37:56.269484   329 solver.cpp:243] Iteration 38400, loss = 3042.57
I1016 16:37:56.269532   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.6991 (* 1 = 10.6991 loss)
I1016 16:37:56.269538   329 solver.cpp:259]     Train net output #1: seg_loss = 3920.45 (* 1 = 3920.45 loss)
I1016 16:37:56.269543   329 sgd_solver.cpp:138] Iteration 38400, lr = 0.00025
I1016 16:38:55.473098   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_38500.caffemodel
I1016 16:38:56.340147   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_38500.solverstate
I1016 16:38:56.951082   329 solver.cpp:243] Iteration 38500, loss = 3741.17
I1016 16:38:56.951138   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.57057 (* 1 = 5.57057 loss)
I1016 16:38:56.951144   329 solver.cpp:259]     Train net output #1: seg_loss = 6647.34 (* 1 = 6647.34 loss)
I1016 16:38:56.951150   329 sgd_solver.cpp:138] Iteration 38500, lr = 0.00025
I1016 16:39:56.230226   329 solver.cpp:243] Iteration 38600, loss = 3319.86
I1016 16:39:56.230260   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.83209 (* 1 = 4.83209 loss)
I1016 16:39:56.230269   329 solver.cpp:259]     Train net output #1: seg_loss = 2979.08 (* 1 = 2979.08 loss)
I1016 16:39:56.230278   329 sgd_solver.cpp:138] Iteration 38600, lr = 0.00025
I1016 16:40:55.776453   329 solver.cpp:243] Iteration 38700, loss = 5227.43
I1016 16:40:55.776501   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.32571 (* 1 = 9.32571 loss)
I1016 16:40:55.776509   329 solver.cpp:259]     Train net output #1: seg_loss = 5440.56 (* 1 = 5440.56 loss)
I1016 16:40:55.776515   329 sgd_solver.cpp:138] Iteration 38700, lr = 0.00025
I1016 16:41:55.972165   329 solver.cpp:243] Iteration 38800, loss = 3667.3
I1016 16:41:55.972213   329 solver.cpp:259]     Train net output #0: mbox_loss = 2.0176 (* 1 = 2.0176 loss)
I1016 16:41:55.972219   329 solver.cpp:259]     Train net output #1: seg_loss = 3249.85 (* 1 = 3249.85 loss)
I1016 16:41:55.972225   329 sgd_solver.cpp:138] Iteration 38800, lr = 0.00025
I1016 16:42:56.465783   329 solver.cpp:243] Iteration 38900, loss = 3262.5
I1016 16:42:56.465818   329 solver.cpp:259]     Train net output #0: mbox_loss = 2.50711 (* 1 = 2.50711 loss)
I1016 16:42:56.465831   329 solver.cpp:259]     Train net output #1: seg_loss = 2643.02 (* 1 = 2643.02 loss)
I1016 16:42:56.465840   329 sgd_solver.cpp:138] Iteration 38900, lr = 0.00025
I1016 16:43:56.343143   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_39000.caffemodel
I1016 16:43:56.577507   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_39000.solverstate
I1016 16:43:57.154294   329 solver.cpp:243] Iteration 39000, loss = 4331.94
I1016 16:43:57.154326   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.21516 (* 1 = 4.21516 loss)
I1016 16:43:57.154333   329 solver.cpp:259]     Train net output #1: seg_loss = 3115.06 (* 1 = 3115.06 loss)
I1016 16:43:57.154340   329 sgd_solver.cpp:138] Iteration 39000, lr = 0.00025
I1016 16:44:56.813457   329 solver.cpp:243] Iteration 39100, loss = 3070.29
I1016 16:44:56.813503   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.56542 (* 1 = 7.56542 loss)
I1016 16:44:56.813508   329 solver.cpp:259]     Train net output #1: seg_loss = 4774.37 (* 1 = 4774.37 loss)
I1016 16:44:56.813514   329 sgd_solver.cpp:138] Iteration 39100, lr = 0.00025
I1016 16:45:13.192260   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:45:56.261665   329 solver.cpp:243] Iteration 39200, loss = 4495
I1016 16:45:56.261715   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.5909 (* 1 = 10.5909 loss)
I1016 16:45:56.261721   329 solver.cpp:259]     Train net output #1: seg_loss = 3637.58 (* 1 = 3637.58 loss)
I1016 16:45:56.261728   329 sgd_solver.cpp:138] Iteration 39200, lr = 0.00025
I1016 16:46:57.587565   329 solver.cpp:243] Iteration 39300, loss = 2852.53
I1016 16:46:57.587597   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.808 (* 1 = 11.808 loss)
I1016 16:46:57.587604   329 solver.cpp:259]     Train net output #1: seg_loss = 2431.46 (* 1 = 2431.46 loss)
I1016 16:46:57.587610   329 sgd_solver.cpp:138] Iteration 39300, lr = 0.00025
I1016 16:47:57.952744   329 solver.cpp:243] Iteration 39400, loss = 3430.93
I1016 16:47:57.952791   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.64911 (* 1 = 3.64911 loss)
I1016 16:47:57.952797   329 solver.cpp:259]     Train net output #1: seg_loss = 2784.01 (* 1 = 2784.01 loss)
I1016 16:47:57.952803   329 sgd_solver.cpp:138] Iteration 39400, lr = 0.00025
I1016 16:48:59.027784   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_39500.caffemodel
I1016 16:49:00.029989   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_39500.solverstate
I1016 16:49:00.637137   329 solver.cpp:243] Iteration 39500, loss = 3171.59
I1016 16:49:00.637172   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.2301 (* 1 = 10.2301 loss)
I1016 16:49:00.637178   329 solver.cpp:259]     Train net output #1: seg_loss = 1899.27 (* 1 = 1899.27 loss)
I1016 16:49:00.637184   329 sgd_solver.cpp:138] Iteration 39500, lr = 0.00025
I1016 16:50:00.018348   329 solver.cpp:243] Iteration 39600, loss = 3557.86
I1016 16:50:00.018399   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.12066 (* 1 = 6.12066 loss)
I1016 16:50:00.018404   329 solver.cpp:259]     Train net output #1: seg_loss = 3098.61 (* 1 = 3098.61 loss)
I1016 16:50:00.018410   329 sgd_solver.cpp:138] Iteration 39600, lr = 0.00025
I1016 16:50:59.644130   329 solver.cpp:243] Iteration 39700, loss = 2801.23
I1016 16:50:59.644178   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.2984 (* 1 = 6.2984 loss)
I1016 16:50:59.644184   329 solver.cpp:259]     Train net output #1: seg_loss = 3371.85 (* 1 = 3371.85 loss)
I1016 16:50:59.644191   329 sgd_solver.cpp:138] Iteration 39700, lr = 0.00025
I1016 16:52:00.154759   329 solver.cpp:243] Iteration 39800, loss = 3145.42
I1016 16:52:00.154793   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.35229 (* 1 = 7.35229 loss)
I1016 16:52:00.154801   329 solver.cpp:259]     Train net output #1: seg_loss = 3093.53 (* 1 = 3093.53 loss)
I1016 16:52:00.154824   329 sgd_solver.cpp:138] Iteration 39800, lr = 0.00025
I1016 16:53:00.594190   329 solver.cpp:243] Iteration 39900, loss = 2615.27
I1016 16:53:00.594223   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.50771 (* 1 = 5.50771 loss)
I1016 16:53:00.594228   329 solver.cpp:259]     Train net output #1: seg_loss = 2229.01 (* 1 = 2229.01 loss)
I1016 16:53:00.594234   329 sgd_solver.cpp:138] Iteration 39900, lr = 0.00025
I1016 16:54:01.400753   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_40000.caffemodel
I1016 16:54:02.204056   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_40000.solverstate
I1016 16:54:02.409505   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 16:54:28.889413   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 16:55:41.058305   329 solver.cpp:243] Iteration 40000, loss = 2295.22
I1016 16:55:41.058336   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.42141 (* 1 = 9.42141 loss)
I1016 16:55:41.058341   329 solver.cpp:259]     Train net output #1: seg_loss = 2285.8 (* 1 = 2285.8 loss)
I1016 16:55:41.058346   329 sgd_solver.cpp:47] MultiStep Status: Iteration 40000, step = 2
I1016 16:55:41.058349   329 sgd_solver.cpp:138] Iteration 40000, lr = 0.000125
I1016 16:56:40.299288   329 solver.cpp:243] Iteration 40100, loss = 3026.57
I1016 16:56:40.299340   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.74519 (* 1 = 3.74519 loss)
I1016 16:56:40.299346   329 solver.cpp:259]     Train net output #1: seg_loss = 2538.47 (* 1 = 2538.47 loss)
I1016 16:56:40.299352   329 sgd_solver.cpp:138] Iteration 40100, lr = 0.000125
I1016 16:57:40.736665   329 solver.cpp:243] Iteration 40200, loss = 2854.09
I1016 16:57:40.736714   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.90693 (* 1 = 6.90693 loss)
I1016 16:57:40.736721   329 solver.cpp:259]     Train net output #1: seg_loss = 3014.27 (* 1 = 3014.27 loss)
I1016 16:57:40.736726   329 sgd_solver.cpp:138] Iteration 40200, lr = 0.000125
I1016 16:58:39.742660   329 solver.cpp:243] Iteration 40300, loss = 3389.31
I1016 16:58:39.742696   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.57111 (* 1 = 6.57111 loss)
I1016 16:58:39.742702   329 solver.cpp:259]     Train net output #1: seg_loss = 2822.42 (* 1 = 2822.42 loss)
I1016 16:58:39.742707   329 sgd_solver.cpp:138] Iteration 40300, lr = 0.000125
I1016 16:59:39.545382   329 solver.cpp:243] Iteration 40400, loss = 2698.4
I1016 16:59:39.545430   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.58132 (* 1 = 5.58132 loss)
I1016 16:59:39.545437   329 solver.cpp:259]     Train net output #1: seg_loss = 4207.26 (* 1 = 4207.26 loss)
I1016 16:59:39.545444   329 sgd_solver.cpp:138] Iteration 40400, lr = 0.000125
I1016 17:00:39.214841   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_40500.caffemodel
I1016 17:00:39.517743   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_40500.solverstate
I1016 17:00:40.166003   329 solver.cpp:243] Iteration 40500, loss = 3164.73
I1016 17:00:40.166038   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.39619 (* 1 = 8.39619 loss)
I1016 17:00:40.166047   329 solver.cpp:259]     Train net output #1: seg_loss = 3683.31 (* 1 = 3683.31 loss)
I1016 17:00:40.166055   329 sgd_solver.cpp:138] Iteration 40500, lr = 0.000125
I1016 17:01:40.011267   329 solver.cpp:243] Iteration 40600, loss = 2647.59
I1016 17:01:40.011303   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.53737 (* 1 = 7.53737 loss)
I1016 17:01:40.011312   329 solver.cpp:259]     Train net output #1: seg_loss = 2050.14 (* 1 = 2050.14 loss)
I1016 17:01:40.011335   329 sgd_solver.cpp:138] Iteration 40600, lr = 0.000125
I1016 17:02:07.290737   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:02:39.388998   329 solver.cpp:243] Iteration 40700, loss = 3194.42
I1016 17:02:39.389034   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.84818 (* 1 = 8.84818 loss)
I1016 17:02:39.389042   329 solver.cpp:259]     Train net output #1: seg_loss = 2765.24 (* 1 = 2765.24 loss)
I1016 17:02:39.389050   329 sgd_solver.cpp:138] Iteration 40700, lr = 0.000125
I1016 17:03:38.217525   329 solver.cpp:243] Iteration 40800, loss = 2852.41
I1016 17:03:38.217557   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.64041 (* 1 = 5.64041 loss)
I1016 17:03:38.217566   329 solver.cpp:259]     Train net output #1: seg_loss = 2566.07 (* 1 = 2566.07 loss)
I1016 17:03:38.217574   329 sgd_solver.cpp:138] Iteration 40800, lr = 0.000125
I1016 17:04:39.267238   329 solver.cpp:243] Iteration 40900, loss = 3028.89
I1016 17:04:39.267288   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.02574 (* 1 = 8.02574 loss)
I1016 17:04:39.267294   329 solver.cpp:259]     Train net output #1: seg_loss = 2781.92 (* 1 = 2781.92 loss)
I1016 17:04:39.267300   329 sgd_solver.cpp:138] Iteration 40900, lr = 0.000125
I1016 17:05:38.197499   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_41000.caffemodel
I1016 17:05:38.970219   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_41000.solverstate
I1016 17:05:39.523674   329 solver.cpp:243] Iteration 41000, loss = 3499.89
I1016 17:05:39.523721   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.99528 (* 1 = 6.99528 loss)
I1016 17:05:39.523727   329 solver.cpp:259]     Train net output #1: seg_loss = 3434.4 (* 1 = 3434.4 loss)
I1016 17:05:39.523735   329 sgd_solver.cpp:138] Iteration 41000, lr = 0.000125
I1016 17:06:39.217716   329 solver.cpp:243] Iteration 41100, loss = 2480.77
I1016 17:06:39.217763   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.21098 (* 1 = 4.21098 loss)
I1016 17:06:39.217769   329 solver.cpp:259]     Train net output #1: seg_loss = 2027.27 (* 1 = 2027.27 loss)
I1016 17:06:39.217775   329 sgd_solver.cpp:138] Iteration 41100, lr = 0.000125
I1016 17:07:38.765986   329 solver.cpp:243] Iteration 41200, loss = 3062.45
I1016 17:07:38.766022   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.35009 (* 1 = 6.35009 loss)
I1016 17:07:38.766031   329 solver.cpp:259]     Train net output #1: seg_loss = 3759.61 (* 1 = 3759.61 loss)
I1016 17:07:38.766039   329 sgd_solver.cpp:138] Iteration 41200, lr = 0.000125
I1016 17:08:38.637159   329 solver.cpp:243] Iteration 41300, loss = 3720.75
I1016 17:08:38.637208   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.22183 (* 1 = 7.22183 loss)
I1016 17:08:38.637214   329 solver.cpp:259]     Train net output #1: seg_loss = 4624.16 (* 1 = 4624.16 loss)
I1016 17:08:38.637220   329 sgd_solver.cpp:138] Iteration 41300, lr = 0.000125
I1016 17:09:38.601143   329 solver.cpp:243] Iteration 41400, loss = 3741.13
I1016 17:09:38.601176   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.37139 (* 1 = 8.37139 loss)
I1016 17:09:38.601181   329 solver.cpp:259]     Train net output #1: seg_loss = 4351.95 (* 1 = 4351.95 loss)
I1016 17:09:38.601187   329 sgd_solver.cpp:138] Iteration 41400, lr = 0.000125
I1016 17:10:38.136854   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_41500.caffemodel
I1016 17:10:38.364326   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_41500.solverstate
I1016 17:10:38.937342   329 solver.cpp:243] Iteration 41500, loss = 2642.59
I1016 17:10:38.937376   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.06502 (* 1 = 6.06502 loss)
I1016 17:10:38.937382   329 solver.cpp:259]     Train net output #1: seg_loss = 3388.75 (* 1 = 3388.75 loss)
I1016 17:10:38.937387   329 sgd_solver.cpp:138] Iteration 41500, lr = 0.000125
I1016 17:11:40.290509   329 solver.cpp:243] Iteration 41600, loss = 3748.99
I1016 17:11:40.290542   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.31057 (* 1 = 3.31057 loss)
I1016 17:11:40.290549   329 solver.cpp:259]     Train net output #1: seg_loss = 3220.48 (* 1 = 3220.48 loss)
I1016 17:11:40.290554   329 sgd_solver.cpp:138] Iteration 41600, lr = 0.000125
I1016 17:12:13.100132   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:12:41.054170   329 solver.cpp:243] Iteration 41700, loss = 3252.19
I1016 17:12:41.054217   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.1652 (* 1 = 10.1652 loss)
I1016 17:12:41.054224   329 solver.cpp:259]     Train net output #1: seg_loss = 3319.31 (* 1 = 3319.31 loss)
I1016 17:12:41.054229   329 sgd_solver.cpp:138] Iteration 41700, lr = 0.000125
I1016 17:13:40.739576   329 solver.cpp:243] Iteration 41800, loss = 2416.47
I1016 17:13:40.739624   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.97137 (* 1 = 3.97137 loss)
I1016 17:13:40.739629   329 solver.cpp:259]     Train net output #1: seg_loss = 1946.12 (* 1 = 1946.12 loss)
I1016 17:13:40.739635   329 sgd_solver.cpp:138] Iteration 41800, lr = 0.000125
I1016 17:14:39.898802   329 solver.cpp:243] Iteration 41900, loss = 3219.07
I1016 17:14:39.898835   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.95988 (* 1 = 3.95988 loss)
I1016 17:14:39.898841   329 solver.cpp:259]     Train net output #1: seg_loss = 2777.7 (* 1 = 2777.7 loss)
I1016 17:14:39.898847   329 sgd_solver.cpp:138] Iteration 41900, lr = 0.000125
I1016 17:15:40.119562   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_42000.caffemodel
I1016 17:15:40.936555   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_42000.solverstate
I1016 17:15:41.505486   329 solver.cpp:243] Iteration 42000, loss = 2718.22
I1016 17:15:41.505530   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.17524 (* 1 = 6.17524 loss)
I1016 17:15:41.505537   329 solver.cpp:259]     Train net output #1: seg_loss = 2279.78 (* 1 = 2279.78 loss)
I1016 17:15:41.505542   329 sgd_solver.cpp:138] Iteration 42000, lr = 0.000125
I1016 17:16:40.929345   329 solver.cpp:243] Iteration 42100, loss = 2546.8
I1016 17:16:40.929394   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.83798 (* 1 = 5.83798 loss)
I1016 17:16:40.929400   329 solver.cpp:259]     Train net output #1: seg_loss = 3576.2 (* 1 = 3576.2 loss)
I1016 17:16:40.929406   329 sgd_solver.cpp:138] Iteration 42100, lr = 0.000125
I1016 17:17:41.359242   329 solver.cpp:243] Iteration 42200, loss = 2950.16
I1016 17:17:41.359290   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.39754 (* 1 = 8.39754 loss)
I1016 17:17:41.359297   329 solver.cpp:259]     Train net output #1: seg_loss = 3278.01 (* 1 = 3278.01 loss)
I1016 17:17:41.359303   329 sgd_solver.cpp:138] Iteration 42200, lr = 0.000125
I1016 17:18:41.242728   329 solver.cpp:243] Iteration 42300, loss = 3533.15
I1016 17:18:41.242776   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.45526 (* 1 = 7.45526 loss)
I1016 17:18:41.242782   329 solver.cpp:259]     Train net output #1: seg_loss = 3507.06 (* 1 = 3507.06 loss)
I1016 17:18:41.242787   329 sgd_solver.cpp:138] Iteration 42300, lr = 0.000125
I1016 17:19:41.669067   329 solver.cpp:243] Iteration 42400, loss = 3023.72
I1016 17:19:41.669101   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.99743 (* 1 = 5.99743 loss)
I1016 17:19:41.669107   329 solver.cpp:259]     Train net output #1: seg_loss = 1855.65 (* 1 = 1855.65 loss)
I1016 17:19:41.669113   329 sgd_solver.cpp:138] Iteration 42400, lr = 0.000125
I1016 17:20:42.180605   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_42500.caffemodel
I1016 17:20:42.428853   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_42500.solverstate
I1016 17:20:43.009641   329 solver.cpp:243] Iteration 42500, loss = 4588.17
I1016 17:20:43.009685   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.83441 (* 1 = 9.83441 loss)
I1016 17:20:43.009691   329 solver.cpp:259]     Train net output #1: seg_loss = 3626.26 (* 1 = 3626.26 loss)
I1016 17:20:43.009697   329 sgd_solver.cpp:138] Iteration 42500, lr = 0.000125
I1016 17:21:44.107290   329 solver.cpp:243] Iteration 42600, loss = 2652.02
I1016 17:21:44.107323   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.6789 (* 1 = 10.6789 loss)
I1016 17:21:44.107329   329 solver.cpp:259]     Train net output #1: seg_loss = 3327.37 (* 1 = 3327.37 loss)
I1016 17:21:44.107336   329 sgd_solver.cpp:138] Iteration 42600, lr = 0.000125
I1016 17:22:21.164494   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:22:45.511764   329 solver.cpp:243] Iteration 42700, loss = 3077.57
I1016 17:22:45.511795   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.52024 (* 1 = 4.52024 loss)
I1016 17:22:45.511801   329 solver.cpp:259]     Train net output #1: seg_loss = 4651.2 (* 1 = 4651.2 loss)
I1016 17:22:45.511807   329 sgd_solver.cpp:138] Iteration 42700, lr = 0.000125
I1016 17:23:45.920275   329 solver.cpp:243] Iteration 42800, loss = 3273.62
I1016 17:23:45.920307   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.79458 (* 1 = 7.79458 loss)
I1016 17:23:45.920315   329 solver.cpp:259]     Train net output #1: seg_loss = 3029.25 (* 1 = 3029.25 loss)
I1016 17:23:45.920320   329 sgd_solver.cpp:138] Iteration 42800, lr = 0.000125
I1016 17:24:45.955327   329 solver.cpp:243] Iteration 42900, loss = 3070.8
I1016 17:24:45.955359   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.61637 (* 1 = 6.61637 loss)
I1016 17:24:45.955365   329 solver.cpp:259]     Train net output #1: seg_loss = 3244.66 (* 1 = 3244.66 loss)
I1016 17:24:45.955371   329 sgd_solver.cpp:138] Iteration 42900, lr = 0.000125
I1016 17:25:45.175043   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_43000.caffemodel
I1016 17:25:45.420913   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_43000.solverstate
I1016 17:25:46.027696   329 solver.cpp:243] Iteration 43000, loss = 3947.03
I1016 17:25:46.027729   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.21983 (* 1 = 4.21983 loss)
I1016 17:25:46.027735   329 solver.cpp:259]     Train net output #1: seg_loss = 4651.22 (* 1 = 4651.22 loss)
I1016 17:25:46.027742   329 sgd_solver.cpp:138] Iteration 43000, lr = 0.000125
I1016 17:26:47.054970   329 solver.cpp:243] Iteration 43100, loss = 2742.39
I1016 17:26:47.055003   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.13255 (* 1 = 7.13255 loss)
I1016 17:26:47.055009   329 solver.cpp:259]     Train net output #1: seg_loss = 2478.63 (* 1 = 2478.63 loss)
I1016 17:26:47.055016   329 sgd_solver.cpp:138] Iteration 43100, lr = 0.000125
I1016 17:27:48.616783   329 solver.cpp:243] Iteration 43200, loss = 3186.21
I1016 17:27:48.616816   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.77801 (* 1 = 6.77801 loss)
I1016 17:27:48.616822   329 solver.cpp:259]     Train net output #1: seg_loss = 3394.12 (* 1 = 3394.12 loss)
I1016 17:27:48.616828   329 sgd_solver.cpp:138] Iteration 43200, lr = 0.000125
I1016 17:28:50.659808   329 solver.cpp:243] Iteration 43300, loss = 2568.84
I1016 17:28:50.659842   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.34536 (* 1 = 4.34536 loss)
I1016 17:28:50.659848   329 solver.cpp:259]     Train net output #1: seg_loss = 2271.7 (* 1 = 2271.7 loss)
I1016 17:28:50.659854   329 sgd_solver.cpp:138] Iteration 43300, lr = 0.000125
I1016 17:29:52.401165   329 solver.cpp:243] Iteration 43400, loss = 2760.59
I1016 17:29:52.401195   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.52688 (* 1 = 5.52688 loss)
I1016 17:29:52.401201   329 solver.cpp:259]     Train net output #1: seg_loss = 3735.68 (* 1 = 3735.68 loss)
I1016 17:29:52.401207   329 sgd_solver.cpp:138] Iteration 43400, lr = 0.000125
I1016 17:30:51.689198   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_43500.caffemodel
I1016 17:30:51.913233   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_43500.solverstate
I1016 17:30:52.482501   329 solver.cpp:243] Iteration 43500, loss = 2451.06
I1016 17:30:52.482532   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.75828 (* 1 = 4.75828 loss)
I1016 17:30:52.482538   329 solver.cpp:259]     Train net output #1: seg_loss = 2184.62 (* 1 = 2184.62 loss)
I1016 17:30:52.482545   329 sgd_solver.cpp:138] Iteration 43500, lr = 0.000125
I1016 17:31:52.994436   329 solver.cpp:243] Iteration 43600, loss = 3271.5
I1016 17:31:52.994468   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.50773 (* 1 = 6.50773 loss)
I1016 17:31:52.994474   329 solver.cpp:259]     Train net output #1: seg_loss = 3450.74 (* 1 = 3450.74 loss)
I1016 17:31:52.994480   329 sgd_solver.cpp:138] Iteration 43600, lr = 0.000125
I1016 17:32:32.680449   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:32:54.919656   329 solver.cpp:243] Iteration 43700, loss = 2875.88
I1016 17:32:54.919690   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.42203 (* 1 = 7.42203 loss)
I1016 17:32:54.919697   329 solver.cpp:259]     Train net output #1: seg_loss = 2752.65 (* 1 = 2752.65 loss)
I1016 17:32:54.919701   329 sgd_solver.cpp:138] Iteration 43700, lr = 0.000125
I1016 17:33:56.224264   329 solver.cpp:243] Iteration 43800, loss = 2495.39
I1016 17:33:56.224314   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.78104 (* 1 = 3.78104 loss)
I1016 17:33:56.224320   329 solver.cpp:259]     Train net output #1: seg_loss = 2235.22 (* 1 = 2235.22 loss)
I1016 17:33:56.224326   329 sgd_solver.cpp:138] Iteration 43800, lr = 0.000125
I1016 17:34:54.873266   329 solver.cpp:243] Iteration 43900, loss = 2703.69
I1016 17:34:54.873317   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.48572 (* 1 = 6.48572 loss)
I1016 17:34:54.873322   329 solver.cpp:259]     Train net output #1: seg_loss = 2701.52 (* 1 = 2701.52 loss)
I1016 17:34:54.873328   329 sgd_solver.cpp:138] Iteration 43900, lr = 0.000125
I1016 17:35:53.099664   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_44000.caffemodel
I1016 17:35:53.856320   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_44000.solverstate
I1016 17:35:54.052178   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 17:37:31.127609   329 solver.cpp:243] Iteration 44000, loss = 6664.76
I1016 17:37:31.127645   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.48057 (* 1 = 5.48057 loss)
I1016 17:37:31.127650   329 solver.cpp:259]     Train net output #1: seg_loss = 6659.28 (* 1 = 6659.28 loss)
I1016 17:37:31.127656   329 sgd_solver.cpp:138] Iteration 44000, lr = 0.000125
I1016 17:38:28.327752   329 solver.cpp:243] Iteration 44100, loss = 3199.49
I1016 17:38:28.327801   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.77675 (* 1 = 8.77675 loss)
I1016 17:38:28.327807   329 solver.cpp:259]     Train net output #1: seg_loss = 2091.07 (* 1 = 2091.07 loss)
I1016 17:38:28.327813   329 sgd_solver.cpp:138] Iteration 44100, lr = 0.000125
I1016 17:39:12.680714   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:39:27.231969   329 solver.cpp:243] Iteration 44200, loss = 2788.56
I1016 17:39:27.232018   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.81797 (* 1 = 3.81797 loss)
I1016 17:39:27.232024   329 solver.cpp:259]     Train net output #1: seg_loss = 3316.6 (* 1 = 3316.6 loss)
I1016 17:39:27.232030   329 sgd_solver.cpp:138] Iteration 44200, lr = 0.000125
I1016 17:40:26.664283   329 solver.cpp:243] Iteration 44300, loss = 3742.08
I1016 17:40:26.664332   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.54796 (* 1 = 5.54796 loss)
I1016 17:40:26.664338   329 solver.cpp:259]     Train net output #1: seg_loss = 4619.15 (* 1 = 4619.15 loss)
I1016 17:40:26.664345   329 sgd_solver.cpp:138] Iteration 44300, lr = 0.000125
I1016 17:41:25.999400   329 solver.cpp:243] Iteration 44400, loss = 2561.47
I1016 17:41:25.999450   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.83668 (* 1 = 4.83668 loss)
I1016 17:41:25.999456   329 solver.cpp:259]     Train net output #1: seg_loss = 2381.99 (* 1 = 2381.99 loss)
I1016 17:41:25.999462   329 sgd_solver.cpp:138] Iteration 44400, lr = 0.000125
I1016 17:42:24.089769   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_44500.caffemodel
I1016 17:42:24.891080   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_44500.solverstate
I1016 17:42:25.447022   329 solver.cpp:243] Iteration 44500, loss = 2588.04
I1016 17:42:25.447068   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.24391 (* 1 = 7.24391 loss)
I1016 17:42:25.447074   329 solver.cpp:259]     Train net output #1: seg_loss = 2165.07 (* 1 = 2165.07 loss)
I1016 17:42:25.447080   329 sgd_solver.cpp:138] Iteration 44500, lr = 0.000125
I1016 17:43:22.327220   329 solver.cpp:243] Iteration 44600, loss = 2817.89
I1016 17:43:22.327271   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.81538 (* 1 = 6.81538 loss)
I1016 17:43:22.327277   329 solver.cpp:259]     Train net output #1: seg_loss = 2706.08 (* 1 = 2706.08 loss)
I1016 17:43:22.327282   329 sgd_solver.cpp:138] Iteration 44600, lr = 0.000125
I1016 17:44:21.986776   329 solver.cpp:243] Iteration 44700, loss = 2757.72
I1016 17:44:21.986824   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.40173 (* 1 = 5.40173 loss)
I1016 17:44:21.986829   329 solver.cpp:259]     Train net output #1: seg_loss = 2382.24 (* 1 = 2382.24 loss)
I1016 17:44:21.986835   329 sgd_solver.cpp:138] Iteration 44700, lr = 0.000125
I1016 17:45:21.022049   329 solver.cpp:243] Iteration 44800, loss = 2463.63
I1016 17:45:21.022083   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.47162 (* 1 = 6.47162 loss)
I1016 17:45:21.022089   329 solver.cpp:259]     Train net output #1: seg_loss = 1078.76 (* 1 = 1078.76 loss)
I1016 17:45:21.022095   329 sgd_solver.cpp:138] Iteration 44800, lr = 0.000125
I1016 17:46:20.776933   329 solver.cpp:243] Iteration 44900, loss = 2559.68
I1016 17:46:20.776983   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.32854 (* 1 = 4.32854 loss)
I1016 17:46:20.776989   329 solver.cpp:259]     Train net output #1: seg_loss = 1824.68 (* 1 = 1824.68 loss)
I1016 17:46:20.776996   329 sgd_solver.cpp:138] Iteration 44900, lr = 0.000125
I1016 17:47:18.893579   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_45000.caffemodel
I1016 17:47:19.108078   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_45000.solverstate
I1016 17:47:19.668362   329 solver.cpp:243] Iteration 45000, loss = 3032.74
I1016 17:47:19.668411   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.53748 (* 1 = 7.53748 loss)
I1016 17:47:19.668418   329 solver.cpp:259]     Train net output #1: seg_loss = 4179.59 (* 1 = 4179.59 loss)
I1016 17:47:19.668424   329 sgd_solver.cpp:138] Iteration 45000, lr = 0.000125
I1016 17:48:17.902484   329 solver.cpp:243] Iteration 45100, loss = 2925.05
I1016 17:48:17.902534   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.35131 (* 1 = 8.35131 loss)
I1016 17:48:17.902541   329 solver.cpp:259]     Train net output #1: seg_loss = 2498.8 (* 1 = 2498.8 loss)
I1016 17:48:17.902546   329 sgd_solver.cpp:138] Iteration 45100, lr = 0.000125
I1016 17:49:05.778250   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:49:16.444672   329 solver.cpp:243] Iteration 45200, loss = 4807.75
I1016 17:49:16.444721   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.55422 (* 1 = 7.55422 loss)
I1016 17:49:16.444727   329 solver.cpp:259]     Train net output #1: seg_loss = 3432.4 (* 1 = 3432.4 loss)
I1016 17:49:16.444733   329 sgd_solver.cpp:138] Iteration 45200, lr = 0.000125
I1016 17:50:15.343147   329 solver.cpp:243] Iteration 45300, loss = 2809.99
I1016 17:50:15.343183   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.8646 (* 1 = 10.8646 loss)
I1016 17:50:15.343189   329 solver.cpp:259]     Train net output #1: seg_loss = 1932.91 (* 1 = 1932.91 loss)
I1016 17:50:15.343194   329 sgd_solver.cpp:138] Iteration 45300, lr = 0.000125
I1016 17:51:14.910297   329 solver.cpp:243] Iteration 45400, loss = 3188.72
I1016 17:51:14.910347   329 solver.cpp:259]     Train net output #0: mbox_loss = 2.6965 (* 1 = 2.6965 loss)
I1016 17:51:14.910354   329 solver.cpp:259]     Train net output #1: seg_loss = 2741.27 (* 1 = 2741.27 loss)
I1016 17:51:14.910359   329 sgd_solver.cpp:138] Iteration 45400, lr = 0.000125
I1016 17:52:13.720021   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_45500.caffemodel
I1016 17:52:13.942806   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_45500.solverstate
I1016 17:52:14.517966   329 solver.cpp:243] Iteration 45500, loss = 3870.91
I1016 17:52:14.517998   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.1065 (* 1 = 8.1065 loss)
I1016 17:52:14.518004   329 solver.cpp:259]     Train net output #1: seg_loss = 4023.04 (* 1 = 4023.04 loss)
I1016 17:52:14.518009   329 sgd_solver.cpp:138] Iteration 45500, lr = 0.000125
I1016 17:53:12.819770   329 solver.cpp:243] Iteration 45600, loss = 2574.9
I1016 17:53:12.819819   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.62531 (* 1 = 5.62531 loss)
I1016 17:53:12.819825   329 solver.cpp:259]     Train net output #1: seg_loss = 2774.99 (* 1 = 2774.99 loss)
I1016 17:53:12.819833   329 sgd_solver.cpp:138] Iteration 45600, lr = 0.000125
I1016 17:54:10.791522   329 solver.cpp:243] Iteration 45700, loss = 3167.63
I1016 17:54:10.791570   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.49404 (* 1 = 5.49404 loss)
I1016 17:54:10.791577   329 solver.cpp:259]     Train net output #1: seg_loss = 3501.73 (* 1 = 3501.73 loss)
I1016 17:54:10.791584   329 sgd_solver.cpp:138] Iteration 45700, lr = 0.000125
I1016 17:55:09.960110   329 solver.cpp:243] Iteration 45800, loss = 2661.98
I1016 17:55:09.960160   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.99406 (* 1 = 4.99406 loss)
I1016 17:55:09.960165   329 solver.cpp:259]     Train net output #1: seg_loss = 2604.37 (* 1 = 2604.37 loss)
I1016 17:55:09.960171   329 sgd_solver.cpp:138] Iteration 45800, lr = 0.000125
I1016 17:56:09.223940   329 solver.cpp:243] Iteration 45900, loss = 3029.72
I1016 17:56:09.223990   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.1889 (* 1 = 6.1889 loss)
I1016 17:56:09.223997   329 solver.cpp:259]     Train net output #1: seg_loss = 2809.63 (* 1 = 2809.63 loss)
I1016 17:56:09.224004   329 sgd_solver.cpp:138] Iteration 45900, lr = 0.000125
I1016 17:57:08.336777   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_46000.caffemodel
I1016 17:57:08.564364   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_46000.solverstate
I1016 17:57:09.120112   329 solver.cpp:243] Iteration 46000, loss = 2998.26
I1016 17:57:09.120159   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.47575 (* 1 = 3.47575 loss)
I1016 17:57:09.120165   329 solver.cpp:259]     Train net output #1: seg_loss = 2986.23 (* 1 = 2986.23 loss)
I1016 17:57:09.120170   329 sgd_solver.cpp:138] Iteration 46000, lr = 0.000125
I1016 17:58:07.507843   329 solver.cpp:243] Iteration 46100, loss = 3195.34
I1016 17:58:07.507892   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.71285 (* 1 = 8.71285 loss)
I1016 17:58:07.507899   329 solver.cpp:259]     Train net output #1: seg_loss = 2505.16 (* 1 = 2505.16 loss)
I1016 17:58:07.507905   329 sgd_solver.cpp:138] Iteration 46100, lr = 0.000125
I1016 17:58:57.735271   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 17:59:05.568429   329 solver.cpp:243] Iteration 46200, loss = 2639.15
I1016 17:59:05.568480   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.10847 (* 1 = 7.10847 loss)
I1016 17:59:05.568485   329 solver.cpp:259]     Train net output #1: seg_loss = 2095.84 (* 1 = 2095.84 loss)
I1016 17:59:05.568491   329 sgd_solver.cpp:138] Iteration 46200, lr = 0.000125
I1016 18:00:04.583951   329 solver.cpp:243] Iteration 46300, loss = 2812.64
I1016 18:00:04.584002   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.79298 (* 1 = 7.79298 loss)
I1016 18:00:04.584007   329 solver.cpp:259]     Train net output #1: seg_loss = 2382.33 (* 1 = 2382.33 loss)
I1016 18:00:04.584013   329 sgd_solver.cpp:138] Iteration 46300, lr = 0.000125
I1016 18:01:03.288779   329 solver.cpp:243] Iteration 46400, loss = 2444.42
I1016 18:01:03.288828   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.74894 (* 1 = 8.74894 loss)
I1016 18:01:03.288835   329 solver.cpp:259]     Train net output #1: seg_loss = 2293.79 (* 1 = 2293.79 loss)
I1016 18:01:03.288841   329 sgd_solver.cpp:138] Iteration 46400, lr = 0.000125
I1016 18:02:02.371510   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_46500.caffemodel
I1016 18:02:02.607540   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_46500.solverstate
I1016 18:02:03.157083   329 solver.cpp:243] Iteration 46500, loss = 3852.41
I1016 18:02:03.157119   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.59307 (* 1 = 6.59307 loss)
I1016 18:02:03.157129   329 solver.cpp:259]     Train net output #1: seg_loss = 2496.72 (* 1 = 2496.72 loss)
I1016 18:02:03.157146   329 sgd_solver.cpp:138] Iteration 46500, lr = 0.000125
I1016 18:03:02.057344   329 solver.cpp:243] Iteration 46600, loss = 2757.09
I1016 18:03:02.057380   329 solver.cpp:259]     Train net output #0: mbox_loss = 12.4849 (* 1 = 12.4849 loss)
I1016 18:03:02.057389   329 solver.cpp:259]     Train net output #1: seg_loss = 2433.27 (* 1 = 2433.27 loss)
I1016 18:03:02.057397   329 sgd_solver.cpp:138] Iteration 46600, lr = 0.000125
I1016 18:04:00.659932   329 solver.cpp:243] Iteration 46700, loss = 2614.97
I1016 18:04:00.659970   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.65716 (* 1 = 6.65716 loss)
I1016 18:04:00.659979   329 solver.cpp:259]     Train net output #1: seg_loss = 2514.15 (* 1 = 2514.15 loss)
I1016 18:04:00.660002   329 sgd_solver.cpp:138] Iteration 46700, lr = 0.000125
I1016 18:04:58.716974   329 solver.cpp:243] Iteration 46800, loss = 3326.37
I1016 18:04:58.717011   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.52389 (* 1 = 7.52389 loss)
I1016 18:04:58.717020   329 solver.cpp:259]     Train net output #1: seg_loss = 2705.31 (* 1 = 2705.31 loss)
I1016 18:04:58.717042   329 sgd_solver.cpp:138] Iteration 46800, lr = 0.000125
I1016 18:05:57.785151   329 solver.cpp:243] Iteration 46900, loss = 2374.51
I1016 18:05:57.785188   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.30015 (* 1 = 6.30015 loss)
I1016 18:05:57.785197   329 solver.cpp:259]     Train net output #1: seg_loss = 2419.11 (* 1 = 2419.11 loss)
I1016 18:05:57.785219   329 sgd_solver.cpp:138] Iteration 46900, lr = 0.000125
I1016 18:06:56.687219   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_47000.caffemodel
I1016 18:06:56.904397   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_47000.solverstate
I1016 18:06:57.472386   329 solver.cpp:243] Iteration 47000, loss = 2916.89
I1016 18:06:57.472436   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.4101 (* 1 = 7.4101 loss)
I1016 18:06:57.472442   329 solver.cpp:259]     Train net output #1: seg_loss = 2426.49 (* 1 = 2426.49 loss)
I1016 18:06:57.472447   329 sgd_solver.cpp:138] Iteration 47000, lr = 0.000125
I1016 18:07:56.849725   329 solver.cpp:243] Iteration 47100, loss = 2495.33
I1016 18:07:56.849772   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.14597 (* 1 = 6.14597 loss)
I1016 18:07:56.849778   329 solver.cpp:259]     Train net output #1: seg_loss = 3219.05 (* 1 = 3219.05 loss)
I1016 18:07:56.849784   329 sgd_solver.cpp:138] Iteration 47100, lr = 0.000125
I1016 18:08:49.666838   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:08:55.470360   329 solver.cpp:243] Iteration 47200, loss = 3096.84
I1016 18:08:55.470408   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.7762 (* 1 = 3.7762 loss)
I1016 18:08:55.470414   329 solver.cpp:259]     Train net output #1: seg_loss = 2503.44 (* 1 = 2503.44 loss)
I1016 18:08:55.470420   329 sgd_solver.cpp:138] Iteration 47200, lr = 0.000125
I1016 18:09:53.241374   329 solver.cpp:243] Iteration 47300, loss = 2596.57
I1016 18:09:53.241423   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.22172 (* 1 = 6.22172 loss)
I1016 18:09:53.241430   329 solver.cpp:259]     Train net output #1: seg_loss = 3153.41 (* 1 = 3153.41 loss)
I1016 18:09:53.241436   329 sgd_solver.cpp:138] Iteration 47300, lr = 0.000125
I1016 18:10:52.526944   329 solver.cpp:243] Iteration 47400, loss = 2841.21
I1016 18:10:52.526983   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.6589 (* 1 = 10.6589 loss)
I1016 18:10:52.526988   329 solver.cpp:259]     Train net output #1: seg_loss = 3423.91 (* 1 = 3423.91 loss)
I1016 18:10:52.526994   329 sgd_solver.cpp:138] Iteration 47400, lr = 0.000125
I1016 18:11:50.885108   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_47500.caffemodel
I1016 18:11:51.690414   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_47500.solverstate
I1016 18:11:52.252246   329 solver.cpp:243] Iteration 47500, loss = 3244.55
I1016 18:11:52.252293   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.41825 (* 1 = 9.41825 loss)
I1016 18:11:52.252300   329 solver.cpp:259]     Train net output #1: seg_loss = 2488.36 (* 1 = 2488.36 loss)
I1016 18:11:52.252305   329 sgd_solver.cpp:138] Iteration 47500, lr = 0.000125
I1016 18:12:51.181882   329 solver.cpp:243] Iteration 47600, loss = 2392.91
I1016 18:12:51.181916   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.06595 (* 1 = 4.06595 loss)
I1016 18:12:51.181922   329 solver.cpp:259]     Train net output #1: seg_loss = 2155.82 (* 1 = 2155.82 loss)
I1016 18:12:51.181928   329 sgd_solver.cpp:138] Iteration 47600, lr = 0.000125
I1016 18:13:49.941594   329 solver.cpp:243] Iteration 47700, loss = 2721.59
I1016 18:13:49.941644   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.27939 (* 1 = 4.27939 loss)
I1016 18:13:49.941651   329 solver.cpp:259]     Train net output #1: seg_loss = 2447.06 (* 1 = 2447.06 loss)
I1016 18:13:49.941658   329 sgd_solver.cpp:138] Iteration 47700, lr = 0.000125
I1016 18:14:48.553758   329 solver.cpp:243] Iteration 47800, loss = 3333.35
I1016 18:14:48.553807   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.44581 (* 1 = 4.44581 loss)
I1016 18:14:48.553812   329 solver.cpp:259]     Train net output #1: seg_loss = 2428.31 (* 1 = 2428.31 loss)
I1016 18:14:48.553818   329 sgd_solver.cpp:138] Iteration 47800, lr = 0.000125
I1016 18:15:46.903944   329 solver.cpp:243] Iteration 47900, loss = 3839.84
I1016 18:15:46.903993   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.84474 (* 1 = 9.84474 loss)
I1016 18:15:46.904000   329 solver.cpp:259]     Train net output #1: seg_loss = 6728.78 (* 1 = 6728.78 loss)
I1016 18:15:46.904006   329 sgd_solver.cpp:138] Iteration 47900, lr = 0.000125
I1016 18:16:45.305296   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_48000.caffemodel
I1016 18:16:45.531051   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_48000.solverstate
I1016 18:16:45.711230   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 18:17:23.961138   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:18:22.677701   329 solver.cpp:243] Iteration 48000, loss = 2789.42
I1016 18:18:22.677736   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.42556 (* 1 = 7.42556 loss)
I1016 18:18:22.677742   329 solver.cpp:259]     Train net output #1: seg_loss = 2781.99 (* 1 = 2781.99 loss)
I1016 18:18:22.677747   329 sgd_solver.cpp:138] Iteration 48000, lr = 0.000125
I1016 18:19:20.983850   329 solver.cpp:243] Iteration 48100, loss = 3602.92
I1016 18:19:20.983899   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.32212 (* 1 = 5.32212 loss)
I1016 18:19:20.983906   329 solver.cpp:259]     Train net output #1: seg_loss = 3086.44 (* 1 = 3086.44 loss)
I1016 18:19:20.983911   329 sgd_solver.cpp:138] Iteration 48100, lr = 0.000125
I1016 18:20:20.366561   329 solver.cpp:243] Iteration 48200, loss = 3103.94
I1016 18:20:20.366611   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.21427 (* 1 = 6.21427 loss)
I1016 18:20:20.366616   329 solver.cpp:259]     Train net output #1: seg_loss = 2248.18 (* 1 = 2248.18 loss)
I1016 18:20:20.366622   329 sgd_solver.cpp:138] Iteration 48200, lr = 0.000125
I1016 18:21:18.836163   329 solver.cpp:243] Iteration 48300, loss = 2341.17
I1016 18:21:18.836211   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.14249 (* 1 = 4.14249 loss)
I1016 18:21:18.836217   329 solver.cpp:259]     Train net output #1: seg_loss = 2407.74 (* 1 = 2407.74 loss)
I1016 18:21:18.836222   329 sgd_solver.cpp:138] Iteration 48300, lr = 0.000125
I1016 18:22:16.648943   329 solver.cpp:243] Iteration 48400, loss = 3096.6
I1016 18:22:16.648995   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.13084 (* 1 = 8.13084 loss)
I1016 18:22:16.649001   329 solver.cpp:259]     Train net output #1: seg_loss = 2589.99 (* 1 = 2589.99 loss)
I1016 18:22:16.649008   329 sgd_solver.cpp:138] Iteration 48400, lr = 0.000125
I1016 18:23:15.406450   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_48500.caffemodel
I1016 18:23:16.213004   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_48500.solverstate
I1016 18:23:16.761445   329 solver.cpp:243] Iteration 48500, loss = 2495.17
I1016 18:23:16.761490   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.56589 (* 1 = 5.56589 loss)
I1016 18:23:16.761497   329 solver.cpp:259]     Train net output #1: seg_loss = 2802.5 (* 1 = 2802.5 loss)
I1016 18:23:16.761503   329 sgd_solver.cpp:138] Iteration 48500, lr = 0.000125
I1016 18:24:15.052387   329 solver.cpp:243] Iteration 48600, loss = 2251.44
I1016 18:24:15.052438   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.1642 (* 1 = 10.1642 loss)
I1016 18:24:15.052444   329 solver.cpp:259]     Train net output #1: seg_loss = 3035.8 (* 1 = 3035.8 loss)
I1016 18:24:15.052450   329 sgd_solver.cpp:138] Iteration 48600, lr = 0.000125
I1016 18:25:14.720247   329 solver.cpp:243] Iteration 48700, loss = 2675.45
I1016 18:25:14.720296   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.43015 (* 1 = 4.43015 loss)
I1016 18:25:14.720302   329 solver.cpp:259]     Train net output #1: seg_loss = 2415.94 (* 1 = 2415.94 loss)
I1016 18:25:14.720309   329 sgd_solver.cpp:138] Iteration 48700, lr = 0.000125
I1016 18:25:20.581615   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:26:13.201750   329 solver.cpp:243] Iteration 48800, loss = 3292.19
I1016 18:26:13.201799   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.20213 (* 1 = 6.20213 loss)
I1016 18:26:13.201807   329 solver.cpp:259]     Train net output #1: seg_loss = 4018.08 (* 1 = 4018.08 loss)
I1016 18:26:13.201812   329 sgd_solver.cpp:138] Iteration 48800, lr = 0.000125
I1016 18:27:11.598655   329 solver.cpp:243] Iteration 48900, loss = 2977.29
I1016 18:27:11.598693   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.18903 (* 1 = 7.18903 loss)
I1016 18:27:11.598702   329 solver.cpp:259]     Train net output #1: seg_loss = 3186.79 (* 1 = 3186.79 loss)
I1016 18:27:11.598726   329 sgd_solver.cpp:138] Iteration 48900, lr = 0.000125
I1016 18:28:09.931627   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_49000.caffemodel
I1016 18:28:10.163169   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_49000.solverstate
I1016 18:28:10.739972   329 solver.cpp:243] Iteration 49000, loss = 4159.48
I1016 18:28:10.740005   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.0624 (* 1 = 11.0624 loss)
I1016 18:28:10.740011   329 solver.cpp:259]     Train net output #1: seg_loss = 2208.92 (* 1 = 2208.92 loss)
I1016 18:28:10.740017   329 sgd_solver.cpp:138] Iteration 49000, lr = 0.000125
I1016 18:29:09.360332   329 solver.cpp:243] Iteration 49100, loss = 2400.46
I1016 18:29:09.360380   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.91242 (* 1 = 6.91242 loss)
I1016 18:29:09.360386   329 solver.cpp:259]     Train net output #1: seg_loss = 2051.56 (* 1 = 2051.56 loss)
I1016 18:29:09.360393   329 sgd_solver.cpp:138] Iteration 49100, lr = 0.000125
I1016 18:30:08.738620   329 solver.cpp:243] Iteration 49200, loss = 2865.54
I1016 18:30:08.738665   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.91557 (* 1 = 4.91557 loss)
I1016 18:30:08.738672   329 solver.cpp:259]     Train net output #1: seg_loss = 2416.03 (* 1 = 2416.03 loss)
I1016 18:30:08.738677   329 sgd_solver.cpp:138] Iteration 49200, lr = 0.000125
I1016 18:31:08.055244   329 solver.cpp:243] Iteration 49300, loss = 2951.92
I1016 18:31:08.055290   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.33391 (* 1 = 6.33391 loss)
I1016 18:31:08.055296   329 solver.cpp:259]     Train net output #1: seg_loss = 2050.29 (* 1 = 2050.29 loss)
I1016 18:31:08.055303   329 sgd_solver.cpp:138] Iteration 49300, lr = 0.000125
I1016 18:32:06.575584   329 solver.cpp:243] Iteration 49400, loss = 2838.15
I1016 18:32:06.575634   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.0845 (* 1 = 9.0845 loss)
I1016 18:32:06.575639   329 solver.cpp:259]     Train net output #1: seg_loss = 2652.39 (* 1 = 2652.39 loss)
I1016 18:32:06.575644   329 sgd_solver.cpp:138] Iteration 49400, lr = 0.000125
I1016 18:33:03.966462   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_49500.caffemodel
I1016 18:33:04.184757   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_49500.solverstate
I1016 18:33:04.748692   329 solver.cpp:243] Iteration 49500, loss = 3640.84
I1016 18:33:04.748740   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.66628 (* 1 = 4.66628 loss)
I1016 18:33:04.748746   329 solver.cpp:259]     Train net output #1: seg_loss = 2881.41 (* 1 = 2881.41 loss)
I1016 18:33:04.748752   329 sgd_solver.cpp:138] Iteration 49500, lr = 0.000125
I1016 18:34:03.732276   329 solver.cpp:243] Iteration 49600, loss = 2701.27
I1016 18:34:03.732324   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.74897 (* 1 = 6.74897 loss)
I1016 18:34:03.732331   329 solver.cpp:259]     Train net output #1: seg_loss = 2654.89 (* 1 = 2654.89 loss)
I1016 18:34:03.732336   329 sgd_solver.cpp:138] Iteration 49600, lr = 0.000125
I1016 18:35:02.960501   329 solver.cpp:243] Iteration 49700, loss = 2986.5
I1016 18:35:02.960535   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.71831 (* 1 = 4.71831 loss)
I1016 18:35:02.960541   329 solver.cpp:259]     Train net output #1: seg_loss = 2189.41 (* 1 = 2189.41 loss)
I1016 18:35:02.960546   329 sgd_solver.cpp:138] Iteration 49700, lr = 0.000125
I1016 18:35:11.414258   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:36:02.640280   329 solver.cpp:243] Iteration 49800, loss = 2475.93
I1016 18:36:02.640313   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.71417 (* 1 = 7.71417 loss)
I1016 18:36:02.640319   329 solver.cpp:259]     Train net output #1: seg_loss = 1806.58 (* 1 = 1806.58 loss)
I1016 18:36:02.640326   329 sgd_solver.cpp:138] Iteration 49800, lr = 0.000125
I1016 18:37:01.253244   329 solver.cpp:243] Iteration 49900, loss = 2460.81
I1016 18:37:01.253296   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.71501 (* 1 = 7.71501 loss)
I1016 18:37:01.253302   329 solver.cpp:259]     Train net output #1: seg_loss = 3079.38 (* 1 = 3079.38 loss)
I1016 18:37:01.253307   329 sgd_solver.cpp:138] Iteration 49900, lr = 0.000125
I1016 18:38:00.046774   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_50000.caffemodel
I1016 18:38:00.280143   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_50000.solverstate
I1016 18:38:00.862849   329 solver.cpp:243] Iteration 50000, loss = 2417.78
I1016 18:38:00.862881   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.28391 (* 1 = 5.28391 loss)
I1016 18:38:00.862888   329 solver.cpp:259]     Train net output #1: seg_loss = 1520.3 (* 1 = 1520.3 loss)
I1016 18:38:00.862895   329 sgd_solver.cpp:138] Iteration 50000, lr = 0.000125
I1016 18:39:03.175763   329 solver.cpp:243] Iteration 50100, loss = 3145.42
I1016 18:39:03.175796   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.42837 (* 1 = 9.42837 loss)
I1016 18:39:03.175801   329 solver.cpp:259]     Train net output #1: seg_loss = 2108.66 (* 1 = 2108.66 loss)
I1016 18:39:03.175807   329 sgd_solver.cpp:138] Iteration 50100, lr = 0.000125
I1016 18:40:05.352764   329 solver.cpp:243] Iteration 50200, loss = 2681.57
I1016 18:40:05.352797   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.67111 (* 1 = 6.67111 loss)
I1016 18:40:05.352803   329 solver.cpp:259]     Train net output #1: seg_loss = 3492.69 (* 1 = 3492.69 loss)
I1016 18:40:05.352810   329 sgd_solver.cpp:138] Iteration 50200, lr = 0.000125
I1016 18:41:07.846405   329 solver.cpp:243] Iteration 50300, loss = 2450.3
I1016 18:41:07.846454   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.03672 (* 1 = 8.03672 loss)
I1016 18:41:07.846460   329 solver.cpp:259]     Train net output #1: seg_loss = 2685.03 (* 1 = 2685.03 loss)
I1016 18:41:07.846467   329 sgd_solver.cpp:138] Iteration 50300, lr = 0.000125
I1016 18:42:08.144373   329 solver.cpp:243] Iteration 50400, loss = 2819.11
I1016 18:42:08.144407   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.30939 (* 1 = 5.30939 loss)
I1016 18:42:08.144412   329 solver.cpp:259]     Train net output #1: seg_loss = 2477.83 (* 1 = 2477.83 loss)
I1016 18:42:08.144418   329 sgd_solver.cpp:138] Iteration 50400, lr = 0.000125
I1016 18:43:07.490341   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_50500.caffemodel
I1016 18:43:08.317787   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_50500.solverstate
I1016 18:43:08.888008   329 solver.cpp:243] Iteration 50500, loss = 3151.22
I1016 18:43:08.888056   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.12494 (* 1 = 6.12494 loss)
I1016 18:43:08.888062   329 solver.cpp:259]     Train net output #1: seg_loss = 2301.9 (* 1 = 2301.9 loss)
I1016 18:43:08.888069   329 sgd_solver.cpp:138] Iteration 50500, lr = 0.000125
I1016 18:44:06.698920   329 solver.cpp:243] Iteration 50600, loss = 3194.91
I1016 18:44:06.698969   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.75101 (* 1 = 6.75101 loss)
I1016 18:44:06.698976   329 solver.cpp:259]     Train net output #1: seg_loss = 4281.49 (* 1 = 4281.49 loss)
I1016 18:44:06.698982   329 sgd_solver.cpp:138] Iteration 50600, lr = 0.000125
I1016 18:45:07.529397   329 solver.cpp:243] Iteration 50700, loss = 2563.37
I1016 18:45:07.529429   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.42407 (* 1 = 8.42407 loss)
I1016 18:45:07.529434   329 solver.cpp:259]     Train net output #1: seg_loss = 2232.87 (* 1 = 2232.87 loss)
I1016 18:45:07.529440   329 sgd_solver.cpp:138] Iteration 50700, lr = 0.000125
I1016 18:45:21.087785   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:46:07.890741   329 solver.cpp:243] Iteration 50800, loss = 3364.94
I1016 18:46:07.890789   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.50061 (* 1 = 7.50061 loss)
I1016 18:46:07.890796   329 solver.cpp:259]     Train net output #1: seg_loss = 6502.79 (* 1 = 6502.79 loss)
I1016 18:46:07.890801   329 sgd_solver.cpp:138] Iteration 50800, lr = 0.000125
I1016 18:47:07.753573   329 solver.cpp:243] Iteration 50900, loss = 2490.36
I1016 18:47:07.753605   329 solver.cpp:259]     Train net output #0: mbox_loss = 2.99422 (* 1 = 2.99422 loss)
I1016 18:47:07.753614   329 solver.cpp:259]     Train net output #1: seg_loss = 2503.59 (* 1 = 2503.59 loss)
I1016 18:47:07.753638   329 sgd_solver.cpp:138] Iteration 50900, lr = 0.000125
I1016 18:48:06.176187   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_51000.caffemodel
I1016 18:48:06.938280   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_51000.solverstate
I1016 18:48:07.495296   329 solver.cpp:243] Iteration 51000, loss = 2480.25
I1016 18:48:07.495343   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.44574 (* 1 = 7.44574 loss)
I1016 18:48:07.495350   329 solver.cpp:259]     Train net output #1: seg_loss = 2756.85 (* 1 = 2756.85 loss)
I1016 18:48:07.495355   329 sgd_solver.cpp:138] Iteration 51000, lr = 0.000125
I1016 18:49:04.850240   329 solver.cpp:243] Iteration 51100, loss = 2765.9
I1016 18:49:04.850287   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.39302 (* 1 = 5.39302 loss)
I1016 18:49:04.850293   329 solver.cpp:259]     Train net output #1: seg_loss = 2592.25 (* 1 = 2592.25 loss)
I1016 18:49:04.850299   329 sgd_solver.cpp:138] Iteration 51100, lr = 0.000125
I1016 18:50:05.662523   329 solver.cpp:243] Iteration 51200, loss = 2640.15
I1016 18:50:05.662569   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.51723 (* 1 = 3.51723 loss)
I1016 18:50:05.662575   329 solver.cpp:259]     Train net output #1: seg_loss = 2178.83 (* 1 = 2178.83 loss)
I1016 18:50:05.662580   329 sgd_solver.cpp:138] Iteration 51200, lr = 0.000125
I1016 18:51:05.867171   329 solver.cpp:243] Iteration 51300, loss = 2787.6
I1016 18:51:05.867219   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.32796 (* 1 = 5.32796 loss)
I1016 18:51:05.867226   329 solver.cpp:259]     Train net output #1: seg_loss = 1925.93 (* 1 = 1925.93 loss)
I1016 18:51:05.867231   329 sgd_solver.cpp:138] Iteration 51300, lr = 0.000125
I1016 18:52:07.135876   329 solver.cpp:243] Iteration 51400, loss = 2465.79
I1016 18:52:07.135910   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.48748 (* 1 = 5.48748 loss)
I1016 18:52:07.135915   329 solver.cpp:259]     Train net output #1: seg_loss = 2429.92 (* 1 = 2429.92 loss)
I1016 18:52:07.135921   329 sgd_solver.cpp:138] Iteration 51400, lr = 0.000125
I1016 18:53:06.024984   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_51500.caffemodel
I1016 18:53:06.251536   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_51500.solverstate
I1016 18:53:06.815021   329 solver.cpp:243] Iteration 51500, loss = 2804.02
I1016 18:53:06.815054   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.21217 (* 1 = 6.21217 loss)
I1016 18:53:06.815063   329 solver.cpp:259]     Train net output #1: seg_loss = 2420.88 (* 1 = 2420.88 loss)
I1016 18:53:06.815071   329 sgd_solver.cpp:138] Iteration 51500, lr = 0.000125
I1016 18:54:06.108922   329 solver.cpp:243] Iteration 51600, loss = 2971.8
I1016 18:54:06.108955   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.07602 (* 1 = 8.07602 loss)
I1016 18:54:06.108964   329 solver.cpp:259]     Train net output #1: seg_loss = 2372.6 (* 1 = 2372.6 loss)
I1016 18:54:06.108973   329 sgd_solver.cpp:138] Iteration 51600, lr = 0.000125
I1016 18:55:05.740036   329 solver.cpp:243] Iteration 51700, loss = 4678.6
I1016 18:55:05.740077   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.6112 (* 1 = 11.6112 loss)
I1016 18:55:05.740084   329 solver.cpp:259]     Train net output #1: seg_loss = 3535.29 (* 1 = 3535.29 loss)
I1016 18:55:05.740089   329 sgd_solver.cpp:138] Iteration 51700, lr = 0.000125
I1016 18:55:23.098985   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 18:56:05.751379   329 solver.cpp:243] Iteration 51800, loss = 2679.93
I1016 18:56:05.751426   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.25501 (* 1 = 8.25501 loss)
I1016 18:56:05.751432   329 solver.cpp:259]     Train net output #1: seg_loss = 2374.8 (* 1 = 2374.8 loss)
I1016 18:56:05.751438   329 sgd_solver.cpp:138] Iteration 51800, lr = 0.000125
I1016 18:57:07.572512   329 solver.cpp:243] Iteration 51900, loss = 3050.08
I1016 18:57:07.572561   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.5612 (* 1 = 4.5612 loss)
I1016 18:57:07.572566   329 solver.cpp:259]     Train net output #1: seg_loss = 3586.43 (* 1 = 3586.43 loss)
I1016 18:57:07.572572   329 sgd_solver.cpp:138] Iteration 51900, lr = 0.000125
I1016 18:58:08.170312   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_52000.caffemodel
I1016 18:58:08.426647   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_52000.solverstate
I1016 18:58:08.660061   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 18:59:47.587980   329 solver.cpp:243] Iteration 52000, loss = 3738.26
I1016 18:59:47.588016   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.78955 (* 1 = 5.78955 loss)
I1016 18:59:47.588023   329 solver.cpp:259]     Train net output #1: seg_loss = 3732.47 (* 1 = 3732.47 loss)
I1016 18:59:47.588029   329 sgd_solver.cpp:138] Iteration 52000, lr = 0.000125
I1016 19:00:45.798048   329 solver.cpp:243] Iteration 52100, loss = 2395.89
I1016 19:00:45.798080   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.69777 (* 1 = 6.69777 loss)
I1016 19:00:45.798086   329 solver.cpp:259]     Train net output #1: seg_loss = 2303.05 (* 1 = 2303.05 loss)
I1016 19:00:45.798091   329 sgd_solver.cpp:138] Iteration 52100, lr = 0.000125
I1016 19:01:44.763422   329 solver.cpp:243] Iteration 52200, loss = 3044.68
I1016 19:01:44.763470   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.34679 (* 1 = 7.34679 loss)
I1016 19:01:44.763476   329 solver.cpp:259]     Train net output #1: seg_loss = 2488.93 (* 1 = 2488.93 loss)
I1016 19:01:44.763483   329 sgd_solver.cpp:138] Iteration 52200, lr = 0.000125
I1016 19:02:08.238965   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:02:44.332358   329 solver.cpp:243] Iteration 52300, loss = 2591.94
I1016 19:02:44.332407   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.29702 (* 1 = 6.29702 loss)
I1016 19:02:44.332413   329 solver.cpp:259]     Train net output #1: seg_loss = 2895.96 (* 1 = 2895.96 loss)
I1016 19:02:44.332418   329 sgd_solver.cpp:138] Iteration 52300, lr = 0.000125
I1016 19:03:45.378126   329 solver.cpp:243] Iteration 52400, loss = 2979.99
I1016 19:03:45.378160   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.56536 (* 1 = 6.56536 loss)
I1016 19:03:45.378166   329 solver.cpp:259]     Train net output #1: seg_loss = 2818.83 (* 1 = 2818.83 loss)
I1016 19:03:45.378172   329 sgd_solver.cpp:138] Iteration 52400, lr = 0.000125
I1016 19:04:45.553411   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_52500.caffemodel
I1016 19:04:45.833750   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_52500.solverstate
I1016 19:04:46.442207   329 solver.cpp:243] Iteration 52500, loss = 2782.66
I1016 19:04:46.442240   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.35416 (* 1 = 5.35416 loss)
I1016 19:04:46.442246   329 solver.cpp:259]     Train net output #1: seg_loss = 2516.95 (* 1 = 2516.95 loss)
I1016 19:04:46.442252   329 sgd_solver.cpp:138] Iteration 52500, lr = 0.000125
I1016 19:05:45.677124   329 solver.cpp:243] Iteration 52600, loss = 3237.19
I1016 19:05:45.677168   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.52447 (* 1 = 5.52447 loss)
I1016 19:05:45.677181   329 solver.cpp:259]     Train net output #1: seg_loss = 2136.82 (* 1 = 2136.82 loss)
I1016 19:05:45.677191   329 sgd_solver.cpp:138] Iteration 52600, lr = 0.000125
I1016 19:06:45.160385   329 solver.cpp:243] Iteration 52700, loss = 2807.77
I1016 19:06:45.160419   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14204 (* 1 = 7.14204 loss)
I1016 19:06:45.160425   329 solver.cpp:259]     Train net output #1: seg_loss = 2521.93 (* 1 = 2521.93 loss)
I1016 19:06:45.160430   329 sgd_solver.cpp:138] Iteration 52700, lr = 0.000125
I1016 19:07:45.483526   329 solver.cpp:243] Iteration 52800, loss = 2802.68
I1016 19:07:45.483561   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.3531 (* 1 = 8.3531 loss)
I1016 19:07:45.483567   329 solver.cpp:259]     Train net output #1: seg_loss = 2800.67 (* 1 = 2800.67 loss)
I1016 19:07:45.483573   329 sgd_solver.cpp:138] Iteration 52800, lr = 0.000125
I1016 19:08:45.058360   329 solver.cpp:243] Iteration 52900, loss = 2367.59
I1016 19:08:45.058408   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.41385 (* 1 = 4.41385 loss)
I1016 19:08:45.058414   329 solver.cpp:259]     Train net output #1: seg_loss = 2565.07 (* 1 = 2565.07 loss)
I1016 19:08:45.058420   329 sgd_solver.cpp:138] Iteration 52900, lr = 0.000125
I1016 19:09:44.629886   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_53000.caffemodel
I1016 19:09:44.854306   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_53000.solverstate
I1016 19:09:45.423904   329 solver.cpp:243] Iteration 53000, loss = 3710.11
I1016 19:09:45.423950   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.38657 (* 1 = 8.38657 loss)
I1016 19:09:45.423956   329 solver.cpp:259]     Train net output #1: seg_loss = 2897.53 (* 1 = 2897.53 loss)
I1016 19:09:45.423962   329 sgd_solver.cpp:138] Iteration 53000, lr = 0.000125
I1016 19:10:44.918599   329 solver.cpp:243] Iteration 53100, loss = 2633.26
I1016 19:10:44.918648   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.65492 (* 1 = 5.65492 loss)
I1016 19:10:44.918653   329 solver.cpp:259]     Train net output #1: seg_loss = 4918.26 (* 1 = 4918.26 loss)
I1016 19:10:44.918660   329 sgd_solver.cpp:138] Iteration 53100, lr = 0.000125
I1016 19:11:43.958820   329 solver.cpp:243] Iteration 53200, loss = 2575.56
I1016 19:11:43.958868   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.03438 (* 1 = 6.03438 loss)
I1016 19:11:43.958873   329 solver.cpp:259]     Train net output #1: seg_loss = 1920.2 (* 1 = 1920.2 loss)
I1016 19:11:43.958879   329 sgd_solver.cpp:138] Iteration 53200, lr = 0.000125
I1016 19:12:08.901636   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:12:42.386361   329 solver.cpp:243] Iteration 53300, loss = 3236.58
I1016 19:12:42.386410   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.02527 (* 1 = 6.02527 loss)
I1016 19:12:42.386416   329 solver.cpp:259]     Train net output #1: seg_loss = 2987.45 (* 1 = 2987.45 loss)
I1016 19:12:42.386422   329 sgd_solver.cpp:138] Iteration 53300, lr = 0.000125
I1016 19:13:41.899477   329 solver.cpp:243] Iteration 53400, loss = 2263.56
I1016 19:13:41.899524   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.48848 (* 1 = 6.48848 loss)
I1016 19:13:41.899531   329 solver.cpp:259]     Train net output #1: seg_loss = 2372.84 (* 1 = 2372.84 loss)
I1016 19:13:41.899536   329 sgd_solver.cpp:138] Iteration 53400, lr = 0.000125
I1016 19:14:41.154654   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_53500.caffemodel
I1016 19:14:41.424410   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_53500.solverstate
I1016 19:14:41.979411   329 solver.cpp:243] Iteration 53500, loss = 2750.05
I1016 19:14:41.979441   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.37589 (* 1 = 7.37589 loss)
I1016 19:14:41.979447   329 solver.cpp:259]     Train net output #1: seg_loss = 2767.89 (* 1 = 2767.89 loss)
I1016 19:14:41.979452   329 sgd_solver.cpp:138] Iteration 53500, lr = 0.000125
I1016 19:15:41.618985   329 solver.cpp:243] Iteration 53600, loss = 2335.21
I1016 19:15:41.619033   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.01878 (* 1 = 5.01878 loss)
I1016 19:15:41.619040   329 solver.cpp:259]     Train net output #1: seg_loss = 2388.71 (* 1 = 2388.71 loss)
I1016 19:15:41.619045   329 sgd_solver.cpp:138] Iteration 53600, lr = 0.000125
I1016 19:16:40.645592   329 solver.cpp:243] Iteration 53700, loss = 2954.38
I1016 19:16:40.645640   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.929 (* 1 = 6.929 loss)
I1016 19:16:40.645647   329 solver.cpp:259]     Train net output #1: seg_loss = 2140.67 (* 1 = 2140.67 loss)
I1016 19:16:40.645653   329 sgd_solver.cpp:138] Iteration 53700, lr = 0.000125
I1016 19:17:38.780107   329 solver.cpp:243] Iteration 53800, loss = 2405.69
I1016 19:17:38.780155   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.1926 (* 1 = 6.1926 loss)
I1016 19:17:38.780161   329 solver.cpp:259]     Train net output #1: seg_loss = 2524.99 (* 1 = 2524.99 loss)
I1016 19:17:38.780166   329 sgd_solver.cpp:138] Iteration 53800, lr = 0.000125
I1016 19:18:38.459077   329 solver.cpp:243] Iteration 53900, loss = 2719.14
I1016 19:18:38.459125   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.50172 (* 1 = 6.50172 loss)
I1016 19:18:38.459131   329 solver.cpp:259]     Train net output #1: seg_loss = 1948.05 (* 1 = 1948.05 loss)
I1016 19:18:38.459137   329 sgd_solver.cpp:138] Iteration 53900, lr = 0.000125
I1016 19:19:37.212492   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_54000.caffemodel
I1016 19:19:37.435261   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_54000.solverstate
I1016 19:19:38.573976   329 solver.cpp:243] Iteration 54000, loss = 3453.41
I1016 19:19:38.574010   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.51317 (* 1 = 6.51317 loss)
I1016 19:19:38.574018   329 solver.cpp:259]     Train net output #1: seg_loss = 5821.88 (* 1 = 5821.88 loss)
I1016 19:19:38.574024   329 sgd_solver.cpp:138] Iteration 54000, lr = 0.000125
I1016 19:20:37.854986   329 solver.cpp:243] Iteration 54100, loss = 2314.91
I1016 19:20:37.855020   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.71263 (* 1 = 4.71263 loss)
I1016 19:20:37.855028   329 solver.cpp:259]     Train net output #1: seg_loss = 1883.19 (* 1 = 1883.19 loss)
I1016 19:20:37.855052   329 sgd_solver.cpp:138] Iteration 54100, lr = 0.000125
I1016 19:21:37.050514   329 solver.cpp:243] Iteration 54200, loss = 2570.12
I1016 19:21:37.050547   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.299 (* 1 = 5.299 loss)
I1016 19:21:37.050556   329 solver.cpp:259]     Train net output #1: seg_loss = 3052.52 (* 1 = 3052.52 loss)
I1016 19:21:37.050580   329 sgd_solver.cpp:138] Iteration 54200, lr = 0.000125
I1016 19:22:06.834702   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:22:36.141710   329 solver.cpp:243] Iteration 54300, loss = 3185.76
I1016 19:22:36.141744   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.92719 (* 1 = 3.92719 loss)
I1016 19:22:36.141753   329 solver.cpp:259]     Train net output #1: seg_loss = 2834.07 (* 1 = 2834.07 loss)
I1016 19:22:36.141762   329 sgd_solver.cpp:138] Iteration 54300, lr = 0.000125
I1016 19:23:34.844211   329 solver.cpp:243] Iteration 54400, loss = 3291.68
I1016 19:23:34.844246   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.01999 (* 1 = 9.01999 loss)
I1016 19:23:34.844269   329 solver.cpp:259]     Train net output #1: seg_loss = 4683.87 (* 1 = 4683.87 loss)
I1016 19:23:34.844277   329 sgd_solver.cpp:138] Iteration 54400, lr = 0.000125
I1016 19:24:33.979728   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_54500.caffemodel
I1016 19:24:34.798414   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_54500.solverstate
I1016 19:24:35.360685   329 solver.cpp:243] Iteration 54500, loss = 2210.6
I1016 19:24:35.360731   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.49263 (* 1 = 5.49263 loss)
I1016 19:24:35.360738   329 solver.cpp:259]     Train net output #1: seg_loss = 2577.24 (* 1 = 2577.24 loss)
I1016 19:24:35.360743   329 sgd_solver.cpp:138] Iteration 54500, lr = 0.000125
I1016 19:25:34.606459   329 solver.cpp:243] Iteration 54600, loss = 3493.75
I1016 19:25:34.606506   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.34162 (* 1 = 5.34162 loss)
I1016 19:25:34.606513   329 solver.cpp:259]     Train net output #1: seg_loss = 3292.27 (* 1 = 3292.27 loss)
I1016 19:25:34.606518   329 sgd_solver.cpp:138] Iteration 54600, lr = 0.000125
I1016 19:26:34.418298   329 solver.cpp:243] Iteration 54700, loss = 2928.71
I1016 19:26:34.418344   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.00524 (* 1 = 5.00524 loss)
I1016 19:26:34.418350   329 solver.cpp:259]     Train net output #1: seg_loss = 4219.11 (* 1 = 4219.11 loss)
I1016 19:26:34.418356   329 sgd_solver.cpp:138] Iteration 54700, lr = 0.000125
I1016 19:27:33.512390   329 solver.cpp:243] Iteration 54800, loss = 2231.77
I1016 19:27:33.512437   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.66281 (* 1 = 6.66281 loss)
I1016 19:27:33.512444   329 solver.cpp:259]     Train net output #1: seg_loss = 1869.96 (* 1 = 1869.96 loss)
I1016 19:27:33.512449   329 sgd_solver.cpp:138] Iteration 54800, lr = 0.000125
I1016 19:28:31.708104   329 solver.cpp:243] Iteration 54900, loss = 3022.05
I1016 19:28:31.708153   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.28162 (* 1 = 7.28162 loss)
I1016 19:28:31.708158   329 solver.cpp:259]     Train net output #1: seg_loss = 2086.86 (* 1 = 2086.86 loss)
I1016 19:28:31.708164   329 sgd_solver.cpp:138] Iteration 54900, lr = 0.000125
I1016 19:29:30.998855   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_55000.caffemodel
I1016 19:29:31.234719   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_55000.solverstate
I1016 19:29:31.796294   329 solver.cpp:243] Iteration 55000, loss = 2276.13
I1016 19:29:31.796341   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.31435 (* 1 = 7.31435 loss)
I1016 19:29:31.796347   329 solver.cpp:259]     Train net output #1: seg_loss = 3118.96 (* 1 = 3118.96 loss)
I1016 19:29:31.796352   329 sgd_solver.cpp:138] Iteration 55000, lr = 0.000125
I1016 19:30:31.084873   329 solver.cpp:243] Iteration 55100, loss = 2111.13
I1016 19:30:31.084923   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.53497 (* 1 = 4.53497 loss)
I1016 19:30:31.084928   329 solver.cpp:259]     Train net output #1: seg_loss = 3077.5 (* 1 = 3077.5 loss)
I1016 19:30:31.084934   329 sgd_solver.cpp:138] Iteration 55100, lr = 0.000125
I1016 19:31:31.261211   329 solver.cpp:243] Iteration 55200, loss = 2811.92
I1016 19:31:31.261258   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.65569 (* 1 = 6.65569 loss)
I1016 19:31:31.261265   329 solver.cpp:259]     Train net output #1: seg_loss = 1461.49 (* 1 = 1461.49 loss)
I1016 19:31:31.261270   329 sgd_solver.cpp:138] Iteration 55200, lr = 0.000125
I1016 19:32:05.076429   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:32:30.225467   329 solver.cpp:243] Iteration 55300, loss = 2962.1
I1016 19:32:30.225515   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.22954 (* 1 = 7.22954 loss)
I1016 19:32:30.225520   329 solver.cpp:259]     Train net output #1: seg_loss = 2721.02 (* 1 = 2721.02 loss)
I1016 19:32:30.225527   329 sgd_solver.cpp:138] Iteration 55300, lr = 0.000125
I1016 19:33:28.876304   329 solver.cpp:243] Iteration 55400, loss = 2829.58
I1016 19:33:28.876336   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.43872 (* 1 = 7.43872 loss)
I1016 19:33:28.876343   329 solver.cpp:259]     Train net output #1: seg_loss = 3696.48 (* 1 = 3696.48 loss)
I1016 19:33:28.876348   329 sgd_solver.cpp:138] Iteration 55400, lr = 0.000125
I1016 19:34:27.540310   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_55500.caffemodel
I1016 19:34:27.782245   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_55500.solverstate
I1016 19:34:28.371496   329 solver.cpp:243] Iteration 55500, loss = 3978.17
I1016 19:34:28.371528   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.70845 (* 1 = 9.70845 loss)
I1016 19:34:28.371534   329 solver.cpp:259]     Train net output #1: seg_loss = 2848.01 (* 1 = 2848.01 loss)
I1016 19:34:28.371541   329 sgd_solver.cpp:138] Iteration 55500, lr = 0.000125
I1016 19:35:27.501585   329 solver.cpp:243] Iteration 55600, loss = 2419.2
I1016 19:35:27.501632   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.98599 (* 1 = 7.98599 loss)
I1016 19:35:27.501639   329 solver.cpp:259]     Train net output #1: seg_loss = 2532.05 (* 1 = 2532.05 loss)
I1016 19:35:27.501646   329 sgd_solver.cpp:138] Iteration 55600, lr = 0.000125
I1016 19:36:27.465394   329 solver.cpp:243] Iteration 55700, loss = 2743.26
I1016 19:36:27.465440   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.93894 (* 1 = 3.93894 loss)
I1016 19:36:27.465446   329 solver.cpp:259]     Train net output #1: seg_loss = 2780.59 (* 1 = 2780.59 loss)
I1016 19:36:27.465453   329 sgd_solver.cpp:138] Iteration 55700, lr = 0.000125
I1016 19:37:27.368407   329 solver.cpp:243] Iteration 55800, loss = 3050.59
I1016 19:37:27.368455   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.33311 (* 1 = 6.33311 loss)
I1016 19:37:27.368463   329 solver.cpp:259]     Train net output #1: seg_loss = 2565.74 (* 1 = 2565.74 loss)
I1016 19:37:27.368468   329 sgd_solver.cpp:138] Iteration 55800, lr = 0.000125
I1016 19:38:26.334429   329 solver.cpp:243] Iteration 55900, loss = 2850.9
I1016 19:38:26.334461   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.4624 (* 1 = 7.4624 loss)
I1016 19:38:26.334467   329 solver.cpp:259]     Train net output #1: seg_loss = 2748.49 (* 1 = 2748.49 loss)
I1016 19:38:26.334473   329 sgd_solver.cpp:138] Iteration 55900, lr = 0.000125
I1016 19:39:24.294524   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_56000.caffemodel
I1016 19:39:24.519132   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_56000.solverstate
I1016 19:39:24.716361   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 19:40:15.595947   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:41:02.340065   329 solver.cpp:243] Iteration 56000, loss = 3068.34
I1016 19:41:02.340102   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.6535 (* 1 = 10.6535 loss)
I1016 19:41:02.340109   329 solver.cpp:259]     Train net output #1: seg_loss = 3057.69 (* 1 = 3057.69 loss)
I1016 19:41:02.340116   329 sgd_solver.cpp:138] Iteration 56000, lr = 0.000125
I1016 19:42:01.084126   329 solver.cpp:243] Iteration 56100, loss = 2580.04
I1016 19:42:01.084173   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.80341 (* 1 = 4.80341 loss)
I1016 19:42:01.084179   329 solver.cpp:259]     Train net output #1: seg_loss = 2188.93 (* 1 = 2188.93 loss)
I1016 19:42:01.084185   329 sgd_solver.cpp:138] Iteration 56100, lr = 0.000125
I1016 19:43:00.918252   329 solver.cpp:243] Iteration 56200, loss = 2915.52
I1016 19:43:00.918299   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.46696 (* 1 = 7.46696 loss)
I1016 19:43:00.918306   329 solver.cpp:259]     Train net output #1: seg_loss = 2740.12 (* 1 = 2740.12 loss)
I1016 19:43:00.918313   329 sgd_solver.cpp:138] Iteration 56200, lr = 0.000125
I1016 19:44:01.163741   329 solver.cpp:243] Iteration 56300, loss = 2504.45
I1016 19:44:01.163787   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.69953 (* 1 = 5.69953 loss)
I1016 19:44:01.163794   329 solver.cpp:259]     Train net output #1: seg_loss = 2696.77 (* 1 = 2696.77 loss)
I1016 19:44:01.163800   329 sgd_solver.cpp:138] Iteration 56300, lr = 0.000125
I1016 19:45:00.530144   329 solver.cpp:243] Iteration 56400, loss = 2289.52
I1016 19:45:00.530175   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67409 (* 1 = 7.67409 loss)
I1016 19:45:00.530181   329 solver.cpp:259]     Train net output #1: seg_loss = 2669.13 (* 1 = 2669.13 loss)
I1016 19:45:00.530187   329 sgd_solver.cpp:138] Iteration 56400, lr = 0.000125
I1016 19:45:58.528292   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_56500.caffemodel
I1016 19:45:58.770464   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_56500.solverstate
I1016 19:45:59.342972   329 solver.cpp:243] Iteration 56500, loss = 2432.95
I1016 19:45:59.343014   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.44447 (* 1 = 6.44447 loss)
I1016 19:45:59.343020   329 solver.cpp:259]     Train net output #1: seg_loss = 2081.77 (* 1 = 2081.77 loss)
I1016 19:45:59.343026   329 sgd_solver.cpp:138] Iteration 56500, lr = 0.000125
I1016 19:46:58.997073   329 solver.cpp:243] Iteration 56600, loss = 3129.44
I1016 19:46:58.997103   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.27365 (* 1 = 5.27365 loss)
I1016 19:46:58.997109   329 solver.cpp:259]     Train net output #1: seg_loss = 3079.74 (* 1 = 3079.74 loss)
I1016 19:46:58.997115   329 sgd_solver.cpp:138] Iteration 56600, lr = 0.000125
I1016 19:47:58.860927   329 solver.cpp:243] Iteration 56700, loss = 2461.09
I1016 19:47:58.860961   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.09547 (* 1 = 7.09547 loss)
I1016 19:47:58.860970   329 solver.cpp:259]     Train net output #1: seg_loss = 3080.87 (* 1 = 3080.87 loss)
I1016 19:47:58.860992   329 sgd_solver.cpp:138] Iteration 56700, lr = 0.000125
I1016 19:48:41.287326   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:48:59.241809   329 solver.cpp:243] Iteration 56800, loss = 2637.66
I1016 19:48:59.241860   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.74615 (* 1 = 5.74615 loss)
I1016 19:48:59.241866   329 solver.cpp:259]     Train net output #1: seg_loss = 3080.5 (* 1 = 3080.5 loss)
I1016 19:48:59.241873   329 sgd_solver.cpp:138] Iteration 56800, lr = 0.000125
I1016 19:49:59.134927   329 solver.cpp:243] Iteration 56900, loss = 2653.36
I1016 19:49:59.134976   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.90459 (* 1 = 4.90459 loss)
I1016 19:49:59.134982   329 solver.cpp:259]     Train net output #1: seg_loss = 1806.42 (* 1 = 1806.42 loss)
I1016 19:49:59.134989   329 sgd_solver.cpp:138] Iteration 56900, lr = 0.000125
I1016 19:50:58.120808   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_57000.caffemodel
I1016 19:50:58.973079   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_57000.solverstate
I1016 19:50:59.546808   329 solver.cpp:243] Iteration 57000, loss = 2984.76
I1016 19:50:59.546851   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.26983 (* 1 = 7.26983 loss)
I1016 19:50:59.546857   329 solver.cpp:259]     Train net output #1: seg_loss = 2467.88 (* 1 = 2467.88 loss)
I1016 19:50:59.546862   329 sgd_solver.cpp:138] Iteration 57000, lr = 0.000125
I1016 19:52:01.157721   329 solver.cpp:243] Iteration 57100, loss = 2979.33
I1016 19:52:01.157771   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.6716 (* 1 = 11.6716 loss)
I1016 19:52:01.157778   329 solver.cpp:259]     Train net output #1: seg_loss = 5282.14 (* 1 = 5282.14 loss)
I1016 19:52:01.157783   329 sgd_solver.cpp:138] Iteration 57100, lr = 0.000125
I1016 19:53:02.065805   329 solver.cpp:243] Iteration 57200, loss = 2443.46
I1016 19:53:02.065847   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.87239 (* 1 = 4.87239 loss)
I1016 19:53:02.065855   329 solver.cpp:259]     Train net output #1: seg_loss = 2303.2 (* 1 = 2303.2 loss)
I1016 19:53:02.065861   329 sgd_solver.cpp:138] Iteration 57200, lr = 0.000125
I1016 19:54:04.979601   329 solver.cpp:243] Iteration 57300, loss = 2946.53
I1016 19:54:04.979634   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.42582 (* 1 = 4.42582 loss)
I1016 19:54:04.979640   329 solver.cpp:259]     Train net output #1: seg_loss = 2767.18 (* 1 = 2767.18 loss)
I1016 19:54:04.979645   329 sgd_solver.cpp:138] Iteration 57300, lr = 0.000125
I1016 19:55:08.094931   329 solver.cpp:243] Iteration 57400, loss = 2366.54
I1016 19:55:08.094965   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.47033 (* 1 = 3.47033 loss)
I1016 19:55:08.094974   329 solver.cpp:259]     Train net output #1: seg_loss = 2544.41 (* 1 = 2544.41 loss)
I1016 19:55:08.094982   329 sgd_solver.cpp:138] Iteration 57400, lr = 0.000125
I1016 19:56:09.415514   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_57500.caffemodel
I1016 19:56:09.716061   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_57500.solverstate
I1016 19:56:10.327373   329 solver.cpp:243] Iteration 57500, loss = 2328.77
I1016 19:56:10.327404   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.37825 (* 1 = 7.37825 loss)
I1016 19:56:10.327410   329 solver.cpp:259]     Train net output #1: seg_loss = 1998 (* 1 = 1998 loss)
I1016 19:56:10.327417   329 sgd_solver.cpp:138] Iteration 57500, lr = 0.000125
I1016 19:57:10.980993   329 solver.cpp:243] Iteration 57600, loss = 2593.1
I1016 19:57:10.981027   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.84441 (* 1 = 5.84441 loss)
I1016 19:57:10.981036   329 solver.cpp:259]     Train net output #1: seg_loss = 3703.61 (* 1 = 3703.61 loss)
I1016 19:57:10.981058   329 sgd_solver.cpp:138] Iteration 57600, lr = 0.000125
I1016 19:58:13.782049   329 solver.cpp:243] Iteration 57700, loss = 2514.56
I1016 19:58:13.782078   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.0303 (* 1 = 5.0303 loss)
I1016 19:58:13.782085   329 solver.cpp:259]     Train net output #1: seg_loss = 1719.21 (* 1 = 1719.21 loss)
I1016 19:58:13.782091   329 sgd_solver.cpp:138] Iteration 57700, lr = 0.000125
I1016 19:59:02.479303   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 19:59:16.345304   329 solver.cpp:243] Iteration 57800, loss = 2689.91
I1016 19:59:16.345337   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.28942 (* 1 = 4.28942 loss)
I1016 19:59:16.345343   329 solver.cpp:259]     Train net output #1: seg_loss = 2598.49 (* 1 = 2598.49 loss)
I1016 19:59:16.345350   329 sgd_solver.cpp:138] Iteration 57800, lr = 0.000125
I1016 20:00:19.563988   329 solver.cpp:243] Iteration 57900, loss = 2385.95
I1016 20:00:19.564020   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.22014 (* 1 = 4.22014 loss)
I1016 20:00:19.564028   329 solver.cpp:259]     Train net output #1: seg_loss = 3284.55 (* 1 = 3284.55 loss)
I1016 20:00:19.564033   329 sgd_solver.cpp:138] Iteration 57900, lr = 0.000125
I1016 20:01:20.946640   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_58000.caffemodel
I1016 20:01:21.197947   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_58000.solverstate
I1016 20:01:21.834987   329 solver.cpp:243] Iteration 58000, loss = 2921.4
I1016 20:01:21.835021   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.84109 (* 1 = 4.84109 loss)
I1016 20:01:21.835031   329 solver.cpp:259]     Train net output #1: seg_loss = 2252.2 (* 1 = 2252.2 loss)
I1016 20:01:21.835050   329 sgd_solver.cpp:138] Iteration 58000, lr = 0.000125
I1016 20:02:23.708412   329 solver.cpp:243] Iteration 58100, loss = 2874.04
I1016 20:02:23.708462   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.81475 (* 1 = 5.81475 loss)
I1016 20:02:23.708469   329 solver.cpp:259]     Train net output #1: seg_loss = 2692.32 (* 1 = 2692.32 loss)
I1016 20:02:23.708474   329 sgd_solver.cpp:138] Iteration 58100, lr = 0.000125
I1016 20:03:25.547706   329 solver.cpp:243] Iteration 58200, loss = 4533.15
I1016 20:03:25.547739   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.60132 (* 1 = 8.60132 loss)
I1016 20:03:25.547744   329 solver.cpp:259]     Train net output #1: seg_loss = 3271.22 (* 1 = 3271.22 loss)
I1016 20:03:25.547750   329 sgd_solver.cpp:138] Iteration 58200, lr = 0.000125
I1016 20:04:27.693548   329 solver.cpp:243] Iteration 58300, loss = 2677.24
I1016 20:04:27.693583   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.73943 (* 1 = 6.73943 loss)
I1016 20:04:27.693590   329 solver.cpp:259]     Train net output #1: seg_loss = 2848.43 (* 1 = 2848.43 loss)
I1016 20:04:27.693598   329 sgd_solver.cpp:138] Iteration 58300, lr = 0.000125
I1016 20:05:30.524718   329 solver.cpp:243] Iteration 58400, loss = 2872.87
I1016 20:05:30.524749   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.54551 (* 1 = 5.54551 loss)
I1016 20:05:30.524755   329 solver.cpp:259]     Train net output #1: seg_loss = 2452.95 (* 1 = 2452.95 loss)
I1016 20:05:30.524761   329 sgd_solver.cpp:138] Iteration 58400, lr = 0.000125
I1016 20:06:32.730351   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_58500.caffemodel
I1016 20:06:32.997447   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_58500.solverstate
I1016 20:06:33.596393   329 solver.cpp:243] Iteration 58500, loss = 3393.5
I1016 20:06:33.596424   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.33327 (* 1 = 7.33327 loss)
I1016 20:06:33.596431   329 solver.cpp:259]     Train net output #1: seg_loss = 4011.76 (* 1 = 4011.76 loss)
I1016 20:06:33.596437   329 sgd_solver.cpp:138] Iteration 58500, lr = 0.000125
I1016 20:07:35.799924   329 solver.cpp:243] Iteration 58600, loss = 2321.33
I1016 20:07:35.799960   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.67919 (* 1 = 8.67919 loss)
I1016 20:07:35.799968   329 solver.cpp:259]     Train net output #1: seg_loss = 3032.29 (* 1 = 3032.29 loss)
I1016 20:07:35.799973   329 sgd_solver.cpp:138] Iteration 58600, lr = 0.000125
I1016 20:08:37.779170   329 solver.cpp:243] Iteration 58700, loss = 3114.01
I1016 20:08:37.779208   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.0755 (* 1 = 11.0755 loss)
I1016 20:08:37.779218   329 solver.cpp:259]     Train net output #1: seg_loss = 2127.79 (* 1 = 2127.79 loss)
I1016 20:08:37.779227   329 sgd_solver.cpp:138] Iteration 58700, lr = 0.000125
I1016 20:10:21.232527   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 20:10:32.358222   329 solver.cpp:243] Iteration 58800, loss = 2500.21
I1016 20:10:32.358256   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.1167 (* 1 = 6.1167 loss)
I1016 20:10:32.358263   329 solver.cpp:259]     Train net output #1: seg_loss = 2737.76 (* 1 = 2737.76 loss)
I1016 20:10:32.358268   329 sgd_solver.cpp:138] Iteration 58800, lr = 0.000125
I1016 20:11:35.041981   329 solver.cpp:243] Iteration 58900, loss = 2809.37
I1016 20:11:35.042012   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.19976 (* 1 = 9.19976 loss)
I1016 20:11:35.042019   329 solver.cpp:259]     Train net output #1: seg_loss = 2301.05 (* 1 = 2301.05 loss)
I1016 20:11:35.042026   329 sgd_solver.cpp:138] Iteration 58900, lr = 0.000125
I1016 20:12:37.679757   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_59000.caffemodel
I1016 20:12:37.981966   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_59000.solverstate
I1016 20:12:38.618216   329 solver.cpp:243] Iteration 59000, loss = 2679.6
I1016 20:12:38.618247   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.54785 (* 1 = 6.54785 loss)
I1016 20:12:38.618253   329 solver.cpp:259]     Train net output #1: seg_loss = 2427.57 (* 1 = 2427.57 loss)
I1016 20:12:38.618259   329 sgd_solver.cpp:138] Iteration 59000, lr = 0.000125
I1016 20:13:40.213645   329 solver.cpp:243] Iteration 59100, loss = 3070.38
I1016 20:13:40.213675   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.44907 (* 1 = 6.44907 loss)
I1016 20:13:40.213681   329 solver.cpp:259]     Train net output #1: seg_loss = 1956.27 (* 1 = 1956.27 loss)
I1016 20:13:40.213687   329 sgd_solver.cpp:138] Iteration 59100, lr = 0.000125
I1016 20:14:41.552944   329 solver.cpp:243] Iteration 59200, loss = 2779.95
I1016 20:14:41.552976   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.26469 (* 1 = 5.26469 loss)
I1016 20:14:41.552983   329 solver.cpp:259]     Train net output #1: seg_loss = 2731.83 (* 1 = 2731.83 loss)
I1016 20:14:41.552989   329 sgd_solver.cpp:138] Iteration 59200, lr = 0.000125
I1016 20:15:43.919415   329 solver.cpp:243] Iteration 59300, loss = 2758.89
I1016 20:15:43.919451   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.57713 (* 1 = 7.57713 loss)
I1016 20:15:43.919457   329 solver.cpp:259]     Train net output #1: seg_loss = 2924.25 (* 1 = 2924.25 loss)
I1016 20:15:43.919463   329 sgd_solver.cpp:138] Iteration 59300, lr = 0.000125
I1016 20:16:45.964412   329 solver.cpp:243] Iteration 59400, loss = 2367.34
I1016 20:16:45.964447   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.94013 (* 1 = 5.94013 loss)
I1016 20:16:45.964453   329 solver.cpp:259]     Train net output #1: seg_loss = 2110.54 (* 1 = 2110.54 loss)
I1016 20:16:45.964459   329 sgd_solver.cpp:138] Iteration 59400, lr = 0.000125
I1016 20:17:48.302255   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_59500.caffemodel
I1016 20:17:48.599150   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_59500.solverstate
I1016 20:17:49.228013   329 solver.cpp:243] Iteration 59500, loss = 3510.33
I1016 20:17:49.228044   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.53369 (* 1 = 6.53369 loss)
I1016 20:17:49.228049   329 solver.cpp:259]     Train net output #1: seg_loss = 3499.78 (* 1 = 3499.78 loss)
I1016 20:17:49.228055   329 sgd_solver.cpp:138] Iteration 59500, lr = 0.000125
I1016 20:18:51.354107   329 solver.cpp:243] Iteration 59600, loss = 2397.38
I1016 20:18:51.354140   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.1329 (* 1 = 10.1329 loss)
I1016 20:18:51.354146   329 solver.cpp:259]     Train net output #1: seg_loss = 2293.93 (* 1 = 2293.93 loss)
I1016 20:18:51.354152   329 sgd_solver.cpp:138] Iteration 59600, lr = 0.000125
I1016 20:19:53.292069   329 solver.cpp:243] Iteration 59700, loss = 2576.92
I1016 20:19:53.292111   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.76807 (* 1 = 6.76807 loss)
I1016 20:19:53.292119   329 solver.cpp:259]     Train net output #1: seg_loss = 1987.09 (* 1 = 1987.09 loss)
I1016 20:19:53.292124   329 sgd_solver.cpp:138] Iteration 59700, lr = 0.000125
I1016 20:20:46.341629   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 20:20:54.411083   329 solver.cpp:243] Iteration 59800, loss = 3028.14
I1016 20:20:54.411119   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.13012 (* 1 = 6.13012 loss)
I1016 20:20:54.411128   329 solver.cpp:259]     Train net output #1: seg_loss = 2618.26 (* 1 = 2618.26 loss)
I1016 20:20:54.411136   329 sgd_solver.cpp:138] Iteration 59800, lr = 0.000125
I1016 20:21:56.918736   329 solver.cpp:243] Iteration 59900, loss = 2306.09
I1016 20:21:56.918783   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.2504 (* 1 = 5.2504 loss)
I1016 20:21:56.918789   329 solver.cpp:259]     Train net output #1: seg_loss = 1868.42 (* 1 = 1868.42 loss)
I1016 20:21:56.918795   329 sgd_solver.cpp:138] Iteration 59900, lr = 0.000125
I1016 20:22:58.967247   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_60000.caffemodel
I1016 20:22:59.241550   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_60000.solverstate
I1016 20:22:59.475214   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 20:24:42.376353   329 solver.cpp:243] Iteration 60000, loss = 2593.43
I1016 20:24:42.376384   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.28051 (* 1 = 8.28051 loss)
I1016 20:24:42.376390   329 solver.cpp:259]     Train net output #1: seg_loss = 2585.15 (* 1 = 2585.15 loss)
I1016 20:24:42.376395   329 sgd_solver.cpp:138] Iteration 60000, lr = 0.000125
I1016 20:25:44.035392   329 solver.cpp:243] Iteration 60100, loss = 2241.88
I1016 20:25:44.035430   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.61727 (* 1 = 4.61727 loss)
I1016 20:25:44.035436   329 solver.cpp:259]     Train net output #1: seg_loss = 2563.98 (* 1 = 2563.98 loss)
I1016 20:25:44.035442   329 sgd_solver.cpp:138] Iteration 60100, lr = 0.000125
I1016 20:26:45.871455   329 solver.cpp:243] Iteration 60200, loss = 2855.26
I1016 20:26:45.871490   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.28166 (* 1 = 7.28166 loss)
I1016 20:26:45.871497   329 solver.cpp:259]     Train net output #1: seg_loss = 2504.83 (* 1 = 2504.83 loss)
I1016 20:26:45.871502   329 sgd_solver.cpp:138] Iteration 60200, lr = 0.000125
I1016 20:27:45.247200   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 20:27:46.948966   329 solver.cpp:243] Iteration 60300, loss = 2297.74
I1016 20:27:46.948997   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.89063 (* 1 = 6.89063 loss)
I1016 20:27:46.949003   329 solver.cpp:259]     Train net output #1: seg_loss = 2718.19 (* 1 = 2718.19 loss)
I1016 20:27:46.949008   329 sgd_solver.cpp:138] Iteration 60300, lr = 0.000125
I1016 20:28:49.661432   329 solver.cpp:243] Iteration 60400, loss = 2864.98
I1016 20:28:49.661464   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.04954 (* 1 = 8.04954 loss)
I1016 20:28:49.661470   329 solver.cpp:259]     Train net output #1: seg_loss = 2337.23 (* 1 = 2337.23 loss)
I1016 20:28:49.661476   329 sgd_solver.cpp:138] Iteration 60400, lr = 0.000125
I1016 20:29:51.189621   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_60500.caffemodel
I1016 20:29:51.459852   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_60500.solverstate
I1016 20:29:52.046649   329 solver.cpp:243] Iteration 60500, loss = 2963.79
I1016 20:29:52.046682   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.99007 (* 1 = 6.99007 loss)
I1016 20:29:52.046689   329 solver.cpp:259]     Train net output #1: seg_loss = 2027.95 (* 1 = 2027.95 loss)
I1016 20:29:52.046694   329 sgd_solver.cpp:138] Iteration 60500, lr = 0.000125
I1016 20:30:54.847373   329 solver.cpp:243] Iteration 60600, loss = 2270.79
I1016 20:30:54.847407   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.87429 (* 1 = 3.87429 loss)
I1016 20:30:54.847415   329 solver.cpp:259]     Train net output #1: seg_loss = 2163.77 (* 1 = 2163.77 loss)
I1016 20:30:54.847440   329 sgd_solver.cpp:138] Iteration 60600, lr = 0.000125
I1016 20:31:56.902178   329 solver.cpp:243] Iteration 60700, loss = 2462.3
I1016 20:31:56.902209   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.07728 (* 1 = 8.07728 loss)
I1016 20:31:56.902215   329 solver.cpp:259]     Train net output #1: seg_loss = 4274.25 (* 1 = 4274.25 loss)
I1016 20:31:56.902221   329 sgd_solver.cpp:138] Iteration 60700, lr = 0.000125
I1016 20:32:58.945986   329 solver.cpp:243] Iteration 60800, loss = 3348.9
I1016 20:32:58.946022   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.87683 (* 1 = 4.87683 loss)
I1016 20:32:58.946029   329 solver.cpp:259]     Train net output #1: seg_loss = 2685.14 (* 1 = 2685.14 loss)
I1016 20:32:58.946035   329 sgd_solver.cpp:138] Iteration 60800, lr = 0.000125
I1016 20:34:00.460300   329 solver.cpp:243] Iteration 60900, loss = 3073.48
I1016 20:34:00.460331   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78533 (* 1 = 6.78533 loss)
I1016 20:34:00.460337   329 solver.cpp:259]     Train net output #1: seg_loss = 1936.68 (* 1 = 1936.68 loss)
I1016 20:34:00.460343   329 sgd_solver.cpp:138] Iteration 60900, lr = 0.000125
I1016 20:35:02.059844   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_61000.caffemodel
I1016 20:35:02.350304   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_61000.solverstate
I1016 20:35:02.932029   329 solver.cpp:243] Iteration 61000, loss = 2122.64
I1016 20:35:02.932061   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.91586 (* 1 = 4.91586 loss)
I1016 20:35:02.932067   329 solver.cpp:259]     Train net output #1: seg_loss = 2822.91 (* 1 = 2822.91 loss)
I1016 20:35:02.932073   329 sgd_solver.cpp:138] Iteration 61000, lr = 0.000125
I1016 20:36:05.485323   329 solver.cpp:243] Iteration 61100, loss = 3211.81
I1016 20:36:05.485357   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.88791 (* 1 = 6.88791 loss)
I1016 20:36:05.485366   329 solver.cpp:259]     Train net output #1: seg_loss = 2773.07 (* 1 = 2773.07 loss)
I1016 20:36:05.485389   329 sgd_solver.cpp:138] Iteration 61100, lr = 0.000125
I1016 20:37:08.081203   329 solver.cpp:243] Iteration 61200, loss = 2635.05
I1016 20:37:08.081241   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.99689 (* 1 = 5.99689 loss)
I1016 20:37:08.081248   329 solver.cpp:259]     Train net output #1: seg_loss = 2785.06 (* 1 = 2785.06 loss)
I1016 20:37:08.081254   329 sgd_solver.cpp:138] Iteration 61200, lr = 0.000125
I1016 20:38:09.894697   329 solver.cpp:243] Iteration 61300, loss = 2172.98
I1016 20:38:09.894728   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.45735 (* 1 = 4.45735 loss)
I1016 20:38:09.894734   329 solver.cpp:259]     Train net output #1: seg_loss = 2142.72 (* 1 = 2142.72 loss)
I1016 20:38:09.894742   329 sgd_solver.cpp:138] Iteration 61300, lr = 0.000125
I1016 20:38:10.556907   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 20:39:10.829789   329 solver.cpp:243] Iteration 61400, loss = 3015.8
I1016 20:39:10.829826   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.88559 (* 1 = 7.88559 loss)
I1016 20:39:10.829835   329 solver.cpp:259]     Train net output #1: seg_loss = 5154.5 (* 1 = 5154.5 loss)
I1016 20:39:10.829841   329 sgd_solver.cpp:138] Iteration 61400, lr = 0.000125
I1016 20:40:12.715564   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_61500.caffemodel
I1016 20:40:12.985651   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_61500.solverstate
I1016 20:40:13.554402   329 solver.cpp:243] Iteration 61500, loss = 2153.49
I1016 20:40:13.554436   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.08736 (* 1 = 6.08736 loss)
I1016 20:40:13.554445   329 solver.cpp:259]     Train net output #1: seg_loss = 2795.68 (* 1 = 2795.68 loss)
I1016 20:40:13.554453   329 sgd_solver.cpp:138] Iteration 61500, lr = 0.000125
I1016 20:41:15.601161   329 solver.cpp:243] Iteration 61600, loss = 1919.63
I1016 20:41:15.601192   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.18866 (* 1 = 3.18866 loss)
I1016 20:41:15.601198   329 solver.cpp:259]     Train net output #1: seg_loss = 2023.8 (* 1 = 2023.8 loss)
I1016 20:41:15.601204   329 sgd_solver.cpp:138] Iteration 61600, lr = 0.000125
I1016 20:42:18.689841   329 solver.cpp:243] Iteration 61700, loss = 2823.21
I1016 20:42:18.689873   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.38237 (* 1 = 6.38237 loss)
I1016 20:42:18.689879   329 solver.cpp:259]     Train net output #1: seg_loss = 2785.3 (* 1 = 2785.3 loss)
I1016 20:42:18.689885   329 sgd_solver.cpp:138] Iteration 61700, lr = 0.000125
I1016 20:43:20.761764   329 solver.cpp:243] Iteration 61800, loss = 2783.36
I1016 20:43:20.761811   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.68593 (* 1 = 6.68593 loss)
I1016 20:43:20.761818   329 solver.cpp:259]     Train net output #1: seg_loss = 2527.45 (* 1 = 2527.45 loss)
I1016 20:43:20.761827   329 sgd_solver.cpp:138] Iteration 61800, lr = 0.000125
I1016 20:44:22.282816   329 solver.cpp:243] Iteration 61900, loss = 2511.59
I1016 20:44:22.282848   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.42668 (* 1 = 6.42668 loss)
I1016 20:44:22.282855   329 solver.cpp:259]     Train net output #1: seg_loss = 3980.69 (* 1 = 3980.69 loss)
I1016 20:44:22.282860   329 sgd_solver.cpp:138] Iteration 61900, lr = 0.000125
I1016 20:45:24.749151   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_62000.caffemodel
I1016 20:45:25.166512   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_62000.solverstate
I1016 20:45:25.781605   329 solver.cpp:243] Iteration 62000, loss = 4197.14
I1016 20:45:25.781637   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.71811 (* 1 = 9.71811 loss)
I1016 20:45:25.781643   329 solver.cpp:259]     Train net output #1: seg_loss = 3283.37 (* 1 = 3283.37 loss)
I1016 20:45:25.781651   329 sgd_solver.cpp:138] Iteration 62000, lr = 0.000125
I1016 20:46:27.619474   329 solver.cpp:243] Iteration 62100, loss = 2437.32
I1016 20:46:27.619508   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.11536 (* 1 = 8.11536 loss)
I1016 20:46:27.619514   329 solver.cpp:259]     Train net output #1: seg_loss = 2041.41 (* 1 = 2041.41 loss)
I1016 20:46:27.619520   329 sgd_solver.cpp:138] Iteration 62100, lr = 0.000125
I1016 20:47:00.950237   366 blocking_queue.cpp:50] Waiting for data
I1016 20:47:38.738348   329 solver.cpp:243] Iteration 62200, loss = 2595.39
I1016 20:47:38.738379   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.44722 (* 1 = 6.44722 loss)
I1016 20:47:38.738385   329 solver.cpp:259]     Train net output #1: seg_loss = 2454.55 (* 1 = 2454.55 loss)
I1016 20:47:38.738391   329 sgd_solver.cpp:138] Iteration 62200, lr = 0.000125
I1016 20:48:42.495419   329 solver.cpp:243] Iteration 62300, loss = 3210.44
I1016 20:48:42.495455   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.61387 (* 1 = 9.61387 loss)
I1016 20:48:42.495465   329 solver.cpp:259]     Train net output #1: seg_loss = 2673.98 (* 1 = 2673.98 loss)
I1016 20:48:42.495472   329 sgd_solver.cpp:138] Iteration 62300, lr = 0.000125
I1016 20:48:46.275051   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 20:49:44.947232   329 solver.cpp:243] Iteration 62400, loss = 2763.31
I1016 20:49:44.947268   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.42927 (* 1 = 8.42927 loss)
I1016 20:49:44.947276   329 solver.cpp:259]     Train net output #1: seg_loss = 2385.01 (* 1 = 2385.01 loss)
I1016 20:49:44.947283   329 sgd_solver.cpp:138] Iteration 62400, lr = 0.000125
I1016 20:50:45.586431   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_62500.caffemodel
I1016 20:50:45.910426   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_62500.solverstate
I1016 20:50:46.568846   329 solver.cpp:243] Iteration 62500, loss = 3389.21
I1016 20:50:46.568881   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.99504 (* 1 = 8.99504 loss)
I1016 20:50:46.568887   329 solver.cpp:259]     Train net output #1: seg_loss = 2676.93 (* 1 = 2676.93 loss)
I1016 20:50:46.568894   329 sgd_solver.cpp:138] Iteration 62500, lr = 0.000125
I1016 20:51:48.922106   329 solver.cpp:243] Iteration 62600, loss = 2532.2
I1016 20:51:48.922138   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.15355 (* 1 = 8.15355 loss)
I1016 20:51:48.922144   329 solver.cpp:259]     Train net output #1: seg_loss = 2522.2 (* 1 = 2522.2 loss)
I1016 20:51:48.922150   329 sgd_solver.cpp:138] Iteration 62600, lr = 0.000125
I1016 20:52:51.154867   329 solver.cpp:243] Iteration 62700, loss = 2825.65
I1016 20:52:51.154914   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.93344 (* 1 = 9.93344 loss)
I1016 20:52:51.154922   329 solver.cpp:259]     Train net output #1: seg_loss = 2601.07 (* 1 = 2601.07 loss)
I1016 20:52:51.154927   329 sgd_solver.cpp:138] Iteration 62700, lr = 0.000125
I1016 20:53:53.109156   329 solver.cpp:243] Iteration 62800, loss = 2454.35
I1016 20:53:53.109194   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.98587 (* 1 = 3.98587 loss)
I1016 20:53:53.109203   329 solver.cpp:259]     Train net output #1: seg_loss = 2220.05 (* 1 = 2220.05 loss)
I1016 20:53:53.109211   329 sgd_solver.cpp:138] Iteration 62800, lr = 0.000125
I1016 20:54:54.284386   329 solver.cpp:243] Iteration 62900, loss = 2249.37
I1016 20:54:54.284416   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.30758 (* 1 = 5.30758 loss)
I1016 20:54:54.284422   329 solver.cpp:259]     Train net output #1: seg_loss = 1996.84 (* 1 = 1996.84 loss)
I1016 20:54:54.284427   329 sgd_solver.cpp:138] Iteration 62900, lr = 0.000125
I1016 20:55:54.733013   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_63000.caffemodel
I1016 20:55:55.042086   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_63000.solverstate
I1016 20:55:55.628985   329 solver.cpp:243] Iteration 63000, loss = 2419.86
I1016 20:55:55.629016   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.67148 (* 1 = 6.67148 loss)
I1016 20:55:55.629022   329 solver.cpp:259]     Train net output #1: seg_loss = 1885.45 (* 1 = 1885.45 loss)
I1016 20:55:55.629029   329 sgd_solver.cpp:138] Iteration 63000, lr = 0.000125
I1016 20:56:57.639879   329 solver.cpp:243] Iteration 63100, loss = 2915.69
I1016 20:56:57.639914   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.3886 (* 1 = 11.3886 loss)
I1016 20:56:57.639919   329 solver.cpp:259]     Train net output #1: seg_loss = 4352.03 (* 1 = 4352.03 loss)
I1016 20:56:57.639925   329 sgd_solver.cpp:138] Iteration 63100, lr = 0.000125
I1016 20:57:59.413101   329 solver.cpp:243] Iteration 63200, loss = 2272.42
I1016 20:57:59.413134   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.34993 (* 1 = 5.34993 loss)
I1016 20:57:59.413141   329 solver.cpp:259]     Train net output #1: seg_loss = 2370.94 (* 1 = 2370.94 loss)
I1016 20:57:59.413146   329 sgd_solver.cpp:138] Iteration 63200, lr = 0.000125
I1016 20:59:02.624019   329 solver.cpp:243] Iteration 63300, loss = 3037.1
I1016 20:59:02.624053   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.06593 (* 1 = 7.06593 loss)
I1016 20:59:02.624058   329 solver.cpp:259]     Train net output #1: seg_loss = 2206.12 (* 1 = 2206.12 loss)
I1016 20:59:02.624064   329 sgd_solver.cpp:138] Iteration 63300, lr = 0.000125
I1016 20:59:09.745851   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:00:04.812541   329 solver.cpp:243] Iteration 63400, loss = 2628.69
I1016 21:00:04.812572   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.25243 (* 1 = 7.25243 loss)
I1016 21:00:04.812578   329 solver.cpp:259]     Train net output #1: seg_loss = 2376.98 (* 1 = 2376.98 loss)
I1016 21:00:04.812584   329 sgd_solver.cpp:138] Iteration 63400, lr = 0.000125
I1016 21:01:06.423990   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_63500.caffemodel
I1016 21:01:06.756494   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_63500.solverstate
I1016 21:01:07.363629   329 solver.cpp:243] Iteration 63500, loss = 2926.22
I1016 21:01:07.363675   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.82758 (* 1 = 7.82758 loss)
I1016 21:01:07.363682   329 solver.cpp:259]     Train net output #1: seg_loss = 4524.21 (* 1 = 4524.21 loss)
I1016 21:01:07.363687   329 sgd_solver.cpp:138] Iteration 63500, lr = 0.000125
I1016 21:02:08.502907   329 solver.cpp:243] Iteration 63600, loss = 2653.33
I1016 21:02:08.502957   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.92771 (* 1 = 4.92771 loss)
I1016 21:02:08.502964   329 solver.cpp:259]     Train net output #1: seg_loss = 2745.84 (* 1 = 2745.84 loss)
I1016 21:02:08.502969   329 sgd_solver.cpp:138] Iteration 63600, lr = 0.000125
I1016 21:03:11.096361   329 solver.cpp:243] Iteration 63700, loss = 2367.76
I1016 21:03:11.096395   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.13898 (* 1 = 7.13898 loss)
I1016 21:03:11.096405   329 solver.cpp:259]     Train net output #1: seg_loss = 2486.47 (* 1 = 2486.47 loss)
I1016 21:03:11.096413   329 sgd_solver.cpp:138] Iteration 63700, lr = 0.000125
I1016 21:04:14.206009   329 solver.cpp:243] Iteration 63800, loss = 2863.58
I1016 21:04:14.206040   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.26275 (* 1 = 8.26275 loss)
I1016 21:04:14.206046   329 solver.cpp:259]     Train net output #1: seg_loss = 3385.65 (* 1 = 3385.65 loss)
I1016 21:04:14.206053   329 sgd_solver.cpp:138] Iteration 63800, lr = 0.000125
I1016 21:05:17.338387   329 solver.cpp:243] Iteration 63900, loss = 2267.03
I1016 21:05:17.338419   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.83451 (* 1 = 6.83451 loss)
I1016 21:05:17.338429   329 solver.cpp:259]     Train net output #1: seg_loss = 2103.39 (* 1 = 2103.39 loss)
I1016 21:05:17.338436   329 sgd_solver.cpp:138] Iteration 63900, lr = 0.000125
I1016 21:06:18.787070   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_64000.caffemodel
I1016 21:06:19.108486   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_64000.solverstate
I1016 21:06:19.389977   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 21:07:24.181598   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:08:02.085026   329 solver.cpp:243] Iteration 64000, loss = 2020.48
I1016 21:08:02.085059   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.46883 (* 1 = 5.46883 loss)
I1016 21:08:02.085067   329 solver.cpp:259]     Train net output #1: seg_loss = 2015.02 (* 1 = 2015.02 loss)
I1016 21:08:02.085072   329 sgd_solver.cpp:138] Iteration 64000, lr = 0.000125
I1016 21:09:01.955781   329 solver.cpp:243] Iteration 64100, loss = 2344.93
I1016 21:09:01.955816   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78005 (* 1 = 6.78005 loss)
I1016 21:09:01.955824   329 solver.cpp:259]     Train net output #1: seg_loss = 2016.37 (* 1 = 2016.37 loss)
I1016 21:09:01.955848   329 sgd_solver.cpp:138] Iteration 64100, lr = 0.000125
I1016 21:10:04.928822   329 solver.cpp:243] Iteration 64200, loss = 2515.88
I1016 21:10:04.928855   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.00564 (* 1 = 5.00564 loss)
I1016 21:10:04.928863   329 solver.cpp:259]     Train net output #1: seg_loss = 2083.92 (* 1 = 2083.92 loss)
I1016 21:10:04.928867   329 sgd_solver.cpp:138] Iteration 64200, lr = 0.000125
I1016 21:11:07.321866   329 solver.cpp:243] Iteration 64300, loss = 2679.51
I1016 21:11:07.321904   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.39629 (* 1 = 6.39629 loss)
I1016 21:11:07.321913   329 solver.cpp:259]     Train net output #1: seg_loss = 2150.82 (* 1 = 2150.82 loss)
I1016 21:11:07.321920   329 sgd_solver.cpp:138] Iteration 64300, lr = 0.000125
I1016 21:12:10.791898   329 solver.cpp:243] Iteration 64400, loss = 2193.13
I1016 21:12:10.791929   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.74618 (* 1 = 5.74618 loss)
I1016 21:12:10.791934   329 solver.cpp:259]     Train net output #1: seg_loss = 4198.13 (* 1 = 4198.13 loss)
I1016 21:12:10.791940   329 sgd_solver.cpp:138] Iteration 64400, lr = 0.000125
I1016 21:13:11.858242   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_64500.caffemodel
I1016 21:13:12.144006   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_64500.solverstate
I1016 21:13:12.771042   329 solver.cpp:243] Iteration 64500, loss = 2851.5
I1016 21:13:12.771100   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.39539 (* 1 = 6.39539 loss)
I1016 21:13:12.771116   329 solver.cpp:259]     Train net output #1: seg_loss = 1817.23 (* 1 = 1817.23 loss)
I1016 21:13:12.771128   329 sgd_solver.cpp:138] Iteration 64500, lr = 0.000125
I1016 21:14:12.898357   329 solver.cpp:243] Iteration 64600, loss = 2815.3
I1016 21:14:12.898389   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.36915 (* 1 = 4.36915 loss)
I1016 21:14:12.898396   329 solver.cpp:259]     Train net output #1: seg_loss = 1935.33 (* 1 = 1935.33 loss)
I1016 21:14:12.898401   329 sgd_solver.cpp:138] Iteration 64600, lr = 0.000125
I1016 21:15:13.173425   329 solver.cpp:243] Iteration 64700, loss = 4622.89
I1016 21:15:13.173458   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.54289 (* 1 = 7.54289 loss)
I1016 21:15:13.173463   329 solver.cpp:259]     Train net output #1: seg_loss = 7136 (* 1 = 7136 loss)
I1016 21:15:13.173470   329 sgd_solver.cpp:138] Iteration 64700, lr = 0.000125
I1016 21:16:13.620545   329 solver.cpp:243] Iteration 64800, loss = 2267.8
I1016 21:16:13.620587   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.74021 (* 1 = 5.74021 loss)
I1016 21:16:13.620594   329 solver.cpp:259]     Train net output #1: seg_loss = 4098.8 (* 1 = 4098.8 loss)
I1016 21:16:13.620600   329 sgd_solver.cpp:138] Iteration 64800, lr = 0.000125
I1016 21:16:28.535028   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:17:13.538342   329 solver.cpp:243] Iteration 64900, loss = 2803.51
I1016 21:17:13.538388   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.2714 (* 1 = 5.2714 loss)
I1016 21:17:13.538393   329 solver.cpp:259]     Train net output #1: seg_loss = 1756.82 (* 1 = 1756.82 loss)
I1016 21:17:13.538400   329 sgd_solver.cpp:138] Iteration 64900, lr = 0.000125
I1016 21:18:13.166672   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_65000.caffemodel
I1016 21:18:13.492856   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_65000.solverstate
I1016 21:18:14.086913   329 solver.cpp:243] Iteration 65000, loss = 3371.02
I1016 21:18:14.086961   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.56055 (* 1 = 6.56055 loss)
I1016 21:18:14.086968   329 solver.cpp:259]     Train net output #1: seg_loss = 4319.69 (* 1 = 4319.69 loss)
I1016 21:18:14.086974   329 sgd_solver.cpp:138] Iteration 65000, lr = 0.000125
I1016 21:19:12.823189   329 solver.cpp:243] Iteration 65100, loss = 2139.26
I1016 21:19:12.823240   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.97119 (* 1 = 8.97119 loss)
I1016 21:19:12.823246   329 solver.cpp:259]     Train net output #1: seg_loss = 2530.94 (* 1 = 2530.94 loss)
I1016 21:19:12.823251   329 sgd_solver.cpp:138] Iteration 65100, lr = 0.000125
I1016 21:20:11.088786   329 solver.cpp:243] Iteration 65200, loss = 3056.8
I1016 21:20:11.088836   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.54533 (* 1 = 7.54533 loss)
I1016 21:20:11.088842   329 solver.cpp:259]     Train net output #1: seg_loss = 3210.19 (* 1 = 3210.19 loss)
I1016 21:20:11.088848   329 sgd_solver.cpp:138] Iteration 65200, lr = 0.000125
I1016 21:21:10.801059   329 solver.cpp:243] Iteration 65300, loss = 2179.66
I1016 21:21:10.801093   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.16266 (* 1 = 7.16266 loss)
I1016 21:21:10.801102   329 solver.cpp:259]     Train net output #1: seg_loss = 1780.17 (* 1 = 1780.17 loss)
I1016 21:21:10.801126   329 sgd_solver.cpp:138] Iteration 65300, lr = 0.000125
I1016 21:22:10.465865   329 solver.cpp:243] Iteration 65400, loss = 2735.31
I1016 21:22:10.465900   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.45974 (* 1 = 6.45974 loss)
I1016 21:22:10.465909   329 solver.cpp:259]     Train net output #1: seg_loss = 2817 (* 1 = 2817 loss)
I1016 21:22:10.465917   329 sgd_solver.cpp:138] Iteration 65400, lr = 0.000125
I1016 21:23:10.170828   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_65500.caffemodel
I1016 21:23:10.458207   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_65500.solverstate
I1016 21:23:11.060199   329 solver.cpp:243] Iteration 65500, loss = 2559.74
I1016 21:23:11.060247   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.86498 (* 1 = 9.86498 loss)
I1016 21:23:11.060253   329 solver.cpp:259]     Train net output #1: seg_loss = 3336.71 (* 1 = 3336.71 loss)
I1016 21:23:11.060259   329 sgd_solver.cpp:138] Iteration 65500, lr = 0.000125
I1016 21:24:09.878219   329 solver.cpp:243] Iteration 65600, loss = 3039.68
I1016 21:24:09.878266   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.3232 (* 1 = 4.3232 loss)
I1016 21:24:09.878273   329 solver.cpp:259]     Train net output #1: seg_loss = 2655.88 (* 1 = 2655.88 loss)
I1016 21:24:09.878279   329 sgd_solver.cpp:138] Iteration 65600, lr = 0.000125
I1016 21:25:08.475740   329 solver.cpp:243] Iteration 65700, loss = 2720.48
I1016 21:25:08.475788   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.31008 (* 1 = 5.31008 loss)
I1016 21:25:08.475795   329 solver.cpp:259]     Train net output #1: seg_loss = 2174.99 (* 1 = 2174.99 loss)
I1016 21:25:08.475800   329 sgd_solver.cpp:138] Iteration 65700, lr = 0.000125
I1016 21:26:07.777679   329 solver.cpp:243] Iteration 65800, loss = 2783.65
I1016 21:26:07.777715   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.65334 (* 1 = 6.65334 loss)
I1016 21:26:07.777721   329 solver.cpp:259]     Train net output #1: seg_loss = 1705.56 (* 1 = 1705.56 loss)
I1016 21:26:07.777727   329 sgd_solver.cpp:138] Iteration 65800, lr = 0.000125
I1016 21:26:26.152640   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:27:06.914134   329 solver.cpp:243] Iteration 65900, loss = 2344.85
I1016 21:27:06.914167   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.92494 (* 1 = 4.92494 loss)
I1016 21:27:06.914175   329 solver.cpp:259]     Train net output #1: seg_loss = 2521.89 (* 1 = 2521.89 loss)
I1016 21:27:06.914180   329 sgd_solver.cpp:138] Iteration 65900, lr = 0.000125
I1016 21:28:06.399286   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_66000.caffemodel
I1016 21:28:06.699048   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_66000.solverstate
I1016 21:28:07.292076   329 solver.cpp:243] Iteration 66000, loss = 3347.1
I1016 21:28:07.292120   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.09268 (* 1 = 7.09268 loss)
I1016 21:28:07.292126   329 solver.cpp:259]     Train net output #1: seg_loss = 6746.35 (* 1 = 6746.35 loss)
I1016 21:28:07.292131   329 sgd_solver.cpp:138] Iteration 66000, lr = 0.000125
I1016 21:29:06.688694   329 solver.cpp:243] Iteration 66100, loss = 2363.76
I1016 21:29:06.688738   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.53471 (* 1 = 9.53471 loss)
I1016 21:29:06.688745   329 solver.cpp:259]     Train net output #1: seg_loss = 2446.73 (* 1 = 2446.73 loss)
I1016 21:29:06.688751   329 sgd_solver.cpp:138] Iteration 66100, lr = 0.000125
I1016 21:30:05.683054   329 solver.cpp:243] Iteration 66200, loss = 2562.62
I1016 21:30:05.683099   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.26368 (* 1 = 5.26368 loss)
I1016 21:30:05.683105   329 solver.cpp:259]     Train net output #1: seg_loss = 2825.42 (* 1 = 2825.42 loss)
I1016 21:30:05.683111   329 sgd_solver.cpp:138] Iteration 66200, lr = 0.000125
I1016 21:31:04.041556   329 solver.cpp:243] Iteration 66300, loss = 3002.29
I1016 21:31:04.041601   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.5272 (* 1 = 7.5272 loss)
I1016 21:31:04.041611   329 solver.cpp:259]     Train net output #1: seg_loss = 2758.64 (* 1 = 2758.64 loss)
I1016 21:31:04.041620   329 sgd_solver.cpp:138] Iteration 66300, lr = 0.000125
I1016 21:32:03.687593   329 solver.cpp:243] Iteration 66400, loss = 2267.33
I1016 21:32:03.687640   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.7066 (* 1 = 4.7066 loss)
I1016 21:32:03.687646   329 solver.cpp:259]     Train net output #1: seg_loss = 1921.18 (* 1 = 1921.18 loss)
I1016 21:32:03.687652   329 sgd_solver.cpp:138] Iteration 66400, lr = 0.000125
I1016 21:33:02.946861   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_66500.caffemodel
I1016 21:33:03.273324   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_66500.solverstate
I1016 21:33:03.857957   329 solver.cpp:243] Iteration 66500, loss = 2758.01
I1016 21:33:03.857988   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.70363 (* 1 = 8.70363 loss)
I1016 21:33:03.857995   329 solver.cpp:259]     Train net output #1: seg_loss = 3388.71 (* 1 = 3388.71 loss)
I1016 21:33:03.858001   329 sgd_solver.cpp:138] Iteration 66500, lr = 0.000125
I1016 21:34:03.515070   329 solver.cpp:243] Iteration 66600, loss = 2188.58
I1016 21:34:03.515103   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.00033 (* 1 = 5.00033 loss)
I1016 21:34:03.515110   329 solver.cpp:259]     Train net output #1: seg_loss = 2157.58 (* 1 = 2157.58 loss)
I1016 21:34:03.515115   329 sgd_solver.cpp:138] Iteration 66600, lr = 0.000125
I1016 21:35:02.542695   329 solver.cpp:243] Iteration 66700, loss = 2707.1
I1016 21:35:02.542743   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.91295 (* 1 = 4.91295 loss)
I1016 21:35:02.542749   329 solver.cpp:259]     Train net output #1: seg_loss = 2091.45 (* 1 = 2091.45 loss)
I1016 21:35:02.542770   329 sgd_solver.cpp:138] Iteration 66700, lr = 0.000125
I1016 21:36:00.757253   329 solver.cpp:243] Iteration 66800, loss = 2181.22
I1016 21:36:00.757284   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.64688 (* 1 = 5.64688 loss)
I1016 21:36:00.757290   329 solver.cpp:259]     Train net output #1: seg_loss = 1936.9 (* 1 = 1936.9 loss)
I1016 21:36:00.757297   329 sgd_solver.cpp:138] Iteration 66800, lr = 0.000125
I1016 21:36:21.509693   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:37:00.456897   329 solver.cpp:243] Iteration 66900, loss = 2893.67
I1016 21:37:00.456929   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.50224 (* 1 = 8.50224 loss)
I1016 21:37:00.456935   329 solver.cpp:259]     Train net output #1: seg_loss = 1575.82 (* 1 = 1575.82 loss)
I1016 21:37:00.456941   329 sgd_solver.cpp:138] Iteration 66900, lr = 0.000125
I1016 21:37:59.194963   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_67000.caffemodel
I1016 21:37:59.483819   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_67000.solverstate
I1016 21:38:00.082383   329 solver.cpp:243] Iteration 67000, loss = 2823.53
I1016 21:38:00.082414   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.63657 (* 1 = 6.63657 loss)
I1016 21:38:00.082422   329 solver.cpp:259]     Train net output #1: seg_loss = 3044.65 (* 1 = 3044.65 loss)
I1016 21:38:00.082427   329 sgd_solver.cpp:138] Iteration 67000, lr = 0.000125
I1016 21:38:59.942468   329 solver.cpp:243] Iteration 67100, loss = 2137.57
I1016 21:38:59.942502   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.7356 (* 1 = 5.7356 loss)
I1016 21:38:59.942508   329 solver.cpp:259]     Train net output #1: seg_loss = 2442.02 (* 1 = 2442.02 loss)
I1016 21:38:59.942514   329 sgd_solver.cpp:138] Iteration 67100, lr = 0.000125
I1016 21:39:59.117151   329 solver.cpp:243] Iteration 67200, loss = 2195.92
I1016 21:39:59.117182   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.36734 (* 1 = 7.36734 loss)
I1016 21:39:59.117188   329 solver.cpp:259]     Train net output #1: seg_loss = 3158.12 (* 1 = 3158.12 loss)
I1016 21:39:59.117195   329 sgd_solver.cpp:138] Iteration 67200, lr = 0.000125
I1016 21:40:58.472252   329 solver.cpp:243] Iteration 67300, loss = 3374.09
I1016 21:40:58.472299   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.32145 (* 1 = 6.32145 loss)
I1016 21:40:58.472306   329 solver.cpp:259]     Train net output #1: seg_loss = 2304.45 (* 1 = 2304.45 loss)
I1016 21:40:58.472311   329 sgd_solver.cpp:138] Iteration 67300, lr = 0.000125
I1016 21:41:57.282537   329 solver.cpp:243] Iteration 67400, loss = 3003.23
I1016 21:41:57.282570   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.3517 (* 1 = 10.3517 loss)
I1016 21:41:57.282577   329 solver.cpp:259]     Train net output #1: seg_loss = 4114.43 (* 1 = 4114.43 loss)
I1016 21:41:57.282582   329 sgd_solver.cpp:138] Iteration 67400, lr = 0.000125
I1016 21:42:56.209810   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_67500.caffemodel
I1016 21:42:56.543288   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_67500.solverstate
I1016 21:42:57.177016   329 solver.cpp:243] Iteration 67500, loss = 1987.32
I1016 21:42:57.177062   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.69558 (* 1 = 5.69558 loss)
I1016 21:42:57.177068   329 solver.cpp:259]     Train net output #1: seg_loss = 257.669 (* 1 = 257.669 loss)
I1016 21:42:57.177074   329 sgd_solver.cpp:138] Iteration 67500, lr = 0.000125
I1016 21:43:56.950357   329 solver.cpp:243] Iteration 67600, loss = 3221.26
I1016 21:43:56.950405   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.40071 (* 1 = 4.40071 loss)
I1016 21:43:56.950412   329 solver.cpp:259]     Train net output #1: seg_loss = 2563.48 (* 1 = 2563.48 loss)
I1016 21:43:56.950418   329 sgd_solver.cpp:138] Iteration 67600, lr = 0.000125
I1016 21:44:56.809522   329 solver.cpp:243] Iteration 67700, loss = 2504.69
I1016 21:44:56.809571   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.37059 (* 1 = 5.37059 loss)
I1016 21:44:56.809576   329 solver.cpp:259]     Train net output #1: seg_loss = 3526.18 (* 1 = 3526.18 loss)
I1016 21:44:56.809582   329 sgd_solver.cpp:138] Iteration 67700, lr = 0.000125
I1016 21:45:55.948626   329 solver.cpp:243] Iteration 67800, loss = 2181.15
I1016 21:45:55.948673   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.56481 (* 1 = 5.56481 loss)
I1016 21:45:55.948678   329 solver.cpp:259]     Train net output #1: seg_loss = 2123.28 (* 1 = 2123.28 loss)
I1016 21:45:55.948684   329 sgd_solver.cpp:138] Iteration 67800, lr = 0.000125
I1016 21:46:19.588891   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:46:54.036051   329 solver.cpp:243] Iteration 67900, loss = 2577.48
I1016 21:46:54.036083   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.39732 (* 1 = 8.39732 loss)
I1016 21:46:54.036092   329 solver.cpp:259]     Train net output #1: seg_loss = 2913.45 (* 1 = 2913.45 loss)
I1016 21:46:54.036115   329 sgd_solver.cpp:138] Iteration 67900, lr = 0.000125
I1016 21:47:53.469485   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_68000.caffemodel
I1016 21:47:53.748409   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_68000.solverstate
I1016 21:47:53.940086   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 21:49:31.514799   329 solver.cpp:243] Iteration 68000, loss = 438.592
I1016 21:49:31.514832   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.28252 (* 1 = 7.28252 loss)
I1016 21:49:31.514838   329 solver.cpp:259]     Train net output #1: seg_loss = 431.309 (* 1 = 431.309 loss)
I1016 21:49:31.514844   329 sgd_solver.cpp:138] Iteration 68000, lr = 0.000125
I1016 21:50:29.983568   329 solver.cpp:243] Iteration 68100, loss = 1872.57
I1016 21:50:29.983618   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.69348 (* 1 = 4.69348 loss)
I1016 21:50:29.983623   329 solver.cpp:259]     Train net output #1: seg_loss = 2696.53 (* 1 = 2696.53 loss)
I1016 21:50:29.983629   329 sgd_solver.cpp:138] Iteration 68100, lr = 0.000125
I1016 21:51:30.523264   329 solver.cpp:243] Iteration 68200, loss = 2645.38
I1016 21:51:30.523313   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.85928 (* 1 = 4.85928 loss)
I1016 21:51:30.523319   329 solver.cpp:259]     Train net output #1: seg_loss = 1984.55 (* 1 = 1984.55 loss)
I1016 21:51:30.523324   329 sgd_solver.cpp:138] Iteration 68200, lr = 0.000125
I1016 21:52:29.883601   329 solver.cpp:243] Iteration 68300, loss = 2725.45
I1016 21:52:29.883633   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.1513 (* 1 = 8.1513 loss)
I1016 21:52:29.883639   329 solver.cpp:259]     Train net output #1: seg_loss = 2796.43 (* 1 = 2796.43 loss)
I1016 21:52:29.883644   329 sgd_solver.cpp:138] Iteration 68300, lr = 0.000125
I1016 21:52:59.718135   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 21:53:28.929466   329 solver.cpp:243] Iteration 68400, loss = 2221.99
I1016 21:53:28.929497   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.57101 (* 1 = 5.57101 loss)
I1016 21:53:28.929503   329 solver.cpp:259]     Train net output #1: seg_loss = 1838.79 (* 1 = 1838.79 loss)
I1016 21:53:28.929509   329 sgd_solver.cpp:138] Iteration 68400, lr = 0.000125
I1016 21:54:27.662601   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_68500.caffemodel
I1016 21:54:27.948990   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_68500.solverstate
I1016 21:54:28.546680   329 solver.cpp:243] Iteration 68500, loss = 4338.75
I1016 21:54:28.546715   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.5274 (* 1 = 8.5274 loss)
I1016 21:54:28.546721   329 solver.cpp:259]     Train net output #1: seg_loss = 2877.43 (* 1 = 2877.43 loss)
I1016 21:54:28.546727   329 sgd_solver.cpp:138] Iteration 68500, lr = 0.000125
I1016 21:55:27.708354   329 solver.cpp:243] Iteration 68600, loss = 2414.6
I1016 21:55:27.708402   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67405 (* 1 = 7.67405 loss)
I1016 21:55:27.708408   329 solver.cpp:259]     Train net output #1: seg_loss = 3594.77 (* 1 = 3594.77 loss)
I1016 21:55:27.708415   329 sgd_solver.cpp:138] Iteration 68600, lr = 0.000125
I1016 21:56:27.903023   329 solver.cpp:243] Iteration 68700, loss = 2598.72
I1016 21:56:27.903056   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.61314 (* 1 = 5.61314 loss)
I1016 21:56:27.903065   329 solver.cpp:259]     Train net output #1: seg_loss = 3091.46 (* 1 = 3091.46 loss)
I1016 21:56:27.903072   329 sgd_solver.cpp:138] Iteration 68700, lr = 0.000125
I1016 21:57:27.866363   329 solver.cpp:243] Iteration 68800, loss = 3200.05
I1016 21:57:27.866410   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.67788 (* 1 = 5.67788 loss)
I1016 21:57:27.866416   329 solver.cpp:259]     Train net output #1: seg_loss = 3053.15 (* 1 = 3053.15 loss)
I1016 21:57:27.866422   329 sgd_solver.cpp:138] Iteration 68800, lr = 0.000125
I1016 21:58:26.914372   329 solver.cpp:243] Iteration 68900, loss = 2676.2
I1016 21:58:26.914423   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.13787 (* 1 = 5.13787 loss)
I1016 21:58:26.914430   329 solver.cpp:259]     Train net output #1: seg_loss = 2624.41 (* 1 = 2624.41 loss)
I1016 21:58:26.914435   329 sgd_solver.cpp:138] Iteration 68900, lr = 0.000125
I1016 21:59:24.715754   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_69000.caffemodel
I1016 21:59:25.020453   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_69000.solverstate
I1016 21:59:25.609855   329 solver.cpp:243] Iteration 69000, loss = 3546.12
I1016 21:59:25.609887   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.69511 (* 1 = 4.69511 loss)
I1016 21:59:25.609894   329 solver.cpp:259]     Train net output #1: seg_loss = 3067.86 (* 1 = 3067.86 loss)
I1016 21:59:25.609899   329 sgd_solver.cpp:138] Iteration 69000, lr = 0.000125
I1016 22:00:25.205332   329 solver.cpp:243] Iteration 69100, loss = 2430.94
I1016 22:00:25.205363   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.72331 (* 1 = 6.72331 loss)
I1016 22:00:25.205369   329 solver.cpp:259]     Train net output #1: seg_loss = 3100.95 (* 1 = 3100.95 loss)
I1016 22:00:25.205375   329 sgd_solver.cpp:138] Iteration 69100, lr = 0.000125
I1016 22:01:25.006407   329 solver.cpp:243] Iteration 69200, loss = 2654.83
I1016 22:01:25.006438   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.50132 (* 1 = 6.50132 loss)
I1016 22:01:25.006443   329 solver.cpp:259]     Train net output #1: seg_loss = 4652.99 (* 1 = 4652.99 loss)
I1016 22:01:25.006450   329 sgd_solver.cpp:138] Iteration 69200, lr = 0.000125
I1016 22:02:25.450860   329 solver.cpp:243] Iteration 69300, loss = 2499.77
I1016 22:02:25.450892   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.95051 (* 1 = 4.95051 loss)
I1016 22:02:25.450898   329 solver.cpp:259]     Train net output #1: seg_loss = 2701.85 (* 1 = 2701.85 loss)
I1016 22:02:25.450903   329 sgd_solver.cpp:138] Iteration 69300, lr = 0.000125
I1016 22:02:58.109141   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:03:24.824419   329 solver.cpp:243] Iteration 69400, loss = 2516.76
I1016 22:03:24.824452   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.64858 (* 1 = 7.64858 loss)
I1016 22:03:24.824458   329 solver.cpp:259]     Train net output #1: seg_loss = 1942.96 (* 1 = 1942.96 loss)
I1016 22:03:24.824465   329 sgd_solver.cpp:138] Iteration 69400, lr = 0.000125
I1016 22:04:22.790735   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_69500.caffemodel
I1016 22:04:23.057795   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_69500.solverstate
I1016 22:04:23.629712   329 solver.cpp:243] Iteration 69500, loss = 2378.62
I1016 22:04:23.629745   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.88564 (* 1 = 4.88564 loss)
I1016 22:04:23.629751   329 solver.cpp:259]     Train net output #1: seg_loss = 2623.43 (* 1 = 2623.43 loss)
I1016 22:04:23.629757   329 sgd_solver.cpp:138] Iteration 69500, lr = 0.000125
I1016 22:05:23.192903   329 solver.cpp:243] Iteration 69600, loss = 2636.73
I1016 22:05:23.192950   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.30164 (* 1 = 7.30164 loss)
I1016 22:05:23.192956   329 solver.cpp:259]     Train net output #1: seg_loss = 3687.87 (* 1 = 3687.87 loss)
I1016 22:05:23.192962   329 sgd_solver.cpp:138] Iteration 69600, lr = 0.000125
I1016 22:06:22.746832   329 solver.cpp:243] Iteration 69700, loss = 2135.41
I1016 22:06:22.746879   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.54005 (* 1 = 3.54005 loss)
I1016 22:06:22.746886   329 solver.cpp:259]     Train net output #1: seg_loss = 1966.82 (* 1 = 1966.82 loss)
I1016 22:06:22.746891   329 sgd_solver.cpp:138] Iteration 69700, lr = 0.000125
I1016 22:07:23.061482   329 solver.cpp:243] Iteration 69800, loss = 3041.45
I1016 22:07:23.061514   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.66413 (* 1 = 5.66413 loss)
I1016 22:07:23.061522   329 solver.cpp:259]     Train net output #1: seg_loss = 1682.11 (* 1 = 1682.11 loss)
I1016 22:07:23.061527   329 sgd_solver.cpp:138] Iteration 69800, lr = 0.000125
I1016 22:08:22.550652   329 solver.cpp:243] Iteration 69900, loss = 2525.04
I1016 22:08:22.550700   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.82001 (* 1 = 7.82001 loss)
I1016 22:08:22.550706   329 solver.cpp:259]     Train net output #1: seg_loss = 2319.93 (* 1 = 2319.93 loss)
I1016 22:08:22.550712   329 sgd_solver.cpp:138] Iteration 69900, lr = 0.000125
I1016 22:09:21.302085   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_70000.caffemodel
I1016 22:09:21.608063   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_70000.solverstate
I1016 22:09:22.245581   329 solver.cpp:243] Iteration 70000, loss = 2634.03
I1016 22:09:22.245627   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.44366 (* 1 = 8.44366 loss)
I1016 22:09:22.245633   329 solver.cpp:259]     Train net output #1: seg_loss = 3146.16 (* 1 = 3146.16 loss)
I1016 22:09:22.245640   329 sgd_solver.cpp:138] Iteration 70000, lr = 0.000125
I1016 22:10:20.752702   329 solver.cpp:243] Iteration 70100, loss = 2520.28
I1016 22:10:20.752733   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.1118 (* 1 = 11.1118 loss)
I1016 22:10:20.752739   329 solver.cpp:259]     Train net output #1: seg_loss = 2554.32 (* 1 = 2554.32 loss)
I1016 22:10:20.752745   329 sgd_solver.cpp:138] Iteration 70100, lr = 0.000125
I1016 22:11:20.422518   329 solver.cpp:243] Iteration 70200, loss = 2290.95
I1016 22:11:20.422551   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.36852 (* 1 = 7.36852 loss)
I1016 22:11:20.422557   329 solver.cpp:259]     Train net output #1: seg_loss = 2209.75 (* 1 = 2209.75 loss)
I1016 22:11:20.422564   329 sgd_solver.cpp:138] Iteration 70200, lr = 0.000125
I1016 22:12:20.353946   329 solver.cpp:243] Iteration 70300, loss = 2641.95
I1016 22:12:20.353978   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.69025 (* 1 = 6.69025 loss)
I1016 22:12:20.353984   329 solver.cpp:259]     Train net output #1: seg_loss = 3660.24 (* 1 = 3660.24 loss)
I1016 22:12:20.353991   329 sgd_solver.cpp:138] Iteration 70300, lr = 0.000125
I1016 22:12:56.732966   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:13:20.480427   329 solver.cpp:243] Iteration 70400, loss = 2234.92
I1016 22:13:20.480460   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.98452 (* 1 = 6.98452 loss)
I1016 22:13:20.480466   329 solver.cpp:259]     Train net output #1: seg_loss = 2154.68 (* 1 = 2154.68 loss)
I1016 22:13:20.480473   329 sgd_solver.cpp:138] Iteration 70400, lr = 0.000125
I1016 22:14:19.075956   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_70500.caffemodel
I1016 22:14:19.374027   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_70500.solverstate
I1016 22:14:19.953366   329 solver.cpp:243] Iteration 70500, loss = 2296.59
I1016 22:14:19.953397   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.33885 (* 1 = 7.33885 loss)
I1016 22:14:19.953403   329 solver.cpp:259]     Train net output #1: seg_loss = 2520.16 (* 1 = 2520.16 loss)
I1016 22:14:19.953409   329 sgd_solver.cpp:138] Iteration 70500, lr = 0.000125
I1016 22:15:17.723003   329 solver.cpp:243] Iteration 70600, loss = 2312.13
I1016 22:15:17.723037   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.3916 (* 1 = 7.3916 loss)
I1016 22:15:17.723042   329 solver.cpp:259]     Train net output #1: seg_loss = 1695.45 (* 1 = 1695.45 loss)
I1016 22:15:17.723049   329 sgd_solver.cpp:138] Iteration 70600, lr = 0.000125
I1016 22:16:17.722990   329 solver.cpp:243] Iteration 70700, loss = 2641.51
I1016 22:16:17.723021   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.68348 (* 1 = 5.68348 loss)
I1016 22:16:17.723026   329 solver.cpp:259]     Train net output #1: seg_loss = 2381.06 (* 1 = 2381.06 loss)
I1016 22:16:17.723031   329 sgd_solver.cpp:138] Iteration 70700, lr = 0.000125
I1016 22:17:17.290359   329 solver.cpp:243] Iteration 70800, loss = 2726.83
I1016 22:17:17.290391   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.29133 (* 1 = 6.29133 loss)
I1016 22:17:17.290397   329 solver.cpp:259]     Train net output #1: seg_loss = 1890.72 (* 1 = 1890.72 loss)
I1016 22:17:17.290403   329 sgd_solver.cpp:138] Iteration 70800, lr = 0.000125
I1016 22:18:17.626184   329 solver.cpp:243] Iteration 70900, loss = 1889.21
I1016 22:18:17.626216   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.45495 (* 1 = 4.45495 loss)
I1016 22:18:17.626222   329 solver.cpp:259]     Train net output #1: seg_loss = 1770.95 (* 1 = 1770.95 loss)
I1016 22:18:17.626229   329 sgd_solver.cpp:138] Iteration 70900, lr = 0.000125
I1016 22:19:16.264343   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_71000.caffemodel
I1016 22:19:16.552776   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_71000.solverstate
I1016 22:19:17.198020   329 solver.cpp:243] Iteration 71000, loss = 2905.82
I1016 22:19:17.198055   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.27223 (* 1 = 6.27223 loss)
I1016 22:19:17.198060   329 solver.cpp:259]     Train net output #1: seg_loss = 3220.48 (* 1 = 3220.48 loss)
I1016 22:19:17.198067   329 sgd_solver.cpp:138] Iteration 71000, lr = 0.000125
I1016 22:20:15.928222   329 solver.cpp:243] Iteration 71100, loss = 2756.03
I1016 22:20:15.928254   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.3236 (* 1 = 6.3236 loss)
I1016 22:20:15.928261   329 solver.cpp:259]     Train net output #1: seg_loss = 1690.27 (* 1 = 1690.27 loss)
I1016 22:20:15.928267   329 sgd_solver.cpp:138] Iteration 71100, lr = 0.000125
I1016 22:21:15.072981   329 solver.cpp:243] Iteration 71200, loss = 3897.46
I1016 22:21:15.073014   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.57786 (* 1 = 7.57786 loss)
I1016 22:21:15.073019   329 solver.cpp:259]     Train net output #1: seg_loss = 4528.54 (* 1 = 4528.54 loss)
I1016 22:21:15.073025   329 sgd_solver.cpp:138] Iteration 71200, lr = 0.000125
I1016 22:22:14.578305   329 solver.cpp:243] Iteration 71300, loss = 2001.02
I1016 22:22:14.578336   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.83818 (* 1 = 6.83818 loss)
I1016 22:22:14.578358   329 solver.cpp:259]     Train net output #1: seg_loss = 2909.48 (* 1 = 2909.48 loss)
I1016 22:22:14.578366   329 sgd_solver.cpp:138] Iteration 71300, lr = 0.000125
I1016 22:22:53.188463   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:23:14.893316   329 solver.cpp:243] Iteration 71400, loss = 2846.54
I1016 22:23:14.893347   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.14445 (* 1 = 5.14445 loss)
I1016 22:23:14.893353   329 solver.cpp:259]     Train net output #1: seg_loss = 3157.29 (* 1 = 3157.29 loss)
I1016 22:23:14.893358   329 sgd_solver.cpp:138] Iteration 71400, lr = 0.000125
I1016 22:24:14.582911   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_71500.caffemodel
I1016 22:24:14.865181   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_71500.solverstate
I1016 22:24:15.471140   329 solver.cpp:243] Iteration 71500, loss = 3120.04
I1016 22:24:15.471171   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.27565 (* 1 = 7.27565 loss)
I1016 22:24:15.471177   329 solver.cpp:259]     Train net output #1: seg_loss = 2774.94 (* 1 = 2774.94 loss)
I1016 22:24:15.471184   329 sgd_solver.cpp:138] Iteration 71500, lr = 0.000125
I1016 22:25:14.521409   329 solver.cpp:243] Iteration 71600, loss = 2047.01
I1016 22:25:14.521442   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.42764 (* 1 = 6.42764 loss)
I1016 22:25:14.521447   329 solver.cpp:259]     Train net output #1: seg_loss = 2339.31 (* 1 = 2339.31 loss)
I1016 22:25:14.521455   329 sgd_solver.cpp:138] Iteration 71600, lr = 0.000125
I1016 22:26:12.889915   329 solver.cpp:243] Iteration 71700, loss = 2909.42
I1016 22:26:12.889950   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.7696 (* 1 = 5.7696 loss)
I1016 22:26:12.889955   329 solver.cpp:259]     Train net output #1: seg_loss = 5148.08 (* 1 = 5148.08 loss)
I1016 22:26:12.889961   329 sgd_solver.cpp:138] Iteration 71700, lr = 0.000125
I1016 22:27:12.748425   329 solver.cpp:243] Iteration 71800, loss = 2148.68
I1016 22:27:12.748456   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.94841 (* 1 = 5.94841 loss)
I1016 22:27:12.748461   329 solver.cpp:259]     Train net output #1: seg_loss = 2566.85 (* 1 = 2566.85 loss)
I1016 22:27:12.748467   329 sgd_solver.cpp:138] Iteration 71800, lr = 0.000125
I1016 22:28:12.681782   329 solver.cpp:243] Iteration 71900, loss = 2598.26
I1016 22:28:12.681815   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.70338 (* 1 = 4.70338 loss)
I1016 22:28:12.681824   329 solver.cpp:259]     Train net output #1: seg_loss = 2155.33 (* 1 = 2155.33 loss)
I1016 22:28:12.681845   329 sgd_solver.cpp:138] Iteration 71900, lr = 0.000125
I1016 22:29:12.581506   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_72000.caffemodel
I1016 22:29:12.862529   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_72000.solverstate
I1016 22:29:13.078907   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 22:30:25.794256   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:30:51.428372   329 solver.cpp:243] Iteration 72000, loss = 2747.07
I1016 22:30:51.428406   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.87213 (* 1 = 6.87213 loss)
I1016 22:30:51.428411   329 solver.cpp:259]     Train net output #1: seg_loss = 2740.2 (* 1 = 2740.2 loss)
I1016 22:30:51.428418   329 sgd_solver.cpp:138] Iteration 72000, lr = 0.000125
I1016 22:31:49.772547   329 solver.cpp:243] Iteration 72100, loss = 2932.89
I1016 22:31:49.772579   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.31245 (* 1 = 6.31245 loss)
I1016 22:31:49.772585   329 solver.cpp:259]     Train net output #1: seg_loss = 4882.29 (* 1 = 4882.29 loss)
I1016 22:31:49.772591   329 sgd_solver.cpp:138] Iteration 72100, lr = 0.000125
I1016 22:32:48.613888   329 solver.cpp:243] Iteration 72200, loss = 2674.58
I1016 22:32:48.613924   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78959 (* 1 = 6.78959 loss)
I1016 22:32:48.613929   329 solver.cpp:259]     Train net output #1: seg_loss = 2353.45 (* 1 = 2353.45 loss)
I1016 22:32:48.613936   329 sgd_solver.cpp:138] Iteration 72200, lr = 0.000125
I1016 22:33:48.052534   329 solver.cpp:243] Iteration 72300, loss = 3191.95
I1016 22:33:48.052582   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.982 (* 1 = 11.982 loss)
I1016 22:33:48.052589   329 solver.cpp:259]     Train net output #1: seg_loss = 2834.5 (* 1 = 2834.5 loss)
I1016 22:33:48.052595   329 sgd_solver.cpp:138] Iteration 72300, lr = 0.000125
I1016 22:34:47.357247   329 solver.cpp:243] Iteration 72400, loss = 2258.58
I1016 22:34:47.357280   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.59543 (* 1 = 4.59543 loss)
I1016 22:34:47.357285   329 solver.cpp:259]     Train net output #1: seg_loss = 1462.83 (* 1 = 1462.83 loss)
I1016 22:34:47.357291   329 sgd_solver.cpp:138] Iteration 72400, lr = 0.000125
I1016 22:35:46.865381   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_72500.caffemodel
I1016 22:35:47.134510   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_72500.solverstate
I1016 22:35:47.709609   329 solver.cpp:243] Iteration 72500, loss = 2871.17
I1016 22:35:47.709641   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.6046 (* 1 = 4.6046 loss)
I1016 22:35:47.709648   329 solver.cpp:259]     Train net output #1: seg_loss = 3393.12 (* 1 = 3393.12 loss)
I1016 22:35:47.709655   329 sgd_solver.cpp:138] Iteration 72500, lr = 0.000125
I1016 22:36:47.284387   329 solver.cpp:243] Iteration 72600, loss = 2388.96
I1016 22:36:47.284421   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67893 (* 1 = 7.67893 loss)
I1016 22:36:47.284426   329 solver.cpp:259]     Train net output #1: seg_loss = 1865.82 (* 1 = 1865.82 loss)
I1016 22:36:47.284433   329 sgd_solver.cpp:138] Iteration 72600, lr = 0.000125
I1016 22:37:46.334786   329 solver.cpp:243] Iteration 72700, loss = 2443.1
I1016 22:37:46.334818   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78689 (* 1 = 6.78689 loss)
I1016 22:37:46.334825   329 solver.cpp:259]     Train net output #1: seg_loss = 2363.31 (* 1 = 2363.31 loss)
I1016 22:37:46.334830   329 sgd_solver.cpp:138] Iteration 72700, lr = 0.000125
I1016 22:38:44.701623   329 solver.cpp:243] Iteration 72800, loss = 3236.54
I1016 22:38:44.701658   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.02246 (* 1 = 6.02246 loss)
I1016 22:38:44.701663   329 solver.cpp:259]     Train net output #1: seg_loss = 2367.37 (* 1 = 2367.37 loss)
I1016 22:38:44.701669   329 sgd_solver.cpp:138] Iteration 72800, lr = 0.000125
I1016 22:39:32.301267   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:39:44.673727   329 solver.cpp:243] Iteration 72900, loss = 2340.57
I1016 22:39:44.673761   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.61082 (* 1 = 3.61082 loss)
I1016 22:39:44.673768   329 solver.cpp:259]     Train net output #1: seg_loss = 2408.47 (* 1 = 2408.47 loss)
I1016 22:39:44.673774   329 sgd_solver.cpp:138] Iteration 72900, lr = 0.000125
I1016 22:40:43.932963   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_73000.caffemodel
I1016 22:40:44.213335   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_73000.solverstate
I1016 22:40:44.782704   329 solver.cpp:243] Iteration 73000, loss = 2683.61
I1016 22:40:44.782752   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.7669 (* 1 = 10.7669 loss)
I1016 22:40:44.782757   329 solver.cpp:259]     Train net output #1: seg_loss = 1923.88 (* 1 = 1923.88 loss)
I1016 22:40:44.782763   329 sgd_solver.cpp:138] Iteration 73000, lr = 0.000125
I1016 22:41:44.554618   329 solver.cpp:243] Iteration 73100, loss = 2142.54
I1016 22:41:44.554651   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.1937 (* 1 = 11.1937 loss)
I1016 22:41:44.554657   329 solver.cpp:259]     Train net output #1: seg_loss = 2211.27 (* 1 = 2211.27 loss)
I1016 22:41:44.554663   329 sgd_solver.cpp:138] Iteration 73100, lr = 0.000125
I1016 22:42:43.662564   329 solver.cpp:243] Iteration 73200, loss = 2744.36
I1016 22:42:43.662598   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.58861 (* 1 = 5.58861 loss)
I1016 22:42:43.662605   329 solver.cpp:259]     Train net output #1: seg_loss = 2907.96 (* 1 = 2907.96 loss)
I1016 22:42:43.662611   329 sgd_solver.cpp:138] Iteration 73200, lr = 0.000125
I1016 22:43:41.959870   329 solver.cpp:243] Iteration 73300, loss = 2141.37
I1016 22:43:41.959920   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.67395 (* 1 = 4.67395 loss)
I1016 22:43:41.959926   329 solver.cpp:259]     Train net output #1: seg_loss = 2030.26 (* 1 = 2030.26 loss)
I1016 22:43:41.959933   329 sgd_solver.cpp:138] Iteration 73300, lr = 0.000125
I1016 22:44:41.768755   329 solver.cpp:243] Iteration 73400, loss = 2909.39
I1016 22:44:41.768805   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.18573 (* 1 = 6.18573 loss)
I1016 22:44:41.768810   329 solver.cpp:259]     Train net output #1: seg_loss = 4314.62 (* 1 = 4314.62 loss)
I1016 22:44:41.768817   329 sgd_solver.cpp:138] Iteration 73400, lr = 0.000125
I1016 22:45:40.527825   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_73500.caffemodel
I1016 22:45:40.820689   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_73500.solverstate
I1016 22:45:41.414252   329 solver.cpp:243] Iteration 73500, loss = 2482.81
I1016 22:45:41.414295   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.42128 (* 1 = 5.42128 loss)
I1016 22:45:41.414301   329 solver.cpp:259]     Train net output #1: seg_loss = 3010.14 (* 1 = 3010.14 loss)
I1016 22:45:41.414307   329 sgd_solver.cpp:138] Iteration 73500, lr = 0.000125
I1016 22:46:41.387183   329 solver.cpp:243] Iteration 73600, loss = 2060.99
I1016 22:46:41.387228   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.98327 (* 1 = 4.98327 loss)
I1016 22:46:41.387234   329 solver.cpp:259]     Train net output #1: seg_loss = 1366.76 (* 1 = 1366.76 loss)
I1016 22:46:41.387240   329 sgd_solver.cpp:138] Iteration 73600, lr = 0.000125
I1016 22:47:40.695958   329 solver.cpp:243] Iteration 73700, loss = 2157.23
I1016 22:47:40.696007   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.13461 (* 1 = 8.13461 loss)
I1016 22:47:40.696013   329 solver.cpp:259]     Train net output #1: seg_loss = 2816.34 (* 1 = 2816.34 loss)
I1016 22:47:40.696019   329 sgd_solver.cpp:138] Iteration 73700, lr = 0.000125
I1016 22:48:40.298912   329 solver.cpp:243] Iteration 73800, loss = 3238.68
I1016 22:48:40.298960   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.7587 (* 1 = 6.7587 loss)
I1016 22:48:40.298966   329 solver.cpp:259]     Train net output #1: seg_loss = 3046.16 (* 1 = 3046.16 loss)
I1016 22:48:40.298972   329 sgd_solver.cpp:138] Iteration 73800, lr = 0.000125
I1016 22:49:28.787119   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:49:39.106086   329 solver.cpp:243] Iteration 73900, loss = 2691.44
I1016 22:49:39.106119   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.49929 (* 1 = 6.49929 loss)
I1016 22:49:39.106124   329 solver.cpp:259]     Train net output #1: seg_loss = 2579.31 (* 1 = 2579.31 loss)
I1016 22:49:39.106132   329 sgd_solver.cpp:138] Iteration 73900, lr = 0.000125
I1016 22:50:38.122365   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_74000.caffemodel
I1016 22:50:38.390651   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_74000.solverstate
I1016 22:50:38.957653   329 solver.cpp:243] Iteration 74000, loss = 2123.73
I1016 22:50:38.957682   329 solver.cpp:259]     Train net output #0: mbox_loss = 2.93938 (* 1 = 2.93938 loss)
I1016 22:50:38.957689   329 solver.cpp:259]     Train net output #1: seg_loss = 1054.36 (* 1 = 1054.36 loss)
I1016 22:50:38.957695   329 sgd_solver.cpp:138] Iteration 74000, lr = 0.000125
I1016 22:51:38.801995   329 solver.cpp:243] Iteration 74100, loss = 3207.83
I1016 22:51:38.802029   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.79376 (* 1 = 3.79376 loss)
I1016 22:51:38.802038   329 solver.cpp:259]     Train net output #1: seg_loss = 2218.8 (* 1 = 2218.8 loss)
I1016 22:51:38.802047   329 sgd_solver.cpp:138] Iteration 74100, lr = 0.000125
I1016 22:52:38.654774   329 solver.cpp:243] Iteration 74200, loss = 2310.63
I1016 22:52:38.654812   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.29481 (* 1 = 7.29481 loss)
I1016 22:52:38.654836   329 solver.cpp:259]     Train net output #1: seg_loss = 3960.39 (* 1 = 3960.39 loss)
I1016 22:52:38.654844   329 sgd_solver.cpp:138] Iteration 74200, lr = 0.000125
I1016 22:53:37.779196   329 solver.cpp:243] Iteration 74300, loss = 2142.46
I1016 22:53:37.779232   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.66812 (* 1 = 8.66812 loss)
I1016 22:53:37.779240   329 solver.cpp:259]     Train net output #1: seg_loss = 2084.07 (* 1 = 2084.07 loss)
I1016 22:53:37.779263   329 sgd_solver.cpp:138] Iteration 74300, lr = 0.000125
I1016 22:54:35.915058   329 solver.cpp:243] Iteration 74400, loss = 2524.87
I1016 22:54:35.915096   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.22548 (* 1 = 7.22548 loss)
I1016 22:54:35.915104   329 solver.cpp:259]     Train net output #1: seg_loss = 2931.41 (* 1 = 2931.41 loss)
I1016 22:54:35.915112   329 sgd_solver.cpp:138] Iteration 74400, lr = 0.000125
I1016 22:55:35.303336   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_74500.caffemodel
I1016 22:55:35.587213   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_74500.solverstate
I1016 22:55:36.189718   329 solver.cpp:243] Iteration 74500, loss = 2238.16
I1016 22:55:36.189748   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.03721 (* 1 = 9.03721 loss)
I1016 22:55:36.189754   329 solver.cpp:259]     Train net output #1: seg_loss = 843.977 (* 1 = 843.977 loss)
I1016 22:55:36.189760   329 sgd_solver.cpp:138] Iteration 74500, lr = 0.000125
I1016 22:56:35.405742   329 solver.cpp:243] Iteration 74600, loss = 1793.73
I1016 22:56:35.405776   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.53574 (* 1 = 5.53574 loss)
I1016 22:56:35.405782   329 solver.cpp:259]     Train net output #1: seg_loss = 1851.49 (* 1 = 1851.49 loss)
I1016 22:56:35.405788   329 sgd_solver.cpp:138] Iteration 74600, lr = 0.000125
I1016 22:57:35.733702   329 solver.cpp:243] Iteration 74700, loss = 2625.76
I1016 22:57:35.733733   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.24892 (* 1 = 4.24892 loss)
I1016 22:57:35.733739   329 solver.cpp:259]     Train net output #1: seg_loss = 1642.81 (* 1 = 1642.81 loss)
I1016 22:57:35.733745   329 sgd_solver.cpp:138] Iteration 74700, lr = 0.000125
I1016 22:58:34.854938   329 solver.cpp:243] Iteration 74800, loss = 2676.08
I1016 22:58:34.854971   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.0077 (* 1 = 5.0077 loss)
I1016 22:58:34.854977   329 solver.cpp:259]     Train net output #1: seg_loss = 1814.37 (* 1 = 1814.37 loss)
I1016 22:58:34.854984   329 sgd_solver.cpp:138] Iteration 74800, lr = 0.000125
I1016 22:59:26.372833   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 22:59:33.777997   329 solver.cpp:243] Iteration 74900, loss = 2448.42
I1016 22:59:33.778031   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.39331 (* 1 = 5.39331 loss)
I1016 22:59:33.778038   329 solver.cpp:259]     Train net output #1: seg_loss = 2828.93 (* 1 = 2828.93 loss)
I1016 22:59:33.778043   329 sgd_solver.cpp:138] Iteration 74900, lr = 0.000125
I1016 23:00:32.420367   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_75000.caffemodel
I1016 23:00:32.716205   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_75000.solverstate
I1016 23:00:33.363575   329 solver.cpp:243] Iteration 75000, loss = 4287.27
I1016 23:00:33.363623   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.29603 (* 1 = 6.29603 loss)
I1016 23:00:33.363629   329 solver.cpp:259]     Train net output #1: seg_loss = 5578.87 (* 1 = 5578.87 loss)
I1016 23:00:33.363636   329 sgd_solver.cpp:138] Iteration 75000, lr = 0.000125
I1016 23:01:32.442031   329 solver.cpp:243] Iteration 75100, loss = 2268.76
I1016 23:01:32.442065   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.38716 (* 1 = 4.38716 loss)
I1016 23:01:32.442070   329 solver.cpp:259]     Train net output #1: seg_loss = 1863.17 (* 1 = 1863.17 loss)
I1016 23:01:32.442076   329 sgd_solver.cpp:138] Iteration 75100, lr = 0.000125
I1016 23:02:32.517256   329 solver.cpp:243] Iteration 75200, loss = 2461.26
I1016 23:02:32.517290   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.30013 (* 1 = 3.30013 loss)
I1016 23:02:32.517297   329 solver.cpp:259]     Train net output #1: seg_loss = 2382.86 (* 1 = 2382.86 loss)
I1016 23:02:32.517302   329 sgd_solver.cpp:138] Iteration 75200, lr = 0.000125
I1016 23:03:32.358006   329 solver.cpp:243] Iteration 75300, loss = 3169.12
I1016 23:03:32.358039   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.90677 (* 1 = 6.90677 loss)
I1016 23:03:32.358044   329 solver.cpp:259]     Train net output #1: seg_loss = 2772.75 (* 1 = 2772.75 loss)
I1016 23:03:32.358050   329 sgd_solver.cpp:138] Iteration 75300, lr = 0.000125
I1016 23:04:31.501436   329 solver.cpp:243] Iteration 75400, loss = 2590.37
I1016 23:04:31.501485   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.74005 (* 1 = 6.74005 loss)
I1016 23:04:31.501492   329 solver.cpp:259]     Train net output #1: seg_loss = 2666.08 (* 1 = 2666.08 loss)
I1016 23:04:31.501497   329 sgd_solver.cpp:138] Iteration 75400, lr = 0.000125
I1016 23:05:29.348114   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_75500.caffemodel
I1016 23:05:29.641667   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_75500.solverstate
I1016 23:05:30.240089   329 solver.cpp:243] Iteration 75500, loss = 3479.2
I1016 23:05:30.240130   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.0966 (* 1 = 7.0966 loss)
I1016 23:05:30.240137   329 solver.cpp:259]     Train net output #1: seg_loss = 5111.39 (* 1 = 5111.39 loss)
I1016 23:05:30.240144   329 sgd_solver.cpp:138] Iteration 75500, lr = 0.000125
I1016 23:06:29.688961   329 solver.cpp:243] Iteration 75600, loss = 2223.36
I1016 23:06:29.688994   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.4802 (* 1 = 5.4802 loss)
I1016 23:06:29.689002   329 solver.cpp:259]     Train net output #1: seg_loss = 2721.07 (* 1 = 2721.07 loss)
I1016 23:06:29.689007   329 sgd_solver.cpp:138] Iteration 75600, lr = 0.000125
I1016 23:07:29.414880   329 solver.cpp:243] Iteration 75700, loss = 2475.73
I1016 23:07:29.414923   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.70803 (* 1 = 9.70803 loss)
I1016 23:07:29.414930   329 solver.cpp:259]     Train net output #1: seg_loss = 3263.15 (* 1 = 3263.15 loss)
I1016 23:07:29.414937   329 sgd_solver.cpp:138] Iteration 75700, lr = 0.000125
I1016 23:08:29.462182   329 solver.cpp:243] Iteration 75800, loss = 2371.92
I1016 23:08:29.462229   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.35843 (* 1 = 7.35843 loss)
I1016 23:08:29.462236   329 solver.cpp:259]     Train net output #1: seg_loss = 2041.2 (* 1 = 2041.2 loss)
I1016 23:08:29.462242   329 sgd_solver.cpp:138] Iteration 75800, lr = 0.000125
I1016 23:09:24.513402   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 23:09:28.604522   329 solver.cpp:243] Iteration 75900, loss = 2679.34
I1016 23:09:28.604557   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.34021 (* 1 = 4.34021 loss)
I1016 23:09:28.604563   329 solver.cpp:259]     Train net output #1: seg_loss = 2499.67 (* 1 = 2499.67 loss)
I1016 23:09:28.604569   329 sgd_solver.cpp:138] Iteration 75900, lr = 0.000125
I1016 23:10:26.524780   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_76000.caffemodel
I1016 23:10:26.785912   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_76000.solverstate
I1016 23:10:26.962098   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 23:12:03.871191   329 solver.cpp:243] Iteration 76000, loss = 2029.27
I1016 23:12:03.871230   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.67126 (* 1 = 6.67126 loss)
I1016 23:12:03.871237   329 solver.cpp:259]     Train net output #1: seg_loss = 2022.6 (* 1 = 2022.6 loss)
I1016 23:12:03.871244   329 sgd_solver.cpp:138] Iteration 76000, lr = 0.000125
I1016 23:13:02.352459   329 solver.cpp:243] Iteration 76100, loss = 2465.82
I1016 23:13:02.352507   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.58017 (* 1 = 6.58017 loss)
I1016 23:13:02.352514   329 solver.cpp:259]     Train net output #1: seg_loss = 1991.54 (* 1 = 1991.54 loss)
I1016 23:13:02.352520   329 sgd_solver.cpp:138] Iteration 76100, lr = 0.000125
I1016 23:14:01.512629   329 solver.cpp:243] Iteration 76200, loss = 2099.73
I1016 23:14:01.512661   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.88746 (* 1 = 7.88746 loss)
I1016 23:14:01.512667   329 solver.cpp:259]     Train net output #1: seg_loss = 2350.52 (* 1 = 2350.52 loss)
I1016 23:14:01.512673   329 sgd_solver.cpp:138] Iteration 76200, lr = 0.000125
I1016 23:15:01.823598   329 solver.cpp:243] Iteration 76300, loss = 2940.04
I1016 23:15:01.823645   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.54572 (* 1 = 3.54572 loss)
I1016 23:15:01.823652   329 solver.cpp:259]     Train net output #1: seg_loss = 2315.18 (* 1 = 2315.18 loss)
I1016 23:15:01.823657   329 sgd_solver.cpp:138] Iteration 76300, lr = 0.000125
I1016 23:16:01.434429   329 solver.cpp:243] Iteration 76400, loss = 2435.69
I1016 23:16:01.434461   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.84804 (* 1 = 4.84804 loss)
I1016 23:16:01.434468   329 solver.cpp:259]     Train net output #1: seg_loss = 2773.89 (* 1 = 2773.89 loss)
I1016 23:16:01.434473   329 sgd_solver.cpp:138] Iteration 76400, lr = 0.000125
I1016 23:16:03.823904   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 23:17:00.249270   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_76500.caffemodel
I1016 23:17:00.551338   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_76500.solverstate
I1016 23:17:01.138123   329 solver.cpp:243] Iteration 76500, loss = 2530.36
I1016 23:17:01.138152   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.65468 (* 1 = 3.65468 loss)
I1016 23:17:01.138159   329 solver.cpp:259]     Train net output #1: seg_loss = 3484.01 (* 1 = 3484.01 loss)
I1016 23:17:01.138165   329 sgd_solver.cpp:138] Iteration 76500, lr = 0.000125
I1016 23:17:59.333168   329 solver.cpp:243] Iteration 76600, loss = 2423.84
I1016 23:17:59.333214   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.28174 (* 1 = 8.28174 loss)
I1016 23:17:59.333220   329 solver.cpp:259]     Train net output #1: seg_loss = 2060.07 (* 1 = 2060.07 loss)
I1016 23:17:59.333226   329 sgd_solver.cpp:138] Iteration 76600, lr = 0.000125
I1016 23:18:58.868468   329 solver.cpp:243] Iteration 76700, loss = 2207.48
I1016 23:18:58.868517   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.67508 (* 1 = 5.67508 loss)
I1016 23:18:58.868523   329 solver.cpp:259]     Train net output #1: seg_loss = 2085.09 (* 1 = 2085.09 loss)
I1016 23:18:58.868530   329 sgd_solver.cpp:138] Iteration 76700, lr = 0.000125
I1016 23:19:58.733590   329 solver.cpp:243] Iteration 76800, loss = 2501.32
I1016 23:19:58.733623   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.65447 (* 1 = 8.65447 loss)
I1016 23:19:58.733629   329 solver.cpp:259]     Train net output #1: seg_loss = 1584.34 (* 1 = 1584.34 loss)
I1016 23:19:58.733636   329 sgd_solver.cpp:138] Iteration 76800, lr = 0.000125
I1016 23:20:58.737298   329 solver.cpp:243] Iteration 76900, loss = 2170.03
I1016 23:20:58.737344   329 solver.cpp:259]     Train net output #0: mbox_loss = 11.1693 (* 1 = 11.1693 loss)
I1016 23:20:58.737351   329 solver.cpp:259]     Train net output #1: seg_loss = 2181.6 (* 1 = 2181.6 loss)
I1016 23:20:58.737360   329 sgd_solver.cpp:138] Iteration 76900, lr = 0.000125
I1016 23:21:57.366902   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_77000.caffemodel
I1016 23:21:57.657833   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_77000.solverstate
I1016 23:21:58.239831   329 solver.cpp:243] Iteration 77000, loss = 2363.35
I1016 23:21:58.239876   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.3868 (* 1 = 5.3868 loss)
I1016 23:21:58.239881   329 solver.cpp:259]     Train net output #1: seg_loss = 2444.48 (* 1 = 2444.48 loss)
I1016 23:21:58.239887   329 sgd_solver.cpp:138] Iteration 77000, lr = 0.000125
I1016 23:22:56.098762   329 solver.cpp:243] Iteration 77100, loss = 2418.78
I1016 23:22:56.098812   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.63062 (* 1 = 4.63062 loss)
I1016 23:22:56.098819   329 solver.cpp:259]     Train net output #1: seg_loss = 2778.29 (* 1 = 2778.29 loss)
I1016 23:22:56.098824   329 sgd_solver.cpp:138] Iteration 77100, lr = 0.000125
I1016 23:23:56.100767   329 solver.cpp:243] Iteration 77200, loss = 2600.17
I1016 23:23:56.100817   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.98304 (* 1 = 8.98304 loss)
I1016 23:23:56.100822   329 solver.cpp:259]     Train net output #1: seg_loss = 2946.82 (* 1 = 2946.82 loss)
I1016 23:23:56.100829   329 sgd_solver.cpp:138] Iteration 77200, lr = 0.000125
I1016 23:24:55.676314   329 solver.cpp:243] Iteration 77300, loss = 2662.33
I1016 23:24:55.676345   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.03343 (* 1 = 6.03343 loss)
I1016 23:24:55.676352   329 solver.cpp:259]     Train net output #1: seg_loss = 2649.76 (* 1 = 2649.76 loss)
I1016 23:24:55.676358   329 sgd_solver.cpp:138] Iteration 77300, lr = 0.000125
I1016 23:25:56.073803   329 solver.cpp:243] Iteration 77400, loss = 1823.04
I1016 23:25:56.073853   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.27666 (* 1 = 8.27666 loss)
I1016 23:25:56.073860   329 solver.cpp:259]     Train net output #1: seg_loss = 2183.85 (* 1 = 2183.85 loss)
I1016 23:25:56.073866   329 sgd_solver.cpp:138] Iteration 77400, lr = 0.000125
I1016 23:26:01.032912   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 23:26:54.785549   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_77500.caffemodel
I1016 23:26:55.096321   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_77500.solverstate
I1016 23:26:55.667953   329 solver.cpp:243] Iteration 77500, loss = 2664.8
I1016 23:26:55.667996   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.97965 (* 1 = 5.97965 loss)
I1016 23:26:55.668002   329 solver.cpp:259]     Train net output #1: seg_loss = 2333.15 (* 1 = 2333.15 loss)
I1016 23:26:55.668009   329 sgd_solver.cpp:138] Iteration 77500, lr = 0.000125
I1016 23:27:54.449956   329 solver.cpp:243] Iteration 77600, loss = 2790.61
I1016 23:27:54.449988   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.6599 (* 1 = 4.6599 loss)
I1016 23:27:54.449995   329 solver.cpp:259]     Train net output #1: seg_loss = 4097.98 (* 1 = 4097.98 loss)
I1016 23:27:54.450001   329 sgd_solver.cpp:138] Iteration 77600, lr = 0.000125
I1016 23:28:53.339699   329 solver.cpp:243] Iteration 77700, loss = 3633.34
I1016 23:28:53.339731   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.15949 (* 1 = 8.15949 loss)
I1016 23:28:53.339737   329 solver.cpp:259]     Train net output #1: seg_loss = 3423.31 (* 1 = 3423.31 loss)
I1016 23:28:53.339743   329 sgd_solver.cpp:138] Iteration 77700, lr = 0.000125
I1016 23:29:52.714056   329 solver.cpp:243] Iteration 77800, loss = 1938.75
I1016 23:29:52.714088   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.6781 (* 1 = 4.6781 loss)
I1016 23:29:52.714095   329 solver.cpp:259]     Train net output #1: seg_loss = 2019.84 (* 1 = 2019.84 loss)
I1016 23:29:52.714102   329 sgd_solver.cpp:138] Iteration 77800, lr = 0.000125
I1016 23:30:52.688930   329 solver.cpp:243] Iteration 77900, loss = 2737.82
I1016 23:30:52.688966   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.15111 (* 1 = 4.15111 loss)
I1016 23:30:52.688971   329 solver.cpp:259]     Train net output #1: seg_loss = 2523.1 (* 1 = 2523.1 loss)
I1016 23:30:52.688978   329 sgd_solver.cpp:138] Iteration 77900, lr = 0.000125
I1016 23:31:52.012414   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_78000.caffemodel
I1016 23:31:52.288199   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_78000.solverstate
I1016 23:31:52.892042   329 solver.cpp:243] Iteration 78000, loss = 3017.32
I1016 23:31:52.892087   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.76154 (* 1 = 8.76154 loss)
I1016 23:31:52.892093   329 solver.cpp:259]     Train net output #1: seg_loss = 3371.61 (* 1 = 3371.61 loss)
I1016 23:31:52.892099   329 sgd_solver.cpp:138] Iteration 78000, lr = 0.000125
I1016 23:32:51.636893   329 solver.cpp:243] Iteration 78100, loss = 2006.48
I1016 23:32:51.636941   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.27739 (* 1 = 6.27739 loss)
I1016 23:32:51.636948   329 solver.cpp:259]     Train net output #1: seg_loss = 2550.97 (* 1 = 2550.97 loss)
I1016 23:32:51.636955   329 sgd_solver.cpp:138] Iteration 78100, lr = 0.000125
I1016 23:33:49.935762   329 solver.cpp:243] Iteration 78200, loss = 2519.91
I1016 23:33:49.935797   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.06778 (* 1 = 5.06778 loss)
I1016 23:33:49.935804   329 solver.cpp:259]     Train net output #1: seg_loss = 2180.47 (* 1 = 2180.47 loss)
I1016 23:33:49.935809   329 sgd_solver.cpp:138] Iteration 78200, lr = 0.000125
I1016 23:34:49.722302   329 solver.cpp:243] Iteration 78300, loss = 2086.05
I1016 23:34:49.722352   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.18179 (* 1 = 4.18179 loss)
I1016 23:34:49.722358   329 solver.cpp:259]     Train net output #1: seg_loss = 2036.33 (* 1 = 2036.33 loss)
I1016 23:34:49.722363   329 sgd_solver.cpp:138] Iteration 78300, lr = 0.000125
I1016 23:35:49.371738   329 solver.cpp:243] Iteration 78400, loss = 2587
I1016 23:35:49.371783   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.76817 (* 1 = 7.76817 loss)
I1016 23:35:49.371788   329 solver.cpp:259]     Train net output #1: seg_loss = 2746.61 (* 1 = 2746.61 loss)
I1016 23:35:49.371794   329 sgd_solver.cpp:138] Iteration 78400, lr = 0.000125
I1016 23:35:57.281570   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 23:36:49.050776   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_78500.caffemodel
I1016 23:36:49.363945   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_78500.solverstate
I1016 23:36:49.948719   329 solver.cpp:243] Iteration 78500, loss = 2491.09
I1016 23:36:49.948766   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.85496 (* 1 = 6.85496 loss)
I1016 23:36:49.948772   329 solver.cpp:259]     Train net output #1: seg_loss = 2251.92 (* 1 = 2251.92 loss)
I1016 23:36:49.948777   329 sgd_solver.cpp:138] Iteration 78500, lr = 0.000125
I1016 23:37:48.771778   329 solver.cpp:243] Iteration 78600, loss = 2674.85
I1016 23:37:48.771826   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.60589 (* 1 = 6.60589 loss)
I1016 23:37:48.771831   329 solver.cpp:259]     Train net output #1: seg_loss = 2758.64 (* 1 = 2758.64 loss)
I1016 23:37:48.771836   329 sgd_solver.cpp:138] Iteration 78600, lr = 0.000125
I1016 23:38:47.530956   329 solver.cpp:243] Iteration 78700, loss = 2525.75
I1016 23:38:47.531002   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.20307 (* 1 = 5.20307 loss)
I1016 23:38:47.531008   329 solver.cpp:259]     Train net output #1: seg_loss = 2778.53 (* 1 = 2778.53 loss)
I1016 23:38:47.531014   329 sgd_solver.cpp:138] Iteration 78700, lr = 0.000125
I1016 23:39:46.880409   329 solver.cpp:243] Iteration 78800, loss = 3014.19
I1016 23:39:46.880441   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.63105 (* 1 = 4.63105 loss)
I1016 23:39:46.880448   329 solver.cpp:259]     Train net output #1: seg_loss = 1821.5 (* 1 = 1821.5 loss)
I1016 23:39:46.880455   329 sgd_solver.cpp:138] Iteration 78800, lr = 0.000125
I1016 23:40:46.066679   329 solver.cpp:243] Iteration 78900, loss = 2196.23
I1016 23:40:46.066716   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.16941 (* 1 = 7.16941 loss)
I1016 23:40:46.066725   329 solver.cpp:259]     Train net output #1: seg_loss = 1710.5 (* 1 = 1710.5 loss)
I1016 23:40:46.066748   329 sgd_solver.cpp:138] Iteration 78900, lr = 0.000125
I1016 23:41:45.539196   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_79000.caffemodel
I1016 23:41:45.841053   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_79000.solverstate
I1016 23:41:46.427836   329 solver.cpp:243] Iteration 79000, loss = 2764.21
I1016 23:41:46.427884   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.213 (* 1 = 5.213 loss)
I1016 23:41:46.427891   329 solver.cpp:259]     Train net output #1: seg_loss = 3172.63 (* 1 = 3172.63 loss)
I1016 23:41:46.427896   329 sgd_solver.cpp:138] Iteration 79000, lr = 0.000125
I1016 23:42:46.069679   329 solver.cpp:243] Iteration 79100, loss = 2360.54
I1016 23:42:46.069712   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.1051 (* 1 = 10.1051 loss)
I1016 23:42:46.069718   329 solver.cpp:259]     Train net output #1: seg_loss = 1977.6 (* 1 = 1977.6 loss)
I1016 23:42:46.069725   329 sgd_solver.cpp:138] Iteration 79100, lr = 0.000125
I1016 23:43:45.067189   329 solver.cpp:243] Iteration 79200, loss = 2355.63
I1016 23:43:45.067237   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.52311 (* 1 = 6.52311 loss)
I1016 23:43:45.067243   329 solver.cpp:259]     Train net output #1: seg_loss = 2341.58 (* 1 = 2341.58 loss)
I1016 23:43:45.067250   329 sgd_solver.cpp:138] Iteration 79200, lr = 0.000125
I1016 23:44:43.486968   329 solver.cpp:243] Iteration 79300, loss = 3363.21
I1016 23:44:43.487015   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.62766 (* 1 = 7.62766 loss)
I1016 23:44:43.487022   329 solver.cpp:259]     Train net output #1: seg_loss = 1921.07 (* 1 = 1921.07 loss)
I1016 23:44:43.487028   329 sgd_solver.cpp:138] Iteration 79300, lr = 0.000125
I1016 23:45:43.200661   329 solver.cpp:243] Iteration 79400, loss = 2227.57
I1016 23:45:43.200712   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.15899 (* 1 = 6.15899 loss)
I1016 23:45:43.200718   329 solver.cpp:259]     Train net output #1: seg_loss = 1812.83 (* 1 = 1812.83 loss)
I1016 23:45:43.200724   329 sgd_solver.cpp:138] Iteration 79400, lr = 0.000125
I1016 23:45:53.854691   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 23:46:42.390563   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_79500.caffemodel
I1016 23:46:42.672013   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_79500.solverstate
I1016 23:46:43.271584   329 solver.cpp:243] Iteration 79500, loss = 2623.09
I1016 23:46:43.271618   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.9636 (* 1 = 5.9636 loss)
I1016 23:46:43.271625   329 solver.cpp:259]     Train net output #1: seg_loss = 2688.95 (* 1 = 2688.95 loss)
I1016 23:46:43.271631   329 sgd_solver.cpp:138] Iteration 79500, lr = 0.000125
I1016 23:47:43.081266   329 solver.cpp:243] Iteration 79600, loss = 2073.46
I1016 23:47:43.081315   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.99611 (* 1 = 4.99611 loss)
I1016 23:47:43.081321   329 solver.cpp:259]     Train net output #1: seg_loss = 1848.8 (* 1 = 1848.8 loss)
I1016 23:47:43.081328   329 sgd_solver.cpp:138] Iteration 79600, lr = 0.000125
I1016 23:48:42.272176   329 solver.cpp:243] Iteration 79700, loss = 2532.73
I1016 23:48:42.272219   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.03418 (* 1 = 5.03418 loss)
I1016 23:48:42.272225   329 solver.cpp:259]     Train net output #1: seg_loss = 3383.04 (* 1 = 3383.04 loss)
I1016 23:48:42.272233   329 sgd_solver.cpp:138] Iteration 79700, lr = 0.000125
I1016 23:49:40.532968   329 solver.cpp:243] Iteration 79800, loss = 2220.42
I1016 23:49:40.533004   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.244 (* 1 = 3.244 loss)
I1016 23:49:40.533011   329 solver.cpp:259]     Train net output #1: seg_loss = 3013.39 (* 1 = 3013.39 loss)
I1016 23:49:40.533035   329 sgd_solver.cpp:138] Iteration 79800, lr = 0.000125
I1016 23:50:40.233894   329 solver.cpp:243] Iteration 79900, loss = 2774.83
I1016 23:50:40.233929   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.14848 (* 1 = 8.14848 loss)
I1016 23:50:40.233938   329 solver.cpp:259]     Train net output #1: seg_loss = 2991.25 (* 1 = 2991.25 loss)
I1016 23:50:40.233947   329 sgd_solver.cpp:138] Iteration 79900, lr = 0.000125
I1016 23:51:39.024982   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_80000.caffemodel
I1016 23:51:39.349508   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_80000.solverstate
I1016 23:51:39.542678   329 net.cpp:693] Ignoring source layer mbox_loss
I1016 23:53:02.305953   329 blocking_queue.cpp:50] Data layer prefetch queue empty
>>> 2018-10-16 10:37:10.282761 Begin seg tests
>>> 2018-10-16 10:38:48.683855 Iteration 4000 loss 29646.367727539062
>>> 2018-10-16 10:38:48.685325 Iteration 4000 overall accuracy 0.94747109375
>>> 2018-10-16 10:38:48.685370 Iteration 4000 mean accuracy 0.9431295232719492
>>> 2018-10-16 10:38:48.685628 Iteration 4000 mean IU 0.8896614016821923
>>> 2018-10-16 10:38:48.685704 Iteration 4000 fwavacc 0.9009317904063963
>>> 2018-10-16 11:19:26.379681 Begin seg tests
>>> 2018-10-16 11:21:04.403373 Iteration 8000 loss 55919.18411230469
>>> 2018-10-16 11:21:04.403450 Iteration 8000 overall accuracy 0.9452963151041667
>>> 2018-10-16 11:21:04.403479 Iteration 8000 mean accuracy 0.9312104234783956
>>> 2018-10-16 11:21:04.403603 Iteration 8000 mean IU 0.8843766176171223
>>> 2018-10-16 11:21:04.403672 Iteration 8000 fwavacc 0.8960648247382802
>>> 2018-10-16 12:02:26.925890 Begin seg tests
>>> 2018-10-16 12:04:06.826521 Iteration 12000 loss 83487.5482138672
>>> 2018-10-16 12:04:06.826597 Iteration 12000 overall accuracy 0.9515099739583334
>>> 2018-10-16 12:04:06.826625 Iteration 12000 mean accuracy 0.9415568319818518
>>> 2018-10-16 12:04:06.828416 Iteration 12000 mean IU 0.8979102638896157
>>> 2018-10-16 12:04:06.828501 Iteration 12000 fwavacc 0.9075168591593084
>>> 2018-10-16 12:45:10.644609 Begin seg tests
>>> 2018-10-16 12:46:51.260412 Iteration 16000 loss 48360.72432910156
>>> 2018-10-16 12:46:51.260488 Iteration 16000 overall accuracy 0.9588885026041667
>>> 2018-10-16 12:46:51.260517 Iteration 16000 mean accuracy 0.9564735012528229
>>> 2018-10-16 12:46:51.260642 Iteration 16000 mean IU 0.9122348575118557
>>> 2018-10-16 12:46:51.260710 Iteration 16000 fwavacc 0.9215934565270638
>>> 2018-10-16 13:26:54.488650 Begin seg tests
>>> 2018-10-16 13:28:31.747594 Iteration 20000 loss 171832.51328515625
>>> 2018-10-16 13:28:31.747667 Iteration 20000 overall accuracy 0.9467923307291667
>>> 2018-10-16 13:28:31.747695 Iteration 20000 mean accuracy 0.9382878622275858
>>> 2018-10-16 13:28:31.749496 Iteration 20000 mean IU 0.889779637143364
>>> 2018-10-16 13:28:31.749581 Iteration 20000 fwavacc 0.8991012523900631
>>> 2018-10-16 14:08:12.524757 Begin seg tests
>>> 2018-10-16 14:09:51.180812 Iteration 24000 loss 78994.77294580078
>>> 2018-10-16 14:09:51.183470 Iteration 24000 overall accuracy 0.95628046875
>>> 2018-10-16 14:09:51.183813 Iteration 24000 mean accuracy 0.9560395047065853
>>> 2018-10-16 14:09:51.186152 Iteration 24000 mean IU 0.9078789917647693
>>> 2018-10-16 14:09:51.186230 Iteration 24000 fwavacc 0.9169675830084802
>>> 2018-10-16 14:49:34.380665 Begin seg tests
>>> 2018-10-16 14:51:11.594480 Iteration 28000 loss 133426.42102441407
>>> 2018-10-16 14:51:11.594599 Iteration 28000 overall accuracy 0.9490333723958333
>>> 2018-10-16 14:51:11.594628 Iteration 28000 mean accuracy 0.9333457462798925
>>> 2018-10-16 14:51:11.596554 Iteration 28000 mean IU 0.8915593514388209
>>> 2018-10-16 14:51:11.596638 Iteration 28000 fwavacc 0.9025549157627738
>>> 2018-10-16 15:30:52.723192 Begin seg tests
>>> 2018-10-16 15:32:31.304088 Iteration 32000 loss 97524.70586376953
>>> 2018-10-16 15:32:31.304164 Iteration 32000 overall accuracy 0.9570357942708333
>>> 2018-10-16 15:32:31.304192 Iteration 32000 mean accuracy 0.9477190069401864
>>> 2018-10-16 15:32:31.304316 Iteration 32000 mean IU 0.9082720825065536
>>> 2018-10-16 15:32:31.304385 Iteration 32000 fwavacc 0.9176521062762545
>>> 2018-10-16 16:12:24.411491 Begin seg tests
>>> 2018-10-16 16:14:02.036644 Iteration 36000 loss 128909.99970605469
>>> 2018-10-16 16:14:02.041082 Iteration 36000 overall accuracy 0.954458359375
>>> 2018-10-16 16:14:02.041385 Iteration 36000 mean accuracy 0.9463531987082582
>>> 2018-10-16 16:14:02.045604 Iteration 36000 mean IU 0.9037609394957898
>>> 2018-10-16 16:14:02.045682 Iteration 36000 fwavacc 0.9130289605334516
>>> 2018-10-16 16:54:02.407891 Begin seg tests
>>> 2018-10-16 16:55:40.663560 Iteration 40000 loss 121891.80098730468
>>> 2018-10-16 16:55:40.663640 Iteration 40000 overall accuracy 0.9592639192708333
>>> 2018-10-16 16:55:40.663669 Iteration 40000 mean accuracy 0.9527501596495642
>>> 2018-10-16 16:55:40.664401 Iteration 40000 mean IU 0.9133903204155998
>>> 2018-10-16 16:55:40.664475 Iteration 40000 fwavacc 0.9219068134046555
>>> 2018-10-16 17:35:54.051931 Begin seg tests
>>> 2018-10-16 17:37:30.717742 Iteration 44000 loss 118753.93934472656
>>> 2018-10-16 17:37:30.719550 Iteration 44000 overall accuracy 0.9587223958333333
>>> 2018-10-16 17:37:30.719867 Iteration 44000 mean accuracy 0.9526471272408235
>>> 2018-10-16 17:37:30.720938 Iteration 44000 mean IU 0.911748574886756
>>> 2018-10-16 17:37:30.721011 Iteration 44000 fwavacc 0.9210065898425825
>>> 2018-10-16 18:16:45.711014 Begin seg tests
>>> 2018-10-16 18:18:22.275663 Iteration 48000 loss 172374.76483789063
>>> 2018-10-16 18:18:22.275733 Iteration 48000 overall accuracy 0.9527120442708333
>>> 2018-10-16 18:18:22.275761 Iteration 48000 mean accuracy 0.9461650396511604
>>> 2018-10-16 18:18:22.275874 Iteration 48000 mean IU 0.9016474733634403
>>> 2018-10-16 18:18:22.275943 Iteration 48000 fwavacc 0.9098900878546179
>>> 2018-10-16 18:58:08.659835 Begin seg tests
>>> 2018-10-16 18:59:47.192157 Iteration 52000 loss 112069.18858886718
>>> 2018-10-16 18:59:47.192231 Iteration 52000 overall accuracy 0.958324140625
>>> 2018-10-16 18:59:47.192259 Iteration 52000 mean accuracy 0.9502351093495938
>>> 2018-10-16 18:59:47.192382 Iteration 52000 mean IU 0.9105210659865746
>>> 2018-10-16 18:59:47.192450 Iteration 52000 fwavacc 0.9201446671650874
>>> 2018-10-16 19:39:24.714554 Begin seg tests
>>> 2018-10-16 19:41:01.912583 Iteration 56000 loss 148383.8485908203
>>> 2018-10-16 19:41:01.913701 Iteration 56000 overall accuracy 0.9560766276041667
>>> 2018-10-16 19:41:01.913774 Iteration 56000 mean accuracy 0.9494840829093911
>>> 2018-10-16 19:41:01.915493 Iteration 56000 mean IU 0.9071091863395122
>>> 2018-10-16 19:41:01.915567 Iteration 56000 fwavacc 0.9160911596745467
>>> 2018-10-16 20:22:59.462901 Begin seg tests
>>> 2018-10-16 20:24:41.961782 Iteration 60000 loss 163956.3560205078
>>> 2018-10-16 20:24:41.961865 Iteration 60000 overall accuracy 0.9552691666666666
>>> 2018-10-16 20:24:41.961903 Iteration 60000 mean accuracy 0.9475173326290283
>>> 2018-10-16 20:24:41.963547 Iteration 60000 mean IU 0.9057400523091728
>>> 2018-10-16 20:24:41.963628 Iteration 60000 fwavacc 0.9144938401640113
>>> 2018-10-16 21:06:19.388161 Begin seg tests
>>> 2018-10-16 21:08:01.691368 Iteration 64000 loss 96898.72302636718
>>> 2018-10-16 21:08:01.691436 Iteration 64000 overall accuracy 0.961459921875
>>> 2018-10-16 21:08:01.691464 Iteration 64000 mean accuracy 0.9581953966414105
>>> 2018-10-16 21:08:01.692339 Iteration 64000 mean IU 0.917300049755764
>>> 2018-10-16 21:08:01.692413 Iteration 64000 fwavacc 0.9262235872184019
>>> 2018-10-16 21:47:53.939841 Begin seg tests
>>> 2018-10-16 21:49:31.132565 Iteration 68000 loss 216555.17129492186
>>> 2018-10-16 21:49:31.132642 Iteration 68000 overall accuracy 0.9503451692708333
>>> 2018-10-16 21:49:31.132671 Iteration 68000 mean accuracy 0.9410106353536367
>>> 2018-10-16 21:49:31.132793 Iteration 68000 mean IU 0.8964999254975707
>>> 2018-10-16 21:49:31.132861 Iteration 68000 fwavacc 0.9053877176442913
>>> 2018-10-16 22:29:13.078687 Begin seg tests
>>> 2018-10-16 22:30:51.031031 Iteration 72000 loss 126010.21501855469
>>> 2018-10-16 22:30:51.031103 Iteration 72000 overall accuracy 0.9582129817708334
>>> 2018-10-16 22:30:51.031131 Iteration 72000 mean accuracy 0.9563991627533779
>>> 2018-10-16 22:30:51.031249 Iteration 72000 mean IU 0.9114757196792979
>>> 2018-10-16 22:30:51.031317 Iteration 72000 fwavacc 0.920362596419978
>>> 2018-10-16 23:10:26.961868 Begin seg tests
>>> 2018-10-16 23:12:03.473931 Iteration 76000 loss 199854.82058300782
>>> 2018-10-16 23:12:03.474003 Iteration 76000 overall accuracy 0.952355390625
>>> 2018-10-16 23:12:03.474030 Iteration 76000 mean accuracy 0.9428130357589325
>>> 2018-10-16 23:12:03.474144 Iteration 76000 mean IU 0.899373938409759
>>> 2018-10-16 23:12:03.474223 Iteration 76000 fwavacc 0.9091077671706981
>>> 2018-10-16 23:51:39.542393 Begin seg tests
>>> 2018-10-16 23:53:17.230794 Iteration 80000I1016 23:53:17.634469   329 solver.cpp:243] Iteration 80000, loss = 2609.14
I1016 23:53:17.634502   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.53531 (* 1 = 5.53531 loss)
I1016 23:53:17.634508   329 solver.cpp:259]     Train net output #1: seg_loss = 2603.61 (* 1 = 2603.61 loss)
I1016 23:53:17.634515   329 sgd_solver.cpp:138] Iteration 80000, lr = 0.000125
I1016 23:54:16.638605   329 solver.cpp:243] Iteration 80100, loss = 2115.72
I1016 23:54:16.638653   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.36807 (* 1 = 5.36807 loss)
I1016 23:54:16.638660   329 solver.cpp:259]     Train net output #1: seg_loss = 1860.17 (* 1 = 1860.17 loss)
I1016 23:54:16.638666   329 sgd_solver.cpp:138] Iteration 80100, lr = 0.000125
I1016 23:55:15.852640   329 solver.cpp:243] Iteration 80200, loss = 2044.39
I1016 23:55:15.852687   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.0573 (* 1 = 8.0573 loss)
I1016 23:55:15.852694   329 solver.cpp:259]     Train net output #1: seg_loss = 1787.15 (* 1 = 1787.15 loss)
I1016 23:55:15.852699   329 sgd_solver.cpp:138] Iteration 80200, lr = 0.000125
I1016 23:56:15.139117   329 solver.cpp:243] Iteration 80300, loss = 3146.16
I1016 23:56:15.139165   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.33945 (* 1 = 8.33945 loss)
I1016 23:56:15.139171   329 solver.cpp:259]     Train net output #1: seg_loss = 2467.23 (* 1 = 2467.23 loss)
I1016 23:56:15.139176   329 sgd_solver.cpp:138] Iteration 80300, lr = 0.000125
I1016 23:57:13.710775   329 solver.cpp:243] Iteration 80400, loss = 2825.41
I1016 23:57:13.710808   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.87787 (* 1 = 7.87787 loss)
I1016 23:57:13.710814   329 solver.cpp:259]     Train net output #1: seg_loss = 2179.32 (* 1 = 2179.32 loss)
I1016 23:57:13.710820   329 sgd_solver.cpp:138] Iteration 80400, lr = 0.000125
I1016 23:58:12.580327   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_80500.caffemodel
I1016 23:58:12.863128   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_80500.solverstate
I1016 23:58:13.439793   329 solver.cpp:243] Iteration 80500, loss = 2148.69
I1016 23:58:13.439837   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.23985 (* 1 = 4.23985 loss)
I1016 23:58:13.439844   329 solver.cpp:259]     Train net output #1: seg_loss = 2776.21 (* 1 = 2776.21 loss)
I1016 23:58:13.439851   329 sgd_solver.cpp:138] Iteration 80500, lr = 0.000125
I1016 23:59:13.230176   329 solver.cpp:243] Iteration 80600, loss = 3029.21
I1016 23:59:13.230209   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.34538 (* 1 = 6.34538 loss)
I1016 23:59:13.230216   329 solver.cpp:259]     Train net output #1: seg_loss = 2899.46 (* 1 = 2899.46 loss)
I1016 23:59:13.230221   329 sgd_solver.cpp:138] Iteration 80600, lr = 0.000125
I1017 00:00:13.041546   329 solver.cpp:243] Iteration 80700, loss = 2110.57
I1017 00:00:13.041594   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.48228 (* 1 = 3.48228 loss)
I1017 00:00:13.041601   329 solver.cpp:259]     Train net output #1: seg_loss = 2357.03 (* 1 = 2357.03 loss)
I1017 00:00:13.041607   329 sgd_solver.cpp:138] Iteration 80700, lr = 0.000125
I1017 00:01:12.266674   329 solver.cpp:243] Iteration 80800, loss = 2086.45
I1017 00:01:12.266721   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.04934 (* 1 = 8.04934 loss)
I1017 00:01:12.266727   329 solver.cpp:259]     Train net output #1: seg_loss = 2160.38 (* 1 = 2160.38 loss)
I1017 00:01:12.266733   329 sgd_solver.cpp:138] Iteration 80800, lr = 0.000125
I1017 00:02:10.367106   329 solver.cpp:243] Iteration 80900, loss = 2417.77
I1017 00:02:10.367143   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.92081 (* 1 = 7.92081 loss)
I1017 00:02:10.367163   329 solver.cpp:259]     Train net output #1: seg_loss = 2541.56 (* 1 = 2541.56 loss)
I1017 00:02:10.367172   329 sgd_solver.cpp:138] Iteration 80900, lr = 0.000125
I1017 00:02:29.648959   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:03:09.720929   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_81000.caffemodel
I1017 00:03:10.015383   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_81000.solverstate
I1017 00:03:10.601562   329 solver.cpp:243] Iteration 81000, loss = 2342.49
I1017 00:03:10.601604   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.62715 (* 1 = 7.62715 loss)
I1017 00:03:10.601610   329 solver.cpp:259]     Train net output #1: seg_loss = 3227.12 (* 1 = 3227.12 loss)
I1017 00:03:10.601617   329 sgd_solver.cpp:138] Iteration 81000, lr = 0.000125
I1017 00:04:09.779942   329 solver.cpp:243] Iteration 81100, loss = 1782.34
I1017 00:04:09.779990   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.41264 (* 1 = 4.41264 loss)
I1017 00:04:09.779997   329 solver.cpp:259]     Train net output #1: seg_loss = 2195.05 (* 1 = 2195.05 loss)
I1017 00:04:09.780004   329 sgd_solver.cpp:138] Iteration 81100, lr = 0.000125
I1017 00:05:10.160002   329 solver.cpp:243] Iteration 81200, loss = 2630.25
I1017 00:05:10.160050   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.84427 (* 1 = 4.84427 loss)
I1017 00:05:10.160056   329 solver.cpp:259]     Train net output #1: seg_loss = 3847.35 (* 1 = 3847.35 loss)
I1017 00:05:10.160063   329 sgd_solver.cpp:138] Iteration 81200, lr = 0.000125
I1017 00:06:09.189172   329 solver.cpp:243] Iteration 81300, loss = 2964.4
I1017 00:06:09.189220   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.83854 (* 1 = 6.83854 loss)
I1017 00:06:09.189226   329 solver.cpp:259]     Train net output #1: seg_loss = 2703.23 (* 1 = 2703.23 loss)
I1017 00:06:09.189234   329 sgd_solver.cpp:138] Iteration 81300, lr = 0.000125
I1017 00:07:08.068289   329 solver.cpp:243] Iteration 81400, loss = 2425.89
I1017 00:07:08.068338   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.0549 (* 1 = 10.0549 loss)
I1017 00:07:08.068344   329 solver.cpp:259]     Train net output #1: seg_loss = 2080.8 (* 1 = 2080.8 loss)
I1017 00:07:08.068351   329 sgd_solver.cpp:138] Iteration 81400, lr = 0.000125
I1017 00:08:06.631229   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_81500.caffemodel
I1017 00:08:06.969149   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_81500.solverstate
I1017 00:08:07.580384   329 solver.cpp:243] Iteration 81500, loss = 4119.84
I1017 00:08:07.580426   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.0034 (* 1 = 10.0034 loss)
I1017 00:08:07.580433   329 solver.cpp:259]     Train net output #1: seg_loss = 3729.22 (* 1 = 3729.22 loss)
I1017 00:08:07.580440   329 sgd_solver.cpp:138] Iteration 81500, lr = 0.000125
I1017 00:09:06.610394   329 solver.cpp:243] Iteration 81600, loss = 2185.89
I1017 00:09:06.610438   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.73032 (* 1 = 4.73032 loss)
I1017 00:09:06.610445   329 solver.cpp:259]     Train net output #1: seg_loss = 1716.08 (* 1 = 1716.08 loss)
I1017 00:09:06.610450   329 sgd_solver.cpp:138] Iteration 81600, lr = 0.000125
I1017 00:10:06.656210   329 solver.cpp:243] Iteration 81700, loss = 2556.36
I1017 00:10:06.656244   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.8563 (* 1 = 3.8563 loss)
I1017 00:10:06.656251   329 solver.cpp:259]     Train net output #1: seg_loss = 2799.36 (* 1 = 2799.36 loss)
I1017 00:10:06.656256   329 sgd_solver.cpp:138] Iteration 81700, lr = 0.000125
I1017 00:11:06.517669   329 solver.cpp:243] Iteration 81800, loss = 3233.56
I1017 00:11:06.517716   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.69372 (* 1 = 5.69372 loss)
I1017 00:11:06.517733   329 solver.cpp:259]     Train net output #1: seg_loss = 2751.12 (* 1 = 2751.12 loss)
I1017 00:11:06.517740   329 sgd_solver.cpp:138] Iteration 81800, lr = 0.000125
I1017 00:12:05.590916   329 solver.cpp:243] Iteration 81900, loss = 2516.35
I1017 00:12:05.590966   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.24441 (* 1 = 8.24441 loss)
I1017 00:12:05.590972   329 solver.cpp:259]     Train net output #1: seg_loss = 2082.2 (* 1 = 2082.2 loss)
I1017 00:12:05.590978   329 sgd_solver.cpp:138] Iteration 81900, lr = 0.000125
I1017 00:12:27.970844   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:13:03.457255   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_82000.caffemodel
I1017 00:13:03.711350   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_82000.solverstate
I1017 00:13:04.317302   329 solver.cpp:243] Iteration 82000, loss = 3153.9
I1017 00:13:04.317333   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.12244 (* 1 = 9.12244 loss)
I1017 00:13:04.317340   329 solver.cpp:259]     Train net output #1: seg_loss = 3478.24 (* 1 = 3478.24 loss)
I1017 00:13:04.317346   329 sgd_solver.cpp:138] Iteration 82000, lr = 0.000125
I1017 00:14:03.721225   329 solver.cpp:243] Iteration 82100, loss = 2097.06
I1017 00:14:03.721256   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.75167 (* 1 = 5.75167 loss)
I1017 00:14:03.721263   329 solver.cpp:259]     Train net output #1: seg_loss = 2346.58 (* 1 = 2346.58 loss)
I1017 00:14:03.721268   329 sgd_solver.cpp:138] Iteration 82100, lr = 0.000125
I1017 00:15:03.426398   329 solver.cpp:243] Iteration 82200, loss = 2367.02
I1017 00:15:03.426447   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.04022 (* 1 = 8.04022 loss)
I1017 00:15:03.426453   329 solver.cpp:259]     Train net output #1: seg_loss = 1942.47 (* 1 = 1942.47 loss)
I1017 00:15:03.426460   329 sgd_solver.cpp:138] Iteration 82200, lr = 0.000125
I1017 00:16:03.467064   329 solver.cpp:243] Iteration 82300, loss = 2439.72
I1017 00:16:03.467097   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.55628 (* 1 = 4.55628 loss)
I1017 00:16:03.467103   329 solver.cpp:259]     Train net output #1: seg_loss = 2275.24 (* 1 = 2275.24 loss)
I1017 00:16:03.467108   329 sgd_solver.cpp:138] Iteration 82300, lr = 0.000125
I1017 00:17:02.651583   329 solver.cpp:243] Iteration 82400, loss = 2424.7
I1017 00:17:02.651633   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.3338 (* 1 = 4.3338 loss)
I1017 00:17:02.651639   329 solver.cpp:259]     Train net output #1: seg_loss = 1567.08 (* 1 = 1567.08 loss)
I1017 00:17:02.651645   329 sgd_solver.cpp:138] Iteration 82400, lr = 0.000125
I1017 00:18:00.634706   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_82500.caffemodel
I1017 00:18:00.894215   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_82500.solverstate
I1017 00:18:01.482904   329 solver.cpp:243] Iteration 82500, loss = 2288.22
I1017 00:18:01.482950   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.41812 (* 1 = 8.41812 loss)
I1017 00:18:01.482956   329 solver.cpp:259]     Train net output #1: seg_loss = 2614 (* 1 = 2614 loss)
I1017 00:18:01.482962   329 sgd_solver.cpp:138] Iteration 82500, lr = 0.000125
I1017 00:19:00.692399   329 solver.cpp:243] Iteration 82600, loss = 2660.97
I1017 00:19:00.692445   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.37018 (* 1 = 8.37018 loss)
I1017 00:19:00.692452   329 solver.cpp:259]     Train net output #1: seg_loss = 5482.19 (* 1 = 5482.19 loss)
I1017 00:19:00.692457   329 sgd_solver.cpp:138] Iteration 82600, lr = 0.000125
I1017 00:19:59.867784   329 solver.cpp:243] Iteration 82700, loss = 2024.08
I1017 00:19:59.867820   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.5612 (* 1 = 8.5612 loss)
I1017 00:19:59.867828   329 solver.cpp:259]     Train net output #1: seg_loss = 2419.32 (* 1 = 2419.32 loss)
I1017 00:19:59.867853   329 sgd_solver.cpp:138] Iteration 82700, lr = 0.000125
I1017 00:20:59.994560   329 solver.cpp:243] Iteration 82800, loss = 2940.49
I1017 00:20:59.994592   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.63392 (* 1 = 5.63392 loss)
I1017 00:20:59.994598   329 solver.cpp:259]     Train net output #1: seg_loss = 1713.63 (* 1 = 1713.63 loss)
I1017 00:20:59.994604   329 sgd_solver.cpp:138] Iteration 82800, lr = 0.000125
I1017 00:21:59.461911   329 solver.cpp:243] Iteration 82900, loss = 2410.29
I1017 00:21:59.461949   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.56507 (* 1 = 6.56507 loss)
I1017 00:21:59.461957   329 solver.cpp:259]     Train net output #1: seg_loss = 2293.54 (* 1 = 2293.54 loss)
I1017 00:21:59.461966   329 sgd_solver.cpp:138] Iteration 82900, lr = 0.000125
I1017 00:22:25.045260   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:22:58.199136   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_83000.caffemodel
I1017 00:22:58.526324   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_83000.solverstate
I1017 00:22:59.087062   329 solver.cpp:243] Iteration 83000, loss = 2364.7
I1017 00:22:59.087105   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.77581 (* 1 = 4.77581 loss)
I1017 00:22:59.087111   329 solver.cpp:259]     Train net output #1: seg_loss = 3794.08 (* 1 = 3794.08 loss)
I1017 00:22:59.087117   329 sgd_solver.cpp:138] Iteration 83000, lr = 0.000125
I1017 00:23:57.261759   329 solver.cpp:243] Iteration 83100, loss = 2485.18
I1017 00:23:57.261807   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.15619 (* 1 = 9.15619 loss)
I1017 00:23:57.261814   329 solver.cpp:259]     Train net output #1: seg_loss = 2703.2 (* 1 = 2703.2 loss)
I1017 00:23:57.261823   329 sgd_solver.cpp:138] Iteration 83100, lr = 0.000125
I1017 00:24:56.847054   329 solver.cpp:243] Iteration 83200, loss = 2169.4
I1017 00:24:56.847092   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.99506 (* 1 = 6.99506 loss)
I1017 00:24:56.847100   329 solver.cpp:259]     Train net output #1: seg_loss = 2652.1 (* 1 = 2652.1 loss)
I1017 00:24:56.847123   329 sgd_solver.cpp:138] Iteration 83200, lr = 0.000125
I1017 00:25:56.748148   329 solver.cpp:243] Iteration 83300, loss = 2571.86
I1017 00:25:56.748183   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.65613 (* 1 = 6.65613 loss)
I1017 00:25:56.748193   329 solver.cpp:259]     Train net output #1: seg_loss = 3230.07 (* 1 = 3230.07 loss)
I1017 00:25:56.748199   329 sgd_solver.cpp:138] Iteration 83300, lr = 0.000125
I1017 00:26:56.800346   329 solver.cpp:243] Iteration 83400, loss = 2067.19
I1017 00:26:56.800381   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.86238 (* 1 = 5.86238 loss)
I1017 00:26:56.800406   329 solver.cpp:259]     Train net output #1: seg_loss = 1947.62 (* 1 = 1947.62 loss)
I1017 00:26:56.800415   329 sgd_solver.cpp:138] Iteration 83400, lr = 0.000125
I1017 00:27:55.517457   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_83500.caffemodel
I1017 00:27:55.789615   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_83500.solverstate
I1017 00:27:56.377738   329 solver.cpp:243] Iteration 83500, loss = 2332.32
I1017 00:27:56.377769   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.42159 (* 1 = 7.42159 loss)
I1017 00:27:56.377775   329 solver.cpp:259]     Train net output #1: seg_loss = 2132.22 (* 1 = 2132.22 loss)
I1017 00:27:56.377781   329 sgd_solver.cpp:138] Iteration 83500, lr = 0.000125
I1017 00:28:54.138217   329 solver.cpp:243] Iteration 83600, loss = 2345.38
I1017 00:28:54.138265   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.61775 (* 1 = 5.61775 loss)
I1017 00:28:54.138272   329 solver.cpp:259]     Train net output #1: seg_loss = 2553.32 (* 1 = 2553.32 loss)
I1017 00:28:54.138278   329 sgd_solver.cpp:138] Iteration 83600, lr = 0.000125
I1017 00:29:54.029919   329 solver.cpp:243] Iteration 83700, loss = 2443.69
I1017 00:29:54.029953   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.59582 (* 1 = 7.59582 loss)
I1017 00:29:54.029959   329 solver.cpp:259]     Train net output #1: seg_loss = 2405.21 (* 1 = 2405.21 loss)
I1017 00:29:54.029965   329 sgd_solver.cpp:138] Iteration 83700, lr = 0.000125
I1017 00:30:53.453704   329 solver.cpp:243] Iteration 83800, loss = 2655.24
I1017 00:30:53.453752   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.81678 (* 1 = 6.81678 loss)
I1017 00:30:53.453758   329 solver.cpp:259]     Train net output #1: seg_loss = 2011.35 (* 1 = 2011.35 loss)
I1017 00:30:53.453765   329 sgd_solver.cpp:138] Iteration 83800, lr = 0.000125
I1017 00:31:53.693119   329 solver.cpp:243] Iteration 83900, loss = 1780.4
I1017 00:31:53.693150   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.59004 (* 1 = 4.59004 loss)
I1017 00:31:53.693156   329 solver.cpp:259]     Train net output #1: seg_loss = 2045.86 (* 1 = 2045.86 loss)
I1017 00:31:53.693163   329 sgd_solver.cpp:138] Iteration 83900, lr = 0.000125
I1017 00:32:22.350941   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:32:52.387893   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_84000.caffemodel
I1017 00:32:52.707710   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_84000.solverstate
I1017 00:32:52.902724   329 net.cpp:693] Ignoring source layer mbox_loss
I1017 00:34:29.918021   329 solver.cpp:243] Iteration 84000, loss = 2743.71
I1017 00:34:29.918056   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.78573 (* 1 = 6.78573 loss)
I1017 00:34:29.918061   329 solver.cpp:259]     Train net output #1: seg_loss = 2736.93 (* 1 = 2736.93 loss)
I1017 00:34:29.918068   329 sgd_solver.cpp:138] Iteration 84000, lr = 0.000125
I1017 00:35:27.826951   329 solver.cpp:243] Iteration 84100, loss = 2612.14
I1017 00:35:27.826983   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.46623 (* 1 = 8.46623 loss)
I1017 00:35:27.826989   329 solver.cpp:259]     Train net output #1: seg_loss = 2345.52 (* 1 = 2345.52 loss)
I1017 00:35:27.827011   329 sgd_solver.cpp:138] Iteration 84100, lr = 0.000125
I1017 00:36:26.640345   329 solver.cpp:243] Iteration 84200, loss = 3718.29
I1017 00:36:26.640378   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.41149 (* 1 = 6.41149 loss)
I1017 00:36:26.640384   329 solver.cpp:259]     Train net output #1: seg_loss = 4447.59 (* 1 = 4447.59 loss)
I1017 00:36:26.640390   329 sgd_solver.cpp:138] Iteration 84200, lr = 0.000125
I1017 00:37:26.004971   329 solver.cpp:243] Iteration 84300, loss = 1950.95
I1017 00:37:26.005004   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.2048 (* 1 = 10.2048 loss)
I1017 00:37:26.005010   329 solver.cpp:259]     Train net output #1: seg_loss = 2113.7 (* 1 = 2113.7 loss)
I1017 00:37:26.005017   329 sgd_solver.cpp:138] Iteration 84300, lr = 0.000125
I1017 00:38:25.974290   329 solver.cpp:243] Iteration 84400, loss = 2738.58
I1017 00:38:25.974324   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.41582 (* 1 = 5.41582 loss)
I1017 00:38:25.974331   329 solver.cpp:259]     Train net output #1: seg_loss = 2795.19 (* 1 = 2795.19 loss)
I1017 00:38:25.974339   329 sgd_solver.cpp:138] Iteration 84400, lr = 0.000125
I1017 00:39:01.048591   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:39:25.337558   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_84500.caffemodel
I1017 00:39:25.620695   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_84500.solverstate
I1017 00:39:26.200676   329 solver.cpp:243] Iteration 84500, loss = 2762.79
I1017 00:39:26.200709   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.74294 (* 1 = 6.74294 loss)
I1017 00:39:26.200716   329 solver.cpp:259]     Train net output #1: seg_loss = 3496.92 (* 1 = 3496.92 loss)
I1017 00:39:26.200721   329 sgd_solver.cpp:138] Iteration 84500, lr = 0.000125
I1017 00:40:25.018517   329 solver.cpp:243] Iteration 84600, loss = 1905.81
I1017 00:40:25.018550   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.33187 (* 1 = 4.33187 loss)
I1017 00:40:25.018556   329 solver.cpp:259]     Train net output #1: seg_loss = 2142.2 (* 1 = 2142.2 loss)
I1017 00:40:25.018563   329 sgd_solver.cpp:138] Iteration 84600, lr = 0.000125
I1017 00:41:23.256753   329 solver.cpp:243] Iteration 84700, loss = 2529.71
I1017 00:41:23.256788   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.11199 (* 1 = 6.11199 loss)
I1017 00:41:23.256793   329 solver.cpp:259]     Train net output #1: seg_loss = 2593.33 (* 1 = 2593.33 loss)
I1017 00:41:23.256798   329 sgd_solver.cpp:138] Iteration 84700, lr = 0.000125
I1017 00:42:23.035676   329 solver.cpp:243] Iteration 84800, loss = 2106.33
I1017 00:42:23.035707   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.41506 (* 1 = 5.41506 loss)
I1017 00:42:23.035713   329 solver.cpp:259]     Train net output #1: seg_loss = 1706.57 (* 1 = 1706.57 loss)
I1017 00:42:23.035719   329 sgd_solver.cpp:138] Iteration 84800, lr = 0.000125
I1017 00:43:22.646595   329 solver.cpp:243] Iteration 84900, loss = 2414.57
I1017 00:43:22.646627   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14166 (* 1 = 7.14166 loss)
I1017 00:43:22.646633   329 solver.cpp:259]     Train net output #1: seg_loss = 2947.28 (* 1 = 2947.28 loss)
I1017 00:43:22.646638   329 sgd_solver.cpp:138] Iteration 84900, lr = 0.000125
I1017 00:44:22.367144   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_85000.caffemodel
I1017 00:44:22.657899   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_85000.solverstate
I1017 00:44:23.262171   329 solver.cpp:243] Iteration 85000, loss = 2744.96
I1017 00:44:23.262202   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.5341 (* 1 = 7.5341 loss)
I1017 00:44:23.262208   329 solver.cpp:259]     Train net output #1: seg_loss = 3043.75 (* 1 = 3043.75 loss)
I1017 00:44:23.262214   329 sgd_solver.cpp:138] Iteration 85000, lr = 0.000125
I1017 00:45:22.002781   329 solver.cpp:243] Iteration 85100, loss = 2680.09
I1017 00:45:22.002815   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.80579 (* 1 = 9.80579 loss)
I1017 00:45:22.002821   329 solver.cpp:259]     Train net output #1: seg_loss = 3319.74 (* 1 = 3319.74 loss)
I1017 00:45:22.002828   329 sgd_solver.cpp:138] Iteration 85100, lr = 0.000125
I1017 00:46:20.747428   329 solver.cpp:243] Iteration 85200, loss = 2501.14
I1017 00:46:20.747459   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.93171 (* 1 = 6.93171 loss)
I1017 00:46:20.747465   329 solver.cpp:259]     Train net output #1: seg_loss = 2339.98 (* 1 = 2339.98 loss)
I1017 00:46:20.747473   329 sgd_solver.cpp:138] Iteration 85200, lr = 0.000125
I1017 00:47:20.085868   329 solver.cpp:243] Iteration 85300, loss = 3475.98
I1017 00:47:20.085901   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.53035 (* 1 = 4.53035 loss)
I1017 00:47:20.085907   329 solver.cpp:259]     Train net output #1: seg_loss = 2537.03 (* 1 = 2537.03 loss)
I1017 00:47:20.085913   329 sgd_solver.cpp:138] Iteration 85300, lr = 0.000125
I1017 00:48:19.294529   329 solver.cpp:243] Iteration 85400, loss = 2173.9
I1017 00:48:19.294562   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.50837 (* 1 = 6.50837 loss)
I1017 00:48:19.294569   329 solver.cpp:259]     Train net output #1: seg_loss = 2285.73 (* 1 = 2285.73 loss)
I1017 00:48:19.294574   329 sgd_solver.cpp:138] Iteration 85400, lr = 0.000125
I1017 00:48:57.256002   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:49:18.773687   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_85500.caffemodel
I1017 00:49:19.053874   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_85500.solverstate
I1017 00:49:19.645200   329 solver.cpp:243] Iteration 85500, loss = 2592.07
I1017 00:49:19.645231   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.87465 (* 1 = 4.87465 loss)
I1017 00:49:19.645237   329 solver.cpp:259]     Train net output #1: seg_loss = 2733.18 (* 1 = 2733.18 loss)
I1017 00:49:19.645243   329 sgd_solver.cpp:138] Iteration 85500, lr = 0.000125
I1017 00:50:19.196069   329 solver.cpp:243] Iteration 85600, loss = 2381.13
I1017 00:50:19.196102   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.16239 (* 1 = 6.16239 loss)
I1017 00:50:19.196108   329 solver.cpp:259]     Train net output #1: seg_loss = 1828.65 (* 1 = 1828.65 loss)
I1017 00:50:19.196113   329 sgd_solver.cpp:138] Iteration 85600, lr = 0.000125
I1017 00:51:18.281349   329 solver.cpp:243] Iteration 85700, loss = 2367.75
I1017 00:51:18.281381   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.92721 (* 1 = 6.92721 loss)
I1017 00:51:18.281388   329 solver.cpp:259]     Train net output #1: seg_loss = 2048.17 (* 1 = 2048.17 loss)
I1017 00:51:18.281394   329 sgd_solver.cpp:138] Iteration 85700, lr = 0.000125
I1017 00:52:16.686269   329 solver.cpp:243] Iteration 85800, loss = 3486.55
I1017 00:52:16.686301   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.17686 (* 1 = 6.17686 loss)
I1017 00:52:16.686319   329 solver.cpp:259]     Train net output #1: seg_loss = 2145.09 (* 1 = 2145.09 loss)
I1017 00:52:16.686336   329 sgd_solver.cpp:138] Iteration 85800, lr = 0.000125
I1017 00:53:16.444196   329 solver.cpp:243] Iteration 85900, loss = 2200.44
I1017 00:53:16.444231   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.49805 (* 1 = 6.49805 loss)
I1017 00:53:16.444236   329 solver.cpp:259]     Train net output #1: seg_loss = 1816.08 (* 1 = 1816.08 loss)
I1017 00:53:16.444242   329 sgd_solver.cpp:138] Iteration 85900, lr = 0.000125
I1017 00:54:15.719915   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_86000.caffemodel
I1017 00:54:16.027217   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_86000.solverstate
I1017 00:54:16.599382   329 solver.cpp:243] Iteration 86000, loss = 2561.1
I1017 00:54:16.599417   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.1544 (* 1 = 7.1544 loss)
I1017 00:54:16.599423   329 solver.cpp:259]     Train net output #1: seg_loss = 1621.84 (* 1 = 1621.84 loss)
I1017 00:54:16.599429   329 sgd_solver.cpp:138] Iteration 86000, lr = 0.000125
I1017 00:55:16.390278   329 solver.cpp:243] Iteration 86100, loss = 2021.37
I1017 00:55:16.390312   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.51975 (* 1 = 5.51975 loss)
I1017 00:55:16.390318   329 solver.cpp:259]     Train net output #1: seg_loss = 1912.85 (* 1 = 1912.85 loss)
I1017 00:55:16.390323   329 sgd_solver.cpp:138] Iteration 86100, lr = 0.000125
I1017 00:56:15.504169   329 solver.cpp:243] Iteration 86200, loss = 2368.47
I1017 00:56:15.504204   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.34377 (* 1 = 8.34377 loss)
I1017 00:56:15.504209   329 solver.cpp:259]     Train net output #1: seg_loss = 2565.41 (* 1 = 2565.41 loss)
I1017 00:56:15.504215   329 sgd_solver.cpp:138] Iteration 86200, lr = 0.000125
I1017 00:57:13.807173   329 solver.cpp:243] Iteration 86300, loss = 2086.01
I1017 00:57:13.807205   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.16258 (* 1 = 6.16258 loss)
I1017 00:57:13.807212   329 solver.cpp:259]     Train net output #1: seg_loss = 2313.2 (* 1 = 2313.2 loss)
I1017 00:57:13.807219   329 sgd_solver.cpp:138] Iteration 86300, lr = 0.000125
I1017 00:58:13.422360   329 solver.cpp:243] Iteration 86400, loss = 2651.08
I1017 00:58:13.422394   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.08653 (* 1 = 9.08653 loss)
I1017 00:58:13.422399   329 solver.cpp:259]     Train net output #1: seg_loss = 1569 (* 1 = 1569 loss)
I1017 00:58:13.422405   329 sgd_solver.cpp:138] Iteration 86400, lr = 0.000125
I1017 00:58:53.130102   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 00:59:12.149709   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_86500.caffemodel
I1017 00:59:12.443871   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_86500.solverstate
I1017 00:59:13.027940   329 solver.cpp:243] Iteration 86500, loss = 2403.61
I1017 00:59:13.027973   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.12874 (* 1 = 8.12874 loss)
I1017 00:59:13.027979   329 solver.cpp:259]     Train net output #1: seg_loss = 2263.64 (* 1 = 2263.64 loss)
I1017 00:59:13.027985   329 sgd_solver.cpp:138] Iteration 86500, lr = 0.000125
I1017 01:00:12.952754   329 solver.cpp:243] Iteration 86600, loss = 2038.01
I1017 01:00:12.952790   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.48969 (* 1 = 7.48969 loss)
I1017 01:00:12.952795   329 solver.cpp:259]     Train net output #1: seg_loss = 2108.73 (* 1 = 2108.73 loss)
I1017 01:00:12.952801   329 sgd_solver.cpp:138] Iteration 86600, lr = 0.000125
I1017 01:01:12.222905   329 solver.cpp:243] Iteration 86700, loss = 2034.84
I1017 01:01:12.222939   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.05274 (* 1 = 8.05274 loss)
I1017 01:01:12.222946   329 solver.cpp:259]     Train net output #1: seg_loss = 1386.24 (* 1 = 1386.24 loss)
I1017 01:01:12.222952   329 sgd_solver.cpp:138] Iteration 86700, lr = 0.000125
I1017 01:02:11.507953   329 solver.cpp:243] Iteration 86800, loss = 3327
I1017 01:02:11.507987   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.50605 (* 1 = 5.50605 loss)
I1017 01:02:11.507993   329 solver.cpp:259]     Train net output #1: seg_loss = 2635.23 (* 1 = 2635.23 loss)
I1017 01:02:11.507999   329 sgd_solver.cpp:138] Iteration 86800, lr = 0.000125
I1017 01:03:10.060281   329 solver.cpp:243] Iteration 86900, loss = 2839.47
I1017 01:03:10.060313   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.90798 (* 1 = 8.90798 loss)
I1017 01:03:10.060320   329 solver.cpp:259]     Train net output #1: seg_loss = 2690.21 (* 1 = 2690.21 loss)
I1017 01:03:10.060325   329 sgd_solver.cpp:138] Iteration 86900, lr = 0.000125
I1017 01:04:08.918913   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_87000.caffemodel
I1017 01:04:09.200579   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_87000.solverstate
I1017 01:04:09.793323   329 solver.cpp:243] Iteration 87000, loss = 2114.94
I1017 01:04:09.793354   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.16364 (* 1 = 4.16364 loss)
I1017 01:04:09.793360   329 solver.cpp:259]     Train net output #1: seg_loss = 1227.31 (* 1 = 1227.31 loss)
I1017 01:04:09.793366   329 sgd_solver.cpp:138] Iteration 87000, lr = 0.000125
I1017 01:05:09.612692   329 solver.cpp:243] Iteration 87100, loss = 3006.13
I1017 01:05:09.612725   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.53377 (* 1 = 9.53377 loss)
I1017 01:05:09.612731   329 solver.cpp:259]     Train net output #1: seg_loss = 2670.35 (* 1 = 2670.35 loss)
I1017 01:05:09.612738   329 sgd_solver.cpp:138] Iteration 87100, lr = 0.000125
I1017 01:06:09.481395   329 solver.cpp:243] Iteration 87200, loss = 2057.83
I1017 01:06:09.481429   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.31 (* 1 = 5.31 loss)
I1017 01:06:09.481436   329 solver.cpp:259]     Train net output #1: seg_loss = 1768.51 (* 1 = 1768.51 loss)
I1017 01:06:09.481441   329 sgd_solver.cpp:138] Iteration 87200, lr = 0.000125
I1017 01:07:08.660423   329 solver.cpp:243] Iteration 87300, loss = 2034.07
I1017 01:07:08.660457   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.97633 (* 1 = 4.97633 loss)
I1017 01:07:08.660464   329 solver.cpp:259]     Train net output #1: seg_loss = 2033.58 (* 1 = 2033.58 loss)
I1017 01:07:08.660470   329 sgd_solver.cpp:138] Iteration 87300, lr = 0.000125
I1017 01:08:06.739357   329 solver.cpp:243] Iteration 87400, loss = 2322.79
I1017 01:08:06.739387   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.4455 (* 1 = 6.4455 loss)
I1017 01:08:06.739393   329 solver.cpp:259]     Train net output #1: seg_loss = 2497.61 (* 1 = 2497.61 loss)
I1017 01:08:06.739399   329 sgd_solver.cpp:138] Iteration 87400, lr = 0.000125
I1017 01:08:49.521545   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:09:06.033942   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_87500.caffemodel
I1017 01:09:06.319914   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_87500.solverstate
I1017 01:09:06.923560   329 solver.cpp:243] Iteration 87500, loss = 2229.05
I1017 01:09:06.923593   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.47629 (* 1 = 7.47629 loss)
I1017 01:09:06.923599   329 solver.cpp:259]     Train net output #1: seg_loss = 2877.46 (* 1 = 2877.46 loss)
I1017 01:09:06.923605   329 sgd_solver.cpp:138] Iteration 87500, lr = 0.000125
I1017 01:10:06.232403   329 solver.cpp:243] Iteration 87600, loss = 1756.33
I1017 01:10:06.232440   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.64823 (* 1 = 4.64823 loss)
I1017 01:10:06.232448   329 solver.cpp:259]     Train net output #1: seg_loss = 1926.62 (* 1 = 1926.62 loss)
I1017 01:10:06.232456   329 sgd_solver.cpp:138] Iteration 87600, lr = 0.000125
I1017 01:11:06.514994   329 solver.cpp:243] Iteration 87700, loss = 2285.32
I1017 01:11:06.515029   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.57834 (* 1 = 9.57834 loss)
I1017 01:11:06.515038   329 solver.cpp:259]     Train net output #1: seg_loss = 3847.16 (* 1 = 3847.16 loss)
I1017 01:11:06.515059   329 sgd_solver.cpp:138] Iteration 87700, lr = 0.000125
I1017 01:12:05.552165   329 solver.cpp:243] Iteration 87800, loss = 2751.43
I1017 01:12:05.552202   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.18024 (* 1 = 7.18024 loss)
I1017 01:12:05.552211   329 solver.cpp:259]     Train net output #1: seg_loss = 2153.37 (* 1 = 2153.37 loss)
I1017 01:12:05.552218   329 sgd_solver.cpp:138] Iteration 87800, lr = 0.000125
I1017 01:13:04.448695   329 solver.cpp:243] Iteration 87900, loss = 2535.34
I1017 01:13:04.448731   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.87269 (* 1 = 6.87269 loss)
I1017 01:13:04.448740   329 solver.cpp:259]     Train net output #1: seg_loss = 2552.04 (* 1 = 2552.04 loss)
I1017 01:13:04.448762   329 sgd_solver.cpp:138] Iteration 87900, lr = 0.000125
I1017 01:14:02.930163   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_88000.caffemodel
I1017 01:14:03.248158   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_88000.solverstate
I1017 01:14:03.452627   329 net.cpp:693] Ignoring source layer mbox_loss
I1017 01:15:36.571558   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:15:41.352936   329 solver.cpp:243] Iteration 88000, loss = 5127.95
I1017 01:15:41.352968   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.93441 (* 1 = 8.93441 loss)
I1017 01:15:41.352975   329 solver.cpp:259]     Train net output #1: seg_loss = 5119.02 (* 1 = 5119.02 loss)
I1017 01:15:41.352982   329 sgd_solver.cpp:138] Iteration 88000, lr = 0.000125
I1017 01:16:39.506261   329 solver.cpp:243] Iteration 88100, loss = 2152.11
I1017 01:16:39.506295   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.63171 (* 1 = 4.63171 loss)
I1017 01:16:39.506301   329 solver.cpp:259]     Train net output #1: seg_loss = 1698.07 (* 1 = 1698.07 loss)
I1017 01:16:39.506306   329 sgd_solver.cpp:138] Iteration 88100, lr = 0.000125
I1017 01:17:39.440657   329 solver.cpp:243] Iteration 88200, loss = 2467.66
I1017 01:17:39.440693   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.39401 (* 1 = 4.39401 loss)
I1017 01:17:39.440703   329 solver.cpp:259]     Train net output #1: seg_loss = 2154.55 (* 1 = 2154.55 loss)
I1017 01:17:39.440711   329 sgd_solver.cpp:138] Iteration 88200, lr = 0.000125
I1017 01:18:39.338433   329 solver.cpp:243] Iteration 88300, loss = 3036.27
I1017 01:18:39.338467   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.39901 (* 1 = 7.39901 loss)
I1017 01:18:39.338476   329 solver.cpp:259]     Train net output #1: seg_loss = 2567.11 (* 1 = 2567.11 loss)
I1017 01:18:39.338485   329 sgd_solver.cpp:138] Iteration 88300, lr = 0.000125
I1017 01:19:38.503520   329 solver.cpp:243] Iteration 88400, loss = 2325.86
I1017 01:19:38.503556   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.73288 (* 1 = 7.73288 loss)
I1017 01:19:38.503564   329 solver.cpp:259]     Train net output #1: seg_loss = 2536.79 (* 1 = 2536.79 loss)
I1017 01:19:38.503587   329 sgd_solver.cpp:138] Iteration 88400, lr = 0.000125
I1017 01:20:36.418383   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_88500.caffemodel
I1017 01:20:36.727468   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_88500.solverstate
I1017 01:20:37.353631   329 solver.cpp:243] Iteration 88500, loss = 2943.54
I1017 01:20:37.353678   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.7012 (* 1 = 10.7012 loss)
I1017 01:20:37.353684   329 solver.cpp:259]     Train net output #1: seg_loss = 5261.82 (* 1 = 5261.82 loss)
I1017 01:20:37.353690   329 sgd_solver.cpp:138] Iteration 88500, lr = 0.000125
I1017 01:21:36.813694   329 solver.cpp:243] Iteration 88600, loss = 2055.52
I1017 01:21:36.813725   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.37884 (* 1 = 7.37884 loss)
I1017 01:21:36.813731   329 solver.cpp:259]     Train net output #1: seg_loss = 1880.03 (* 1 = 1880.03 loss)
I1017 01:21:36.813737   329 sgd_solver.cpp:138] Iteration 88600, lr = 0.000125
I1017 01:22:36.472558   329 solver.cpp:243] Iteration 88700, loss = 2469.16
I1017 01:22:36.472600   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.71208 (* 1 = 4.71208 loss)
I1017 01:22:36.472609   329 solver.cpp:259]     Train net output #1: seg_loss = 2466.89 (* 1 = 2466.89 loss)
I1017 01:22:36.472617   329 sgd_solver.cpp:138] Iteration 88700, lr = 0.000125
I1017 01:23:36.484195   329 solver.cpp:243] Iteration 88800, loss = 2417.81
I1017 01:23:36.484237   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.70538 (* 1 = 5.70538 loss)
I1017 01:23:36.484243   329 solver.cpp:259]     Train net output #1: seg_loss = 1830.11 (* 1 = 1830.11 loss)
I1017 01:23:36.484251   329 sgd_solver.cpp:138] Iteration 88800, lr = 0.000125
I1017 01:24:35.624955   329 solver.cpp:243] Iteration 88900, loss = 2510.85
I1017 01:24:35.624986   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.50187 (* 1 = 4.50187 loss)
I1017 01:24:35.624994   329 solver.cpp:259]     Train net output #1: seg_loss = 1946.77 (* 1 = 1946.77 loss)
I1017 01:24:35.625000   329 sgd_solver.cpp:138] Iteration 88900, lr = 0.000125
I1017 01:25:26.831779   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:25:33.668961   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_89000.caffemodel
I1017 01:25:33.918447   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_89000.solverstate
I1017 01:25:34.496014   329 solver.cpp:243] Iteration 89000, loss = 2156.9
I1017 01:25:34.496060   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.68453 (* 1 = 7.68453 loss)
I1017 01:25:34.496067   329 solver.cpp:259]     Train net output #1: seg_loss = 2161.9 (* 1 = 2161.9 loss)
I1017 01:25:34.496073   329 sgd_solver.cpp:138] Iteration 89000, lr = 0.000125
I1017 01:26:33.727624   329 solver.cpp:243] Iteration 89100, loss = 2387.35
I1017 01:26:33.727656   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.61928 (* 1 = 7.61928 loss)
I1017 01:26:33.727663   329 solver.cpp:259]     Train net output #1: seg_loss = 2671.35 (* 1 = 2671.35 loss)
I1017 01:26:33.727668   329 sgd_solver.cpp:138] Iteration 89100, lr = 0.000125
I1017 01:27:32.886221   329 solver.cpp:243] Iteration 89200, loss = 2006.37
I1017 01:27:32.886270   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.65505 (* 1 = 4.65505 loss)
I1017 01:27:32.886276   329 solver.cpp:259]     Train net output #1: seg_loss = 2182.73 (* 1 = 2182.73 loss)
I1017 01:27:32.886282   329 sgd_solver.cpp:138] Iteration 89200, lr = 0.000125
I1017 01:28:33.034924   329 solver.cpp:243] Iteration 89300, loss = 3233.77
I1017 01:28:33.034974   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.08147 (* 1 = 6.08147 loss)
I1017 01:28:33.034981   329 solver.cpp:259]     Train net output #1: seg_loss = 1944.34 (* 1 = 1944.34 loss)
I1017 01:28:33.034986   329 sgd_solver.cpp:138] Iteration 89300, lr = 0.000125
I1017 01:29:32.565102   329 solver.cpp:243] Iteration 89400, loss = 2229.15
I1017 01:29:32.565147   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.11021 (* 1 = 4.11021 loss)
I1017 01:29:32.565153   329 solver.cpp:259]     Train net output #1: seg_loss = 2165.71 (* 1 = 2165.71 loss)
I1017 01:29:32.565160   329 sgd_solver.cpp:138] Iteration 89400, lr = 0.000125
I1017 01:30:31.199481   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_89500.caffemodel
I1017 01:30:31.562996   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_89500.solverstate
I1017 01:30:32.171509   329 solver.cpp:243] Iteration 89500, loss = 2203.42
I1017 01:30:32.171556   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.85123 (* 1 = 7.85123 loss)
I1017 01:30:32.171563   329 solver.cpp:259]     Train net output #1: seg_loss = 2547.61 (* 1 = 2547.61 loss)
I1017 01:30:32.171568   329 sgd_solver.cpp:138] Iteration 89500, lr = 0.000125
I1017 01:31:30.231321   329 solver.cpp:243] Iteration 89600, loss = 2773.49
I1017 01:31:30.231371   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.8792 (* 1 = 9.8792 loss)
I1017 01:31:30.231377   329 solver.cpp:259]     Train net output #1: seg_loss = 2607.4 (* 1 = 2607.4 loss)
I1017 01:31:30.231384   329 sgd_solver.cpp:138] Iteration 89600, lr = 0.000125
I1017 01:32:29.821655   329 solver.cpp:243] Iteration 89700, loss = 2048.33
I1017 01:32:29.821691   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.84743 (* 1 = 6.84743 loss)
I1017 01:32:29.821700   329 solver.cpp:259]     Train net output #1: seg_loss = 2642.99 (* 1 = 2642.99 loss)
I1017 01:32:29.821722   329 sgd_solver.cpp:138] Iteration 89700, lr = 0.000125
I1017 01:33:29.680032   329 solver.cpp:243] Iteration 89800, loss = 2439.19
I1017 01:33:29.680080   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.97645 (* 1 = 9.97645 loss)
I1017 01:33:29.680086   329 solver.cpp:259]     Train net output #1: seg_loss = 2208.55 (* 1 = 2208.55 loss)
I1017 01:33:29.680092   329 sgd_solver.cpp:138] Iteration 89800, lr = 0.000125
I1017 01:34:29.715093   329 solver.cpp:243] Iteration 89900, loss = 2019.66
I1017 01:34:29.715142   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.21383 (* 1 = 9.21383 loss)
I1017 01:34:29.715147   329 solver.cpp:259]     Train net output #1: seg_loss = 2577.47 (* 1 = 2577.47 loss)
I1017 01:34:29.715153   329 sgd_solver.cpp:138] Iteration 89900, lr = 0.000125
I1017 01:35:24.804924   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:35:28.334827   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_90000.caffemodel
I1017 01:35:28.623889   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_90000.solverstate
I1017 01:35:29.223978   329 solver.cpp:243] Iteration 90000, loss = 2402.2
I1017 01:35:29.224009   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.57686 (* 1 = 8.57686 loss)
I1017 01:35:29.224014   329 solver.cpp:259]     Train net output #1: seg_loss = 1990.64 (* 1 = 1990.64 loss)
I1017 01:35:29.224021   329 sgd_solver.cpp:138] Iteration 90000, lr = 0.000125
I1017 01:36:27.064061   329 solver.cpp:243] Iteration 90100, loss = 2267.41
I1017 01:36:27.064110   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.01016 (* 1 = 5.01016 loss)
I1017 01:36:27.064115   329 solver.cpp:259]     Train net output #1: seg_loss = 1935.79 (* 1 = 1935.79 loss)
I1017 01:36:27.064121   329 sgd_solver.cpp:138] Iteration 90100, lr = 0.000125
I1017 01:37:26.933179   329 solver.cpp:243] Iteration 90200, loss = 2388.7
I1017 01:37:26.933225   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.71625 (* 1 = 8.71625 loss)
I1017 01:37:26.933233   329 solver.cpp:259]     Train net output #1: seg_loss = 2451.46 (* 1 = 2451.46 loss)
I1017 01:37:26.933239   329 sgd_solver.cpp:138] Iteration 90200, lr = 0.000125
I1017 01:38:26.362823   329 solver.cpp:243] Iteration 90300, loss = 2692.73
I1017 01:38:26.362872   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.3393 (* 1 = 4.3393 loss)
I1017 01:38:26.362879   329 solver.cpp:259]     Train net output #1: seg_loss = 2100.96 (* 1 = 2100.96 loss)
I1017 01:38:26.362884   329 sgd_solver.cpp:138] Iteration 90300, lr = 0.000125
I1017 01:39:26.622413   329 solver.cpp:243] Iteration 90400, loss = 1735.31
I1017 01:39:26.622453   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.87053 (* 1 = 4.87053 loss)
I1017 01:39:26.622460   329 solver.cpp:259]     Train net output #1: seg_loss = 1302.55 (* 1 = 1302.55 loss)
I1017 01:39:26.622467   329 sgd_solver.cpp:138] Iteration 90400, lr = 0.000125
I1017 01:40:25.331574   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_90500.caffemodel
I1017 01:40:25.615415   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_90500.solverstate
I1017 01:40:26.212669   329 solver.cpp:243] Iteration 90500, loss = 2378.96
I1017 01:40:26.212714   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.62928 (* 1 = 9.62928 loss)
I1017 01:40:26.212720   329 solver.cpp:259]     Train net output #1: seg_loss = 2491.6 (* 1 = 2491.6 loss)
I1017 01:40:26.212726   329 sgd_solver.cpp:138] Iteration 90500, lr = 0.000125
I1017 01:41:25.100448   329 solver.cpp:243] Iteration 90600, loss = 2821.77
I1017 01:41:25.100483   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.95244 (* 1 = 5.95244 loss)
I1017 01:41:25.100492   329 solver.cpp:259]     Train net output #1: seg_loss = 3170.05 (* 1 = 3170.05 loss)
I1017 01:41:25.100515   329 sgd_solver.cpp:138] Iteration 90600, lr = 0.000125
I1017 01:42:23.929694   329 solver.cpp:243] Iteration 90700, loss = 3274.7
I1017 01:42:23.929728   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.6246 (* 1 = 10.6246 loss)
I1017 01:42:23.929734   329 solver.cpp:259]     Train net output #1: seg_loss = 5200.17 (* 1 = 5200.17 loss)
I1017 01:42:23.929739   329 sgd_solver.cpp:138] Iteration 90700, lr = 0.000125
I1017 01:43:23.258926   329 solver.cpp:243] Iteration 90800, loss = 1756.72
I1017 01:43:23.258975   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.35889 (* 1 = 5.35889 loss)
I1017 01:43:23.258980   329 solver.cpp:259]     Train net output #1: seg_loss = 1906 (* 1 = 1906 loss)
I1017 01:43:23.258986   329 sgd_solver.cpp:138] Iteration 90800, lr = 0.000125
I1017 01:44:23.232385   329 solver.cpp:243] Iteration 90900, loss = 2715.14
I1017 01:44:23.232421   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.73258 (* 1 = 5.73258 loss)
I1017 01:44:23.232430   329 solver.cpp:259]     Train net output #1: seg_loss = 3037.56 (* 1 = 3037.56 loss)
I1017 01:44:23.232437   329 sgd_solver.cpp:138] Iteration 90900, lr = 0.000125
I1017 01:45:21.965555   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:45:22.553184   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_91000.caffemodel
I1017 01:45:22.866989   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_91000.solverstate
I1017 01:45:23.457983   329 solver.cpp:243] Iteration 91000, loss = 2588.68
I1017 01:45:23.458017   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.31415 (* 1 = 7.31415 loss)
I1017 01:45:23.458024   329 solver.cpp:259]     Train net output #1: seg_loss = 2468.8 (* 1 = 2468.8 loss)
I1017 01:45:23.458029   329 sgd_solver.cpp:138] Iteration 91000, lr = 0.000125
I1017 01:46:22.146306   329 solver.cpp:243] Iteration 91100, loss = 1839.47
I1017 01:46:22.146353   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.90429 (* 1 = 4.90429 loss)
I1017 01:46:22.146359   329 solver.cpp:259]     Train net output #1: seg_loss = 1355.67 (* 1 = 1355.67 loss)
I1017 01:46:22.146365   329 sgd_solver.cpp:138] Iteration 91100, lr = 0.000125
I1017 01:47:20.426254   329 solver.cpp:243] Iteration 91200, loss = 2475.7
I1017 01:47:20.426287   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.0077 (* 1 = 7.0077 loss)
I1017 01:47:20.426295   329 solver.cpp:259]     Train net output #1: seg_loss = 1826.65 (* 1 = 1826.65 loss)
I1017 01:47:20.426301   329 sgd_solver.cpp:138] Iteration 91200, lr = 0.000125
I1017 01:48:20.232396   329 solver.cpp:243] Iteration 91300, loss = 2089.13
I1017 01:48:20.232445   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.97906 (* 1 = 5.97906 loss)
I1017 01:48:20.232451   329 solver.cpp:259]     Train net output #1: seg_loss = 2493.96 (* 1 = 2493.96 loss)
I1017 01:48:20.232457   329 sgd_solver.cpp:138] Iteration 91300, lr = 0.000125
I1017 01:49:19.851325   329 solver.cpp:243] Iteration 91400, loss = 2140.39
I1017 01:49:19.851359   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.26961 (* 1 = 8.26961 loss)
I1017 01:49:19.851366   329 solver.cpp:259]     Train net output #1: seg_loss = 2905.73 (* 1 = 2905.73 loss)
I1017 01:49:19.851372   329 sgd_solver.cpp:138] Iteration 91400, lr = 0.000125
I1017 01:50:19.609469   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_91500.caffemodel
I1017 01:50:19.909833   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_91500.solverstate
I1017 01:50:20.527468   329 solver.cpp:243] Iteration 91500, loss = 2288.27
I1017 01:50:20.527503   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.58638 (* 1 = 8.58638 loss)
I1017 01:50:20.527509   329 solver.cpp:259]     Train net output #1: seg_loss = 2839.95 (* 1 = 2839.95 loss)
I1017 01:50:20.527515   329 sgd_solver.cpp:138] Iteration 91500, lr = 0.000125
I1017 01:51:19.255527   329 solver.cpp:243] Iteration 91600, loss = 2774.16
I1017 01:51:19.255563   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.71819 (* 1 = 6.71819 loss)
I1017 01:51:19.255568   329 solver.cpp:259]     Train net output #1: seg_loss = 2369.27 (* 1 = 2369.27 loss)
I1017 01:51:19.255574   329 sgd_solver.cpp:138] Iteration 91600, lr = 0.000125
I1017 01:52:17.981752   329 solver.cpp:243] Iteration 91700, loss = 2400.95
I1017 01:52:17.981786   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.95793 (* 1 = 4.95793 loss)
I1017 01:52:17.981792   329 solver.cpp:259]     Train net output #1: seg_loss = 1433.52 (* 1 = 1433.52 loss)
I1017 01:52:17.981798   329 sgd_solver.cpp:138] Iteration 91700, lr = 0.000125
I1017 01:53:17.297749   329 solver.cpp:243] Iteration 91800, loss = 3576.34
I1017 01:53:17.297791   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.4636 (* 1 = 10.4636 loss)
I1017 01:53:17.297798   329 solver.cpp:259]     Train net output #1: seg_loss = 3015.09 (* 1 = 3015.09 loss)
I1017 01:53:17.297804   329 sgd_solver.cpp:138] Iteration 91800, lr = 0.000125
I1017 01:54:16.535434   329 solver.cpp:243] Iteration 91900, loss = 2100.43
I1017 01:54:16.535468   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.25395 (* 1 = 7.25395 loss)
I1017 01:54:16.535476   329 solver.cpp:259]     Train net output #1: seg_loss = 2042.31 (* 1 = 2042.31 loss)
I1017 01:54:16.535501   329 sgd_solver.cpp:138] Iteration 91900, lr = 0.000125
I1017 01:55:16.054935   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_92000.caffemodel
I1017 01:55:16.381263   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_92000.solverstate
I1017 01:55:16.603396   329 net.cpp:693] Ignoring source layer mbox_loss
I1017 01:55:17.691905   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 01:56:53.947432   329 solver.cpp:243] Iteration 92000, loss = 2798.45
I1017 01:56:53.947463   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.66508 (* 1 = 4.66508 loss)
I1017 01:56:53.947469   329 solver.cpp:259]     Train net output #1: seg_loss = 2793.79 (* 1 = 2793.79 loss)
I1017 01:56:53.947474   329 sgd_solver.cpp:138] Iteration 92000, lr = 0.000125
I1017 01:57:52.704017   329 solver.cpp:243] Iteration 92100, loss = 2432.27
I1017 01:57:52.704051   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.14961 (* 1 = 6.14961 loss)
I1017 01:57:52.704057   329 solver.cpp:259]     Train net output #1: seg_loss = 1916.93 (* 1 = 1916.93 loss)
I1017 01:57:52.704063   329 sgd_solver.cpp:138] Iteration 92100, lr = 0.000125
I1017 01:58:51.719979   329 solver.cpp:243] Iteration 92200, loss = 2488.35
I1017 01:58:51.720011   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.73942 (* 1 = 5.73942 loss)
I1017 01:58:51.720017   329 solver.cpp:259]     Train net output #1: seg_loss = 2393.68 (* 1 = 2393.68 loss)
I1017 01:58:51.720023   329 sgd_solver.cpp:138] Iteration 92200, lr = 0.000125
I1017 01:59:50.041873   329 solver.cpp:243] Iteration 92300, loss = 3427.12
I1017 01:59:50.041904   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.96757 (* 1 = 7.96757 loss)
I1017 01:59:50.041911   329 solver.cpp:259]     Train net output #1: seg_loss = 5579.5 (* 1 = 5579.5 loss)
I1017 01:59:50.041916   329 sgd_solver.cpp:138] Iteration 92300, lr = 0.000125
I1017 02:00:49.807025   329 solver.cpp:243] Iteration 92400, loss = 2178.05
I1017 02:00:49.807073   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.86485 (* 1 = 6.86485 loss)
I1017 02:00:49.807080   329 solver.cpp:259]     Train net output #1: seg_loss = 2162.68 (* 1 = 2162.68 loss)
I1017 02:00:49.807085   329 sgd_solver.cpp:138] Iteration 92400, lr = 0.000125
I1017 02:01:49.064457   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_92500.caffemodel
I1017 02:01:49.357228   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_92500.solverstate
I1017 02:01:49.941411   329 solver.cpp:243] Iteration 92500, loss = 2497.72
I1017 02:01:49.941453   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.17061 (* 1 = 9.17061 loss)
I1017 02:01:49.941460   329 solver.cpp:259]     Train net output #1: seg_loss = 2514.12 (* 1 = 2514.12 loss)
I1017 02:01:49.941467   329 sgd_solver.cpp:138] Iteration 92500, lr = 0.000125
I1017 02:01:59.379307   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:02:49.755291   329 solver.cpp:243] Iteration 92600, loss = 1943.22
I1017 02:02:49.755321   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.62219 (* 1 = 3.62219 loss)
I1017 02:02:49.755327   329 solver.cpp:259]     Train net output #1: seg_loss = 1859.91 (* 1 = 1859.91 loss)
I1017 02:02:49.755333   329 sgd_solver.cpp:138] Iteration 92600, lr = 0.000125
I1017 02:03:48.894873   329 solver.cpp:243] Iteration 92700, loss = 2294.41
I1017 02:03:48.894922   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.92484 (* 1 = 8.92484 loss)
I1017 02:03:48.894932   329 solver.cpp:259]     Train net output #1: seg_loss = 3807.36 (* 1 = 3807.36 loss)
I1017 02:03:48.894938   329 sgd_solver.cpp:138] Iteration 92700, lr = 0.000125
I1017 02:04:47.235971   329 solver.cpp:243] Iteration 92800, loss = 2017.62
I1017 02:04:47.236022   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.437 (* 1 = 7.437 loss)
I1017 02:04:47.236028   329 solver.cpp:259]     Train net output #1: seg_loss = 2378.56 (* 1 = 2378.56 loss)
I1017 02:04:47.236034   329 sgd_solver.cpp:138] Iteration 92800, lr = 0.000125
I1017 02:05:46.864533   329 solver.cpp:243] Iteration 92900, loss = 2795.69
I1017 02:05:46.864584   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.68894 (* 1 = 5.68894 loss)
I1017 02:05:46.864590   329 solver.cpp:259]     Train net output #1: seg_loss = 2099.31 (* 1 = 2099.31 loss)
I1017 02:05:46.864595   329 sgd_solver.cpp:138] Iteration 92900, lr = 0.000125
I1017 02:06:45.692771   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_93000.caffemodel
I1017 02:06:45.953891   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_93000.solverstate
I1017 02:06:46.573223   329 solver.cpp:243] Iteration 93000, loss = 2349.35
I1017 02:06:46.573268   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.90296 (* 1 = 6.90296 loss)
I1017 02:06:46.573274   329 solver.cpp:259]     Train net output #1: seg_loss = 3189.08 (* 1 = 3189.08 loss)
I1017 02:06:46.573282   329 sgd_solver.cpp:138] Iteration 93000, lr = 0.000125
I1017 02:07:46.472879   329 solver.cpp:243] Iteration 93100, loss = 1937.48
I1017 02:07:46.472929   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.40029 (* 1 = 3.40029 loss)
I1017 02:07:46.472935   329 solver.cpp:259]     Train net output #1: seg_loss = 2368 (* 1 = 2368 loss)
I1017 02:07:46.472941   329 sgd_solver.cpp:138] Iteration 93100, lr = 0.000125
I1017 02:08:45.801198   329 solver.cpp:243] Iteration 93200, loss = 2036.13
I1017 02:08:45.801241   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.90608 (* 1 = 7.90608 loss)
I1017 02:08:45.801247   329 solver.cpp:259]     Train net output #1: seg_loss = 1686.69 (* 1 = 1686.69 loss)
I1017 02:08:45.801254   329 sgd_solver.cpp:138] Iteration 93200, lr = 0.000125
I1017 02:09:45.048732   329 solver.cpp:243] Iteration 93300, loss = 3015.73
I1017 02:09:45.048780   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.11265 (* 1 = 7.11265 loss)
I1017 02:09:45.048786   329 solver.cpp:259]     Train net output #1: seg_loss = 2520.74 (* 1 = 2520.74 loss)
I1017 02:09:45.048791   329 sgd_solver.cpp:138] Iteration 93300, lr = 0.000125
I1017 02:10:43.567895   329 solver.cpp:243] Iteration 93400, loss = 2593.42
I1017 02:10:43.567943   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.85934 (* 1 = 5.85934 loss)
I1017 02:10:43.567950   329 solver.cpp:259]     Train net output #1: seg_loss = 1910.41 (* 1 = 1910.41 loss)
I1017 02:10:43.567956   329 sgd_solver.cpp:138] Iteration 93400, lr = 0.000125
I1017 02:11:42.465502   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_93500.caffemodel
I1017 02:11:42.736932   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_93500.solverstate
I1017 02:11:43.307216   329 solver.cpp:243] Iteration 93500, loss = 2227.43
I1017 02:11:43.307251   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.21925 (* 1 = 5.21925 loss)
I1017 02:11:43.307257   329 solver.cpp:259]     Train net output #1: seg_loss = 2005.81 (* 1 = 2005.81 loss)
I1017 02:11:43.307262   329 sgd_solver.cpp:138] Iteration 93500, lr = 0.000125
I1017 02:11:55.039911   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:12:43.072938   329 solver.cpp:243] Iteration 93600, loss = 2841.11
I1017 02:12:43.072980   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14643 (* 1 = 7.14643 loss)
I1017 02:12:43.072986   329 solver.cpp:259]     Train net output #1: seg_loss = 2828.95 (* 1 = 2828.95 loss)
I1017 02:12:43.072993   329 sgd_solver.cpp:138] Iteration 93600, lr = 0.000125
I1017 02:13:42.949903   329 solver.cpp:243] Iteration 93700, loss = 2032.05
I1017 02:13:42.949935   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.34602 (* 1 = 4.34602 loss)
I1017 02:13:42.949942   329 solver.cpp:259]     Train net output #1: seg_loss = 1888.03 (* 1 = 1888.03 loss)
I1017 02:13:42.949949   329 sgd_solver.cpp:138] Iteration 93700, lr = 0.000125
I1017 02:14:42.035497   329 solver.cpp:243] Iteration 93800, loss = 1996.55
I1017 02:14:42.035531   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.87546 (* 1 = 6.87546 loss)
I1017 02:14:42.035537   329 solver.cpp:259]     Train net output #1: seg_loss = 1996.34 (* 1 = 1996.34 loss)
I1017 02:14:42.035542   329 sgd_solver.cpp:138] Iteration 93800, lr = 0.000125
I1017 02:15:40.127171   329 solver.cpp:243] Iteration 93900, loss = 2284.35
I1017 02:15:40.127221   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.49622 (* 1 = 5.49622 loss)
I1017 02:15:40.127228   329 solver.cpp:259]     Train net output #1: seg_loss = 2580.59 (* 1 = 2580.59 loss)
I1017 02:15:40.127234   329 sgd_solver.cpp:138] Iteration 93900, lr = 0.000125
I1017 02:16:39.518257   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_94000.caffemodel
I1017 02:16:39.826491   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_94000.solverstate
I1017 02:16:40.453512   329 solver.cpp:243] Iteration 94000, loss = 2194.84
I1017 02:16:40.453554   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.5325 (* 1 = 6.5325 loss)
I1017 02:16:40.453560   329 solver.cpp:259]     Train net output #1: seg_loss = 1751.09 (* 1 = 1751.09 loss)
I1017 02:16:40.453567   329 sgd_solver.cpp:138] Iteration 94000, lr = 0.000125
I1017 02:17:39.700240   329 solver.cpp:243] Iteration 94100, loss = 1696.17
I1017 02:17:39.700289   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.65499 (* 1 = 5.65499 loss)
I1017 02:17:39.700294   329 solver.cpp:259]     Train net output #1: seg_loss = 150.837 (* 1 = 150.837 loss)
I1017 02:17:39.700300   329 sgd_solver.cpp:138] Iteration 94100, lr = 0.000125
I1017 02:18:39.975159   329 solver.cpp:243] Iteration 94200, loss = 2015.83
I1017 02:18:39.975193   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.66089 (* 1 = 8.66089 loss)
I1017 02:18:39.975198   329 solver.cpp:259]     Train net output #1: seg_loss = 1610.09 (* 1 = 1610.09 loss)
I1017 02:18:39.975204   329 sgd_solver.cpp:138] Iteration 94200, lr = 0.000125
I1017 02:19:39.042107   329 solver.cpp:243] Iteration 94300, loss = 2687.95
I1017 02:19:39.042138   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.93571 (* 1 = 6.93571 loss)
I1017 02:19:39.042145   329 solver.cpp:259]     Train net output #1: seg_loss = 4894.84 (* 1 = 4894.84 loss)
I1017 02:19:39.042151   329 sgd_solver.cpp:138] Iteration 94300, lr = 0.000125
I1017 02:20:38.001094   329 solver.cpp:243] Iteration 94400, loss = 2387.83
I1017 02:20:38.001132   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.84787 (* 1 = 5.84787 loss)
I1017 02:20:38.001138   329 solver.cpp:259]     Train net output #1: seg_loss = 1994.22 (* 1 = 1994.22 loss)
I1017 02:20:38.001144   329 sgd_solver.cpp:138] Iteration 94400, lr = 0.000125
I1017 02:21:36.516258   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_94500.caffemodel
I1017 02:21:36.837322   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_94500.solverstate
I1017 02:21:37.428424   329 solver.cpp:243] Iteration 94500, loss = 3968.4
I1017 02:21:37.428472   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.67287 (* 1 = 7.67287 loss)
I1017 02:21:37.428478   329 solver.cpp:259]     Train net output #1: seg_loss = 4618.78 (* 1 = 4618.78 loss)
I1017 02:21:37.428485   329 sgd_solver.cpp:138] Iteration 94500, lr = 0.000125
I1017 02:21:52.714015   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:22:36.444535   329 solver.cpp:243] Iteration 94600, loss = 2263.95
I1017 02:22:36.444568   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.76569 (* 1 = 3.76569 loss)
I1017 02:22:36.444574   329 solver.cpp:259]     Train net output #1: seg_loss = 1960.48 (* 1 = 1960.48 loss)
I1017 02:22:36.444581   329 sgd_solver.cpp:138] Iteration 94600, lr = 0.000125
I1017 02:23:36.443013   329 solver.cpp:243] Iteration 94700, loss = 2414.34
I1017 02:23:36.443058   329 solver.cpp:259]     Train net output #0: mbox_loss = 1.78403 (* 1 = 1.78403 loss)
I1017 02:23:36.443065   329 solver.cpp:259]     Train net output #1: seg_loss = 1832.05 (* 1 = 1832.05 loss)
I1017 02:23:36.443073   329 sgd_solver.cpp:138] Iteration 94700, lr = 0.000125
I1017 02:24:36.214171   329 solver.cpp:243] Iteration 94800, loss = 2957.39
I1017 02:24:36.214205   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.43649 (* 1 = 5.43649 loss)
I1017 02:24:36.214210   329 solver.cpp:259]     Train net output #1: seg_loss = 2861.88 (* 1 = 2861.88 loss)
I1017 02:24:36.214216   329 sgd_solver.cpp:138] Iteration 94800, lr = 0.000125
I1017 02:25:35.200498   329 solver.cpp:243] Iteration 94900, loss = 2261.12
I1017 02:25:35.200536   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.78978 (* 1 = 7.78978 loss)
I1017 02:25:35.200544   329 solver.cpp:259]     Train net output #1: seg_loss = 3634.2 (* 1 = 3634.2 loss)
I1017 02:25:35.200553   329 sgd_solver.cpp:138] Iteration 94900, lr = 0.000125
I1017 02:26:33.069072   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_95000.caffemodel
I1017 02:26:33.367743   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_95000.solverstate
I1017 02:26:33.956655   329 solver.cpp:243] Iteration 95000, loss = 2726.62
I1017 02:26:33.956686   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.14983 (* 1 = 9.14983 loss)
I1017 02:26:33.956691   329 solver.cpp:259]     Train net output #1: seg_loss = 2426.42 (* 1 = 2426.42 loss)
I1017 02:26:33.956696   329 sgd_solver.cpp:138] Iteration 95000, lr = 0.000125
I1017 02:27:33.400499   329 solver.cpp:243] Iteration 95100, loss = 1986.32
I1017 02:27:33.400549   329 solver.cpp:259]     Train net output #0: mbox_loss = 13.6899 (* 1 = 13.6899 loss)
I1017 02:27:33.400555   329 solver.cpp:259]     Train net output #1: seg_loss = 1702.5 (* 1 = 1702.5 loss)
I1017 02:27:33.400562   329 sgd_solver.cpp:138] Iteration 95100, lr = 0.000125
I1017 02:28:33.066150   329 solver.cpp:243] Iteration 95200, loss = 2429.02
I1017 02:28:33.066197   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.59829 (* 1 = 3.59829 loss)
I1017 02:28:33.066205   329 solver.cpp:259]     Train net output #1: seg_loss = 1734.95 (* 1 = 1734.95 loss)
I1017 02:28:33.066210   329 sgd_solver.cpp:138] Iteration 95200, lr = 0.000125
I1017 02:29:33.982122   329 solver.cpp:243] Iteration 95300, loss = 2424.07
I1017 02:29:33.982169   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.8317 (* 1 = 8.8317 loss)
I1017 02:29:33.982192   329 solver.cpp:259]     Train net output #1: seg_loss = 1434.79 (* 1 = 1434.79 loss)
I1017 02:29:33.982197   329 sgd_solver.cpp:138] Iteration 95300, lr = 0.000125
I1017 02:30:33.218869   329 solver.cpp:243] Iteration 95400, loss = 2665.07
I1017 02:30:33.218919   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.77197 (* 1 = 7.77197 loss)
I1017 02:30:33.218925   329 solver.cpp:259]     Train net output #1: seg_loss = 2384.95 (* 1 = 2384.95 loss)
I1017 02:30:33.218931   329 sgd_solver.cpp:138] Iteration 95400, lr = 0.000125
I1017 02:31:31.348907   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_95500.caffemodel
I1017 02:31:31.608041   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_95500.solverstate
I1017 02:31:32.174610   329 solver.cpp:243] Iteration 95500, loss = 2063.39
I1017 02:31:32.174655   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.04707 (* 1 = 6.04707 loss)
I1017 02:31:32.174661   329 solver.cpp:259]     Train net output #1: seg_loss = 2214.28 (* 1 = 2214.28 loss)
I1017 02:31:32.174669   329 sgd_solver.cpp:138] Iteration 95500, lr = 0.000125
I1017 02:31:50.537235   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:32:31.374228   329 solver.cpp:243] Iteration 95600, loss = 2398.49
I1017 02:32:31.374274   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.31668 (* 1 = 5.31668 loss)
I1017 02:32:31.374279   329 solver.cpp:259]     Train net output #1: seg_loss = 2490.01 (* 1 = 2490.01 loss)
I1017 02:32:31.374285   329 sgd_solver.cpp:138] Iteration 95600, lr = 0.000125
I1017 02:33:30.580687   329 solver.cpp:243] Iteration 95700, loss = 1926.37
I1017 02:33:30.580736   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.34294 (* 1 = 6.34294 loss)
I1017 02:33:30.580744   329 solver.cpp:259]     Train net output #1: seg_loss = 1487.87 (* 1 = 1487.87 loss)
I1017 02:33:30.580749   329 sgd_solver.cpp:138] Iteration 95700, lr = 0.000125
I1017 02:34:30.713524   329 solver.cpp:243] Iteration 95800, loss = 3249.02
I1017 02:34:30.713557   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.79039 (* 1 = 8.79039 loss)
I1017 02:34:30.713563   329 solver.cpp:259]     Train net output #1: seg_loss = 1551.36 (* 1 = 1551.36 loss)
I1017 02:34:30.713569   329 sgd_solver.cpp:138] Iteration 95800, lr = 0.000125
I1017 02:35:30.296315   329 solver.cpp:243] Iteration 95900, loss = 2212.55
I1017 02:35:30.296363   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.65121 (* 1 = 4.65121 loss)
I1017 02:35:30.296370   329 solver.cpp:259]     Train net output #1: seg_loss = 1786.84 (* 1 = 1786.84 loss)
I1017 02:35:30.296375   329 sgd_solver.cpp:138] Iteration 95900, lr = 0.000125
I1017 02:36:28.918598   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_96000.caffemodel
I1017 02:36:29.238595   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_96000.solverstate
I1017 02:36:29.480716   329 net.cpp:693] Ignoring source layer mbox_loss
I1017 02:38:06.534158   329 solver.cpp:243] Iteration 96000, loss = 2419.4
I1017 02:38:06.534193   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.41527 (* 1 = 8.41527 loss)
I1017 02:38:06.534198   329 solver.cpp:259]     Train net output #1: seg_loss = 2410.99 (* 1 = 2410.99 loss)
I1017 02:38:06.534205   329 sgd_solver.cpp:138] Iteration 96000, lr = 0.000125
I1017 02:38:29.841410   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:39:04.018645   329 solver.cpp:243] Iteration 96100, loss = 2660.54
I1017 02:39:04.018677   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.83074 (* 1 = 5.83074 loss)
I1017 02:39:04.018684   329 solver.cpp:259]     Train net output #1: seg_loss = 1882.04 (* 1 = 1882.04 loss)
I1017 02:39:04.018690   329 sgd_solver.cpp:138] Iteration 96100, lr = 0.000125
I1017 02:40:03.592749   329 solver.cpp:243] Iteration 96200, loss = 1937.2
I1017 02:40:03.592785   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.07607 (* 1 = 6.07607 loss)
I1017 02:40:03.592794   329 solver.cpp:259]     Train net output #1: seg_loss = 2261.25 (* 1 = 2261.25 loss)
I1017 02:40:03.592816   329 sgd_solver.cpp:138] Iteration 96200, lr = 0.000125
I1017 02:41:03.470572   329 solver.cpp:243] Iteration 96300, loss = 2259.78
I1017 02:41:03.470619   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.33147 (* 1 = 7.33147 loss)
I1017 02:41:03.470626   329 solver.cpp:259]     Train net output #1: seg_loss = 2192.68 (* 1 = 2192.68 loss)
I1017 02:41:03.470631   329 sgd_solver.cpp:138] Iteration 96300, lr = 0.000125
I1017 02:42:03.464725   329 solver.cpp:243] Iteration 96400, loss = 1901.47
I1017 02:42:03.464774   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.56578 (* 1 = 5.56578 loss)
I1017 02:42:03.464781   329 solver.cpp:259]     Train net output #1: seg_loss = 1371.29 (* 1 = 1371.29 loss)
I1017 02:42:03.464787   329 sgd_solver.cpp:138] Iteration 96400, lr = 0.000125
I1017 02:43:02.021809   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_96500.caffemodel
I1017 02:43:02.313992   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_96500.solverstate
I1017 02:43:02.935385   329 solver.cpp:243] Iteration 96500, loss = 2423.61
I1017 02:43:02.935417   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.11629 (* 1 = 9.11629 loss)
I1017 02:43:02.935423   329 solver.cpp:259]     Train net output #1: seg_loss = 2044.54 (* 1 = 2044.54 loss)
I1017 02:43:02.935429   329 sgd_solver.cpp:138] Iteration 96500, lr = 0.000125
I1017 02:44:00.819197   329 solver.cpp:243] Iteration 96600, loss = 2190.29
I1017 02:44:00.819245   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.51274 (* 1 = 4.51274 loss)
I1017 02:44:00.819252   329 solver.cpp:259]     Train net output #1: seg_loss = 2462.85 (* 1 = 2462.85 loss)
I1017 02:44:00.819257   329 sgd_solver.cpp:138] Iteration 96600, lr = 0.000125
I1017 02:45:00.669581   329 solver.cpp:243] Iteration 96700, loss = 2323.54
I1017 02:45:00.669615   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.10049 (* 1 = 7.10049 loss)
I1017 02:45:00.669621   329 solver.cpp:259]     Train net output #1: seg_loss = 3072.17 (* 1 = 3072.17 loss)
I1017 02:45:00.669626   329 sgd_solver.cpp:138] Iteration 96700, lr = 0.000125
I1017 02:46:00.049931   329 solver.cpp:243] Iteration 96800, loss = 2698.31
I1017 02:46:00.049963   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.09105 (* 1 = 8.09105 loss)
I1017 02:46:00.049969   329 solver.cpp:259]     Train net output #1: seg_loss = 1857.45 (* 1 = 1857.45 loss)
I1017 02:46:00.049975   329 sgd_solver.cpp:138] Iteration 96800, lr = 0.000125
I1017 02:47:00.273988   329 solver.cpp:243] Iteration 96900, loss = 1756.95
I1017 02:47:00.274020   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.54407 (* 1 = 4.54407 loss)
I1017 02:47:00.274027   329 solver.cpp:259]     Train net output #1: seg_loss = 1577.65 (* 1 = 1577.65 loss)
I1017 02:47:00.274034   329 sgd_solver.cpp:138] Iteration 96900, lr = 0.000125
I1017 02:47:58.961036   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_97000.caffemodel
I1017 02:47:59.297526   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_97000.solverstate
I1017 02:47:59.946944   329 solver.cpp:243] Iteration 97000, loss = 2205.47
I1017 02:47:59.946976   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.43193 (* 1 = 4.43193 loss)
I1017 02:47:59.946983   329 solver.cpp:259]     Train net output #1: seg_loss = 2990.08 (* 1 = 2990.08 loss)
I1017 02:47:59.946988   329 sgd_solver.cpp:138] Iteration 97000, lr = 0.000125
I1017 02:48:28.302407   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:48:58.812058   329 solver.cpp:243] Iteration 97100, loss = 2678.11
I1017 02:48:58.812106   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.6303 (* 1 = 6.6303 loss)
I1017 02:48:58.812113   329 solver.cpp:259]     Train net output #1: seg_loss = 2727.42 (* 1 = 2727.42 loss)
I1017 02:48:58.812119   329 sgd_solver.cpp:138] Iteration 97100, lr = 0.000125
I1017 02:49:57.709025   329 solver.cpp:243] Iteration 97200, loss = 2914.39
I1017 02:49:57.709074   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.91721 (* 1 = 7.91721 loss)
I1017 02:49:57.709079   329 solver.cpp:259]     Train net output #1: seg_loss = 3949.95 (* 1 = 3949.95 loss)
I1017 02:49:57.709085   329 sgd_solver.cpp:138] Iteration 97200, lr = 0.000125
I1017 02:50:56.994927   329 solver.cpp:243] Iteration 97300, loss = 1812.48
I1017 02:50:56.994961   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.26454 (* 1 = 6.26454 loss)
I1017 02:50:56.994966   329 solver.cpp:259]     Train net output #1: seg_loss = 2192 (* 1 = 2192 loss)
I1017 02:50:56.994972   329 sgd_solver.cpp:138] Iteration 97300, lr = 0.000125
I1017 02:51:56.975751   329 solver.cpp:243] Iteration 97400, loss = 2825.43
I1017 02:51:56.975783   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.71582 (* 1 = 3.71582 loss)
I1017 02:51:56.975790   329 solver.cpp:259]     Train net output #1: seg_loss = 2204.45 (* 1 = 2204.45 loss)
I1017 02:51:56.975795   329 sgd_solver.cpp:138] Iteration 97400, lr = 0.000125
I1017 02:52:56.332145   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_97500.caffemodel
I1017 02:52:56.632472   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_97500.solverstate
I1017 02:52:57.214327   329 solver.cpp:243] Iteration 97500, loss = 2479.26
I1017 02:52:57.214360   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.93024 (* 1 = 7.93024 loss)
I1017 02:52:57.214366   329 solver.cpp:259]     Train net output #1: seg_loss = 1957.73 (* 1 = 1957.73 loss)
I1017 02:52:57.214372   329 sgd_solver.cpp:138] Iteration 97500, lr = 0.000125
I1017 02:53:55.940310   329 solver.cpp:243] Iteration 97600, loss = 1825.03
I1017 02:53:55.940345   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.82029 (* 1 = 3.82029 loss)
I1017 02:53:55.940351   329 solver.cpp:259]     Train net output #1: seg_loss = 1956.54 (* 1 = 1956.54 loss)
I1017 02:53:55.940356   329 sgd_solver.cpp:138] Iteration 97600, lr = 0.000125
I1017 02:54:54.170878   329 solver.cpp:243] Iteration 97700, loss = 2420.69
I1017 02:54:54.170912   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.8729 (* 1 = 3.8729 loss)
I1017 02:54:54.170917   329 solver.cpp:259]     Train net output #1: seg_loss = 2377.99 (* 1 = 2377.99 loss)
I1017 02:54:54.170924   329 sgd_solver.cpp:138] Iteration 97700, lr = 0.000125
I1017 02:55:53.929798   329 solver.cpp:243] Iteration 97800, loss = 1996.76
I1017 02:55:53.929834   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.35866 (* 1 = 5.35866 loss)
I1017 02:55:53.929841   329 solver.cpp:259]     Train net output #1: seg_loss = 1688.93 (* 1 = 1688.93 loss)
I1017 02:55:53.929847   329 sgd_solver.cpp:138] Iteration 97800, lr = 0.000125
I1017 02:56:53.500532   329 solver.cpp:243] Iteration 97900, loss = 1888.86
I1017 02:56:53.500579   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.2933 (* 1 = 7.2933 loss)
I1017 02:56:53.500586   329 solver.cpp:259]     Train net output #1: seg_loss = 3393.22 (* 1 = 3393.22 loss)
I1017 02:56:53.500592   329 sgd_solver.cpp:138] Iteration 97900, lr = 0.000125
I1017 02:57:53.223124   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_98000.caffemodel
I1017 02:57:53.512523   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_98000.solverstate
I1017 02:57:54.093502   329 solver.cpp:243] Iteration 98000, loss = 2164.48
I1017 02:57:54.093539   329 solver.cpp:259]     Train net output #0: mbox_loss = 8.26153 (* 1 = 8.26153 loss)
I1017 02:57:54.093545   329 solver.cpp:259]     Train net output #1: seg_loss = 2431.7 (* 1 = 2431.7 loss)
I1017 02:57:54.093552   329 sgd_solver.cpp:138] Iteration 98000, lr = 0.000125
I1017 02:58:25.841753   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 02:58:52.827945   329 solver.cpp:243] Iteration 98100, loss = 2856.84
I1017 02:58:52.827992   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.52887 (* 1 = 7.52887 loss)
I1017 02:58:52.827998   329 solver.cpp:259]     Train net output #1: seg_loss = 3593.56 (* 1 = 3593.56 loss)
I1017 02:58:52.828004   329 sgd_solver.cpp:138] Iteration 98100, lr = 0.000125
I1017 02:59:51.559270   329 solver.cpp:243] Iteration 98200, loss = 2338.48
I1017 02:59:51.559317   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.73555 (* 1 = 4.73555 loss)
I1017 02:59:51.559324   329 solver.cpp:259]     Train net output #1: seg_loss = 1571.04 (* 1 = 1571.04 loss)
I1017 02:59:51.559330   329 sgd_solver.cpp:138] Iteration 98200, lr = 0.000125
I1017 03:00:50.916312   329 solver.cpp:243] Iteration 98300, loss = 3475.32
I1017 03:00:50.916347   329 solver.cpp:259]     Train net output #0: mbox_loss = 10.7341 (* 1 = 10.7341 loss)
I1017 03:00:50.916353   329 solver.cpp:259]     Train net output #1: seg_loss = 3168.53 (* 1 = 3168.53 loss)
I1017 03:00:50.916359   329 sgd_solver.cpp:138] Iteration 98300, lr = 0.000125
I1017 03:01:50.153384   329 solver.cpp:243] Iteration 98400, loss = 2017.22
I1017 03:01:50.153434   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.54736 (* 1 = 9.54736 loss)
I1017 03:01:50.153440   329 solver.cpp:259]     Train net output #1: seg_loss = 2484.82 (* 1 = 2484.82 loss)
I1017 03:01:50.153446   329 sgd_solver.cpp:138] Iteration 98400, lr = 0.000125
I1017 03:02:49.569635   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_98500.caffemodel
I1017 03:02:49.859870   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_98500.solverstate
I1017 03:02:50.449108   329 solver.cpp:243] Iteration 98500, loss = 2423.6
I1017 03:02:50.449143   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.73337 (* 1 = 4.73337 loss)
I1017 03:02:50.449153   329 solver.cpp:259]     Train net output #1: seg_loss = 3271.28 (* 1 = 3271.28 loss)
I1017 03:02:50.449172   329 sgd_solver.cpp:138] Iteration 98500, lr = 0.000125
I1017 03:03:50.003000   329 solver.cpp:243] Iteration 98600, loss = 2544.67
I1017 03:03:50.003036   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.0558 (* 1 = 9.0558 loss)
I1017 03:03:50.003046   329 solver.cpp:259]     Train net output #1: seg_loss = 2478.03 (* 1 = 2478.03 loss)
I1017 03:03:50.003068   329 sgd_solver.cpp:138] Iteration 98600, lr = 0.000125
I1017 03:04:49.005852   329 solver.cpp:243] Iteration 98700, loss = 2366.87
I1017 03:04:49.005887   329 solver.cpp:259]     Train net output #0: mbox_loss = 6.55316 (* 1 = 6.55316 loss)
I1017 03:04:49.005892   329 solver.cpp:259]     Train net output #1: seg_loss = 2590.3 (* 1 = 2590.3 loss)
I1017 03:04:49.005898   329 sgd_solver.cpp:138] Iteration 98700, lr = 0.000125
I1017 03:05:47.424464   329 solver.cpp:243] Iteration 98800, loss = 3073.94
I1017 03:05:47.424510   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.16474 (* 1 = 4.16474 loss)
I1017 03:05:47.424517   329 solver.cpp:259]     Train net output #1: seg_loss = 2923.9 (* 1 = 2923.9 loss)
I1017 03:05:47.424523   329 sgd_solver.cpp:138] Iteration 98800, lr = 0.000125
I1017 03:06:47.275570   329 solver.cpp:243] Iteration 98900, loss = 2177.63
I1017 03:06:47.275604   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.24494 (* 1 = 5.24494 loss)
I1017 03:06:47.275609   329 solver.cpp:259]     Train net output #1: seg_loss = 1839.23 (* 1 = 1839.23 loss)
I1017 03:06:47.275616   329 sgd_solver.cpp:138] Iteration 98900, lr = 0.000125
I1017 03:07:46.522825   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_99000.caffemodel
I1017 03:07:46.821374   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_99000.solverstate
I1017 03:07:47.412490   329 solver.cpp:243] Iteration 99000, loss = 2456.2
I1017 03:07:47.412526   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.20449 (* 1 = 4.20449 loss)
I1017 03:07:47.412535   329 solver.cpp:259]     Train net output #1: seg_loss = 2175.62 (* 1 = 2175.62 loss)
I1017 03:07:47.412554   329 sgd_solver.cpp:138] Iteration 99000, lr = 0.000125
I1017 03:08:22.663439   329 blocking_queue.cpp:50] Data layer prefetch queue empty
I1017 03:08:47.200749   329 solver.cpp:243] Iteration 99100, loss = 1996.99
I1017 03:08:47.200785   329 solver.cpp:259]     Train net output #0: mbox_loss = 4.81816 (* 1 = 4.81816 loss)
I1017 03:08:47.200794   329 solver.cpp:259]     Train net output #1: seg_loss = 1746.71 (* 1 = 1746.71 loss)
I1017 03:08:47.200819   329 sgd_solver.cpp:138] Iteration 99100, lr = 0.000125
I1017 03:09:46.415197   329 solver.cpp:243] Iteration 99200, loss = 2061.09
I1017 03:09:46.415261   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.14167 (* 1 = 7.14167 loss)
I1017 03:09:46.415271   329 solver.cpp:259]     Train net output #1: seg_loss = 2401.86 (* 1 = 2401.86 loss)
I1017 03:09:46.415278   329 sgd_solver.cpp:138] Iteration 99200, lr = 0.000125
I1017 03:10:44.803308   329 solver.cpp:243] Iteration 99300, loss = 1935.01
I1017 03:10:44.803344   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.82826 (* 1 = 3.82826 loss)
I1017 03:10:44.803351   329 solver.cpp:259]     Train net output #1: seg_loss = 1671.35 (* 1 = 1671.35 loss)
I1017 03:10:44.803375   329 sgd_solver.cpp:138] Iteration 99300, lr = 0.000125
I1017 03:11:44.466260   329 solver.cpp:243] Iteration 99400, loss = 2647.2
I1017 03:11:44.466310   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.98729 (* 1 = 7.98729 loss)
I1017 03:11:44.466315   329 solver.cpp:259]     Train net output #1: seg_loss = 2754.36 (* 1 = 2754.36 loss)
I1017 03:11:44.466321   329 sgd_solver.cpp:138] Iteration 99400, lr = 0.000125
I1017 03:12:43.190131   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_99500.caffemodel
I1017 03:12:43.532858   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_99500.solverstate
I1017 03:12:44.108692   329 solver.cpp:243] Iteration 99500, loss = 2132.12
I1017 03:12:44.108738   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.74056 (* 1 = 5.74056 loss)
I1017 03:12:44.108744   329 solver.cpp:259]     Train net output #1: seg_loss = 2572.05 (* 1 = 2572.05 loss)
I1017 03:12:44.108750   329 sgd_solver.cpp:138] Iteration 99500, lr = 0.000125
I1017 03:13:44.137990   329 solver.cpp:243] Iteration 99600, loss = 1843.51
I1017 03:13:44.138033   329 solver.cpp:259]     Train net output #0: mbox_loss = 3.93411 (* 1 = 3.93411 loss)
I1017 03:13:44.138039   329 solver.cpp:259]     Train net output #1: seg_loss = 1355.33 (* 1 = 1355.33 loss)
I1017 03:13:44.138046   329 sgd_solver.cpp:138] Iteration 99600, lr = 0.000125
I1017 03:14:43.477651   329 solver.cpp:243] Iteration 99700, loss = 2154.43
I1017 03:14:43.477700   329 solver.cpp:259]     Train net output #0: mbox_loss = 7.58231 (* 1 = 7.58231 loss)
I1017 03:14:43.477706   329 solver.cpp:259]     Train net output #1: seg_loss = 1546.85 (* 1 = 1546.85 loss)
I1017 03:14:43.477712   329 sgd_solver.cpp:138] Iteration 99700, lr = 0.000125
I1017 03:15:42.760994   329 solver.cpp:243] Iteration 99800, loss = 2955.09
I1017 03:15:42.761044   329 solver.cpp:259]     Train net output #0: mbox_loss = 5.97606 (* 1 = 5.97606 loss)
I1017 03:15:42.761049   329 solver.cpp:259]     Train net output #1: seg_loss = 5239.87 (* 1 = 5239.87 loss)
I1017 03:15:42.761055   329 sgd_solver.cpp:138] Iteration 99800, lr = 0.000125
I1017 03:16:41.297191   329 solver.cpp:243] Iteration 99900, loss = 2555.69
I1017 03:16:41.297224   329 solver.cpp:259]     Train net output #0: mbox_loss = 9.08771 (* 1 = 9.08771 loss)
I1017 03:16:41.297230   329 solver.cpp:259]     Train net output #1: seg_loss = 1878.75 (* 1 = 1878.75 loss)
I1017 03:16:41.297236   329 sgd_solver.cpp:138] Iteration 99900, lr = 0.000125
I1017 03:17:40.253051   329 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_100000.caffemodel
I1017 03:17:40.512089   329 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_100000.solverstate
I1017 03:17:40.701818   329 net.cpp:693] Ignoring source layer mbox_loss
I1017 03:17:53.125947   329 blocking_queue.cpp:50] Data layer prefetch queue empty
 loss 133531.02775146483
>>> 2018-10-16 23:53:17.230957 Iteration 80000 overall accuracy 0.9584947786458333
>>> 2018-10-16 23:53:17.231001 Iteration 80000 mean accuracy 0.9544096623889453
>>> 2018-10-16 23:53:17.231149 Iteration 80000 mean IU 0.9120685895776552
>>> 2018-10-16 23:53:17.231232 Iteration 80000 fwavacc 0.9206893016907839
>>> 2018-10-17 00:32:52.902490 Begin seg tests
>>> 2018-10-17 00:34:29.521929 Iteration 84000 loss 170271.76455615234
>>> 2018-10-17 00:34:29.522001 Iteration 84000 overall accuracy 0.9547668098958333
>>> 2018-10-17 00:34:29.522030 Iteration 84000 mean accuracy 0.9473818604018178
>>> 2018-10-17 00:34:29.522147 Iteration 84000 mean IU 0.9045014242097158
>>> 2018-10-17 00:34:29.522226 Iteration 84000 fwavacc 0.9136442409239003
>>> 2018-10-17 01:14:03.452371 Begin seg tests
>>> 2018-10-17 01:15:40.929158 Iteration 88000 loss 155857.85843261718
>>> 2018-10-17 01:15:40.929231 Iteration 88000 overall accuracy 0.959166328125
>>> 2018-10-17 01:15:40.929259 Iteration 88000 mean accuracy 0.9529714149142172
>>> 2018-10-17 01:15:40.929374 Iteration 88000 mean IU 0.9132460988937736
>>> 2018-10-17 01:15:40.929442 Iteration 88000 fwavacc 0.9217512524178021
>>> 2018-10-17 01:55:16.603179 Begin seg tests
>>> 2018-10-17 01:56:53.539451 Iteration 92000 loss 147956.2342675781
>>> 2018-10-17 01:56:53.539523 Iteration 92000 overall accuracy 0.9585870052083333
>>> 2018-10-17 01:56:53.539552 Iteration 92000 mean accuracy 0.9543841558773878
>>> 2018-10-17 01:56:53.539667 Iteration 92000 mean IU 0.9117785314551746
>>> 2018-10-17 01:56:53.539736 Iteration 92000 fwavacc 0.9208895163799811
>>> 2018-10-17 02:36:29.480506 Begin seg tests
>>> 2018-10-17 02:38:06.138562 Iteration 96000 loss 209302.8632163086
>>> 2018-10-17 02:38:06.138643 Iteration 96000 overall accuracy 0.952984921875
>>> 2018-10-17 02:38:06.138672 Iteration 96000 mean accuracy 0.9450488645393118
>>> 2018-10-17 02:38:06.138793 Iteration 96000 mean IU 0.9019254126630682
>>> 2018-10-17 02:38:06.138863 Iteration 96000 fwavacc 0.9102680143034505
>>> 2018-10-17 03:17:40.701617 Begin seg tests
>>> 2018-10-17 03:19:18.591463 Iteration 100000 loss 136516.94418945312
>>> 2018-10-17 03:19:18.591535 Iteration 100000 overall accuracy 0.9577601432291667
>>> 2018-10-17 03:19:18.591563 Iteration 100000 mean accuracy 0.9544450844500387
>>> 2018-10-17 03:19:18.591679 Iteration 100000 mean IU 0.9101720393950927
>>> 2018-10-17 03:19:18.591747 Iteration 100000 fwavacc 0.9194561858550324
