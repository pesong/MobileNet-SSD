WARNING: Logging before InitGoogleLogging() is written to STDERR
I1015 10:56:50.995378 15018 solver.cpp:63] Initializing solver from parameters: 
train_net: "proto/union/MobileNetSSD_train.prototxt"
test_net: "proto/union/MobileNetSSD_test.prototxt"
test_iter: 673
test_interval: 99999999
base_lr: 0.0005
display: 20
max_iter: 120000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 500
snapshot_prefix: "snapshot/union/"
solver_mode: GPU
debug_info: false
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I1015 10:56:50.996623 15018 solver.cpp:96] Creating training net from train_net file: proto/union/MobileNetSSD_train.prototxt
I1015 10:56:51.008944 15018 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_train.prototxt
I1015 10:56:51.008958 15018 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 10:56:51.010622 15018 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_trainval_lmdb/"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_
I1015 10:56:51.011808 15018 layer_factory.hpp:77] Creating layer data
I1015 10:56:51.011987 15018 net.cpp:100] Creating Layer data
I1015 10:56:51.012006 15018 net.cpp:408] data -> data
I1015 10:56:51.012027 15018 net.cpp:408] data -> label
I1015 10:56:51.012042 15018 net.cpp:408] data -> label_seg
I1015 10:56:51.012265 15018 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1015 10:56:51.023865 15071 db_lmdb.cpp:35] Opened lmdb lmdb/seg_trainval_lmdb/
I1015 10:56:51.112211 15018 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 4,3,320,480
I1015 10:56:51.128943 15018 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1015 10:56:51.129007 15018 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1015 10:56:51.129014 15018 net.cpp:150] Setting up data
I1015 10:56:51.129022 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129026 15018 net.cpp:157] Top shape: 1 1 6 8 (48)
I1015 10:56:51.129029 15018 net.cpp:157] Top shape: 4 1 320 480 (614400)
I1015 10:56:51.129031 15018 net.cpp:165] Memory required for data: 9830592
I1015 10:56:51.129037 15018 layer_factory.hpp:77] Creating layer data_data_0_split
I1015 10:56:51.129051 15018 net.cpp:100] Creating Layer data_data_0_split
I1015 10:56:51.129055 15018 net.cpp:434] data_data_0_split <- data
I1015 10:56:51.129063 15018 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1015 10:56:51.129091 15018 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1015 10:56:51.129099 15018 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1015 10:56:51.129104 15018 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1015 10:56:51.129108 15018 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1015 10:56:51.129113 15018 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1015 10:56:51.129119 15018 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1015 10:56:51.129140 15018 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1015 10:56:51.129465 15018 net.cpp:150] Setting up data_data_0_split
I1015 10:56:51.129485 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129494 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129501 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129508 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129514 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129523 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129529 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129535 15018 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 10:56:51.129540 15018 net.cpp:165] Memory required for data: 68812992
I1015 10:56:51.129547 15018 layer_factory.hpp:77] Creating layer conv0
I1015 10:56:51.129570 15018 net.cpp:100] Creating Layer conv0
I1015 10:56:51.129576 15018 net.cpp:434] conv0 <- data_data_0_split_0
I1015 10:56:51.129588 15018 net.cpp:408] conv0 -> conv0
I1015 10:56:51.131963 15072 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1015 10:56:51.665534 15018 net.cpp:150] Setting up conv0
I1015 10:56:51.665556 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.665560 15018 net.cpp:165] Memory required for data: 88473792
I1015 10:56:51.665571 15018 layer_factory.hpp:77] Creating layer conv0/bn
I1015 10:56:51.665580 15018 net.cpp:100] Creating Layer conv0/bn
I1015 10:56:51.665583 15018 net.cpp:434] conv0/bn <- conv0
I1015 10:56:51.665588 15018 net.cpp:395] conv0/bn -> conv0 (in-place)
I1015 10:56:51.666563 15018 net.cpp:150] Setting up conv0/bn
I1015 10:56:51.666574 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.666594 15018 net.cpp:165] Memory required for data: 108134592
I1015 10:56:51.666602 15018 layer_factory.hpp:77] Creating layer conv0/scale
I1015 10:56:51.666612 15018 net.cpp:100] Creating Layer conv0/scale
I1015 10:56:51.666615 15018 net.cpp:434] conv0/scale <- conv0
I1015 10:56:51.666620 15018 net.cpp:395] conv0/scale -> conv0 (in-place)
I1015 10:56:51.666656 15018 layer_factory.hpp:77] Creating layer conv0/scale
I1015 10:56:51.666776 15018 net.cpp:150] Setting up conv0/scale
I1015 10:56:51.666784 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.666785 15018 net.cpp:165] Memory required for data: 127795392
I1015 10:56:51.666791 15018 layer_factory.hpp:77] Creating layer conv0/relu
I1015 10:56:51.666797 15018 net.cpp:100] Creating Layer conv0/relu
I1015 10:56:51.666800 15018 net.cpp:434] conv0/relu <- conv0
I1015 10:56:51.666802 15018 net.cpp:395] conv0/relu -> conv0 (in-place)
I1015 10:56:51.667104 15018 net.cpp:150] Setting up conv0/relu
I1015 10:56:51.667114 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.667116 15018 net.cpp:165] Memory required for data: 147456192
I1015 10:56:51.667119 15018 layer_factory.hpp:77] Creating layer conv1/dw
I1015 10:56:51.667129 15018 net.cpp:100] Creating Layer conv1/dw
I1015 10:56:51.667131 15018 net.cpp:434] conv1/dw <- conv0
I1015 10:56:51.667135 15018 net.cpp:408] conv1/dw -> conv1/dw
I1015 10:56:51.667294 15018 net.cpp:150] Setting up conv1/dw
I1015 10:56:51.667300 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.667304 15018 net.cpp:165] Memory required for data: 167116992
I1015 10:56:51.667307 15018 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1015 10:56:51.667311 15018 net.cpp:100] Creating Layer conv1/dw/bn
I1015 10:56:51.667315 15018 net.cpp:434] conv1/dw/bn <- conv1/dw
I1015 10:56:51.667317 15018 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1015 10:56:51.667474 15018 net.cpp:150] Setting up conv1/dw/bn
I1015 10:56:51.667481 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.667484 15018 net.cpp:165] Memory required for data: 186777792
I1015 10:56:51.667490 15018 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 10:56:51.667496 15018 net.cpp:100] Creating Layer conv1/dw/scale
I1015 10:56:51.667498 15018 net.cpp:434] conv1/dw/scale <- conv1/dw
I1015 10:56:51.667502 15018 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1015 10:56:51.667533 15018 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 10:56:51.667649 15018 net.cpp:150] Setting up conv1/dw/scale
I1015 10:56:51.667655 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.667657 15018 net.cpp:165] Memory required for data: 206438592
I1015 10:56:51.667662 15018 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1015 10:56:51.667666 15018 net.cpp:100] Creating Layer conv1/dw/relu
I1015 10:56:51.667668 15018 net.cpp:434] conv1/dw/relu <- conv1/dw
I1015 10:56:51.667671 15018 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1015 10:56:51.667966 15018 net.cpp:150] Setting up conv1/dw/relu
I1015 10:56:51.667975 15018 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 10:56:51.667978 15018 net.cpp:165] Memory required for data: 226099392
I1015 10:56:51.667980 15018 layer_factory.hpp:77] Creating layer conv1
I1015 10:56:51.667986 15018 net.cpp:100] Creating Layer conv1
I1015 10:56:51.667989 15018 net.cpp:434] conv1 <- conv1/dw
I1015 10:56:51.667994 15018 net.cpp:408] conv1 -> conv1
I1015 10:56:51.670119 15018 net.cpp:150] Setting up conv1
I1015 10:56:51.670130 15018 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 10:56:51.670133 15018 net.cpp:165] Memory required for data: 265420992
I1015 10:56:51.670137 15018 layer_factory.hpp:77] Creating layer conv1/bn
I1015 10:56:51.670142 15018 net.cpp:100] Creating Layer conv1/bn
I1015 10:56:51.670145 15018 net.cpp:434] conv1/bn <- conv1
I1015 10:56:51.670150 15018 net.cpp:395] conv1/bn -> conv1 (in-place)
I1015 10:56:51.670311 15018 net.cpp:150] Setting up conv1/bn
I1015 10:56:51.670320 15018 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 10:56:51.670321 15018 net.cpp:165] Memory required for data: 304742592
I1015 10:56:51.670327 15018 layer_factory.hpp:77] Creating layer conv1/scale
I1015 10:56:51.670332 15018 net.cpp:100] Creating Layer conv1/scale
I1015 10:56:51.670334 15018 net.cpp:434] conv1/scale <- conv1
I1015 10:56:51.670338 15018 net.cpp:395] conv1/scale -> conv1 (in-place)
I1015 10:56:51.670369 15018 layer_factory.hpp:77] Creating layer conv1/scale
I1015 10:56:51.670497 15018 net.cpp:150] Setting up conv1/scale
I1015 10:56:51.670505 15018 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 10:56:51.670507 15018 net.cpp:165] Memory required for data: 344064192
I1015 10:56:51.670514 15018 layer_factory.hpp:77] Creating layer conv1/relu
I1015 10:56:51.670518 15018 net.cpp:100] Creating Layer conv1/relu
I1015 10:56:51.670521 15018 net.cpp:434] conv1/relu <- conv1
I1015 10:56:51.670524 15018 net.cpp:395] conv1/relu -> conv1 (in-place)
I1015 10:56:51.671116 15018 net.cpp:150] Setting up conv1/relu
I1015 10:56:51.671128 15018 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 10:56:51.671130 15018 net.cpp:165] Memory required for data: 383385792
I1015 10:56:51.671133 15018 layer_factory.hpp:77] Creating layer conv2/dw
I1015 10:56:51.671140 15018 net.cpp:100] Creating Layer conv2/dw
I1015 10:56:51.671144 15018 net.cpp:434] conv2/dw <- conv1
I1015 10:56:51.671147 15018 net.cpp:408] conv2/dw -> conv2/dw
I1015 10:56:51.671304 15018 net.cpp:150] Setting up conv2/dw
I1015 10:56:51.671311 15018 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 10:56:51.671314 15018 net.cpp:165] Memory required for data: 393216192
I1015 10:56:51.671317 15018 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1015 10:56:51.671321 15018 net.cpp:100] Creating Layer conv2/dw/bn
I1015 10:56:51.671324 15018 net.cpp:434] conv2/dw/bn <- conv2/dw
I1015 10:56:51.671327 15018 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1015 10:56:51.672217 15018 net.cpp:150] Setting up conv2/dw/bn
I1015 10:56:51.672228 15018 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 10:56:51.672230 15018 net.cpp:165] Memory required for data: 403046592
I1015 10:56:51.672237 15018 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 10:56:51.672245 15018 net.cpp:100] Creating Layer conv2/dw/scale
I1015 10:56:51.672247 15018 net.cpp:434] conv2/dw/scale <- conv2/dw
I1015 10:56:51.672251 15018 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1015 10:56:51.672286 15018 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 10:56:51.672374 15018 net.cpp:150] Setting up conv2/dw/scale
I1015 10:56:51.672379 15018 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 10:56:51.672381 15018 net.cpp:165] Memory required for data: 412876992
I1015 10:56:51.672385 15018 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1015 10:56:51.672389 15018 net.cpp:100] Creating Layer conv2/dw/relu
I1015 10:56:51.672392 15018 net.cpp:434] conv2/dw/relu <- conv2/dw
I1015 10:56:51.672395 15018 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1015 10:56:51.672696 15018 net.cpp:150] Setting up conv2/dw/relu
I1015 10:56:51.672705 15018 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 10:56:51.672708 15018 net.cpp:165] Memory required for data: 422707392
I1015 10:56:51.672710 15018 layer_factory.hpp:77] Creating layer conv2
I1015 10:56:51.672718 15018 net.cpp:100] Creating Layer conv2
I1015 10:56:51.672719 15018 net.cpp:434] conv2 <- conv2/dw
I1015 10:56:51.672724 15018 net.cpp:408] conv2 -> conv2
I1015 10:56:51.674423 15018 net.cpp:150] Setting up conv2
I1015 10:56:51.674435 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.674438 15018 net.cpp:165] Memory required for data: 442368192
I1015 10:56:51.674443 15018 layer_factory.hpp:77] Creating layer conv2/bn
I1015 10:56:51.674448 15018 net.cpp:100] Creating Layer conv2/bn
I1015 10:56:51.674450 15018 net.cpp:434] conv2/bn <- conv2
I1015 10:56:51.674454 15018 net.cpp:395] conv2/bn -> conv2 (in-place)
I1015 10:56:51.674602 15018 net.cpp:150] Setting up conv2/bn
I1015 10:56:51.674608 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.674610 15018 net.cpp:165] Memory required for data: 462028992
I1015 10:56:51.674616 15018 layer_factory.hpp:77] Creating layer conv2/scale
I1015 10:56:51.674621 15018 net.cpp:100] Creating Layer conv2/scale
I1015 10:56:51.674623 15018 net.cpp:434] conv2/scale <- conv2
I1015 10:56:51.674628 15018 net.cpp:395] conv2/scale -> conv2 (in-place)
I1015 10:56:51.674657 15018 layer_factory.hpp:77] Creating layer conv2/scale
I1015 10:56:51.674739 15018 net.cpp:150] Setting up conv2/scale
I1015 10:56:51.674746 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.674747 15018 net.cpp:165] Memory required for data: 481689792
I1015 10:56:51.674752 15018 layer_factory.hpp:77] Creating layer conv2/relu
I1015 10:56:51.674755 15018 net.cpp:100] Creating Layer conv2/relu
I1015 10:56:51.674758 15018 net.cpp:434] conv2/relu <- conv2
I1015 10:56:51.674762 15018 net.cpp:395] conv2/relu -> conv2 (in-place)
I1015 10:56:51.675068 15018 net.cpp:150] Setting up conv2/relu
I1015 10:56:51.675078 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.675081 15018 net.cpp:165] Memory required for data: 501350592
I1015 10:56:51.675083 15018 layer_factory.hpp:77] Creating layer conv3/dw
I1015 10:56:51.675091 15018 net.cpp:100] Creating Layer conv3/dw
I1015 10:56:51.675093 15018 net.cpp:434] conv3/dw <- conv2
I1015 10:56:51.675097 15018 net.cpp:408] conv3/dw -> conv3/dw
I1015 10:56:51.675257 15018 net.cpp:150] Setting up conv3/dw
I1015 10:56:51.675266 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.675269 15018 net.cpp:165] Memory required for data: 521011392
I1015 10:56:51.675272 15018 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1015 10:56:51.675276 15018 net.cpp:100] Creating Layer conv3/dw/bn
I1015 10:56:51.675279 15018 net.cpp:434] conv3/dw/bn <- conv3/dw
I1015 10:56:51.675282 15018 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1015 10:56:51.675420 15018 net.cpp:150] Setting up conv3/dw/bn
I1015 10:56:51.675426 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.675427 15018 net.cpp:165] Memory required for data: 540672192
I1015 10:56:51.675436 15018 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 10:56:51.675441 15018 net.cpp:100] Creating Layer conv3/dw/scale
I1015 10:56:51.675443 15018 net.cpp:434] conv3/dw/scale <- conv3/dw
I1015 10:56:51.675447 15018 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1015 10:56:51.675477 15018 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 10:56:51.675559 15018 net.cpp:150] Setting up conv3/dw/scale
I1015 10:56:51.675563 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.675565 15018 net.cpp:165] Memory required for data: 560332992
I1015 10:56:51.675570 15018 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1015 10:56:51.675573 15018 net.cpp:100] Creating Layer conv3/dw/relu
I1015 10:56:51.675576 15018 net.cpp:434] conv3/dw/relu <- conv3/dw
I1015 10:56:51.675580 15018 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1015 10:56:51.676170 15018 net.cpp:150] Setting up conv3/dw/relu
I1015 10:56:51.676182 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.676185 15018 net.cpp:165] Memory required for data: 579993792
I1015 10:56:51.676187 15018 layer_factory.hpp:77] Creating layer conv3
I1015 10:56:51.676195 15018 net.cpp:100] Creating Layer conv3
I1015 10:56:51.676198 15018 net.cpp:434] conv3 <- conv3/dw
I1015 10:56:51.676203 15018 net.cpp:408] conv3 -> conv3
I1015 10:56:51.677850 15018 net.cpp:150] Setting up conv3
I1015 10:56:51.677862 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.677865 15018 net.cpp:165] Memory required for data: 599654592
I1015 10:56:51.677870 15018 layer_factory.hpp:77] Creating layer conv3/bn
I1015 10:56:51.677875 15018 net.cpp:100] Creating Layer conv3/bn
I1015 10:56:51.677877 15018 net.cpp:434] conv3/bn <- conv3
I1015 10:56:51.677882 15018 net.cpp:395] conv3/bn -> conv3 (in-place)
I1015 10:56:51.678038 15018 net.cpp:150] Setting up conv3/bn
I1015 10:56:51.678045 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.678047 15018 net.cpp:165] Memory required for data: 619315392
I1015 10:56:51.678052 15018 layer_factory.hpp:77] Creating layer conv3/scale
I1015 10:56:51.678058 15018 net.cpp:100] Creating Layer conv3/scale
I1015 10:56:51.678061 15018 net.cpp:434] conv3/scale <- conv3
I1015 10:56:51.678066 15018 net.cpp:395] conv3/scale -> conv3 (in-place)
I1015 10:56:51.678097 15018 layer_factory.hpp:77] Creating layer conv3/scale
I1015 10:56:51.678189 15018 net.cpp:150] Setting up conv3/scale
I1015 10:56:51.678194 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.678195 15018 net.cpp:165] Memory required for data: 638976192
I1015 10:56:51.678200 15018 layer_factory.hpp:77] Creating layer conv3/relu
I1015 10:56:51.678203 15018 net.cpp:100] Creating Layer conv3/relu
I1015 10:56:51.678206 15018 net.cpp:434] conv3/relu <- conv3
I1015 10:56:51.678210 15018 net.cpp:395] conv3/relu -> conv3 (in-place)
I1015 10:56:51.678560 15018 net.cpp:150] Setting up conv3/relu
I1015 10:56:51.678570 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.678572 15018 net.cpp:165] Memory required for data: 658636992
I1015 10:56:51.678575 15018 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1015 10:56:51.678580 15018 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1015 10:56:51.678582 15018 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1015 10:56:51.678587 15018 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1015 10:56:51.678593 15018 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1015 10:56:51.678630 15018 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1015 10:56:51.678634 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.678637 15018 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 10:56:51.678639 15018 net.cpp:165] Memory required for data: 697958592
I1015 10:56:51.678642 15018 layer_factory.hpp:77] Creating layer conv4/dw
I1015 10:56:51.678649 15018 net.cpp:100] Creating Layer conv4/dw
I1015 10:56:51.678652 15018 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1015 10:56:51.678658 15018 net.cpp:408] conv4/dw -> conv4/dw
I1015 10:56:51.678815 15018 net.cpp:150] Setting up conv4/dw
I1015 10:56:51.678822 15018 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 10:56:51.678824 15018 net.cpp:165] Memory required for data: 702873792
I1015 10:56:51.678828 15018 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1015 10:56:51.678835 15018 net.cpp:100] Creating Layer conv4/dw/bn
I1015 10:56:51.678838 15018 net.cpp:434] conv4/dw/bn <- conv4/dw
I1015 10:56:51.678841 15018 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1015 10:56:51.678985 15018 net.cpp:150] Setting up conv4/dw/bn
I1015 10:56:51.678992 15018 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 10:56:51.678994 15018 net.cpp:165] Memory required for data: 707788992
I1015 10:56:51.678999 15018 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 10:56:51.679004 15018 net.cpp:100] Creating Layer conv4/dw/scale
I1015 10:56:51.679008 15018 net.cpp:434] conv4/dw/scale <- conv4/dw
I1015 10:56:51.679010 15018 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1015 10:56:51.679041 15018 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 10:56:51.679132 15018 net.cpp:150] Setting up conv4/dw/scale
I1015 10:56:51.679137 15018 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 10:56:51.679139 15018 net.cpp:165] Memory required for data: 712704192
I1015 10:56:51.679143 15018 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1015 10:56:51.679148 15018 net.cpp:100] Creating Layer conv4/dw/relu
I1015 10:56:51.679150 15018 net.cpp:434] conv4/dw/relu <- conv4/dw
I1015 10:56:51.679154 15018 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1015 10:56:51.679505 15018 net.cpp:150] Setting up conv4/dw/relu
I1015 10:56:51.679514 15018 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 10:56:51.679517 15018 net.cpp:165] Memory required for data: 717619392
I1015 10:56:51.679519 15018 layer_factory.hpp:77] Creating layer conv4
I1015 10:56:51.679525 15018 net.cpp:100] Creating Layer conv4
I1015 10:56:51.679529 15018 net.cpp:434] conv4 <- conv4/dw
I1015 10:56:51.679534 15018 net.cpp:408] conv4 -> conv4
I1015 10:56:51.681344 15018 net.cpp:150] Setting up conv4
I1015 10:56:51.681356 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.681360 15018 net.cpp:165] Memory required for data: 727449792
I1015 10:56:51.681365 15018 layer_factory.hpp:77] Creating layer conv4/bn
I1015 10:56:51.681368 15018 net.cpp:100] Creating Layer conv4/bn
I1015 10:56:51.681371 15018 net.cpp:434] conv4/bn <- conv4
I1015 10:56:51.681376 15018 net.cpp:395] conv4/bn -> conv4 (in-place)
I1015 10:56:51.681533 15018 net.cpp:150] Setting up conv4/bn
I1015 10:56:51.681541 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.681543 15018 net.cpp:165] Memory required for data: 737280192
I1015 10:56:51.681548 15018 layer_factory.hpp:77] Creating layer conv4/scale
I1015 10:56:51.681553 15018 net.cpp:100] Creating Layer conv4/scale
I1015 10:56:51.681556 15018 net.cpp:434] conv4/scale <- conv4
I1015 10:56:51.681560 15018 net.cpp:395] conv4/scale -> conv4 (in-place)
I1015 10:56:51.681593 15018 layer_factory.hpp:77] Creating layer conv4/scale
I1015 10:56:51.681684 15018 net.cpp:150] Setting up conv4/scale
I1015 10:56:51.681691 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.681694 15018 net.cpp:165] Memory required for data: 747110592
I1015 10:56:51.681697 15018 layer_factory.hpp:77] Creating layer conv4/relu
I1015 10:56:51.681701 15018 net.cpp:100] Creating Layer conv4/relu
I1015 10:56:51.681704 15018 net.cpp:434] conv4/relu <- conv4
I1015 10:56:51.681708 15018 net.cpp:395] conv4/relu -> conv4 (in-place)
I1015 10:56:51.682063 15018 net.cpp:150] Setting up conv4/relu
I1015 10:56:51.682072 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.682076 15018 net.cpp:165] Memory required for data: 756940992
I1015 10:56:51.682078 15018 layer_factory.hpp:77] Creating layer conv5/dw
I1015 10:56:51.682085 15018 net.cpp:100] Creating Layer conv5/dw
I1015 10:56:51.682088 15018 net.cpp:434] conv5/dw <- conv4
I1015 10:56:51.682096 15018 net.cpp:408] conv5/dw -> conv5/dw
I1015 10:56:51.682276 15018 net.cpp:150] Setting up conv5/dw
I1015 10:56:51.682282 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.682284 15018 net.cpp:165] Memory required for data: 766771392
I1015 10:56:51.682287 15018 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1015 10:56:51.682291 15018 net.cpp:100] Creating Layer conv5/dw/bn
I1015 10:56:51.682294 15018 net.cpp:434] conv5/dw/bn <- conv5/dw
I1015 10:56:51.682297 15018 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1015 10:56:51.682440 15018 net.cpp:150] Setting up conv5/dw/bn
I1015 10:56:51.682446 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.682449 15018 net.cpp:165] Memory required for data: 776601792
I1015 10:56:51.682454 15018 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 10:56:51.682458 15018 net.cpp:100] Creating Layer conv5/dw/scale
I1015 10:56:51.682461 15018 net.cpp:434] conv5/dw/scale <- conv5/dw
I1015 10:56:51.682464 15018 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1015 10:56:51.682495 15018 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 10:56:51.682582 15018 net.cpp:150] Setting up conv5/dw/scale
I1015 10:56:51.682588 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.682590 15018 net.cpp:165] Memory required for data: 786432192
I1015 10:56:51.682595 15018 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1015 10:56:51.682598 15018 net.cpp:100] Creating Layer conv5/dw/relu
I1015 10:56:51.682600 15018 net.cpp:434] conv5/dw/relu <- conv5/dw
I1015 10:56:51.682605 15018 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1015 10:56:51.683248 15018 net.cpp:150] Setting up conv5/dw/relu
I1015 10:56:51.683260 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.683264 15018 net.cpp:165] Memory required for data: 796262592
I1015 10:56:51.683266 15018 layer_factory.hpp:77] Creating layer conv5
I1015 10:56:51.683274 15018 net.cpp:100] Creating Layer conv5
I1015 10:56:51.683276 15018 net.cpp:434] conv5 <- conv5/dw
I1015 10:56:51.683282 15018 net.cpp:408] conv5 -> conv5
I1015 10:56:51.686007 15018 net.cpp:150] Setting up conv5
I1015 10:56:51.686018 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686022 15018 net.cpp:165] Memory required for data: 806092992
I1015 10:56:51.686025 15018 layer_factory.hpp:77] Creating layer conv5/bn
I1015 10:56:51.686031 15018 net.cpp:100] Creating Layer conv5/bn
I1015 10:56:51.686034 15018 net.cpp:434] conv5/bn <- conv5
I1015 10:56:51.686039 15018 net.cpp:395] conv5/bn -> conv5 (in-place)
I1015 10:56:51.686205 15018 net.cpp:150] Setting up conv5/bn
I1015 10:56:51.686213 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686215 15018 net.cpp:165] Memory required for data: 815923392
I1015 10:56:51.686220 15018 layer_factory.hpp:77] Creating layer conv5/scale
I1015 10:56:51.686226 15018 net.cpp:100] Creating Layer conv5/scale
I1015 10:56:51.686229 15018 net.cpp:434] conv5/scale <- conv5
I1015 10:56:51.686233 15018 net.cpp:395] conv5/scale -> conv5 (in-place)
I1015 10:56:51.686265 15018 layer_factory.hpp:77] Creating layer conv5/scale
I1015 10:56:51.686357 15018 net.cpp:150] Setting up conv5/scale
I1015 10:56:51.686363 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686365 15018 net.cpp:165] Memory required for data: 825753792
I1015 10:56:51.686377 15018 layer_factory.hpp:77] Creating layer conv5/relu
I1015 10:56:51.686380 15018 net.cpp:100] Creating Layer conv5/relu
I1015 10:56:51.686383 15018 net.cpp:434] conv5/relu <- conv5
I1015 10:56:51.686386 15018 net.cpp:395] conv5/relu -> conv5 (in-place)
I1015 10:56:51.686738 15018 net.cpp:150] Setting up conv5/relu
I1015 10:56:51.686748 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686751 15018 net.cpp:165] Memory required for data: 835584192
I1015 10:56:51.686754 15018 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1015 10:56:51.686758 15018 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1015 10:56:51.686761 15018 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1015 10:56:51.686766 15018 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1015 10:56:51.686771 15018 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1015 10:56:51.686807 15018 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1015 10:56:51.686811 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686815 15018 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 10:56:51.686816 15018 net.cpp:165] Memory required for data: 855244992
I1015 10:56:51.686820 15018 layer_factory.hpp:77] Creating layer conv6/dw
I1015 10:56:51.686832 15018 net.cpp:100] Creating Layer conv6/dw
I1015 10:56:51.686836 15018 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1015 10:56:51.686841 15018 net.cpp:408] conv6/dw -> conv6/dw
I1015 10:56:51.687013 15018 net.cpp:150] Setting up conv6/dw
I1015 10:56:51.687021 15018 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 10:56:51.687022 15018 net.cpp:165] Memory required for data: 857702592
I1015 10:56:51.687026 15018 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1015 10:56:51.687031 15018 net.cpp:100] Creating Layer conv6/dw/bn
I1015 10:56:51.687032 15018 net.cpp:434] conv6/dw/bn <- conv6/dw
I1015 10:56:51.687036 15018 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1015 10:56:51.687197 15018 net.cpp:150] Setting up conv6/dw/bn
I1015 10:56:51.687204 15018 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 10:56:51.687206 15018 net.cpp:165] Memory required for data: 860160192
I1015 10:56:51.687211 15018 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 10:56:51.687217 15018 net.cpp:100] Creating Layer conv6/dw/scale
I1015 10:56:51.687220 15018 net.cpp:434] conv6/dw/scale <- conv6/dw
I1015 10:56:51.687223 15018 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1015 10:56:51.687256 15018 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 10:56:51.687350 15018 net.cpp:150] Setting up conv6/dw/scale
I1015 10:56:51.687355 15018 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 10:56:51.687357 15018 net.cpp:165] Memory required for data: 862617792
I1015 10:56:51.687362 15018 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1015 10:56:51.687367 15018 net.cpp:100] Creating Layer conv6/dw/relu
I1015 10:56:51.687369 15018 net.cpp:434] conv6/dw/relu <- conv6/dw
I1015 10:56:51.687372 15018 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1015 10:56:51.687723 15018 net.cpp:150] Setting up conv6/dw/relu
I1015 10:56:51.687732 15018 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 10:56:51.687734 15018 net.cpp:165] Memory required for data: 865075392
I1015 10:56:51.687737 15018 layer_factory.hpp:77] Creating layer conv6
I1015 10:56:51.687744 15018 net.cpp:100] Creating Layer conv6
I1015 10:56:51.687747 15018 net.cpp:434] conv6 <- conv6/dw
I1015 10:56:51.687752 15018 net.cpp:408] conv6 -> conv6
I1015 10:56:51.691056 15018 net.cpp:150] Setting up conv6
I1015 10:56:51.691069 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.691072 15018 net.cpp:165] Memory required for data: 869990592
I1015 10:56:51.691076 15018 layer_factory.hpp:77] Creating layer conv6/bn
I1015 10:56:51.691082 15018 net.cpp:100] Creating Layer conv6/bn
I1015 10:56:51.691085 15018 net.cpp:434] conv6/bn <- conv6
I1015 10:56:51.691088 15018 net.cpp:395] conv6/bn -> conv6 (in-place)
I1015 10:56:51.691270 15018 net.cpp:150] Setting up conv6/bn
I1015 10:56:51.691279 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.691282 15018 net.cpp:165] Memory required for data: 874905792
I1015 10:56:51.691287 15018 layer_factory.hpp:77] Creating layer conv6/scale
I1015 10:56:51.691293 15018 net.cpp:100] Creating Layer conv6/scale
I1015 10:56:51.691294 15018 net.cpp:434] conv6/scale <- conv6
I1015 10:56:51.691298 15018 net.cpp:395] conv6/scale -> conv6 (in-place)
I1015 10:56:51.691335 15018 layer_factory.hpp:77] Creating layer conv6/scale
I1015 10:56:51.691426 15018 net.cpp:150] Setting up conv6/scale
I1015 10:56:51.691432 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.691434 15018 net.cpp:165] Memory required for data: 879820992
I1015 10:56:51.691438 15018 layer_factory.hpp:77] Creating layer conv6/relu
I1015 10:56:51.691442 15018 net.cpp:100] Creating Layer conv6/relu
I1015 10:56:51.691444 15018 net.cpp:434] conv6/relu <- conv6
I1015 10:56:51.691448 15018 net.cpp:395] conv6/relu -> conv6 (in-place)
I1015 10:56:51.692126 15018 net.cpp:150] Setting up conv6/relu
I1015 10:56:51.692137 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.692140 15018 net.cpp:165] Memory required for data: 884736192
I1015 10:56:51.692143 15018 layer_factory.hpp:77] Creating layer conv7/dw
I1015 10:56:51.692152 15018 net.cpp:100] Creating Layer conv7/dw
I1015 10:56:51.692153 15018 net.cpp:434] conv7/dw <- conv6
I1015 10:56:51.692158 15018 net.cpp:408] conv7/dw -> conv7/dw
I1015 10:56:51.692373 15018 net.cpp:150] Setting up conv7/dw
I1015 10:56:51.692379 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.692382 15018 net.cpp:165] Memory required for data: 889651392
I1015 10:56:51.692385 15018 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1015 10:56:51.692390 15018 net.cpp:100] Creating Layer conv7/dw/bn
I1015 10:56:51.692394 15018 net.cpp:434] conv7/dw/bn <- conv7/dw
I1015 10:56:51.692396 15018 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1015 10:56:51.692551 15018 net.cpp:150] Setting up conv7/dw/bn
I1015 10:56:51.692559 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.692560 15018 net.cpp:165] Memory required for data: 894566592
I1015 10:56:51.692565 15018 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 10:56:51.692571 15018 net.cpp:100] Creating Layer conv7/dw/scale
I1015 10:56:51.692574 15018 net.cpp:434] conv7/dw/scale <- conv7/dw
I1015 10:56:51.692577 15018 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1015 10:56:51.692612 15018 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 10:56:51.692704 15018 net.cpp:150] Setting up conv7/dw/scale
I1015 10:56:51.692711 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.692713 15018 net.cpp:165] Memory required for data: 899481792
I1015 10:56:51.692718 15018 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1015 10:56:51.692721 15018 net.cpp:100] Creating Layer conv7/dw/relu
I1015 10:56:51.692724 15018 net.cpp:434] conv7/dw/relu <- conv7/dw
I1015 10:56:51.692728 15018 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1015 10:56:51.693078 15018 net.cpp:150] Setting up conv7/dw/relu
I1015 10:56:51.693089 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.693090 15018 net.cpp:165] Memory required for data: 904396992
I1015 10:56:51.693094 15018 layer_factory.hpp:77] Creating layer conv7
I1015 10:56:51.693100 15018 net.cpp:100] Creating Layer conv7
I1015 10:56:51.693102 15018 net.cpp:434] conv7 <- conv7/dw
I1015 10:56:51.693107 15018 net.cpp:408] conv7 -> conv7
I1015 10:56:51.696631 15018 net.cpp:150] Setting up conv7
I1015 10:56:51.696645 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.696646 15018 net.cpp:165] Memory required for data: 909312192
I1015 10:56:51.696651 15018 layer_factory.hpp:77] Creating layer conv7/bn
I1015 10:56:51.696657 15018 net.cpp:100] Creating Layer conv7/bn
I1015 10:56:51.696660 15018 net.cpp:434] conv7/bn <- conv7
I1015 10:56:51.696663 15018 net.cpp:395] conv7/bn -> conv7 (in-place)
I1015 10:56:51.696827 15018 net.cpp:150] Setting up conv7/bn
I1015 10:56:51.696835 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.696836 15018 net.cpp:165] Memory required for data: 914227392
I1015 10:56:51.696841 15018 layer_factory.hpp:77] Creating layer conv7/scale
I1015 10:56:51.696848 15018 net.cpp:100] Creating Layer conv7/scale
I1015 10:56:51.696851 15018 net.cpp:434] conv7/scale <- conv7
I1015 10:56:51.696854 15018 net.cpp:395] conv7/scale -> conv7 (in-place)
I1015 10:56:51.696889 15018 layer_factory.hpp:77] Creating layer conv7/scale
I1015 10:56:51.696982 15018 net.cpp:150] Setting up conv7/scale
I1015 10:56:51.696988 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.696991 15018 net.cpp:165] Memory required for data: 919142592
I1015 10:56:51.696995 15018 layer_factory.hpp:77] Creating layer conv7/relu
I1015 10:56:51.697001 15018 net.cpp:100] Creating Layer conv7/relu
I1015 10:56:51.697003 15018 net.cpp:434] conv7/relu <- conv7
I1015 10:56:51.697006 15018 net.cpp:395] conv7/relu -> conv7 (in-place)
I1015 10:56:51.697397 15018 net.cpp:150] Setting up conv7/relu
I1015 10:56:51.697407 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.697409 15018 net.cpp:165] Memory required for data: 924057792
I1015 10:56:51.697412 15018 layer_factory.hpp:77] Creating layer conv8/dw
I1015 10:56:51.697427 15018 net.cpp:100] Creating Layer conv8/dw
I1015 10:56:51.697430 15018 net.cpp:434] conv8/dw <- conv7
I1015 10:56:51.697434 15018 net.cpp:408] conv8/dw -> conv8/dw
I1015 10:56:51.697633 15018 net.cpp:150] Setting up conv8/dw
I1015 10:56:51.697640 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.697643 15018 net.cpp:165] Memory required for data: 928972992
I1015 10:56:51.697646 15018 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1015 10:56:51.697651 15018 net.cpp:100] Creating Layer conv8/dw/bn
I1015 10:56:51.697654 15018 net.cpp:434] conv8/dw/bn <- conv8/dw
I1015 10:56:51.697657 15018 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1015 10:56:51.697813 15018 net.cpp:150] Setting up conv8/dw/bn
I1015 10:56:51.697819 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.697821 15018 net.cpp:165] Memory required for data: 933888192
I1015 10:56:51.697826 15018 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 10:56:51.697831 15018 net.cpp:100] Creating Layer conv8/dw/scale
I1015 10:56:51.697834 15018 net.cpp:434] conv8/dw/scale <- conv8/dw
I1015 10:56:51.697837 15018 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1015 10:56:51.697873 15018 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 10:56:51.697963 15018 net.cpp:150] Setting up conv8/dw/scale
I1015 10:56:51.697969 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.697971 15018 net.cpp:165] Memory required for data: 938803392
I1015 10:56:51.697976 15018 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1015 10:56:51.697981 15018 net.cpp:100] Creating Layer conv8/dw/relu
I1015 10:56:51.697983 15018 net.cpp:434] conv8/dw/relu <- conv8/dw
I1015 10:56:51.697986 15018 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1015 10:56:51.698644 15018 net.cpp:150] Setting up conv8/dw/relu
I1015 10:56:51.698655 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.698658 15018 net.cpp:165] Memory required for data: 943718592
I1015 10:56:51.698660 15018 layer_factory.hpp:77] Creating layer conv8
I1015 10:56:51.698669 15018 net.cpp:100] Creating Layer conv8
I1015 10:56:51.698673 15018 net.cpp:434] conv8 <- conv8/dw
I1015 10:56:51.698676 15018 net.cpp:408] conv8 -> conv8
I1015 10:56:51.703003 15018 net.cpp:150] Setting up conv8
I1015 10:56:51.703018 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.703021 15018 net.cpp:165] Memory required for data: 948633792
I1015 10:56:51.703025 15018 layer_factory.hpp:77] Creating layer conv8/bn
I1015 10:56:51.703032 15018 net.cpp:100] Creating Layer conv8/bn
I1015 10:56:51.703034 15018 net.cpp:434] conv8/bn <- conv8
I1015 10:56:51.703038 15018 net.cpp:395] conv8/bn -> conv8 (in-place)
I1015 10:56:51.703207 15018 net.cpp:150] Setting up conv8/bn
I1015 10:56:51.703214 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.703217 15018 net.cpp:165] Memory required for data: 953548992
I1015 10:56:51.703222 15018 layer_factory.hpp:77] Creating layer conv8/scale
I1015 10:56:51.703227 15018 net.cpp:100] Creating Layer conv8/scale
I1015 10:56:51.703230 15018 net.cpp:434] conv8/scale <- conv8
I1015 10:56:51.703234 15018 net.cpp:395] conv8/scale -> conv8 (in-place)
I1015 10:56:51.703271 15018 layer_factory.hpp:77] Creating layer conv8/scale
I1015 10:56:51.703362 15018 net.cpp:150] Setting up conv8/scale
I1015 10:56:51.703372 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.703374 15018 net.cpp:165] Memory required for data: 958464192
I1015 10:56:51.703378 15018 layer_factory.hpp:77] Creating layer conv8/relu
I1015 10:56:51.703382 15018 net.cpp:100] Creating Layer conv8/relu
I1015 10:56:51.703384 15018 net.cpp:434] conv8/relu <- conv8
I1015 10:56:51.703388 15018 net.cpp:395] conv8/relu -> conv8 (in-place)
I1015 10:56:51.703747 15018 net.cpp:150] Setting up conv8/relu
I1015 10:56:51.703758 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.703759 15018 net.cpp:165] Memory required for data: 963379392
I1015 10:56:51.703763 15018 layer_factory.hpp:77] Creating layer conv9/dw
I1015 10:56:51.703770 15018 net.cpp:100] Creating Layer conv9/dw
I1015 10:56:51.703773 15018 net.cpp:434] conv9/dw <- conv8
I1015 10:56:51.703776 15018 net.cpp:408] conv9/dw -> conv9/dw
I1015 10:56:51.703992 15018 net.cpp:150] Setting up conv9/dw
I1015 10:56:51.703999 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.704001 15018 net.cpp:165] Memory required for data: 968294592
I1015 10:56:51.704005 15018 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1015 10:56:51.704008 15018 net.cpp:100] Creating Layer conv9/dw/bn
I1015 10:56:51.704011 15018 net.cpp:434] conv9/dw/bn <- conv9/dw
I1015 10:56:51.704016 15018 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1015 10:56:51.704174 15018 net.cpp:150] Setting up conv9/dw/bn
I1015 10:56:51.704180 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.704181 15018 net.cpp:165] Memory required for data: 973209792
I1015 10:56:51.704186 15018 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 10:56:51.704191 15018 net.cpp:100] Creating Layer conv9/dw/scale
I1015 10:56:51.704193 15018 net.cpp:434] conv9/dw/scale <- conv9/dw
I1015 10:56:51.704198 15018 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1015 10:56:51.704233 15018 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 10:56:51.704325 15018 net.cpp:150] Setting up conv9/dw/scale
I1015 10:56:51.704331 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.704334 15018 net.cpp:165] Memory required for data: 978124992
I1015 10:56:51.704337 15018 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1015 10:56:51.704341 15018 net.cpp:100] Creating Layer conv9/dw/relu
I1015 10:56:51.704344 15018 net.cpp:434] conv9/dw/relu <- conv9/dw
I1015 10:56:51.704349 15018 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1015 10:56:51.704708 15018 net.cpp:150] Setting up conv9/dw/relu
I1015 10:56:51.704717 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.704720 15018 net.cpp:165] Memory required for data: 983040192
I1015 10:56:51.704722 15018 layer_factory.hpp:77] Creating layer conv9
I1015 10:56:51.704730 15018 net.cpp:100] Creating Layer conv9
I1015 10:56:51.704732 15018 net.cpp:434] conv9 <- conv9/dw
I1015 10:56:51.704738 15018 net.cpp:408] conv9 -> conv9
I1015 10:56:51.708293 15018 net.cpp:150] Setting up conv9
I1015 10:56:51.708305 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.708309 15018 net.cpp:165] Memory required for data: 987955392
I1015 10:56:51.708314 15018 layer_factory.hpp:77] Creating layer conv9/bn
I1015 10:56:51.708318 15018 net.cpp:100] Creating Layer conv9/bn
I1015 10:56:51.708322 15018 net.cpp:434] conv9/bn <- conv9
I1015 10:56:51.708325 15018 net.cpp:395] conv9/bn -> conv9 (in-place)
I1015 10:56:51.708493 15018 net.cpp:150] Setting up conv9/bn
I1015 10:56:51.708500 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.708503 15018 net.cpp:165] Memory required for data: 992870592
I1015 10:56:51.708508 15018 layer_factory.hpp:77] Creating layer conv9/scale
I1015 10:56:51.708513 15018 net.cpp:100] Creating Layer conv9/scale
I1015 10:56:51.708515 15018 net.cpp:434] conv9/scale <- conv9
I1015 10:56:51.708519 15018 net.cpp:395] conv9/scale -> conv9 (in-place)
I1015 10:56:51.708555 15018 layer_factory.hpp:77] Creating layer conv9/scale
I1015 10:56:51.708648 15018 net.cpp:150] Setting up conv9/scale
I1015 10:56:51.708653 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.708657 15018 net.cpp:165] Memory required for data: 997785792
I1015 10:56:51.708660 15018 layer_factory.hpp:77] Creating layer conv9/relu
I1015 10:56:51.708664 15018 net.cpp:100] Creating Layer conv9/relu
I1015 10:56:51.708667 15018 net.cpp:434] conv9/relu <- conv9
I1015 10:56:51.708670 15018 net.cpp:395] conv9/relu -> conv9 (in-place)
I1015 10:56:51.709039 15018 net.cpp:150] Setting up conv9/relu
I1015 10:56:51.709049 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.709051 15018 net.cpp:165] Memory required for data: 1002700992
I1015 10:56:51.709054 15018 layer_factory.hpp:77] Creating layer conv10/dw
I1015 10:56:51.709061 15018 net.cpp:100] Creating Layer conv10/dw
I1015 10:56:51.709064 15018 net.cpp:434] conv10/dw <- conv9
I1015 10:56:51.709069 15018 net.cpp:408] conv10/dw -> conv10/dw
I1015 10:56:51.709271 15018 net.cpp:150] Setting up conv10/dw
I1015 10:56:51.709277 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.709280 15018 net.cpp:165] Memory required for data: 1007616192
I1015 10:56:51.709283 15018 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1015 10:56:51.709287 15018 net.cpp:100] Creating Layer conv10/dw/bn
I1015 10:56:51.709290 15018 net.cpp:434] conv10/dw/bn <- conv10/dw
I1015 10:56:51.709293 15018 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1015 10:56:51.709455 15018 net.cpp:150] Setting up conv10/dw/bn
I1015 10:56:51.709461 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.709463 15018 net.cpp:165] Memory required for data: 1012531392
I1015 10:56:51.709470 15018 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 10:56:51.709473 15018 net.cpp:100] Creating Layer conv10/dw/scale
I1015 10:56:51.709475 15018 net.cpp:434] conv10/dw/scale <- conv10/dw
I1015 10:56:51.709481 15018 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1015 10:56:51.709516 15018 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 10:56:51.709609 15018 net.cpp:150] Setting up conv10/dw/scale
I1015 10:56:51.709614 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.709616 15018 net.cpp:165] Memory required for data: 1017446592
I1015 10:56:51.709620 15018 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1015 10:56:51.709625 15018 net.cpp:100] Creating Layer conv10/dw/relu
I1015 10:56:51.709626 15018 net.cpp:434] conv10/dw/relu <- conv10/dw
I1015 10:56:51.709630 15018 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1015 10:56:51.710299 15018 net.cpp:150] Setting up conv10/dw/relu
I1015 10:56:51.710310 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.710312 15018 net.cpp:165] Memory required for data: 1022361792
I1015 10:56:51.710315 15018 layer_factory.hpp:77] Creating layer conv10
I1015 10:56:51.710324 15018 net.cpp:100] Creating Layer conv10
I1015 10:56:51.710326 15018 net.cpp:434] conv10 <- conv10/dw
I1015 10:56:51.710330 15018 net.cpp:408] conv10 -> conv10
I1015 10:56:51.714689 15018 net.cpp:150] Setting up conv10
I1015 10:56:51.714702 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.714704 15018 net.cpp:165] Memory required for data: 1027276992
I1015 10:56:51.714709 15018 layer_factory.hpp:77] Creating layer conv10/bn
I1015 10:56:51.714713 15018 net.cpp:100] Creating Layer conv10/bn
I1015 10:56:51.714716 15018 net.cpp:434] conv10/bn <- conv10
I1015 10:56:51.714721 15018 net.cpp:395] conv10/bn -> conv10 (in-place)
I1015 10:56:51.714890 15018 net.cpp:150] Setting up conv10/bn
I1015 10:56:51.714896 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.714900 15018 net.cpp:165] Memory required for data: 1032192192
I1015 10:56:51.714905 15018 layer_factory.hpp:77] Creating layer conv10/scale
I1015 10:56:51.714910 15018 net.cpp:100] Creating Layer conv10/scale
I1015 10:56:51.714911 15018 net.cpp:434] conv10/scale <- conv10
I1015 10:56:51.714916 15018 net.cpp:395] conv10/scale -> conv10 (in-place)
I1015 10:56:51.714951 15018 layer_factory.hpp:77] Creating layer conv10/scale
I1015 10:56:51.715046 15018 net.cpp:150] Setting up conv10/scale
I1015 10:56:51.715052 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.715054 15018 net.cpp:165] Memory required for data: 1037107392
I1015 10:56:51.715059 15018 layer_factory.hpp:77] Creating layer conv10/relu
I1015 10:56:51.715064 15018 net.cpp:100] Creating Layer conv10/relu
I1015 10:56:51.715065 15018 net.cpp:434] conv10/relu <- conv10
I1015 10:56:51.715070 15018 net.cpp:395] conv10/relu -> conv10 (in-place)
I1015 10:56:51.715432 15018 net.cpp:150] Setting up conv10/relu
I1015 10:56:51.715442 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.715445 15018 net.cpp:165] Memory required for data: 1042022592
I1015 10:56:51.715447 15018 layer_factory.hpp:77] Creating layer conv11/dw
I1015 10:56:51.715454 15018 net.cpp:100] Creating Layer conv11/dw
I1015 10:56:51.715457 15018 net.cpp:434] conv11/dw <- conv10
I1015 10:56:51.715462 15018 net.cpp:408] conv11/dw -> conv11/dw
I1015 10:56:51.715662 15018 net.cpp:150] Setting up conv11/dw
I1015 10:56:51.715669 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.715672 15018 net.cpp:165] Memory required for data: 1046937792
I1015 10:56:51.715675 15018 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1015 10:56:51.715679 15018 net.cpp:100] Creating Layer conv11/dw/bn
I1015 10:56:51.715682 15018 net.cpp:434] conv11/dw/bn <- conv11/dw
I1015 10:56:51.715687 15018 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1015 10:56:51.715857 15018 net.cpp:150] Setting up conv11/dw/bn
I1015 10:56:51.715862 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.715864 15018 net.cpp:165] Memory required for data: 1051852992
I1015 10:56:51.715881 15018 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 10:56:51.715886 15018 net.cpp:100] Creating Layer conv11/dw/scale
I1015 10:56:51.715889 15018 net.cpp:434] conv11/dw/scale <- conv11/dw
I1015 10:56:51.715893 15018 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1015 10:56:51.715930 15018 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 10:56:51.716022 15018 net.cpp:150] Setting up conv11/dw/scale
I1015 10:56:51.716029 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.716032 15018 net.cpp:165] Memory required for data: 1056768192
I1015 10:56:51.716035 15018 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1015 10:56:51.716039 15018 net.cpp:100] Creating Layer conv11/dw/relu
I1015 10:56:51.716042 15018 net.cpp:434] conv11/dw/relu <- conv11/dw
I1015 10:56:51.716047 15018 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1015 10:56:51.716400 15018 net.cpp:150] Setting up conv11/dw/relu
I1015 10:56:51.716410 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.716413 15018 net.cpp:165] Memory required for data: 1061683392
I1015 10:56:51.716415 15018 layer_factory.hpp:77] Creating layer conv11
I1015 10:56:51.716423 15018 net.cpp:100] Creating Layer conv11
I1015 10:56:51.716425 15018 net.cpp:434] conv11 <- conv11/dw
I1015 10:56:51.716430 15018 net.cpp:408] conv11 -> conv11
I1015 10:56:51.720263 15018 net.cpp:150] Setting up conv11
I1015 10:56:51.720275 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.720278 15018 net.cpp:165] Memory required for data: 1066598592
I1015 10:56:51.720283 15018 layer_factory.hpp:77] Creating layer conv11/bn
I1015 10:56:51.720288 15018 net.cpp:100] Creating Layer conv11/bn
I1015 10:56:51.720291 15018 net.cpp:434] conv11/bn <- conv11
I1015 10:56:51.720294 15018 net.cpp:395] conv11/bn -> conv11 (in-place)
I1015 10:56:51.720463 15018 net.cpp:150] Setting up conv11/bn
I1015 10:56:51.720470 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.720472 15018 net.cpp:165] Memory required for data: 1071513792
I1015 10:56:51.720479 15018 layer_factory.hpp:77] Creating layer conv11/scale
I1015 10:56:51.720484 15018 net.cpp:100] Creating Layer conv11/scale
I1015 10:56:51.720485 15018 net.cpp:434] conv11/scale <- conv11
I1015 10:56:51.720489 15018 net.cpp:395] conv11/scale -> conv11 (in-place)
I1015 10:56:51.720527 15018 layer_factory.hpp:77] Creating layer conv11/scale
I1015 10:56:51.720623 15018 net.cpp:150] Setting up conv11/scale
I1015 10:56:51.720630 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.720633 15018 net.cpp:165] Memory required for data: 1076428992
I1015 10:56:51.720636 15018 layer_factory.hpp:77] Creating layer conv11/relu
I1015 10:56:51.720640 15018 net.cpp:100] Creating Layer conv11/relu
I1015 10:56:51.720643 15018 net.cpp:434] conv11/relu <- conv11
I1015 10:56:51.720645 15018 net.cpp:395] conv11/relu -> conv11 (in-place)
I1015 10:56:51.721366 15018 net.cpp:150] Setting up conv11/relu
I1015 10:56:51.721379 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721381 15018 net.cpp:165] Memory required for data: 1081344192
I1015 10:56:51.721384 15018 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1015 10:56:51.721390 15018 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1015 10:56:51.721393 15018 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1015 10:56:51.721398 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1015 10:56:51.721405 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1015 10:56:51.721410 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1015 10:56:51.721415 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1015 10:56:51.721418 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1015 10:56:51.721488 15018 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1015 10:56:51.721495 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721498 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721500 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721503 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721505 15018 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 10:56:51.721508 15018 net.cpp:165] Memory required for data: 1105920192
I1015 10:56:51.721513 15018 layer_factory.hpp:77] Creating layer conv12/dw
I1015 10:56:51.721520 15018 net.cpp:100] Creating Layer conv12/dw
I1015 10:56:51.721524 15018 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1015 10:56:51.721527 15018 net.cpp:408] conv12/dw -> conv12/dw
I1015 10:56:51.721736 15018 net.cpp:150] Setting up conv12/dw
I1015 10:56:51.721743 15018 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 10:56:51.721746 15018 net.cpp:165] Memory required for data: 1107148992
I1015 10:56:51.721750 15018 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1015 10:56:51.721755 15018 net.cpp:100] Creating Layer conv12/dw/bn
I1015 10:56:51.721756 15018 net.cpp:434] conv12/dw/bn <- conv12/dw
I1015 10:56:51.721760 15018 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1015 10:56:51.721925 15018 net.cpp:150] Setting up conv12/dw/bn
I1015 10:56:51.721930 15018 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 10:56:51.721932 15018 net.cpp:165] Memory required for data: 1108377792
I1015 10:56:51.721937 15018 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 10:56:51.721942 15018 net.cpp:100] Creating Layer conv12/dw/scale
I1015 10:56:51.721945 15018 net.cpp:434] conv12/dw/scale <- conv12/dw
I1015 10:56:51.721948 15018 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1015 10:56:51.721981 15018 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 10:56:51.722086 15018 net.cpp:150] Setting up conv12/dw/scale
I1015 10:56:51.722093 15018 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 10:56:51.722095 15018 net.cpp:165] Memory required for data: 1109606592
I1015 10:56:51.722100 15018 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1015 10:56:51.722103 15018 net.cpp:100] Creating Layer conv12/dw/relu
I1015 10:56:51.722106 15018 net.cpp:434] conv12/dw/relu <- conv12/dw
I1015 10:56:51.722110 15018 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1015 10:56:51.722462 15018 net.cpp:150] Setting up conv12/dw/relu
I1015 10:56:51.722472 15018 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 10:56:51.722476 15018 net.cpp:165] Memory required for data: 1110835392
I1015 10:56:51.722477 15018 layer_factory.hpp:77] Creating layer conv12
I1015 10:56:51.722486 15018 net.cpp:100] Creating Layer conv12
I1015 10:56:51.722488 15018 net.cpp:434] conv12 <- conv12/dw
I1015 10:56:51.722492 15018 net.cpp:408] conv12 -> conv12
I1015 10:56:51.729362 15018 net.cpp:150] Setting up conv12
I1015 10:56:51.729377 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.729379 15018 net.cpp:165] Memory required for data: 1113292992
I1015 10:56:51.729384 15018 layer_factory.hpp:77] Creating layer conv12/bn
I1015 10:56:51.729390 15018 net.cpp:100] Creating Layer conv12/bn
I1015 10:56:51.729393 15018 net.cpp:434] conv12/bn <- conv12
I1015 10:56:51.729398 15018 net.cpp:395] conv12/bn -> conv12 (in-place)
I1015 10:56:51.729578 15018 net.cpp:150] Setting up conv12/bn
I1015 10:56:51.729585 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.729588 15018 net.cpp:165] Memory required for data: 1115750592
I1015 10:56:51.729593 15018 layer_factory.hpp:77] Creating layer conv12/scale
I1015 10:56:51.729598 15018 net.cpp:100] Creating Layer conv12/scale
I1015 10:56:51.729600 15018 net.cpp:434] conv12/scale <- conv12
I1015 10:56:51.729604 15018 net.cpp:395] conv12/scale -> conv12 (in-place)
I1015 10:56:51.729640 15018 layer_factory.hpp:77] Creating layer conv12/scale
I1015 10:56:51.729737 15018 net.cpp:150] Setting up conv12/scale
I1015 10:56:51.729744 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.729748 15018 net.cpp:165] Memory required for data: 1118208192
I1015 10:56:51.729751 15018 layer_factory.hpp:77] Creating layer conv12/relu
I1015 10:56:51.729755 15018 net.cpp:100] Creating Layer conv12/relu
I1015 10:56:51.729758 15018 net.cpp:434] conv12/relu <- conv12
I1015 10:56:51.729761 15018 net.cpp:395] conv12/relu -> conv12 (in-place)
I1015 10:56:51.730126 15018 net.cpp:150] Setting up conv12/relu
I1015 10:56:51.730137 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.730139 15018 net.cpp:165] Memory required for data: 1120665792
I1015 10:56:51.730142 15018 layer_factory.hpp:77] Creating layer conv13/dw
I1015 10:56:51.730149 15018 net.cpp:100] Creating Layer conv13/dw
I1015 10:56:51.730152 15018 net.cpp:434] conv13/dw <- conv12
I1015 10:56:51.730156 15018 net.cpp:408] conv13/dw -> conv13/dw
I1015 10:56:51.730403 15018 net.cpp:150] Setting up conv13/dw
I1015 10:56:51.730410 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.730413 15018 net.cpp:165] Memory required for data: 1123123392
I1015 10:56:51.730417 15018 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1015 10:56:51.730422 15018 net.cpp:100] Creating Layer conv13/dw/bn
I1015 10:56:51.730424 15018 net.cpp:434] conv13/dw/bn <- conv13/dw
I1015 10:56:51.730427 15018 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1015 10:56:51.730592 15018 net.cpp:150] Setting up conv13/dw/bn
I1015 10:56:51.730597 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.730599 15018 net.cpp:165] Memory required for data: 1125580992
I1015 10:56:51.730604 15018 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 10:56:51.730609 15018 net.cpp:100] Creating Layer conv13/dw/scale
I1015 10:56:51.730612 15018 net.cpp:434] conv13/dw/scale <- conv13/dw
I1015 10:56:51.730615 15018 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1015 10:56:51.730650 15018 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 10:56:51.730746 15018 net.cpp:150] Setting up conv13/dw/scale
I1015 10:56:51.730752 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.730754 15018 net.cpp:165] Memory required for data: 1128038592
I1015 10:56:51.730758 15018 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1015 10:56:51.730763 15018 net.cpp:100] Creating Layer conv13/dw/relu
I1015 10:56:51.730765 15018 net.cpp:434] conv13/dw/relu <- conv13/dw
I1015 10:56:51.730769 15018 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1015 10:56:51.731492 15018 net.cpp:150] Setting up conv13/dw/relu
I1015 10:56:51.731503 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.731505 15018 net.cpp:165] Memory required for data: 1130496192
I1015 10:56:51.731508 15018 layer_factory.hpp:77] Creating layer conv13
I1015 10:56:51.731516 15018 net.cpp:100] Creating Layer conv13
I1015 10:56:51.731519 15018 net.cpp:434] conv13 <- conv13/dw
I1015 10:56:51.731524 15018 net.cpp:408] conv13 -> conv13
I1015 10:56:51.742195 15018 net.cpp:150] Setting up conv13
I1015 10:56:51.742211 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.742213 15018 net.cpp:165] Memory required for data: 1132953792
I1015 10:56:51.742219 15018 layer_factory.hpp:77] Creating layer conv13/bn
I1015 10:56:51.742225 15018 net.cpp:100] Creating Layer conv13/bn
I1015 10:56:51.742229 15018 net.cpp:434] conv13/bn <- conv13
I1015 10:56:51.742233 15018 net.cpp:395] conv13/bn -> conv13 (in-place)
I1015 10:56:51.742419 15018 net.cpp:150] Setting up conv13/bn
I1015 10:56:51.742427 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.742429 15018 net.cpp:165] Memory required for data: 1135411392
I1015 10:56:51.742436 15018 layer_factory.hpp:77] Creating layer conv13/scale
I1015 10:56:51.742444 15018 net.cpp:100] Creating Layer conv13/scale
I1015 10:56:51.742449 15018 net.cpp:434] conv13/scale <- conv13
I1015 10:56:51.742455 15018 net.cpp:395] conv13/scale -> conv13 (in-place)
I1015 10:56:51.742522 15018 layer_factory.hpp:77] Creating layer conv13/scale
I1015 10:56:51.742655 15018 net.cpp:150] Setting up conv13/scale
I1015 10:56:51.742664 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.742667 15018 net.cpp:165] Memory required for data: 1137868992
I1015 10:56:51.742671 15018 layer_factory.hpp:77] Creating layer conv13/relu
I1015 10:56:51.742677 15018 net.cpp:100] Creating Layer conv13/relu
I1015 10:56:51.742681 15018 net.cpp:434] conv13/relu <- conv13
I1015 10:56:51.742684 15018 net.cpp:395] conv13/relu -> conv13 (in-place)
I1015 10:56:51.743068 15018 net.cpp:150] Setting up conv13/relu
I1015 10:56:51.743078 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743082 15018 net.cpp:165] Memory required for data: 1140326592
I1015 10:56:51.743084 15018 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1015 10:56:51.743090 15018 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1015 10:56:51.743093 15018 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1015 10:56:51.743101 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1015 10:56:51.743108 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1015 10:56:51.743113 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1015 10:56:51.743119 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1015 10:56:51.743124 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1015 10:56:51.743203 15018 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1015 10:56:51.743211 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743216 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743219 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743222 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743225 15018 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 10:56:51.743227 15018 net.cpp:165] Memory required for data: 1152614592
I1015 10:56:51.743229 15018 layer_factory.hpp:77] Creating layer conv14_1
I1015 10:56:51.743237 15018 net.cpp:100] Creating Layer conv14_1
I1015 10:56:51.743240 15018 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1015 10:56:51.743247 15018 net.cpp:408] conv14_1 -> conv14_1
I1015 10:56:51.747931 15018 net.cpp:150] Setting up conv14_1
I1015 10:56:51.747949 15018 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 10:56:51.747952 15018 net.cpp:165] Memory required for data: 1153228992
I1015 10:56:51.747956 15018 layer_factory.hpp:77] Creating layer conv14_1/bn
I1015 10:56:51.747962 15018 net.cpp:100] Creating Layer conv14_1/bn
I1015 10:56:51.747965 15018 net.cpp:434] conv14_1/bn <- conv14_1
I1015 10:56:51.747972 15018 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1015 10:56:51.748149 15018 net.cpp:150] Setting up conv14_1/bn
I1015 10:56:51.748158 15018 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 10:56:51.748160 15018 net.cpp:165] Memory required for data: 1153843392
I1015 10:56:51.748167 15018 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 10:56:51.748173 15018 net.cpp:100] Creating Layer conv14_1/scale
I1015 10:56:51.748176 15018 net.cpp:434] conv14_1/scale <- conv14_1
I1015 10:56:51.748180 15018 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1015 10:56:51.748219 15018 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 10:56:51.748319 15018 net.cpp:150] Setting up conv14_1/scale
I1015 10:56:51.748325 15018 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 10:56:51.748327 15018 net.cpp:165] Memory required for data: 1154457792
I1015 10:56:51.748332 15018 layer_factory.hpp:77] Creating layer conv14_1/relu
I1015 10:56:51.748337 15018 net.cpp:100] Creating Layer conv14_1/relu
I1015 10:56:51.748338 15018 net.cpp:434] conv14_1/relu <- conv14_1
I1015 10:56:51.748343 15018 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1015 10:56:51.748718 15018 net.cpp:150] Setting up conv14_1/relu
I1015 10:56:51.748728 15018 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 10:56:51.748730 15018 net.cpp:165] Memory required for data: 1155072192
I1015 10:56:51.748733 15018 layer_factory.hpp:77] Creating layer conv14_2
I1015 10:56:51.748740 15018 net.cpp:100] Creating Layer conv14_2
I1015 10:56:51.748744 15018 net.cpp:434] conv14_2 <- conv14_1
I1015 10:56:51.748749 15018 net.cpp:408] conv14_2 -> conv14_2
I1015 10:56:51.760869 15018 net.cpp:150] Setting up conv14_2
I1015 10:56:51.760886 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.760888 15018 net.cpp:165] Memory required for data: 1155399872
I1015 10:56:51.760895 15018 layer_factory.hpp:77] Creating layer conv14_2/bn
I1015 10:56:51.760903 15018 net.cpp:100] Creating Layer conv14_2/bn
I1015 10:56:51.760906 15018 net.cpp:434] conv14_2/bn <- conv14_2
I1015 10:56:51.760911 15018 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1015 10:56:51.761123 15018 net.cpp:150] Setting up conv14_2/bn
I1015 10:56:51.761131 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.761133 15018 net.cpp:165] Memory required for data: 1155727552
I1015 10:56:51.761140 15018 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 10:56:51.761147 15018 net.cpp:100] Creating Layer conv14_2/scale
I1015 10:56:51.761149 15018 net.cpp:434] conv14_2/scale <- conv14_2
I1015 10:56:51.761153 15018 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1015 10:56:51.761193 15018 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 10:56:51.761344 15018 net.cpp:150] Setting up conv14_2/scale
I1015 10:56:51.761359 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.761361 15018 net.cpp:165] Memory required for data: 1156055232
I1015 10:56:51.761366 15018 layer_factory.hpp:77] Creating layer conv14_2/relu
I1015 10:56:51.761371 15018 net.cpp:100] Creating Layer conv14_2/relu
I1015 10:56:51.761374 15018 net.cpp:434] conv14_2/relu <- conv14_2
I1015 10:56:51.761379 15018 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1015 10:56:51.761870 15018 net.cpp:150] Setting up conv14_2/relu
I1015 10:56:51.761883 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.761884 15018 net.cpp:165] Memory required for data: 1156382912
I1015 10:56:51.761888 15018 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1015 10:56:51.761893 15018 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1015 10:56:51.761895 15018 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1015 10:56:51.761901 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1015 10:56:51.761906 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1015 10:56:51.761911 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1015 10:56:51.761916 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1015 10:56:51.762012 15018 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1015 10:56:51.762022 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.762027 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.762032 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.762037 15018 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 10:56:51.762039 15018 net.cpp:165] Memory required for data: 1157693632
I1015 10:56:51.762042 15018 layer_factory.hpp:77] Creating layer conv15_1
I1015 10:56:51.762053 15018 net.cpp:100] Creating Layer conv15_1
I1015 10:56:51.762059 15018 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1015 10:56:51.762068 15018 net.cpp:408] conv15_1 -> conv15_1
I1015 10:56:51.765111 15018 net.cpp:150] Setting up conv15_1
I1015 10:56:51.765125 15018 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 10:56:51.765127 15018 net.cpp:165] Memory required for data: 1157775552
I1015 10:56:51.765131 15018 layer_factory.hpp:77] Creating layer conv15_1/bn
I1015 10:56:51.765136 15018 net.cpp:100] Creating Layer conv15_1/bn
I1015 10:56:51.765139 15018 net.cpp:434] conv15_1/bn <- conv15_1
I1015 10:56:51.765144 15018 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1015 10:56:51.765420 15018 net.cpp:150] Setting up conv15_1/bn
I1015 10:56:51.765431 15018 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 10:56:51.765434 15018 net.cpp:165] Memory required for data: 1157857472
I1015 10:56:51.765439 15018 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 10:56:51.765445 15018 net.cpp:100] Creating Layer conv15_1/scale
I1015 10:56:51.765449 15018 net.cpp:434] conv15_1/scale <- conv15_1
I1015 10:56:51.765452 15018 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1015 10:56:51.765503 15018 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 10:56:51.765664 15018 net.cpp:150] Setting up conv15_1/scale
I1015 10:56:51.765676 15018 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 10:56:51.765681 15018 net.cpp:165] Memory required for data: 1157939392
I1015 10:56:51.765686 15018 layer_factory.hpp:77] Creating layer conv15_1/relu
I1015 10:56:51.765691 15018 net.cpp:100] Creating Layer conv15_1/relu
I1015 10:56:51.765696 15018 net.cpp:434] conv15_1/relu <- conv15_1
I1015 10:56:51.765703 15018 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1015 10:56:51.766451 15018 net.cpp:150] Setting up conv15_1/relu
I1015 10:56:51.766463 15018 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 10:56:51.766466 15018 net.cpp:165] Memory required for data: 1158021312
I1015 10:56:51.766469 15018 layer_factory.hpp:77] Creating layer conv15_2
I1015 10:56:51.766476 15018 net.cpp:100] Creating Layer conv15_2
I1015 10:56:51.766479 15018 net.cpp:434] conv15_2 <- conv15_1
I1015 10:56:51.766485 15018 net.cpp:408] conv15_2 -> conv15_2
I1015 10:56:51.771464 15018 net.cpp:150] Setting up conv15_2
I1015 10:56:51.771479 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.771482 15018 net.cpp:165] Memory required for data: 1158070464
I1015 10:56:51.771487 15018 layer_factory.hpp:77] Creating layer conv15_2/bn
I1015 10:56:51.771510 15018 net.cpp:100] Creating Layer conv15_2/bn
I1015 10:56:51.771513 15018 net.cpp:434] conv15_2/bn <- conv15_2
I1015 10:56:51.771518 15018 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1015 10:56:51.771728 15018 net.cpp:150] Setting up conv15_2/bn
I1015 10:56:51.771740 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.771745 15018 net.cpp:165] Memory required for data: 1158119616
I1015 10:56:51.771754 15018 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 10:56:51.771762 15018 net.cpp:100] Creating Layer conv15_2/scale
I1015 10:56:51.771766 15018 net.cpp:434] conv15_2/scale <- conv15_2
I1015 10:56:51.771770 15018 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1015 10:56:51.771811 15018 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 10:56:51.771932 15018 net.cpp:150] Setting up conv15_2/scale
I1015 10:56:51.771941 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.771944 15018 net.cpp:165] Memory required for data: 1158168768
I1015 10:56:51.771948 15018 layer_factory.hpp:77] Creating layer conv15_2/relu
I1015 10:56:51.771956 15018 net.cpp:100] Creating Layer conv15_2/relu
I1015 10:56:51.771961 15018 net.cpp:434] conv15_2/relu <- conv15_2
I1015 10:56:51.771967 15018 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1015 10:56:51.772434 15018 net.cpp:150] Setting up conv15_2/relu
I1015 10:56:51.772449 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.772454 15018 net.cpp:165] Memory required for data: 1158217920
I1015 10:56:51.772456 15018 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1015 10:56:51.772461 15018 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1015 10:56:51.772464 15018 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1015 10:56:51.772475 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1015 10:56:51.772485 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1015 10:56:51.772491 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1015 10:56:51.772496 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1015 10:56:51.772590 15018 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1015 10:56:51.772598 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.772600 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.772603 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.772608 15018 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 10:56:51.772611 15018 net.cpp:165] Memory required for data: 1158414528
I1015 10:56:51.772615 15018 layer_factory.hpp:77] Creating layer conv16_1
I1015 10:56:51.772626 15018 net.cpp:100] Creating Layer conv16_1
I1015 10:56:51.772632 15018 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1015 10:56:51.772639 15018 net.cpp:408] conv16_1 -> conv16_1
I1015 10:56:51.775722 15018 net.cpp:150] Setting up conv16_1
I1015 10:56:51.775738 15018 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 10:56:51.775741 15018 net.cpp:165] Memory required for data: 1158439104
I1015 10:56:51.775745 15018 layer_factory.hpp:77] Creating layer conv16_1/bn
I1015 10:56:51.775751 15018 net.cpp:100] Creating Layer conv16_1/bn
I1015 10:56:51.775754 15018 net.cpp:434] conv16_1/bn <- conv16_1
I1015 10:56:51.775760 15018 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1015 10:56:51.776000 15018 net.cpp:150] Setting up conv16_1/bn
I1015 10:56:51.776007 15018 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 10:56:51.776010 15018 net.cpp:165] Memory required for data: 1158463680
I1015 10:56:51.776018 15018 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 10:56:51.776026 15018 net.cpp:100] Creating Layer conv16_1/scale
I1015 10:56:51.776031 15018 net.cpp:434] conv16_1/scale <- conv16_1
I1015 10:56:51.776039 15018 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1015 10:56:51.776093 15018 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 10:56:51.776243 15018 net.cpp:150] Setting up conv16_1/scale
I1015 10:56:51.776255 15018 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 10:56:51.776259 15018 net.cpp:165] Memory required for data: 1158488256
I1015 10:56:51.776265 15018 layer_factory.hpp:77] Creating layer conv16_1/relu
I1015 10:56:51.776269 15018 net.cpp:100] Creating Layer conv16_1/relu
I1015 10:56:51.776273 15018 net.cpp:434] conv16_1/relu <- conv16_1
I1015 10:56:51.776278 15018 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1015 10:56:51.776727 15018 net.cpp:150] Setting up conv16_1/relu
I1015 10:56:51.776738 15018 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 10:56:51.776741 15018 net.cpp:165] Memory required for data: 1158512832
I1015 10:56:51.776742 15018 layer_factory.hpp:77] Creating layer conv16_2
I1015 10:56:51.776751 15018 net.cpp:100] Creating Layer conv16_2
I1015 10:56:51.776754 15018 net.cpp:434] conv16_2 <- conv16_1
I1015 10:56:51.776760 15018 net.cpp:408] conv16_2 -> conv16_2
I1015 10:56:51.781481 15018 net.cpp:150] Setting up conv16_2
I1015 10:56:51.781494 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.781497 15018 net.cpp:165] Memory required for data: 1158529216
I1015 10:56:51.781502 15018 layer_factory.hpp:77] Creating layer conv16_2/bn
I1015 10:56:51.781507 15018 net.cpp:100] Creating Layer conv16_2/bn
I1015 10:56:51.781510 15018 net.cpp:434] conv16_2/bn <- conv16_2
I1015 10:56:51.781514 15018 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1015 10:56:51.781769 15018 net.cpp:150] Setting up conv16_2/bn
I1015 10:56:51.781778 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.781783 15018 net.cpp:165] Memory required for data: 1158545600
I1015 10:56:51.781792 15018 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 10:56:51.781798 15018 net.cpp:100] Creating Layer conv16_2/scale
I1015 10:56:51.781801 15018 net.cpp:434] conv16_2/scale <- conv16_2
I1015 10:56:51.781805 15018 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1015 10:56:51.781862 15018 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 10:56:51.782016 15018 net.cpp:150] Setting up conv16_2/scale
I1015 10:56:51.782027 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782029 15018 net.cpp:165] Memory required for data: 1158561984
I1015 10:56:51.782033 15018 layer_factory.hpp:77] Creating layer conv16_2/relu
I1015 10:56:51.782038 15018 net.cpp:100] Creating Layer conv16_2/relu
I1015 10:56:51.782040 15018 net.cpp:434] conv16_2/relu <- conv16_2
I1015 10:56:51.782044 15018 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1015 10:56:51.782815 15018 net.cpp:150] Setting up conv16_2/relu
I1015 10:56:51.782827 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782829 15018 net.cpp:165] Memory required for data: 1158578368
I1015 10:56:51.782832 15018 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1015 10:56:51.782840 15018 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1015 10:56:51.782842 15018 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1015 10:56:51.782848 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1015 10:56:51.782855 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1015 10:56:51.782860 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1015 10:56:51.782863 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1015 10:56:51.782928 15018 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1015 10:56:51.782935 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782939 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782943 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782948 15018 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 10:56:51.782951 15018 net.cpp:165] Memory required for data: 1158643904
I1015 10:56:51.782956 15018 layer_factory.hpp:77] Creating layer conv17_1
I1015 10:56:51.782968 15018 net.cpp:100] Creating Layer conv17_1
I1015 10:56:51.782974 15018 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1015 10:56:51.782982 15018 net.cpp:408] conv17_1 -> conv17_1
I1015 10:56:51.785987 15018 net.cpp:150] Setting up conv17_1
I1015 10:56:51.786001 15018 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 10:56:51.786003 15018 net.cpp:165] Memory required for data: 1158648000
I1015 10:56:51.786008 15018 layer_factory.hpp:77] Creating layer conv17_1/bn
I1015 10:56:51.786012 15018 net.cpp:100] Creating Layer conv17_1/bn
I1015 10:56:51.786015 15018 net.cpp:434] conv17_1/bn <- conv17_1
I1015 10:56:51.786020 15018 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1015 10:56:51.786262 15018 net.cpp:150] Setting up conv17_1/bn
I1015 10:56:51.786273 15018 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 10:56:51.786276 15018 net.cpp:165] Memory required for data: 1158652096
I1015 10:56:51.786283 15018 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 10:56:51.786290 15018 net.cpp:100] Creating Layer conv17_1/scale
I1015 10:56:51.786293 15018 net.cpp:434] conv17_1/scale <- conv17_1
I1015 10:56:51.786299 15018 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1015 10:56:51.786355 15018 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 10:56:51.786509 15018 net.cpp:150] Setting up conv17_1/scale
I1015 10:56:51.786517 15018 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 10:56:51.786521 15018 net.cpp:165] Memory required for data: 1158656192
I1015 10:56:51.786528 15018 layer_factory.hpp:77] Creating layer conv17_1/relu
I1015 10:56:51.786533 15018 net.cpp:100] Creating Layer conv17_1/relu
I1015 10:56:51.786536 15018 net.cpp:434] conv17_1/relu <- conv17_1
I1015 10:56:51.786541 15018 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1015 10:56:51.787008 15018 net.cpp:150] Setting up conv17_1/relu
I1015 10:56:51.787017 15018 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 10:56:51.787019 15018 net.cpp:165] Memory required for data: 1158660288
I1015 10:56:51.787021 15018 layer_factory.hpp:77] Creating layer conv17_2
I1015 10:56:51.787029 15018 net.cpp:100] Creating Layer conv17_2
I1015 10:56:51.787034 15018 net.cpp:434] conv17_2 <- conv17_1
I1015 10:56:51.787039 15018 net.cpp:408] conv17_2 -> conv17_2
I1015 10:56:51.789321 15018 net.cpp:150] Setting up conv17_2
I1015 10:56:51.789338 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.789341 15018 net.cpp:165] Memory required for data: 1158662336
I1015 10:56:51.789346 15018 layer_factory.hpp:77] Creating layer conv17_2/bn
I1015 10:56:51.789351 15018 net.cpp:100] Creating Layer conv17_2/bn
I1015 10:56:51.789355 15018 net.cpp:434] conv17_2/bn <- conv17_2
I1015 10:56:51.789361 15018 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1015 10:56:51.789557 15018 net.cpp:150] Setting up conv17_2/bn
I1015 10:56:51.789564 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.789566 15018 net.cpp:165] Memory required for data: 1158664384
I1015 10:56:51.789572 15018 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 10:56:51.789582 15018 net.cpp:100] Creating Layer conv17_2/scale
I1015 10:56:51.789587 15018 net.cpp:434] conv17_2/scale <- conv17_2
I1015 10:56:51.789592 15018 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1015 10:56:51.789635 15018 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 10:56:51.789764 15018 net.cpp:150] Setting up conv17_2/scale
I1015 10:56:51.789775 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.789778 15018 net.cpp:165] Memory required for data: 1158666432
I1015 10:56:51.789786 15018 layer_factory.hpp:77] Creating layer conv17_2/relu
I1015 10:56:51.789791 15018 net.cpp:100] Creating Layer conv17_2/relu
I1015 10:56:51.789794 15018 net.cpp:434] conv17_2/relu <- conv17_2
I1015 10:56:51.789799 15018 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1015 10:56:51.790241 15018 net.cpp:150] Setting up conv17_2/relu
I1015 10:56:51.790251 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.790253 15018 net.cpp:165] Memory required for data: 1158668480
I1015 10:56:51.790256 15018 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1015 10:56:51.790263 15018 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1015 10:56:51.790268 15018 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1015 10:56:51.790277 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1015 10:56:51.790283 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1015 10:56:51.790288 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1015 10:56:51.790356 15018 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1015 10:56:51.790362 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.790365 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.790369 15018 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 10:56:51.790370 15018 net.cpp:165] Memory required for data: 1158674624
I1015 10:56:51.790372 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1015 10:56:51.790381 15018 net.cpp:100] Creating Layer conv11_mbox_loc
I1015 10:56:51.790385 15018 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1015 10:56:51.790395 15018 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1015 10:56:51.792366 15018 net.cpp:150] Setting up conv11_mbox_loc
I1015 10:56:51.792377 15018 net.cpp:157] Top shape: 4 12 20 30 (28800)
I1015 10:56:51.792381 15018 net.cpp:165] Memory required for data: 1158789824
I1015 10:56:51.792385 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1015 10:56:51.792392 15018 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1015 10:56:51.792394 15018 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1015 10:56:51.792400 15018 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1015 10:56:51.792521 15018 net.cpp:150] Setting up conv11_mbox_loc_perm
I1015 10:56:51.792527 15018 net.cpp:157] Top shape: 4 20 30 12 (28800)
I1015 10:56:51.792529 15018 net.cpp:165] Memory required for data: 1158905024
I1015 10:56:51.792532 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1015 10:56:51.792537 15018 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1015 10:56:51.792541 15018 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1015 10:56:51.792546 15018 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1015 10:56:51.792570 15018 net.cpp:150] Setting up conv11_mbox_loc_flat
I1015 10:56:51.792574 15018 net.cpp:157] Top shape: 4 7200 (28800)
I1015 10:56:51.792577 15018 net.cpp:165] Memory required for data: 1159020224
I1015 10:56:51.792579 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1015 10:56:51.792587 15018 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1015 10:56:51.792589 15018 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1015 10:56:51.792595 15018 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1015 10:56:51.794561 15018 net.cpp:150] Setting up conv11_mbox_conf_new
I1015 10:56:51.794574 15018 net.cpp:157] Top shape: 4 9 20 30 (21600)
I1015 10:56:51.794576 15018 net.cpp:165] Memory required for data: 1159106624
I1015 10:56:51.794581 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1015 10:56:51.794589 15018 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1015 10:56:51.794591 15018 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1015 10:56:51.794596 15018 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1015 10:56:51.794714 15018 net.cpp:150] Setting up conv11_mbox_conf_perm
I1015 10:56:51.794721 15018 net.cpp:157] Top shape: 4 20 30 9 (21600)
I1015 10:56:51.794724 15018 net.cpp:165] Memory required for data: 1159193024
I1015 10:56:51.794726 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1015 10:56:51.794731 15018 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1015 10:56:51.794734 15018 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1015 10:56:51.794739 15018 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1015 10:56:51.794762 15018 net.cpp:150] Setting up conv11_mbox_conf_flat
I1015 10:56:51.794767 15018 net.cpp:157] Top shape: 4 5400 (21600)
I1015 10:56:51.794770 15018 net.cpp:165] Memory required for data: 1159279424
I1015 10:56:51.794773 15018 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1015 10:56:51.794781 15018 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1015 10:56:51.794786 15018 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1015 10:56:51.794792 15018 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1015 10:56:51.794800 15018 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1015 10:56:51.794836 15018 net.cpp:150] Setting up conv11_mbox_priorbox
I1015 10:56:51.794843 15018 net.cpp:157] Top shape: 1 2 7200 (14400)
I1015 10:56:51.794845 15018 net.cpp:165] Memory required for data: 1159337024
I1015 10:56:51.794847 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1015 10:56:51.794855 15018 net.cpp:100] Creating Layer conv13_mbox_loc
I1015 10:56:51.794859 15018 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1015 10:56:51.794869 15018 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1015 10:56:51.796919 15018 net.cpp:150] Setting up conv13_mbox_loc
I1015 10:56:51.796932 15018 net.cpp:157] Top shape: 4 24 10 15 (14400)
I1015 10:56:51.796934 15018 net.cpp:165] Memory required for data: 1159394624
I1015 10:56:51.796939 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1015 10:56:51.796946 15018 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1015 10:56:51.796948 15018 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1015 10:56:51.796953 15018 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1015 10:56:51.797053 15018 net.cpp:150] Setting up conv13_mbox_loc_perm
I1015 10:56:51.797058 15018 net.cpp:157] Top shape: 4 10 15 24 (14400)
I1015 10:56:51.797061 15018 net.cpp:165] Memory required for data: 1159452224
I1015 10:56:51.797063 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1015 10:56:51.797067 15018 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1015 10:56:51.797070 15018 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1015 10:56:51.797075 15018 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1015 10:56:51.797098 15018 net.cpp:150] Setting up conv13_mbox_loc_flat
I1015 10:56:51.797102 15018 net.cpp:157] Top shape: 4 3600 (14400)
I1015 10:56:51.797104 15018 net.cpp:165] Memory required for data: 1159509824
I1015 10:56:51.797106 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1015 10:56:51.797114 15018 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1015 10:56:51.797117 15018 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1015 10:56:51.797122 15018 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1015 10:56:51.798957 15018 net.cpp:150] Setting up conv13_mbox_conf_new
I1015 10:56:51.798969 15018 net.cpp:157] Top shape: 4 18 10 15 (10800)
I1015 10:56:51.798972 15018 net.cpp:165] Memory required for data: 1159553024
I1015 10:56:51.798977 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1015 10:56:51.798985 15018 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1015 10:56:51.798987 15018 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1015 10:56:51.798991 15018 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1015 10:56:51.799088 15018 net.cpp:150] Setting up conv13_mbox_conf_perm
I1015 10:56:51.799094 15018 net.cpp:157] Top shape: 4 10 15 18 (10800)
I1015 10:56:51.799096 15018 net.cpp:165] Memory required for data: 1159596224
I1015 10:56:51.799098 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1015 10:56:51.799104 15018 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1015 10:56:51.799106 15018 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1015 10:56:51.799110 15018 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1015 10:56:51.799134 15018 net.cpp:150] Setting up conv13_mbox_conf_flat
I1015 10:56:51.799137 15018 net.cpp:157] Top shape: 4 2700 (10800)
I1015 10:56:51.799139 15018 net.cpp:165] Memory required for data: 1159639424
I1015 10:56:51.799141 15018 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1015 10:56:51.799147 15018 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1015 10:56:51.799150 15018 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1015 10:56:51.799154 15018 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1015 10:56:51.799157 15018 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1015 10:56:51.799181 15018 net.cpp:150] Setting up conv13_mbox_priorbox
I1015 10:56:51.799185 15018 net.cpp:157] Top shape: 1 2 3600 (7200)
I1015 10:56:51.799187 15018 net.cpp:165] Memory required for data: 1159668224
I1015 10:56:51.799190 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1015 10:56:51.799197 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1015 10:56:51.799201 15018 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1015 10:56:51.799206 15018 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1015 10:56:51.800985 15018 net.cpp:150] Setting up conv14_2_mbox_loc
I1015 10:56:51.800997 15018 net.cpp:157] Top shape: 4 24 5 8 (3840)
I1015 10:56:51.801000 15018 net.cpp:165] Memory required for data: 1159683584
I1015 10:56:51.801005 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1015 10:56:51.801012 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1015 10:56:51.801014 15018 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1015 10:56:51.801018 15018 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1015 10:56:51.801117 15018 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1015 10:56:51.801121 15018 net.cpp:157] Top shape: 4 5 8 24 (3840)
I1015 10:56:51.801123 15018 net.cpp:165] Memory required for data: 1159698944
I1015 10:56:51.801126 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1015 10:56:51.801131 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1015 10:56:51.801133 15018 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1015 10:56:51.801138 15018 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1015 10:56:51.801160 15018 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1015 10:56:51.801164 15018 net.cpp:157] Top shape: 4 960 (3840)
I1015 10:56:51.801165 15018 net.cpp:165] Memory required for data: 1159714304
I1015 10:56:51.801167 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1015 10:56:51.801177 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1015 10:56:51.801179 15018 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1015 10:56:51.801183 15018 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1015 10:56:51.803295 15018 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1015 10:56:51.803308 15018 net.cpp:157] Top shape: 4 18 5 8 (2880)
I1015 10:56:51.803310 15018 net.cpp:165] Memory required for data: 1159725824
I1015 10:56:51.803315 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1015 10:56:51.803320 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1015 10:56:51.803323 15018 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1015 10:56:51.803329 15018 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1015 10:56:51.803426 15018 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1015 10:56:51.803431 15018 net.cpp:157] Top shape: 4 5 8 18 (2880)
I1015 10:56:51.803433 15018 net.cpp:165] Memory required for data: 1159737344
I1015 10:56:51.803436 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1015 10:56:51.803441 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1015 10:56:51.803443 15018 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1015 10:56:51.803449 15018 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1015 10:56:51.803472 15018 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1015 10:56:51.803477 15018 net.cpp:157] Top shape: 4 720 (2880)
I1015 10:56:51.803478 15018 net.cpp:165] Memory required for data: 1159748864
I1015 10:56:51.803481 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1015 10:56:51.803486 15018 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1015 10:56:51.803488 15018 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1015 10:56:51.803493 15018 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1015 10:56:51.803498 15018 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1015 10:56:51.803522 15018 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1015 10:56:51.803526 15018 net.cpp:157] Top shape: 1 2 960 (1920)
I1015 10:56:51.803529 15018 net.cpp:165] Memory required for data: 1159756544
I1015 10:56:51.803530 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1015 10:56:51.803539 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1015 10:56:51.803540 15018 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1015 10:56:51.803545 15018 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1015 10:56:51.805794 15018 net.cpp:150] Setting up conv15_2_mbox_loc
I1015 10:56:51.805805 15018 net.cpp:157] Top shape: 4 24 3 4 (1152)
I1015 10:56:51.805807 15018 net.cpp:165] Memory required for data: 1159761152
I1015 10:56:51.805812 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1015 10:56:51.805819 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1015 10:56:51.805822 15018 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1015 10:56:51.805826 15018 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1015 10:56:51.805938 15018 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1015 10:56:51.805943 15018 net.cpp:157] Top shape: 4 3 4 24 (1152)
I1015 10:56:51.805944 15018 net.cpp:165] Memory required for data: 1159765760
I1015 10:56:51.805946 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1015 10:56:51.805953 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1015 10:56:51.805955 15018 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1015 10:56:51.805959 15018 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1015 10:56:51.805982 15018 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1015 10:56:51.805986 15018 net.cpp:157] Top shape: 4 288 (1152)
I1015 10:56:51.805989 15018 net.cpp:165] Memory required for data: 1159770368
I1015 10:56:51.805991 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1015 10:56:51.805999 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1015 10:56:51.806001 15018 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1015 10:56:51.806006 15018 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1015 10:56:51.807734 15018 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1015 10:56:51.807744 15018 net.cpp:157] Top shape: 4 18 3 4 (864)
I1015 10:56:51.807747 15018 net.cpp:165] Memory required for data: 1159773824
I1015 10:56:51.807752 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1015 10:56:51.807759 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1015 10:56:51.807761 15018 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1015 10:56:51.807767 15018 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1015 10:56:51.807868 15018 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1015 10:56:51.807873 15018 net.cpp:157] Top shape: 4 3 4 18 (864)
I1015 10:56:51.807875 15018 net.cpp:165] Memory required for data: 1159777280
I1015 10:56:51.807878 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1015 10:56:51.807883 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1015 10:56:51.807886 15018 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1015 10:56:51.807891 15018 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1015 10:56:51.807914 15018 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1015 10:56:51.807919 15018 net.cpp:157] Top shape: 4 216 (864)
I1015 10:56:51.807919 15018 net.cpp:165] Memory required for data: 1159780736
I1015 10:56:51.807922 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1015 10:56:51.807927 15018 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1015 10:56:51.807930 15018 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1015 10:56:51.807934 15018 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1015 10:56:51.807940 15018 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1015 10:56:51.807962 15018 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1015 10:56:51.807966 15018 net.cpp:157] Top shape: 1 2 288 (576)
I1015 10:56:51.807968 15018 net.cpp:165] Memory required for data: 1159783040
I1015 10:56:51.807971 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1015 10:56:51.807979 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1015 10:56:51.807982 15018 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1015 10:56:51.807987 15018 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1015 10:56:51.809749 15018 net.cpp:150] Setting up conv16_2_mbox_loc
I1015 10:56:51.809762 15018 net.cpp:157] Top shape: 4 24 2 2 (384)
I1015 10:56:51.809764 15018 net.cpp:165] Memory required for data: 1159784576
I1015 10:56:51.809769 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1015 10:56:51.809774 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1015 10:56:51.809777 15018 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1015 10:56:51.809783 15018 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1015 10:56:51.809880 15018 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1015 10:56:51.809885 15018 net.cpp:157] Top shape: 4 2 2 24 (384)
I1015 10:56:51.809887 15018 net.cpp:165] Memory required for data: 1159786112
I1015 10:56:51.809890 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1015 10:56:51.809893 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1015 10:56:51.809896 15018 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1015 10:56:51.809901 15018 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1015 10:56:51.809924 15018 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1015 10:56:51.809928 15018 net.cpp:157] Top shape: 4 96 (384)
I1015 10:56:51.809931 15018 net.cpp:165] Memory required for data: 1159787648
I1015 10:56:51.809932 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1015 10:56:51.809940 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1015 10:56:51.809943 15018 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1015 10:56:51.809948 15018 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1015 10:56:51.811697 15018 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1015 10:56:51.811708 15018 net.cpp:157] Top shape: 4 18 2 2 (288)
I1015 10:56:51.811710 15018 net.cpp:165] Memory required for data: 1159788800
I1015 10:56:51.811717 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1015 10:56:51.811722 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1015 10:56:51.811725 15018 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1015 10:56:51.811731 15018 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1015 10:56:51.811830 15018 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1015 10:56:51.811834 15018 net.cpp:157] Top shape: 4 2 2 18 (288)
I1015 10:56:51.811836 15018 net.cpp:165] Memory required for data: 1159789952
I1015 10:56:51.811838 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1015 10:56:51.811854 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1015 10:56:51.811857 15018 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1015 10:56:51.811861 15018 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1015 10:56:51.811884 15018 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1015 10:56:51.811888 15018 net.cpp:157] Top shape: 4 72 (288)
I1015 10:56:51.811890 15018 net.cpp:165] Memory required for data: 1159791104
I1015 10:56:51.811892 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1015 10:56:51.811898 15018 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1015 10:56:51.811902 15018 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1015 10:56:51.811904 15018 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1015 10:56:51.811909 15018 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1015 10:56:51.811933 15018 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1015 10:56:51.811939 15018 net.cpp:157] Top shape: 1 2 96 (192)
I1015 10:56:51.811939 15018 net.cpp:165] Memory required for data: 1159791872
I1015 10:56:51.811942 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1015 10:56:51.811950 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1015 10:56:51.811952 15018 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1015 10:56:51.811959 15018 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1015 10:56:51.813817 15018 net.cpp:150] Setting up conv17_2_mbox_loc
I1015 10:56:51.813828 15018 net.cpp:157] Top shape: 4 24 1 1 (96)
I1015 10:56:51.813832 15018 net.cpp:165] Memory required for data: 1159792256
I1015 10:56:51.813836 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1015 10:56:51.813843 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1015 10:56:51.813846 15018 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1015 10:56:51.813850 15018 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1015 10:56:51.813951 15018 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1015 10:56:51.813956 15018 net.cpp:157] Top shape: 4 1 1 24 (96)
I1015 10:56:51.813958 15018 net.cpp:165] Memory required for data: 1159792640
I1015 10:56:51.813961 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1015 10:56:51.813964 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1015 10:56:51.813967 15018 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1015 10:56:51.813972 15018 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1015 10:56:51.813997 15018 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1015 10:56:51.814002 15018 net.cpp:157] Top shape: 4 24 (96)
I1015 10:56:51.814003 15018 net.cpp:165] Memory required for data: 1159793024
I1015 10:56:51.814005 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1015 10:56:51.814013 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1015 10:56:51.814015 15018 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1015 10:56:51.814021 15018 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1015 10:56:51.815742 15018 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1015 10:56:51.815752 15018 net.cpp:157] Top shape: 4 18 1 1 (72)
I1015 10:56:51.815755 15018 net.cpp:165] Memory required for data: 1159793312
I1015 10:56:51.815760 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1015 10:56:51.815766 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1015 10:56:51.815770 15018 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1015 10:56:51.815774 15018 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1015 10:56:51.815876 15018 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1015 10:56:51.815881 15018 net.cpp:157] Top shape: 4 1 1 18 (72)
I1015 10:56:51.815882 15018 net.cpp:165] Memory required for data: 1159793600
I1015 10:56:51.815884 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1015 10:56:51.815891 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1015 10:56:51.815893 15018 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1015 10:56:51.815896 15018 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1015 10:56:51.815920 15018 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1015 10:56:51.815924 15018 net.cpp:157] Top shape: 4 18 (72)
I1015 10:56:51.815927 15018 net.cpp:165] Memory required for data: 1159793888
I1015 10:56:51.815928 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1015 10:56:51.815934 15018 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1015 10:56:51.815937 15018 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1015 10:56:51.815942 15018 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1015 10:56:51.815946 15018 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1015 10:56:51.815970 15018 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1015 10:56:51.815974 15018 net.cpp:157] Top shape: 1 2 24 (48)
I1015 10:56:51.815976 15018 net.cpp:165] Memory required for data: 1159794080
I1015 10:56:51.815979 15018 layer_factory.hpp:77] Creating layer mbox_loc
I1015 10:56:51.815985 15018 net.cpp:100] Creating Layer mbox_loc
I1015 10:56:51.815989 15018 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1015 10:56:51.815992 15018 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1015 10:56:51.815996 15018 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1015 10:56:51.815999 15018 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1015 10:56:51.816002 15018 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1015 10:56:51.816005 15018 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1015 10:56:51.816009 15018 net.cpp:408] mbox_loc -> mbox_loc
I1015 10:56:51.816033 15018 net.cpp:150] Setting up mbox_loc
I1015 10:56:51.816037 15018 net.cpp:157] Top shape: 4 12168 (48672)
I1015 10:56:51.816040 15018 net.cpp:165] Memory required for data: 1159988768
I1015 10:56:51.816041 15018 layer_factory.hpp:77] Creating layer mbox_conf
I1015 10:56:51.816047 15018 net.cpp:100] Creating Layer mbox_conf
I1015 10:56:51.816051 15018 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1015 10:56:51.816053 15018 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1015 10:56:51.816056 15018 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1015 10:56:51.816059 15018 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1015 10:56:51.816062 15018 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1015 10:56:51.816066 15018 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1015 10:56:51.816068 15018 net.cpp:408] mbox_conf -> mbox_conf
I1015 10:56:51.816090 15018 net.cpp:150] Setting up mbox_conf
I1015 10:56:51.816094 15018 net.cpp:157] Top shape: 4 9126 (36504)
I1015 10:56:51.816097 15018 net.cpp:165] Memory required for data: 1160134784
I1015 10:56:51.816098 15018 layer_factory.hpp:77] Creating layer mbox_priorbox
I1015 10:56:51.816102 15018 net.cpp:100] Creating Layer mbox_priorbox
I1015 10:56:51.816105 15018 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1015 10:56:51.816108 15018 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1015 10:56:51.816110 15018 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1015 10:56:51.816113 15018 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1015 10:56:51.816117 15018 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1015 10:56:51.816118 15018 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1015 10:56:51.816123 15018 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1015 10:56:51.816145 15018 net.cpp:150] Setting up mbox_priorbox
I1015 10:56:51.816150 15018 net.cpp:157] Top shape: 1 2 12168 (24336)
I1015 10:56:51.816153 15018 net.cpp:165] Memory required for data: 1160232128
I1015 10:56:51.816154 15018 layer_factory.hpp:77] Creating layer mbox_loss
I1015 10:56:51.816161 15018 net.cpp:100] Creating Layer mbox_loss
I1015 10:56:51.816164 15018 net.cpp:434] mbox_loss <- mbox_loc
I1015 10:56:51.816167 15018 net.cpp:434] mbox_loss <- mbox_conf
I1015 10:56:51.816170 15018 net.cpp:434] mbox_loss <- mbox_priorbox
I1015 10:56:51.816172 15018 net.cpp:434] mbox_loss <- label
I1015 10:56:51.816177 15018 net.cpp:408] mbox_loss -> mbox_loss
I1015 10:56:51.816239 15018 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I1015 10:56:51.816323 15018 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1015 10:56:51.816330 15018 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1015 10:56:51.817131 15018 net.cpp:150] Setting up mbox_loss
I1015 10:56:51.817142 15018 net.cpp:157] Top shape: (1)
I1015 10:56:51.817144 15018 net.cpp:160]     with loss weight 1
I1015 10:56:51.817152 15018 net.cpp:165] Memory required for data: 1160232132
I1015 10:56:51.817155 15018 layer_factory.hpp:77] Creating layer score_32
I1015 10:56:51.817163 15018 net.cpp:100] Creating Layer score_32
I1015 10:56:51.817167 15018 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1015 10:56:51.817171 15018 net.cpp:408] score_32 -> score_32
I1015 10:56:51.818897 15018 net.cpp:150] Setting up score_32
I1015 10:56:51.818909 15018 net.cpp:157] Top shape: 4 2 10 15 (1200)
I1015 10:56:51.818912 15018 net.cpp:165] Memory required for data: 1160236932
I1015 10:56:51.818917 15018 layer_factory.hpp:77] Creating layer upscore_16
I1015 10:56:51.818924 15018 net.cpp:100] Creating Layer upscore_16
I1015 10:56:51.818928 15018 net.cpp:434] upscore_16 <- score_32
I1015 10:56:51.818931 15018 net.cpp:408] upscore_16 -> upscore_16
I1015 10:56:51.819126 15018 net.cpp:150] Setting up upscore_16
I1015 10:56:51.819134 15018 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 10:56:51.819136 15018 net.cpp:165] Memory required for data: 1160256132
I1015 10:56:51.819140 15018 layer_factory.hpp:77] Creating layer score_16
I1015 10:56:51.819146 15018 net.cpp:100] Creating Layer score_16
I1015 10:56:51.819149 15018 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1015 10:56:51.819154 15018 net.cpp:408] score_16 -> score_16
I1015 10:56:51.820896 15018 net.cpp:150] Setting up score_16
I1015 10:56:51.820909 15018 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 10:56:51.820912 15018 net.cpp:165] Memory required for data: 1160275332
I1015 10:56:51.820917 15018 layer_factory.hpp:77] Creating layer fuse_16
I1015 10:56:51.820924 15018 net.cpp:100] Creating Layer fuse_16
I1015 10:56:51.820925 15018 net.cpp:434] fuse_16 <- upscore_16
I1015 10:56:51.820930 15018 net.cpp:434] fuse_16 <- score_16
I1015 10:56:51.820935 15018 net.cpp:408] fuse_16 -> fuse_16
I1015 10:56:51.820962 15018 net.cpp:150] Setting up fuse_16
I1015 10:56:51.820968 15018 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 10:56:51.820971 15018 net.cpp:165] Memory required for data: 1160294532
I1015 10:56:51.820973 15018 layer_factory.hpp:77] Creating layer upscore_8
I1015 10:56:51.820977 15018 net.cpp:100] Creating Layer upscore_8
I1015 10:56:51.820981 15018 net.cpp:434] upscore_8 <- fuse_16
I1015 10:56:51.820986 15018 net.cpp:408] upscore_8 -> upscore_8
I1015 10:56:51.821171 15018 net.cpp:150] Setting up upscore_8
I1015 10:56:51.821177 15018 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 10:56:51.821179 15018 net.cpp:165] Memory required for data: 1160371332
I1015 10:56:51.821183 15018 layer_factory.hpp:77] Creating layer score_8
I1015 10:56:51.821188 15018 net.cpp:100] Creating Layer score_8
I1015 10:56:51.821192 15018 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1015 10:56:51.821197 15018 net.cpp:408] score_8 -> score_8
I1015 10:56:51.822911 15018 net.cpp:150] Setting up score_8
I1015 10:56:51.822923 15018 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 10:56:51.822926 15018 net.cpp:165] Memory required for data: 1160448132
I1015 10:56:51.822932 15018 layer_factory.hpp:77] Creating layer fuse_8
I1015 10:56:51.822937 15018 net.cpp:100] Creating Layer fuse_8
I1015 10:56:51.822939 15018 net.cpp:434] fuse_8 <- upscore_8
I1015 10:56:51.822942 15018 net.cpp:434] fuse_8 <- score_8
I1015 10:56:51.822947 15018 net.cpp:408] fuse_8 -> fuse_8
I1015 10:56:51.822976 15018 net.cpp:150] Setting up fuse_8
I1015 10:56:51.822980 15018 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 10:56:51.822983 15018 net.cpp:165] Memory required for data: 1160524932
I1015 10:56:51.822985 15018 layer_factory.hpp:77] Creating layer upscore_4
I1015 10:56:51.822990 15018 net.cpp:100] Creating Layer upscore_4
I1015 10:56:51.822993 15018 net.cpp:434] upscore_4 <- fuse_8
I1015 10:56:51.822998 15018 net.cpp:408] upscore_4 -> upscore_4
I1015 10:56:51.823204 15018 net.cpp:150] Setting up upscore_4
I1015 10:56:51.823211 15018 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 10:56:51.823213 15018 net.cpp:165] Memory required for data: 1160832132
I1015 10:56:51.823217 15018 layer_factory.hpp:77] Creating layer score_4
I1015 10:56:51.823223 15018 net.cpp:100] Creating Layer score_4
I1015 10:56:51.823226 15018 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1015 10:56:51.823230 15018 net.cpp:408] score_4 -> score_4
I1015 10:56:51.825186 15018 net.cpp:150] Setting up score_4
I1015 10:56:51.825198 15018 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 10:56:51.825201 15018 net.cpp:165] Memory required for data: 1161139332
I1015 10:56:51.825206 15018 layer_factory.hpp:77] Creating layer fuse_4
I1015 10:56:51.825212 15018 net.cpp:100] Creating Layer fuse_4
I1015 10:56:51.825215 15018 net.cpp:434] fuse_4 <- upscore_4
I1015 10:56:51.825219 15018 net.cpp:434] fuse_4 <- score_4
I1015 10:56:51.825222 15018 net.cpp:408] fuse_4 -> fuse_4
I1015 10:56:51.825250 15018 net.cpp:150] Setting up fuse_4
I1015 10:56:51.825255 15018 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 10:56:51.825258 15018 net.cpp:165] Memory required for data: 1161446532
I1015 10:56:51.825259 15018 layer_factory.hpp:77] Creating layer upscore
I1015 10:56:51.825266 15018 net.cpp:100] Creating Layer upscore
I1015 10:56:51.825268 15018 net.cpp:434] upscore <- fuse_4
I1015 10:56:51.825273 15018 net.cpp:408] upscore -> upscore
I1015 10:56:51.825464 15018 net.cpp:150] Setting up upscore
I1015 10:56:51.825472 15018 net.cpp:157] Top shape: 4 2 331 491 (1300168)
I1015 10:56:51.825475 15018 net.cpp:165] Memory required for data: 1166647204
I1015 10:56:51.825479 15018 layer_factory.hpp:77] Creating layer score
I1015 10:56:51.825485 15018 net.cpp:100] Creating Layer score
I1015 10:56:51.825489 15018 net.cpp:434] score <- upscore
I1015 10:56:51.825491 15018 net.cpp:434] score <- data_data_0_split_7
I1015 10:56:51.825495 15018 net.cpp:408] score -> score
I1015 10:56:51.825518 15018 net.cpp:150] Setting up score
I1015 10:56:51.825523 15018 net.cpp:157] Top shape: 4 2 320 480 (1228800)
I1015 10:56:51.825525 15018 net.cpp:165] Memory required for data: 1171562404
I1015 10:56:51.825527 15018 layer_factory.hpp:77] Creating layer seg_loss
I1015 10:56:51.825531 15018 net.cpp:100] Creating Layer seg_loss
I1015 10:56:51.825533 15018 net.cpp:434] seg_loss <- score
I1015 10:56:51.825536 15018 net.cpp:434] seg_loss <- label_seg
I1015 10:56:51.825541 15018 net.cpp:408] seg_loss -> seg_loss
I1015 10:56:51.825546 15018 layer_factory.hpp:77] Creating layer seg_loss
I1015 10:56:51.828662 15018 net.cpp:150] Setting up seg_loss
I1015 10:56:51.828676 15018 net.cpp:157] Top shape: (1)
I1015 10:56:51.828680 15018 net.cpp:160]     with loss weight 1
I1015 10:56:51.828686 15018 net.cpp:165] Memory required for data: 1171562408
I1015 10:56:51.828689 15018 net.cpp:226] seg_loss needs backward computation.
I1015 10:56:51.828692 15018 net.cpp:226] score needs backward computation.
I1015 10:56:51.828696 15018 net.cpp:226] upscore needs backward computation.
I1015 10:56:51.828699 15018 net.cpp:226] fuse_4 needs backward computation.
I1015 10:56:51.828703 15018 net.cpp:226] score_4 needs backward computation.
I1015 10:56:51.828708 15018 net.cpp:226] upscore_4 needs backward computation.
I1015 10:56:51.828712 15018 net.cpp:226] fuse_8 needs backward computation.
I1015 10:56:51.828716 15018 net.cpp:226] score_8 needs backward computation.
I1015 10:56:51.828721 15018 net.cpp:226] upscore_8 needs backward computation.
I1015 10:56:51.828724 15018 net.cpp:226] fuse_16 needs backward computation.
I1015 10:56:51.828728 15018 net.cpp:226] score_16 needs backward computation.
I1015 10:56:51.828732 15018 net.cpp:226] upscore_16 needs backward computation.
I1015 10:56:51.828735 15018 net.cpp:226] score_32 needs backward computation.
I1015 10:56:51.828739 15018 net.cpp:226] mbox_loss needs backward computation.
I1015 10:56:51.828745 15018 net.cpp:228] mbox_priorbox does not need backward computation.
I1015 10:56:51.828755 15018 net.cpp:226] mbox_conf needs backward computation.
I1015 10:56:51.828760 15018 net.cpp:226] mbox_loc needs backward computation.
I1015 10:56:51.828766 15018 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1015 10:56:51.828773 15018 net.cpp:226] conv17_2_mbox_conf_flat needs backward computation.
I1015 10:56:51.828776 15018 net.cpp:226] conv17_2_mbox_conf_perm needs backward computation.
I1015 10:56:51.828780 15018 net.cpp:226] conv17_2_mbox_conf_new needs backward computation.
I1015 10:56:51.828784 15018 net.cpp:226] conv17_2_mbox_loc_flat needs backward computation.
I1015 10:56:51.828789 15018 net.cpp:226] conv17_2_mbox_loc_perm needs backward computation.
I1015 10:56:51.828791 15018 net.cpp:226] conv17_2_mbox_loc needs backward computation.
I1015 10:56:51.828795 15018 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1015 10:56:51.828799 15018 net.cpp:226] conv16_2_mbox_conf_flat needs backward computation.
I1015 10:56:51.828804 15018 net.cpp:226] conv16_2_mbox_conf_perm needs backward computation.
I1015 10:56:51.828809 15018 net.cpp:226] conv16_2_mbox_conf_new needs backward computation.
I1015 10:56:51.828812 15018 net.cpp:226] conv16_2_mbox_loc_flat needs backward computation.
I1015 10:56:51.828819 15018 net.cpp:226] conv16_2_mbox_loc_perm needs backward computation.
I1015 10:56:51.828822 15018 net.cpp:226] conv16_2_mbox_loc needs backward computation.
I1015 10:56:51.828827 15018 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1015 10:56:51.828833 15018 net.cpp:226] conv15_2_mbox_conf_flat needs backward computation.
I1015 10:56:51.828837 15018 net.cpp:226] conv15_2_mbox_conf_perm needs backward computation.
I1015 10:56:51.828841 15018 net.cpp:226] conv15_2_mbox_conf_new needs backward computation.
I1015 10:56:51.828845 15018 net.cpp:226] conv15_2_mbox_loc_flat needs backward computation.
I1015 10:56:51.828847 15018 net.cpp:226] conv15_2_mbox_loc_perm needs backward computation.
I1015 10:56:51.828850 15018 net.cpp:226] conv15_2_mbox_loc needs backward computation.
I1015 10:56:51.828855 15018 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1015 10:56:51.828861 15018 net.cpp:226] conv14_2_mbox_conf_flat needs backward computation.
I1015 10:56:51.828866 15018 net.cpp:226] conv14_2_mbox_conf_perm needs backward computation.
I1015 10:56:51.828869 15018 net.cpp:226] conv14_2_mbox_conf_new needs backward computation.
I1015 10:56:51.828874 15018 net.cpp:226] conv14_2_mbox_loc_flat needs backward computation.
I1015 10:56:51.828878 15018 net.cpp:226] conv14_2_mbox_loc_perm needs backward computation.
I1015 10:56:51.828881 15018 net.cpp:226] conv14_2_mbox_loc needs backward computation.
I1015 10:56:51.828884 15018 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1015 10:56:51.828888 15018 net.cpp:226] conv13_mbox_conf_flat needs backward computation.
I1015 10:56:51.828893 15018 net.cpp:226] conv13_mbox_conf_perm needs backward computation.
I1015 10:56:51.828898 15018 net.cpp:226] conv13_mbox_conf_new needs backward computation.
I1015 10:56:51.828902 15018 net.cpp:226] conv13_mbox_loc_flat needs backward computation.
I1015 10:56:51.828905 15018 net.cpp:226] conv13_mbox_loc_perm needs backward computation.
I1015 10:56:51.828909 15018 net.cpp:226] conv13_mbox_loc needs backward computation.
I1015 10:56:51.828914 15018 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1015 10:56:51.828922 15018 net.cpp:226] conv11_mbox_conf_flat needs backward computation.
I1015 10:56:51.828925 15018 net.cpp:226] conv11_mbox_conf_perm needs backward computation.
I1015 10:56:51.828929 15018 net.cpp:226] conv11_mbox_conf_new needs backward computation.
I1015 10:56:51.828933 15018 net.cpp:226] conv11_mbox_loc_flat needs backward computation.
I1015 10:56:51.828938 15018 net.cpp:226] conv11_mbox_loc_perm needs backward computation.
I1015 10:56:51.828941 15018 net.cpp:226] conv11_mbox_loc needs backward computation.
I1015 10:56:51.828946 15018 net.cpp:226] conv17_2_conv17_2/relu_0_split needs backward computation.
I1015 10:56:51.828950 15018 net.cpp:226] conv17_2/relu needs backward computation.
I1015 10:56:51.828954 15018 net.cpp:226] conv17_2/scale needs backward computation.
I1015 10:56:51.828958 15018 net.cpp:226] conv17_2/bn needs backward computation.
I1015 10:56:51.828961 15018 net.cpp:226] conv17_2 needs backward computation.
I1015 10:56:51.828965 15018 net.cpp:226] conv17_1/relu needs backward computation.
I1015 10:56:51.828968 15018 net.cpp:226] conv17_1/scale needs backward computation.
I1015 10:56:51.828970 15018 net.cpp:226] conv17_1/bn needs backward computation.
I1015 10:56:51.828974 15018 net.cpp:226] conv17_1 needs backward computation.
I1015 10:56:51.828977 15018 net.cpp:226] conv16_2_conv16_2/relu_0_split needs backward computation.
I1015 10:56:51.828981 15018 net.cpp:226] conv16_2/relu needs backward computation.
I1015 10:56:51.828985 15018 net.cpp:226] conv16_2/scale needs backward computation.
I1015 10:56:51.828989 15018 net.cpp:226] conv16_2/bn needs backward computation.
I1015 10:56:51.828991 15018 net.cpp:226] conv16_2 needs backward computation.
I1015 10:56:51.828994 15018 net.cpp:226] conv16_1/relu needs backward computation.
I1015 10:56:51.828999 15018 net.cpp:226] conv16_1/scale needs backward computation.
I1015 10:56:51.829001 15018 net.cpp:226] conv16_1/bn needs backward computation.
I1015 10:56:51.829005 15018 net.cpp:226] conv16_1 needs backward computation.
I1015 10:56:51.829008 15018 net.cpp:226] conv15_2_conv15_2/relu_0_split needs backward computation.
I1015 10:56:51.829013 15018 net.cpp:226] conv15_2/relu needs backward computation.
I1015 10:56:51.829015 15018 net.cpp:226] conv15_2/scale needs backward computation.
I1015 10:56:51.829017 15018 net.cpp:226] conv15_2/bn needs backward computation.
I1015 10:56:51.829020 15018 net.cpp:226] conv15_2 needs backward computation.
I1015 10:56:51.829022 15018 net.cpp:226] conv15_1/relu needs backward computation.
I1015 10:56:51.829025 15018 net.cpp:226] conv15_1/scale needs backward computation.
I1015 10:56:51.829028 15018 net.cpp:226] conv15_1/bn needs backward computation.
I1015 10:56:51.829032 15018 net.cpp:226] conv15_1 needs backward computation.
I1015 10:56:51.829036 15018 net.cpp:226] conv14_2_conv14_2/relu_0_split needs backward computation.
I1015 10:56:51.829042 15018 net.cpp:226] conv14_2/relu needs backward computation.
I1015 10:56:51.829046 15018 net.cpp:226] conv14_2/scale needs backward computation.
I1015 10:56:51.829049 15018 net.cpp:226] conv14_2/bn needs backward computation.
I1015 10:56:51.829053 15018 net.cpp:226] conv14_2 needs backward computation.
I1015 10:56:51.829057 15018 net.cpp:226] conv14_1/relu needs backward computation.
I1015 10:56:51.829061 15018 net.cpp:226] conv14_1/scale needs backward computation.
I1015 10:56:51.829066 15018 net.cpp:226] conv14_1/bn needs backward computation.
I1015 10:56:51.829069 15018 net.cpp:226] conv14_1 needs backward computation.
I1015 10:56:51.829072 15018 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1015 10:56:51.829075 15018 net.cpp:226] conv13/relu needs backward computation.
I1015 10:56:51.829079 15018 net.cpp:226] conv13/scale needs backward computation.
I1015 10:56:51.829082 15018 net.cpp:226] conv13/bn needs backward computation.
I1015 10:56:51.829087 15018 net.cpp:226] conv13 needs backward computation.
I1015 10:56:51.829089 15018 net.cpp:226] conv13/dw/relu needs backward computation.
I1015 10:56:51.829093 15018 net.cpp:226] conv13/dw/scale needs backward computation.
I1015 10:56:51.829097 15018 net.cpp:226] conv13/dw/bn needs backward computation.
I1015 10:56:51.829100 15018 net.cpp:226] conv13/dw needs backward computation.
I1015 10:56:51.829104 15018 net.cpp:226] conv12/relu needs backward computation.
I1015 10:56:51.829107 15018 net.cpp:226] conv12/scale needs backward computation.
I1015 10:56:51.829109 15018 net.cpp:226] conv12/bn needs backward computation.
I1015 10:56:51.829113 15018 net.cpp:226] conv12 needs backward computation.
I1015 10:56:51.829116 15018 net.cpp:226] conv12/dw/relu needs backward computation.
I1015 10:56:51.829120 15018 net.cpp:226] conv12/dw/scale needs backward computation.
I1015 10:56:51.829124 15018 net.cpp:226] conv12/dw/bn needs backward computation.
I1015 10:56:51.829128 15018 net.cpp:226] conv12/dw needs backward computation.
I1015 10:56:51.829131 15018 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1015 10:56:51.829135 15018 net.cpp:226] conv11/relu needs backward computation.
I1015 10:56:51.829139 15018 net.cpp:226] conv11/scale needs backward computation.
I1015 10:56:51.829143 15018 net.cpp:226] conv11/bn needs backward computation.
I1015 10:56:51.829145 15018 net.cpp:226] conv11 needs backward computation.
I1015 10:56:51.829149 15018 net.cpp:226] conv11/dw/relu needs backward computation.
I1015 10:56:51.829154 15018 net.cpp:226] conv11/dw/scale needs backward computation.
I1015 10:56:51.829156 15018 net.cpp:226] conv11/dw/bn needs backward computation.
I1015 10:56:51.829160 15018 net.cpp:226] conv11/dw needs backward computation.
I1015 10:56:51.829164 15018 net.cpp:226] conv10/relu needs backward computation.
I1015 10:56:51.829169 15018 net.cpp:226] conv10/scale needs backward computation.
I1015 10:56:51.829171 15018 net.cpp:226] conv10/bn needs backward computation.
I1015 10:56:51.829175 15018 net.cpp:226] conv10 needs backward computation.
I1015 10:56:51.829179 15018 net.cpp:226] conv10/dw/relu needs backward computation.
I1015 10:56:51.829182 15018 net.cpp:226] conv10/dw/scale needs backward computation.
I1015 10:56:51.829186 15018 net.cpp:226] conv10/dw/bn needs backward computation.
I1015 10:56:51.829190 15018 net.cpp:226] conv10/dw needs backward computation.
I1015 10:56:51.829195 15018 net.cpp:226] conv9/relu needs backward computation.
I1015 10:56:51.829198 15018 net.cpp:226] conv9/scale needs backward computation.
I1015 10:56:51.829201 15018 net.cpp:226] conv9/bn needs backward computation.
I1015 10:56:51.829205 15018 net.cpp:226] conv9 needs backward computation.
I1015 10:56:51.829210 15018 net.cpp:226] conv9/dw/relu needs backward computation.
I1015 10:56:51.829212 15018 net.cpp:226] conv9/dw/scale needs backward computation.
I1015 10:56:51.829216 15018 net.cpp:226] conv9/dw/bn needs backward computation.
I1015 10:56:51.829219 15018 net.cpp:226] conv9/dw needs backward computation.
I1015 10:56:51.829222 15018 net.cpp:226] conv8/relu needs backward computation.
I1015 10:56:51.829224 15018 net.cpp:226] conv8/scale needs backward computation.
I1015 10:56:51.829227 15018 net.cpp:226] conv8/bn needs backward computation.
I1015 10:56:51.829229 15018 net.cpp:226] conv8 needs backward computation.
I1015 10:56:51.829231 15018 net.cpp:226] conv8/dw/relu needs backward computation.
I1015 10:56:51.829234 15018 net.cpp:226] conv8/dw/scale needs backward computation.
I1015 10:56:51.829236 15018 net.cpp:226] conv8/dw/bn needs backward computation.
I1015 10:56:51.829238 15018 net.cpp:226] conv8/dw needs backward computation.
I1015 10:56:51.829242 15018 net.cpp:226] conv7/relu needs backward computation.
I1015 10:56:51.829246 15018 net.cpp:226] conv7/scale needs backward computation.
I1015 10:56:51.829249 15018 net.cpp:226] conv7/bn needs backward computation.
I1015 10:56:51.829252 15018 net.cpp:226] conv7 needs backward computation.
I1015 10:56:51.829254 15018 net.cpp:226] conv7/dw/relu needs backward computation.
I1015 10:56:51.829258 15018 net.cpp:226] conv7/dw/scale needs backward computation.
I1015 10:56:51.829262 15018 net.cpp:226] conv7/dw/bn needs backward computation.
I1015 10:56:51.829264 15018 net.cpp:226] conv7/dw needs backward computation.
I1015 10:56:51.829267 15018 net.cpp:226] conv6/relu needs backward computation.
I1015 10:56:51.829270 15018 net.cpp:226] conv6/scale needs backward computation.
I1015 10:56:51.829273 15018 net.cpp:226] conv6/bn needs backward computation.
I1015 10:56:51.829275 15018 net.cpp:226] conv6 needs backward computation.
I1015 10:56:51.829278 15018 net.cpp:226] conv6/dw/relu needs backward computation.
I1015 10:56:51.829280 15018 net.cpp:226] conv6/dw/scale needs backward computation.
I1015 10:56:51.829283 15018 net.cpp:226] conv6/dw/bn needs backward computation.
I1015 10:56:51.829285 15018 net.cpp:226] conv6/dw needs backward computation.
I1015 10:56:51.829289 15018 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1015 10:56:51.829294 15018 net.cpp:226] conv5/relu needs backward computation.
I1015 10:56:51.829298 15018 net.cpp:226] conv5/scale needs backward computation.
I1015 10:56:51.829300 15018 net.cpp:226] conv5/bn needs backward computation.
I1015 10:56:51.829304 15018 net.cpp:226] conv5 needs backward computation.
I1015 10:56:51.829308 15018 net.cpp:226] conv5/dw/relu needs backward computation.
I1015 10:56:51.829313 15018 net.cpp:226] conv5/dw/scale needs backward computation.
I1015 10:56:51.829316 15018 net.cpp:226] conv5/dw/bn needs backward computation.
I1015 10:56:51.829319 15018 net.cpp:226] conv5/dw needs backward computation.
I1015 10:56:51.829324 15018 net.cpp:226] conv4/relu needs backward computation.
I1015 10:56:51.829327 15018 net.cpp:226] conv4/scale needs backward computation.
I1015 10:56:51.829339 15018 net.cpp:226] conv4/bn needs backward computation.
I1015 10:56:51.829342 15018 net.cpp:226] conv4 needs backward computation.
I1015 10:56:51.829347 15018 net.cpp:226] conv4/dw/relu needs backward computation.
I1015 10:56:51.829350 15018 net.cpp:226] conv4/dw/scale needs backward computation.
I1015 10:56:51.829355 15018 net.cpp:226] conv4/dw/bn needs backward computation.
I1015 10:56:51.829358 15018 net.cpp:226] conv4/dw needs backward computation.
I1015 10:56:51.829362 15018 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1015 10:56:51.829373 15018 net.cpp:226] conv3/relu needs backward computation.
I1015 10:56:51.829376 15018 net.cpp:226] conv3/scale needs backward computation.
I1015 10:56:51.829378 15018 net.cpp:226] conv3/bn needs backward computation.
I1015 10:56:51.829380 15018 net.cpp:226] conv3 needs backward computation.
I1015 10:56:51.829383 15018 net.cpp:226] conv3/dw/relu needs backward computation.
I1015 10:56:51.829385 15018 net.cpp:226] conv3/dw/scale needs backward computation.
I1015 10:56:51.829388 15018 net.cpp:226] conv3/dw/bn needs backward computation.
I1015 10:56:51.829391 15018 net.cpp:226] conv3/dw needs backward computation.
I1015 10:56:51.829393 15018 net.cpp:226] conv2/relu needs backward computation.
I1015 10:56:51.829396 15018 net.cpp:226] conv2/scale needs backward computation.
I1015 10:56:51.829397 15018 net.cpp:226] conv2/bn needs backward computation.
I1015 10:56:51.829401 15018 net.cpp:226] conv2 needs backward computation.
I1015 10:56:51.829403 15018 net.cpp:226] conv2/dw/relu needs backward computation.
I1015 10:56:51.829407 15018 net.cpp:226] conv2/dw/scale needs backward computation.
I1015 10:56:51.829411 15018 net.cpp:226] conv2/dw/bn needs backward computation.
I1015 10:56:51.829414 15018 net.cpp:226] conv2/dw needs backward computation.
I1015 10:56:51.829418 15018 net.cpp:226] conv1/relu needs backward computation.
I1015 10:56:51.829422 15018 net.cpp:226] conv1/scale needs backward computation.
I1015 10:56:51.829425 15018 net.cpp:226] conv1/bn needs backward computation.
I1015 10:56:51.829429 15018 net.cpp:226] conv1 needs backward computation.
I1015 10:56:51.829433 15018 net.cpp:226] conv1/dw/relu needs backward computation.
I1015 10:56:51.829437 15018 net.cpp:226] conv1/dw/scale needs backward computation.
I1015 10:56:51.829440 15018 net.cpp:226] conv1/dw/bn needs backward computation.
I1015 10:56:51.829444 15018 net.cpp:226] conv1/dw needs backward computation.
I1015 10:56:51.829448 15018 net.cpp:226] conv0/relu needs backward computation.
I1015 10:56:51.829452 15018 net.cpp:226] conv0/scale needs backward computation.
I1015 10:56:51.829455 15018 net.cpp:226] conv0/bn needs backward computation.
I1015 10:56:51.829459 15018 net.cpp:226] conv0 needs backward computation.
I1015 10:56:51.829466 15018 net.cpp:228] data_data_0_split does not need backward computation.
I1015 10:56:51.829471 15018 net.cpp:228] data does not need backward computation.
I1015 10:56:51.829474 15018 net.cpp:270] This network produces output mbox_loss
I1015 10:56:51.829479 15018 net.cpp:270] This network produces output seg_loss
I1015 10:56:51.829612 15018 net.cpp:283] Network initialization done.
I1015 10:56:51.839331 15018 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_test.prototxt
I1015 10:56:51.839350 15018 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 10:56:51.839356 15018 solver.cpp:196] Creating test net (#0) specified by test_net file: proto/union/MobileNetSSD_test.prototxt
I1015 10:56:51.840581 15018 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_conf_perm"
  type: "Permute"
  bottom: "conv13_mbox_conf"
  top: "conv13_mbox_conf_perm"
  permute_param {
    
I1015 10:56:51.841200 15018 layer_factory.hpp:77] Creating layer data
I1015 10:56:51.841270 15018 net.cpp:100] Creating Layer data
I1015 10:56:51.841279 15018 net.cpp:408] data -> data
I1015 10:56:51.841289 15018 net.cpp:408] data -> label
I1015 10:56:51.841296 15018 net.cpp:408] data -> label_seg
I1015 10:56:51.841305 15018 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1015 10:56:51.909390 15084 db_lmdb.cpp:35] Opened lmdb lmdb/seg_test_lmdb
I1015 10:56:52.019549 15018 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 1,3,320,480
I1015 10:56:52.025925 15018 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1015 10:56:52.025984 15018 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1015 10:56:52.025990 15018 net.cpp:150] Setting up data
I1015 10:56:52.025998 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026002 15018 net.cpp:157] Top shape: 1 1 2 8 (16)
I1015 10:56:52.026005 15018 net.cpp:157] Top shape: 1 1 320 480 (153600)
I1015 10:56:52.026008 15018 net.cpp:165] Memory required for data: 2457664
I1015 10:56:52.026015 15018 layer_factory.hpp:77] Creating layer data_data_0_split
I1015 10:56:52.026026 15018 net.cpp:100] Creating Layer data_data_0_split
I1015 10:56:52.026029 15018 net.cpp:434] data_data_0_split <- data
I1015 10:56:52.026038 15018 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1015 10:56:52.026047 15018 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1015 10:56:52.026053 15018 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1015 10:56:52.026058 15018 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1015 10:56:52.026062 15018 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1015 10:56:52.026067 15018 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1015 10:56:52.026074 15018 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1015 10:56:52.026080 15018 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1015 10:56:52.026260 15018 net.cpp:150] Setting up data_data_0_split
I1015 10:56:52.026273 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026278 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026280 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026283 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026286 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026288 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026291 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026294 15018 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 10:56:52.026296 15018 net.cpp:165] Memory required for data: 17203264
I1015 10:56:52.026299 15018 layer_factory.hpp:77] Creating layer conv0
I1015 10:56:52.026311 15018 net.cpp:100] Creating Layer conv0
I1015 10:56:52.026314 15018 net.cpp:434] conv0 <- data_data_0_split_0
I1015 10:56:52.026321 15018 net.cpp:408] conv0 -> conv0
I1015 10:56:52.027789 15085 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1015 10:56:52.028672 15018 net.cpp:150] Setting up conv0
I1015 10:56:52.028686 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.028687 15018 net.cpp:165] Memory required for data: 22118464
I1015 10:56:52.028695 15018 layer_factory.hpp:77] Creating layer conv0/bn
I1015 10:56:52.028700 15018 net.cpp:100] Creating Layer conv0/bn
I1015 10:56:52.028703 15018 net.cpp:434] conv0/bn <- conv0
I1015 10:56:52.028708 15018 net.cpp:395] conv0/bn -> conv0 (in-place)
I1015 10:56:52.029075 15018 net.cpp:150] Setting up conv0/bn
I1015 10:56:52.029089 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.029093 15018 net.cpp:165] Memory required for data: 27033664
I1015 10:56:52.029103 15018 layer_factory.hpp:77] Creating layer conv0/scale
I1015 10:56:52.029112 15018 net.cpp:100] Creating Layer conv0/scale
I1015 10:56:52.029116 15018 net.cpp:434] conv0/scale <- conv0
I1015 10:56:52.029124 15018 net.cpp:395] conv0/scale -> conv0 (in-place)
I1015 10:56:52.029183 15018 layer_factory.hpp:77] Creating layer conv0/scale
I1015 10:56:52.029407 15018 net.cpp:150] Setting up conv0/scale
I1015 10:56:52.029417 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.029422 15018 net.cpp:165] Memory required for data: 31948864
I1015 10:56:52.029431 15018 layer_factory.hpp:77] Creating layer conv0/relu
I1015 10:56:52.029440 15018 net.cpp:100] Creating Layer conv0/relu
I1015 10:56:52.029443 15018 net.cpp:434] conv0/relu <- conv0
I1015 10:56:52.029448 15018 net.cpp:395] conv0/relu -> conv0 (in-place)
I1015 10:56:52.029888 15018 net.cpp:150] Setting up conv0/relu
I1015 10:56:52.029901 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.029903 15018 net.cpp:165] Memory required for data: 36864064
I1015 10:56:52.029906 15018 layer_factory.hpp:77] Creating layer conv1/dw
I1015 10:56:52.029916 15018 net.cpp:100] Creating Layer conv1/dw
I1015 10:56:52.029917 15018 net.cpp:434] conv1/dw <- conv0
I1015 10:56:52.029923 15018 net.cpp:408] conv1/dw -> conv1/dw
I1015 10:56:52.030200 15018 net.cpp:150] Setting up conv1/dw
I1015 10:56:52.030210 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.030211 15018 net.cpp:165] Memory required for data: 41779264
I1015 10:56:52.030216 15018 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1015 10:56:52.030222 15018 net.cpp:100] Creating Layer conv1/dw/bn
I1015 10:56:52.030227 15018 net.cpp:434] conv1/dw/bn <- conv1/dw
I1015 10:56:52.030232 15018 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1015 10:56:52.030521 15018 net.cpp:150] Setting up conv1/dw/bn
I1015 10:56:52.030529 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.030532 15018 net.cpp:165] Memory required for data: 46694464
I1015 10:56:52.030541 15018 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 10:56:52.030550 15018 net.cpp:100] Creating Layer conv1/dw/scale
I1015 10:56:52.030555 15018 net.cpp:434] conv1/dw/scale <- conv1/dw
I1015 10:56:52.030561 15018 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1015 10:56:52.030614 15018 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 10:56:52.030813 15018 net.cpp:150] Setting up conv1/dw/scale
I1015 10:56:52.030824 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.030828 15018 net.cpp:165] Memory required for data: 51609664
I1015 10:56:52.030835 15018 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1015 10:56:52.030841 15018 net.cpp:100] Creating Layer conv1/dw/relu
I1015 10:56:52.030844 15018 net.cpp:434] conv1/dw/relu <- conv1/dw
I1015 10:56:52.030848 15018 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1015 10:56:52.031230 15018 net.cpp:150] Setting up conv1/dw/relu
I1015 10:56:52.031244 15018 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 10:56:52.031250 15018 net.cpp:165] Memory required for data: 56524864
I1015 10:56:52.031253 15018 layer_factory.hpp:77] Creating layer conv1
I1015 10:56:52.031262 15018 net.cpp:100] Creating Layer conv1
I1015 10:56:52.031265 15018 net.cpp:434] conv1 <- conv1/dw
I1015 10:56:52.031270 15018 net.cpp:408] conv1 -> conv1
I1015 10:56:52.032912 15018 net.cpp:150] Setting up conv1
I1015 10:56:52.032925 15018 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 10:56:52.032928 15018 net.cpp:165] Memory required for data: 66355264
I1015 10:56:52.032933 15018 layer_factory.hpp:77] Creating layer conv1/bn
I1015 10:56:52.032938 15018 net.cpp:100] Creating Layer conv1/bn
I1015 10:56:52.032941 15018 net.cpp:434] conv1/bn <- conv1
I1015 10:56:52.032945 15018 net.cpp:395] conv1/bn -> conv1 (in-place)
I1015 10:56:52.033255 15018 net.cpp:150] Setting up conv1/bn
I1015 10:56:52.033269 15018 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 10:56:52.033273 15018 net.cpp:165] Memory required for data: 76185664
I1015 10:56:52.033282 15018 layer_factory.hpp:77] Creating layer conv1/scale
I1015 10:56:52.033291 15018 net.cpp:100] Creating Layer conv1/scale
I1015 10:56:52.033295 15018 net.cpp:434] conv1/scale <- conv1
I1015 10:56:52.033301 15018 net.cpp:395] conv1/scale -> conv1 (in-place)
I1015 10:56:52.033365 15018 layer_factory.hpp:77] Creating layer conv1/scale
I1015 10:56:52.033607 15018 net.cpp:150] Setting up conv1/scale
I1015 10:56:52.033617 15018 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 10:56:52.033618 15018 net.cpp:165] Memory required for data: 86016064
I1015 10:56:52.033627 15018 layer_factory.hpp:77] Creating layer conv1/relu
I1015 10:56:52.033632 15018 net.cpp:100] Creating Layer conv1/relu
I1015 10:56:52.033634 15018 net.cpp:434] conv1/relu <- conv1
I1015 10:56:52.033638 15018 net.cpp:395] conv1/relu -> conv1 (in-place)
I1015 10:56:52.034317 15018 net.cpp:150] Setting up conv1/relu
I1015 10:56:52.034329 15018 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 10:56:52.034332 15018 net.cpp:165] Memory required for data: 95846464
I1015 10:56:52.034335 15018 layer_factory.hpp:77] Creating layer conv2/dw
I1015 10:56:52.034345 15018 net.cpp:100] Creating Layer conv2/dw
I1015 10:56:52.034350 15018 net.cpp:434] conv2/dw <- conv1
I1015 10:56:52.034358 15018 net.cpp:408] conv2/dw -> conv2/dw
I1015 10:56:52.034593 15018 net.cpp:150] Setting up conv2/dw
I1015 10:56:52.034603 15018 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 10:56:52.034605 15018 net.cpp:165] Memory required for data: 98304064
I1015 10:56:52.034610 15018 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1015 10:56:52.034615 15018 net.cpp:100] Creating Layer conv2/dw/bn
I1015 10:56:52.034620 15018 net.cpp:434] conv2/dw/bn <- conv2/dw
I1015 10:56:52.034626 15018 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1015 10:56:52.034848 15018 net.cpp:150] Setting up conv2/dw/bn
I1015 10:56:52.034857 15018 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 10:56:52.034858 15018 net.cpp:165] Memory required for data: 100761664
I1015 10:56:52.034865 15018 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 10:56:52.034874 15018 net.cpp:100] Creating Layer conv2/dw/scale
I1015 10:56:52.034878 15018 net.cpp:434] conv2/dw/scale <- conv2/dw
I1015 10:56:52.034884 15018 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1015 10:56:52.034936 15018 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 10:56:52.035084 15018 net.cpp:150] Setting up conv2/dw/scale
I1015 10:56:52.035094 15018 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 10:56:52.035095 15018 net.cpp:165] Memory required for data: 103219264
I1015 10:56:52.035100 15018 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1015 10:56:52.035105 15018 net.cpp:100] Creating Layer conv2/dw/relu
I1015 10:56:52.035109 15018 net.cpp:434] conv2/dw/relu <- conv2/dw
I1015 10:56:52.035115 15018 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1015 10:56:52.035459 15018 net.cpp:150] Setting up conv2/dw/relu
I1015 10:56:52.035468 15018 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 10:56:52.035470 15018 net.cpp:165] Memory required for data: 105676864
I1015 10:56:52.035473 15018 layer_factory.hpp:77] Creating layer conv2
I1015 10:56:52.035482 15018 net.cpp:100] Creating Layer conv2
I1015 10:56:52.035486 15018 net.cpp:434] conv2 <- conv2/dw
I1015 10:56:52.035493 15018 net.cpp:408] conv2 -> conv2
I1015 10:56:52.037101 15018 net.cpp:150] Setting up conv2
I1015 10:56:52.037114 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.037117 15018 net.cpp:165] Memory required for data: 110592064
I1015 10:56:52.037122 15018 layer_factory.hpp:77] Creating layer conv2/bn
I1015 10:56:52.037127 15018 net.cpp:100] Creating Layer conv2/bn
I1015 10:56:52.037130 15018 net.cpp:434] conv2/bn <- conv2
I1015 10:56:52.037135 15018 net.cpp:395] conv2/bn -> conv2 (in-place)
I1015 10:56:52.037364 15018 net.cpp:150] Setting up conv2/bn
I1015 10:56:52.037374 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.037376 15018 net.cpp:165] Memory required for data: 115507264
I1015 10:56:52.037382 15018 layer_factory.hpp:77] Creating layer conv2/scale
I1015 10:56:52.037389 15018 net.cpp:100] Creating Layer conv2/scale
I1015 10:56:52.037394 15018 net.cpp:434] conv2/scale <- conv2
I1015 10:56:52.037400 15018 net.cpp:395] conv2/scale -> conv2 (in-place)
I1015 10:56:52.037452 15018 layer_factory.hpp:77] Creating layer conv2/scale
I1015 10:56:52.037607 15018 net.cpp:150] Setting up conv2/scale
I1015 10:56:52.037616 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.037618 15018 net.cpp:165] Memory required for data: 120422464
I1015 10:56:52.037623 15018 layer_factory.hpp:77] Creating layer conv2/relu
I1015 10:56:52.037629 15018 net.cpp:100] Creating Layer conv2/relu
I1015 10:56:52.037633 15018 net.cpp:434] conv2/relu <- conv2
I1015 10:56:52.037639 15018 net.cpp:395] conv2/relu -> conv2 (in-place)
I1015 10:56:52.038005 15018 net.cpp:150] Setting up conv2/relu
I1015 10:56:52.038015 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.038017 15018 net.cpp:165] Memory required for data: 125337664
I1015 10:56:52.038020 15018 layer_factory.hpp:77] Creating layer conv3/dw
I1015 10:56:52.038028 15018 net.cpp:100] Creating Layer conv3/dw
I1015 10:56:52.038033 15018 net.cpp:434] conv3/dw <- conv2
I1015 10:56:52.038039 15018 net.cpp:408] conv3/dw -> conv3/dw
I1015 10:56:52.038275 15018 net.cpp:150] Setting up conv3/dw
I1015 10:56:52.038285 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.038286 15018 net.cpp:165] Memory required for data: 130252864
I1015 10:56:52.038290 15018 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1015 10:56:52.038295 15018 net.cpp:100] Creating Layer conv3/dw/bn
I1015 10:56:52.038300 15018 net.cpp:434] conv3/dw/bn <- conv3/dw
I1015 10:56:52.038305 15018 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1015 10:56:52.038518 15018 net.cpp:150] Setting up conv3/dw/bn
I1015 10:56:52.038527 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.038528 15018 net.cpp:165] Memory required for data: 135168064
I1015 10:56:52.038538 15018 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 10:56:52.038547 15018 net.cpp:100] Creating Layer conv3/dw/scale
I1015 10:56:52.038550 15018 net.cpp:434] conv3/dw/scale <- conv3/dw
I1015 10:56:52.038556 15018 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1015 10:56:52.038606 15018 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 10:56:52.038743 15018 net.cpp:150] Setting up conv3/dw/scale
I1015 10:56:52.038751 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.038753 15018 net.cpp:165] Memory required for data: 140083264
I1015 10:56:52.038758 15018 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1015 10:56:52.038763 15018 net.cpp:100] Creating Layer conv3/dw/relu
I1015 10:56:52.038766 15018 net.cpp:434] conv3/dw/relu <- conv3/dw
I1015 10:56:52.038771 15018 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1015 10:56:52.039445 15018 net.cpp:150] Setting up conv3/dw/relu
I1015 10:56:52.039458 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.039460 15018 net.cpp:165] Memory required for data: 144998464
I1015 10:56:52.039463 15018 layer_factory.hpp:77] Creating layer conv3
I1015 10:56:52.039471 15018 net.cpp:100] Creating Layer conv3
I1015 10:56:52.039475 15018 net.cpp:434] conv3 <- conv3/dw
I1015 10:56:52.039484 15018 net.cpp:408] conv3 -> conv3
I1015 10:56:52.041178 15018 net.cpp:150] Setting up conv3
I1015 10:56:52.041191 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.041193 15018 net.cpp:165] Memory required for data: 149913664
I1015 10:56:52.041198 15018 layer_factory.hpp:77] Creating layer conv3/bn
I1015 10:56:52.041205 15018 net.cpp:100] Creating Layer conv3/bn
I1015 10:56:52.041209 15018 net.cpp:434] conv3/bn <- conv3
I1015 10:56:52.041215 15018 net.cpp:395] conv3/bn -> conv3 (in-place)
I1015 10:56:52.041450 15018 net.cpp:150] Setting up conv3/bn
I1015 10:56:52.041460 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.041461 15018 net.cpp:165] Memory required for data: 154828864
I1015 10:56:52.041467 15018 layer_factory.hpp:77] Creating layer conv3/scale
I1015 10:56:52.041474 15018 net.cpp:100] Creating Layer conv3/scale
I1015 10:56:52.041478 15018 net.cpp:434] conv3/scale <- conv3
I1015 10:56:52.041484 15018 net.cpp:395] conv3/scale -> conv3 (in-place)
I1015 10:56:52.041537 15018 layer_factory.hpp:77] Creating layer conv3/scale
I1015 10:56:52.041693 15018 net.cpp:150] Setting up conv3/scale
I1015 10:56:52.041702 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.041704 15018 net.cpp:165] Memory required for data: 159744064
I1015 10:56:52.041708 15018 layer_factory.hpp:77] Creating layer conv3/relu
I1015 10:56:52.041714 15018 net.cpp:100] Creating Layer conv3/relu
I1015 10:56:52.041718 15018 net.cpp:434] conv3/relu <- conv3
I1015 10:56:52.041723 15018 net.cpp:395] conv3/relu -> conv3 (in-place)
I1015 10:56:52.042070 15018 net.cpp:150] Setting up conv3/relu
I1015 10:56:52.042081 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.042083 15018 net.cpp:165] Memory required for data: 164659264
I1015 10:56:52.042085 15018 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1015 10:56:52.042091 15018 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1015 10:56:52.042095 15018 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1015 10:56:52.042102 15018 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1015 10:56:52.042109 15018 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1015 10:56:52.042162 15018 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1015 10:56:52.042170 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.042171 15018 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 10:56:52.042174 15018 net.cpp:165] Memory required for data: 174489664
I1015 10:56:52.042178 15018 layer_factory.hpp:77] Creating layer conv4/dw
I1015 10:56:52.042187 15018 net.cpp:100] Creating Layer conv4/dw
I1015 10:56:52.042192 15018 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1015 10:56:52.042198 15018 net.cpp:408] conv4/dw -> conv4/dw
I1015 10:56:52.042421 15018 net.cpp:150] Setting up conv4/dw
I1015 10:56:52.042431 15018 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 10:56:52.042433 15018 net.cpp:165] Memory required for data: 175718464
I1015 10:56:52.042438 15018 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1015 10:56:52.042444 15018 net.cpp:100] Creating Layer conv4/dw/bn
I1015 10:56:52.042448 15018 net.cpp:434] conv4/dw/bn <- conv4/dw
I1015 10:56:52.042454 15018 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1015 10:56:52.042673 15018 net.cpp:150] Setting up conv4/dw/bn
I1015 10:56:52.042685 15018 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 10:56:52.042688 15018 net.cpp:165] Memory required for data: 176947264
I1015 10:56:52.042697 15018 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 10:56:52.042704 15018 net.cpp:100] Creating Layer conv4/dw/scale
I1015 10:56:52.042708 15018 net.cpp:434] conv4/dw/scale <- conv4/dw
I1015 10:56:52.042713 15018 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1015 10:56:52.042757 15018 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 10:56:52.042874 15018 net.cpp:150] Setting up conv4/dw/scale
I1015 10:56:52.042886 15018 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 10:56:52.042889 15018 net.cpp:165] Memory required for data: 178176064
I1015 10:56:52.042896 15018 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1015 10:56:52.042902 15018 net.cpp:100] Creating Layer conv4/dw/relu
I1015 10:56:52.042906 15018 net.cpp:434] conv4/dw/relu <- conv4/dw
I1015 10:56:52.042912 15018 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1015 10:56:52.043310 15018 net.cpp:150] Setting up conv4/dw/relu
I1015 10:56:52.043325 15018 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 10:56:52.043329 15018 net.cpp:165] Memory required for data: 179404864
I1015 10:56:52.043334 15018 layer_factory.hpp:77] Creating layer conv4
I1015 10:56:52.043344 15018 net.cpp:100] Creating Layer conv4
I1015 10:56:52.043347 15018 net.cpp:434] conv4 <- conv4/dw
I1015 10:56:52.043354 15018 net.cpp:408] conv4 -> conv4
I1015 10:56:52.046263 15018 net.cpp:150] Setting up conv4
I1015 10:56:52.046279 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.046283 15018 net.cpp:165] Memory required for data: 181862464
I1015 10:56:52.046288 15018 layer_factory.hpp:77] Creating layer conv4/bn
I1015 10:56:52.046293 15018 net.cpp:100] Creating Layer conv4/bn
I1015 10:56:52.046295 15018 net.cpp:434] conv4/bn <- conv4
I1015 10:56:52.046300 15018 net.cpp:395] conv4/bn -> conv4 (in-place)
I1015 10:56:52.046552 15018 net.cpp:150] Setting up conv4/bn
I1015 10:56:52.046562 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.046566 15018 net.cpp:165] Memory required for data: 184320064
I1015 10:56:52.046573 15018 layer_factory.hpp:77] Creating layer conv4/scale
I1015 10:56:52.046578 15018 net.cpp:100] Creating Layer conv4/scale
I1015 10:56:52.046583 15018 net.cpp:434] conv4/scale <- conv4
I1015 10:56:52.046589 15018 net.cpp:395] conv4/scale -> conv4 (in-place)
I1015 10:56:52.046646 15018 layer_factory.hpp:77] Creating layer conv4/scale
I1015 10:56:52.046826 15018 net.cpp:150] Setting up conv4/scale
I1015 10:56:52.046838 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.046842 15018 net.cpp:165] Memory required for data: 186777664
I1015 10:56:52.046847 15018 layer_factory.hpp:77] Creating layer conv4/relu
I1015 10:56:52.046851 15018 net.cpp:100] Creating Layer conv4/relu
I1015 10:56:52.046854 15018 net.cpp:434] conv4/relu <- conv4
I1015 10:56:52.046857 15018 net.cpp:395] conv4/relu -> conv4 (in-place)
I1015 10:56:52.047890 15018 net.cpp:150] Setting up conv4/relu
I1015 10:56:52.047902 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.047905 15018 net.cpp:165] Memory required for data: 189235264
I1015 10:56:52.047909 15018 layer_factory.hpp:77] Creating layer conv5/dw
I1015 10:56:52.047916 15018 net.cpp:100] Creating Layer conv5/dw
I1015 10:56:52.047919 15018 net.cpp:434] conv5/dw <- conv4
I1015 10:56:52.047924 15018 net.cpp:408] conv5/dw -> conv5/dw
I1015 10:56:52.048241 15018 net.cpp:150] Setting up conv5/dw
I1015 10:56:52.048252 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.048254 15018 net.cpp:165] Memory required for data: 191692864
I1015 10:56:52.048259 15018 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1015 10:56:52.048264 15018 net.cpp:100] Creating Layer conv5/dw/bn
I1015 10:56:52.048266 15018 net.cpp:434] conv5/dw/bn <- conv5/dw
I1015 10:56:52.048269 15018 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1015 10:56:52.048539 15018 net.cpp:150] Setting up conv5/dw/bn
I1015 10:56:52.048548 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.048552 15018 net.cpp:165] Memory required for data: 194150464
I1015 10:56:52.048557 15018 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 10:56:52.048561 15018 net.cpp:100] Creating Layer conv5/dw/scale
I1015 10:56:52.048564 15018 net.cpp:434] conv5/dw/scale <- conv5/dw
I1015 10:56:52.048568 15018 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1015 10:56:52.048620 15018 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 10:56:52.048787 15018 net.cpp:150] Setting up conv5/dw/scale
I1015 10:56:52.048795 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.048799 15018 net.cpp:165] Memory required for data: 196608064
I1015 10:56:52.048805 15018 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1015 10:56:52.048812 15018 net.cpp:100] Creating Layer conv5/dw/relu
I1015 10:56:52.048816 15018 net.cpp:434] conv5/dw/relu <- conv5/dw
I1015 10:56:52.048820 15018 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1015 10:56:52.049218 15018 net.cpp:150] Setting up conv5/dw/relu
I1015 10:56:52.049229 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.049232 15018 net.cpp:165] Memory required for data: 199065664
I1015 10:56:52.049234 15018 layer_factory.hpp:77] Creating layer conv5
I1015 10:56:52.049242 15018 net.cpp:100] Creating Layer conv5
I1015 10:56:52.049244 15018 net.cpp:434] conv5 <- conv5/dw
I1015 10:56:52.049248 15018 net.cpp:408] conv5 -> conv5
I1015 10:56:52.051399 15018 net.cpp:150] Setting up conv5
I1015 10:56:52.051411 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.051415 15018 net.cpp:165] Memory required for data: 201523264
I1015 10:56:52.051420 15018 layer_factory.hpp:77] Creating layer conv5/bn
I1015 10:56:52.051424 15018 net.cpp:100] Creating Layer conv5/bn
I1015 10:56:52.051427 15018 net.cpp:434] conv5/bn <- conv5
I1015 10:56:52.051431 15018 net.cpp:395] conv5/bn -> conv5 (in-place)
I1015 10:56:52.051717 15018 net.cpp:150] Setting up conv5/bn
I1015 10:56:52.051725 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.051728 15018 net.cpp:165] Memory required for data: 203980864
I1015 10:56:52.051734 15018 layer_factory.hpp:77] Creating layer conv5/scale
I1015 10:56:52.051739 15018 net.cpp:100] Creating Layer conv5/scale
I1015 10:56:52.051741 15018 net.cpp:434] conv5/scale <- conv5
I1015 10:56:52.051745 15018 net.cpp:395] conv5/scale -> conv5 (in-place)
I1015 10:56:52.051798 15018 layer_factory.hpp:77] Creating layer conv5/scale
I1015 10:56:52.051975 15018 net.cpp:150] Setting up conv5/scale
I1015 10:56:52.051985 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.051987 15018 net.cpp:165] Memory required for data: 206438464
I1015 10:56:52.052003 15018 layer_factory.hpp:77] Creating layer conv5/relu
I1015 10:56:52.052012 15018 net.cpp:100] Creating Layer conv5/relu
I1015 10:56:52.052016 15018 net.cpp:434] conv5/relu <- conv5
I1015 10:56:52.052021 15018 net.cpp:395] conv5/relu -> conv5 (in-place)
I1015 10:56:52.052417 15018 net.cpp:150] Setting up conv5/relu
I1015 10:56:52.052428 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.052430 15018 net.cpp:165] Memory required for data: 208896064
I1015 10:56:52.052433 15018 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1015 10:56:52.052438 15018 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1015 10:56:52.052441 15018 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1015 10:56:52.052446 15018 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1015 10:56:52.052451 15018 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1015 10:56:52.052513 15018 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1015 10:56:52.052522 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.052525 15018 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 10:56:52.052527 15018 net.cpp:165] Memory required for data: 213811264
I1015 10:56:52.052529 15018 layer_factory.hpp:77] Creating layer conv6/dw
I1015 10:56:52.052536 15018 net.cpp:100] Creating Layer conv6/dw
I1015 10:56:52.052539 15018 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1015 10:56:52.052544 15018 net.cpp:408] conv6/dw -> conv6/dw
I1015 10:56:52.052914 15018 net.cpp:150] Setting up conv6/dw
I1015 10:56:52.052927 15018 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 10:56:52.052932 15018 net.cpp:165] Memory required for data: 214425664
I1015 10:56:52.052938 15018 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1015 10:56:52.052945 15018 net.cpp:100] Creating Layer conv6/dw/bn
I1015 10:56:52.052950 15018 net.cpp:434] conv6/dw/bn <- conv6/dw
I1015 10:56:52.052956 15018 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1015 10:56:52.053244 15018 net.cpp:150] Setting up conv6/dw/bn
I1015 10:56:52.053252 15018 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 10:56:52.053256 15018 net.cpp:165] Memory required for data: 215040064
I1015 10:56:52.053261 15018 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 10:56:52.053266 15018 net.cpp:100] Creating Layer conv6/dw/scale
I1015 10:56:52.053268 15018 net.cpp:434] conv6/dw/scale <- conv6/dw
I1015 10:56:52.053272 15018 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1015 10:56:52.053324 15018 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 10:56:52.053512 15018 net.cpp:150] Setting up conv6/dw/scale
I1015 10:56:52.053524 15018 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 10:56:52.053529 15018 net.cpp:165] Memory required for data: 215654464
I1015 10:56:52.053534 15018 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1015 10:56:52.053539 15018 net.cpp:100] Creating Layer conv6/dw/relu
I1015 10:56:52.053542 15018 net.cpp:434] conv6/dw/relu <- conv6/dw
I1015 10:56:52.053548 15018 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1015 10:56:52.053941 15018 net.cpp:150] Setting up conv6/dw/relu
I1015 10:56:52.053951 15018 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 10:56:52.053954 15018 net.cpp:165] Memory required for data: 216268864
I1015 10:56:52.053957 15018 layer_factory.hpp:77] Creating layer conv6
I1015 10:56:52.053963 15018 net.cpp:100] Creating Layer conv6
I1015 10:56:52.053966 15018 net.cpp:434] conv6 <- conv6/dw
I1015 10:56:52.053972 15018 net.cpp:408] conv6 -> conv6
I1015 10:56:52.056583 15018 net.cpp:150] Setting up conv6
I1015 10:56:52.056596 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.056599 15018 net.cpp:165] Memory required for data: 217497664
I1015 10:56:52.056603 15018 layer_factory.hpp:77] Creating layer conv6/bn
I1015 10:56:52.056608 15018 net.cpp:100] Creating Layer conv6/bn
I1015 10:56:52.056612 15018 net.cpp:434] conv6/bn <- conv6
I1015 10:56:52.056614 15018 net.cpp:395] conv6/bn -> conv6 (in-place)
I1015 10:56:52.056905 15018 net.cpp:150] Setting up conv6/bn
I1015 10:56:52.056913 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.056916 15018 net.cpp:165] Memory required for data: 218726464
I1015 10:56:52.056922 15018 layer_factory.hpp:77] Creating layer conv6/scale
I1015 10:56:52.056927 15018 net.cpp:100] Creating Layer conv6/scale
I1015 10:56:52.056929 15018 net.cpp:434] conv6/scale <- conv6
I1015 10:56:52.056933 15018 net.cpp:395] conv6/scale -> conv6 (in-place)
I1015 10:56:52.056990 15018 layer_factory.hpp:77] Creating layer conv6/scale
I1015 10:56:52.057178 15018 net.cpp:150] Setting up conv6/scale
I1015 10:56:52.057189 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.057191 15018 net.cpp:165] Memory required for data: 219955264
I1015 10:56:52.057196 15018 layer_factory.hpp:77] Creating layer conv6/relu
I1015 10:56:52.057200 15018 net.cpp:100] Creating Layer conv6/relu
I1015 10:56:52.057204 15018 net.cpp:434] conv6/relu <- conv6
I1015 10:56:52.057206 15018 net.cpp:395] conv6/relu -> conv6 (in-place)
I1015 10:56:52.057919 15018 net.cpp:150] Setting up conv6/relu
I1015 10:56:52.057931 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.057934 15018 net.cpp:165] Memory required for data: 221184064
I1015 10:56:52.057936 15018 layer_factory.hpp:77] Creating layer conv7/dw
I1015 10:56:52.057945 15018 net.cpp:100] Creating Layer conv7/dw
I1015 10:56:52.057947 15018 net.cpp:434] conv7/dw <- conv6
I1015 10:56:52.057951 15018 net.cpp:408] conv7/dw -> conv7/dw
I1015 10:56:52.058284 15018 net.cpp:150] Setting up conv7/dw
I1015 10:56:52.058293 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.058295 15018 net.cpp:165] Memory required for data: 222412864
I1015 10:56:52.058300 15018 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1015 10:56:52.058303 15018 net.cpp:100] Creating Layer conv7/dw/bn
I1015 10:56:52.058306 15018 net.cpp:434] conv7/dw/bn <- conv7/dw
I1015 10:56:52.058310 15018 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1015 10:56:52.058591 15018 net.cpp:150] Setting up conv7/dw/bn
I1015 10:56:52.058599 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.058601 15018 net.cpp:165] Memory required for data: 223641664
I1015 10:56:52.058607 15018 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 10:56:52.058612 15018 net.cpp:100] Creating Layer conv7/dw/scale
I1015 10:56:52.058614 15018 net.cpp:434] conv7/dw/scale <- conv7/dw
I1015 10:56:52.058619 15018 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1015 10:56:52.058673 15018 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 10:56:52.058858 15018 net.cpp:150] Setting up conv7/dw/scale
I1015 10:56:52.058866 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.058871 15018 net.cpp:165] Memory required for data: 224870464
I1015 10:56:52.058877 15018 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1015 10:56:52.058883 15018 net.cpp:100] Creating Layer conv7/dw/relu
I1015 10:56:52.058887 15018 net.cpp:434] conv7/dw/relu <- conv7/dw
I1015 10:56:52.058892 15018 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1015 10:56:52.059248 15018 net.cpp:150] Setting up conv7/dw/relu
I1015 10:56:52.059259 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.059262 15018 net.cpp:165] Memory required for data: 226099264
I1015 10:56:52.059264 15018 layer_factory.hpp:77] Creating layer conv7
I1015 10:56:52.059271 15018 net.cpp:100] Creating Layer conv7
I1015 10:56:52.059274 15018 net.cpp:434] conv7 <- conv7/dw
I1015 10:56:52.059279 15018 net.cpp:408] conv7 -> conv7
I1015 10:56:52.063648 15018 net.cpp:150] Setting up conv7
I1015 10:56:52.063661 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.063663 15018 net.cpp:165] Memory required for data: 227328064
I1015 10:56:52.063668 15018 layer_factory.hpp:77] Creating layer conv7/bn
I1015 10:56:52.063673 15018 net.cpp:100] Creating Layer conv7/bn
I1015 10:56:52.063676 15018 net.cpp:434] conv7/bn <- conv7
I1015 10:56:52.063680 15018 net.cpp:395] conv7/bn -> conv7 (in-place)
I1015 10:56:52.063889 15018 net.cpp:150] Setting up conv7/bn
I1015 10:56:52.063895 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.063897 15018 net.cpp:165] Memory required for data: 228556864
I1015 10:56:52.063904 15018 layer_factory.hpp:77] Creating layer conv7/scale
I1015 10:56:52.063910 15018 net.cpp:100] Creating Layer conv7/scale
I1015 10:56:52.063911 15018 net.cpp:434] conv7/scale <- conv7
I1015 10:56:52.063915 15018 net.cpp:395] conv7/scale -> conv7 (in-place)
I1015 10:56:52.063958 15018 layer_factory.hpp:77] Creating layer conv7/scale
I1015 10:56:52.064077 15018 net.cpp:150] Setting up conv7/scale
I1015 10:56:52.064085 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.064086 15018 net.cpp:165] Memory required for data: 229785664
I1015 10:56:52.064090 15018 layer_factory.hpp:77] Creating layer conv7/relu
I1015 10:56:52.064095 15018 net.cpp:100] Creating Layer conv7/relu
I1015 10:56:52.064098 15018 net.cpp:434] conv7/relu <- conv7
I1015 10:56:52.064101 15018 net.cpp:395] conv7/relu -> conv7 (in-place)
I1015 10:56:52.064482 15018 net.cpp:150] Setting up conv7/relu
I1015 10:56:52.064493 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.064496 15018 net.cpp:165] Memory required for data: 231014464
I1015 10:56:52.064498 15018 layer_factory.hpp:77] Creating layer conv8/dw
I1015 10:56:52.064515 15018 net.cpp:100] Creating Layer conv8/dw
I1015 10:56:52.064518 15018 net.cpp:434] conv8/dw <- conv7
I1015 10:56:52.064522 15018 net.cpp:408] conv8/dw -> conv8/dw
I1015 10:56:52.064764 15018 net.cpp:150] Setting up conv8/dw
I1015 10:56:52.064770 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.064772 15018 net.cpp:165] Memory required for data: 232243264
I1015 10:56:52.064776 15018 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1015 10:56:52.064780 15018 net.cpp:100] Creating Layer conv8/dw/bn
I1015 10:56:52.064783 15018 net.cpp:434] conv8/dw/bn <- conv8/dw
I1015 10:56:52.064787 15018 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1015 10:56:52.064985 15018 net.cpp:150] Setting up conv8/dw/bn
I1015 10:56:52.064991 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.064993 15018 net.cpp:165] Memory required for data: 233472064
I1015 10:56:52.064998 15018 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 10:56:52.065003 15018 net.cpp:100] Creating Layer conv8/dw/scale
I1015 10:56:52.065006 15018 net.cpp:434] conv8/dw/scale <- conv8/dw
I1015 10:56:52.065011 15018 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1015 10:56:52.065050 15018 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 10:56:52.065166 15018 net.cpp:150] Setting up conv8/dw/scale
I1015 10:56:52.065171 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.065174 15018 net.cpp:165] Memory required for data: 234700864
I1015 10:56:52.065178 15018 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1015 10:56:52.065181 15018 net.cpp:100] Creating Layer conv8/dw/relu
I1015 10:56:52.065184 15018 net.cpp:434] conv8/dw/relu <- conv8/dw
I1015 10:56:52.065187 15018 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1015 10:56:52.065912 15018 net.cpp:150] Setting up conv8/dw/relu
I1015 10:56:52.065924 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.065927 15018 net.cpp:165] Memory required for data: 235929664
I1015 10:56:52.065929 15018 layer_factory.hpp:77] Creating layer conv8
I1015 10:56:52.065937 15018 net.cpp:100] Creating Layer conv8
I1015 10:56:52.065940 15018 net.cpp:434] conv8 <- conv8/dw
I1015 10:56:52.065946 15018 net.cpp:408] conv8 -> conv8
I1015 10:56:52.069630 15018 net.cpp:150] Setting up conv8
I1015 10:56:52.069644 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.069646 15018 net.cpp:165] Memory required for data: 237158464
I1015 10:56:52.069651 15018 layer_factory.hpp:77] Creating layer conv8/bn
I1015 10:56:52.069658 15018 net.cpp:100] Creating Layer conv8/bn
I1015 10:56:52.069661 15018 net.cpp:434] conv8/bn <- conv8
I1015 10:56:52.069665 15018 net.cpp:395] conv8/bn -> conv8 (in-place)
I1015 10:56:52.069872 15018 net.cpp:150] Setting up conv8/bn
I1015 10:56:52.069880 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.069883 15018 net.cpp:165] Memory required for data: 238387264
I1015 10:56:52.069891 15018 layer_factory.hpp:77] Creating layer conv8/scale
I1015 10:56:52.069900 15018 net.cpp:100] Creating Layer conv8/scale
I1015 10:56:52.069905 15018 net.cpp:434] conv8/scale <- conv8
I1015 10:56:52.069911 15018 net.cpp:395] conv8/scale -> conv8 (in-place)
I1015 10:56:52.069957 15018 layer_factory.hpp:77] Creating layer conv8/scale
I1015 10:56:52.070077 15018 net.cpp:150] Setting up conv8/scale
I1015 10:56:52.070085 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.070086 15018 net.cpp:165] Memory required for data: 239616064
I1015 10:56:52.070091 15018 layer_factory.hpp:77] Creating layer conv8/relu
I1015 10:56:52.070096 15018 net.cpp:100] Creating Layer conv8/relu
I1015 10:56:52.070098 15018 net.cpp:434] conv8/relu <- conv8
I1015 10:56:52.070101 15018 net.cpp:395] conv8/relu -> conv8 (in-place)
I1015 10:56:52.070482 15018 net.cpp:150] Setting up conv8/relu
I1015 10:56:52.070492 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.070494 15018 net.cpp:165] Memory required for data: 240844864
I1015 10:56:52.070497 15018 layer_factory.hpp:77] Creating layer conv9/dw
I1015 10:56:52.070506 15018 net.cpp:100] Creating Layer conv9/dw
I1015 10:56:52.070509 15018 net.cpp:434] conv9/dw <- conv8
I1015 10:56:52.070513 15018 net.cpp:408] conv9/dw -> conv9/dw
I1015 10:56:52.070762 15018 net.cpp:150] Setting up conv9/dw
I1015 10:56:52.070770 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.070772 15018 net.cpp:165] Memory required for data: 242073664
I1015 10:56:52.070777 15018 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1015 10:56:52.070781 15018 net.cpp:100] Creating Layer conv9/dw/bn
I1015 10:56:52.070785 15018 net.cpp:434] conv9/dw/bn <- conv9/dw
I1015 10:56:52.070787 15018 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1015 10:56:52.070986 15018 net.cpp:150] Setting up conv9/dw/bn
I1015 10:56:52.070993 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.070996 15018 net.cpp:165] Memory required for data: 243302464
I1015 10:56:52.071002 15018 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 10:56:52.071005 15018 net.cpp:100] Creating Layer conv9/dw/scale
I1015 10:56:52.071008 15018 net.cpp:434] conv9/dw/scale <- conv9/dw
I1015 10:56:52.071012 15018 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1015 10:56:52.071054 15018 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 10:56:52.071168 15018 net.cpp:150] Setting up conv9/dw/scale
I1015 10:56:52.071175 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.071177 15018 net.cpp:165] Memory required for data: 244531264
I1015 10:56:52.071182 15018 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1015 10:56:52.071185 15018 net.cpp:100] Creating Layer conv9/dw/relu
I1015 10:56:52.071187 15018 net.cpp:434] conv9/dw/relu <- conv9/dw
I1015 10:56:52.071192 15018 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1015 10:56:52.071566 15018 net.cpp:150] Setting up conv9/dw/relu
I1015 10:56:52.071576 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.071578 15018 net.cpp:165] Memory required for data: 245760064
I1015 10:56:52.071580 15018 layer_factory.hpp:77] Creating layer conv9
I1015 10:56:52.071588 15018 net.cpp:100] Creating Layer conv9
I1015 10:56:52.071590 15018 net.cpp:434] conv9 <- conv9/dw
I1015 10:56:52.071596 15018 net.cpp:408] conv9 -> conv9
I1015 10:56:52.076325 15018 net.cpp:150] Setting up conv9
I1015 10:56:52.076340 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.076342 15018 net.cpp:165] Memory required for data: 246988864
I1015 10:56:52.076347 15018 layer_factory.hpp:77] Creating layer conv9/bn
I1015 10:56:52.076352 15018 net.cpp:100] Creating Layer conv9/bn
I1015 10:56:52.076355 15018 net.cpp:434] conv9/bn <- conv9
I1015 10:56:52.076360 15018 net.cpp:395] conv9/bn -> conv9 (in-place)
I1015 10:56:52.076570 15018 net.cpp:150] Setting up conv9/bn
I1015 10:56:52.076578 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.076581 15018 net.cpp:165] Memory required for data: 248217664
I1015 10:56:52.076586 15018 layer_factory.hpp:77] Creating layer conv9/scale
I1015 10:56:52.076591 15018 net.cpp:100] Creating Layer conv9/scale
I1015 10:56:52.076594 15018 net.cpp:434] conv9/scale <- conv9
I1015 10:56:52.076597 15018 net.cpp:395] conv9/scale -> conv9 (in-place)
I1015 10:56:52.076645 15018 layer_factory.hpp:77] Creating layer conv9/scale
I1015 10:56:52.076771 15018 net.cpp:150] Setting up conv9/scale
I1015 10:56:52.076778 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.076781 15018 net.cpp:165] Memory required for data: 249446464
I1015 10:56:52.076787 15018 layer_factory.hpp:77] Creating layer conv9/relu
I1015 10:56:52.076792 15018 net.cpp:100] Creating Layer conv9/relu
I1015 10:56:52.076793 15018 net.cpp:434] conv9/relu <- conv9
I1015 10:56:52.076798 15018 net.cpp:395] conv9/relu -> conv9 (in-place)
I1015 10:56:52.077555 15018 net.cpp:150] Setting up conv9/relu
I1015 10:56:52.077567 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.077569 15018 net.cpp:165] Memory required for data: 250675264
I1015 10:56:52.077572 15018 layer_factory.hpp:77] Creating layer conv10/dw
I1015 10:56:52.077580 15018 net.cpp:100] Creating Layer conv10/dw
I1015 10:56:52.077584 15018 net.cpp:434] conv10/dw <- conv9
I1015 10:56:52.077589 15018 net.cpp:408] conv10/dw -> conv10/dw
I1015 10:56:52.077843 15018 net.cpp:150] Setting up conv10/dw
I1015 10:56:52.077852 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.077853 15018 net.cpp:165] Memory required for data: 251904064
I1015 10:56:52.077859 15018 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1015 10:56:52.077865 15018 net.cpp:100] Creating Layer conv10/dw/bn
I1015 10:56:52.077867 15018 net.cpp:434] conv10/dw/bn <- conv10/dw
I1015 10:56:52.077872 15018 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1015 10:56:52.078080 15018 net.cpp:150] Setting up conv10/dw/bn
I1015 10:56:52.078088 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.078090 15018 net.cpp:165] Memory required for data: 253132864
I1015 10:56:52.078095 15018 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 10:56:52.078100 15018 net.cpp:100] Creating Layer conv10/dw/scale
I1015 10:56:52.078102 15018 net.cpp:434] conv10/dw/scale <- conv10/dw
I1015 10:56:52.078107 15018 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1015 10:56:52.078152 15018 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 10:56:52.078276 15018 net.cpp:150] Setting up conv10/dw/scale
I1015 10:56:52.078284 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.078285 15018 net.cpp:165] Memory required for data: 254361664
I1015 10:56:52.078292 15018 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1015 10:56:52.078296 15018 net.cpp:100] Creating Layer conv10/dw/relu
I1015 10:56:52.078299 15018 net.cpp:434] conv10/dw/relu <- conv10/dw
I1015 10:56:52.078303 15018 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1015 10:56:52.078689 15018 net.cpp:150] Setting up conv10/dw/relu
I1015 10:56:52.078699 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.078702 15018 net.cpp:165] Memory required for data: 255590464
I1015 10:56:52.078706 15018 layer_factory.hpp:77] Creating layer conv10
I1015 10:56:52.078714 15018 net.cpp:100] Creating Layer conv10
I1015 10:56:52.078717 15018 net.cpp:434] conv10 <- conv10/dw
I1015 10:56:52.078723 15018 net.cpp:408] conv10 -> conv10
I1015 10:56:52.082402 15018 net.cpp:150] Setting up conv10
I1015 10:56:52.082414 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.082417 15018 net.cpp:165] Memory required for data: 256819264
I1015 10:56:52.082422 15018 layer_factory.hpp:77] Creating layer conv10/bn
I1015 10:56:52.082428 15018 net.cpp:100] Creating Layer conv10/bn
I1015 10:56:52.082432 15018 net.cpp:434] conv10/bn <- conv10
I1015 10:56:52.082435 15018 net.cpp:395] conv10/bn -> conv10 (in-place)
I1015 10:56:52.082650 15018 net.cpp:150] Setting up conv10/bn
I1015 10:56:52.082659 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.082660 15018 net.cpp:165] Memory required for data: 258048064
I1015 10:56:52.082667 15018 layer_factory.hpp:77] Creating layer conv10/scale
I1015 10:56:52.082674 15018 net.cpp:100] Creating Layer conv10/scale
I1015 10:56:52.082675 15018 net.cpp:434] conv10/scale <- conv10
I1015 10:56:52.082679 15018 net.cpp:395] conv10/scale -> conv10 (in-place)
I1015 10:56:52.082728 15018 layer_factory.hpp:77] Creating layer conv10/scale
I1015 10:56:52.082849 15018 net.cpp:150] Setting up conv10/scale
I1015 10:56:52.082856 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.082859 15018 net.cpp:165] Memory required for data: 259276864
I1015 10:56:52.082864 15018 layer_factory.hpp:77] Creating layer conv10/relu
I1015 10:56:52.082870 15018 net.cpp:100] Creating Layer conv10/relu
I1015 10:56:52.082872 15018 net.cpp:434] conv10/relu <- conv10
I1015 10:56:52.082877 15018 net.cpp:395] conv10/relu -> conv10 (in-place)
I1015 10:56:52.083286 15018 net.cpp:150] Setting up conv10/relu
I1015 10:56:52.083295 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.083298 15018 net.cpp:165] Memory required for data: 260505664
I1015 10:56:52.083300 15018 layer_factory.hpp:77] Creating layer conv11/dw
I1015 10:56:52.083309 15018 net.cpp:100] Creating Layer conv11/dw
I1015 10:56:52.083312 15018 net.cpp:434] conv11/dw <- conv10
I1015 10:56:52.083318 15018 net.cpp:408] conv11/dw -> conv11/dw
I1015 10:56:52.083564 15018 net.cpp:150] Setting up conv11/dw
I1015 10:56:52.083572 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.083575 15018 net.cpp:165] Memory required for data: 261734464
I1015 10:56:52.083578 15018 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1015 10:56:52.083582 15018 net.cpp:100] Creating Layer conv11/dw/bn
I1015 10:56:52.083585 15018 net.cpp:434] conv11/dw/bn <- conv11/dw
I1015 10:56:52.083588 15018 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1015 10:56:52.083788 15018 net.cpp:150] Setting up conv11/dw/bn
I1015 10:56:52.083794 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.083796 15018 net.cpp:165] Memory required for data: 262963264
I1015 10:56:52.083817 15018 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 10:56:52.083822 15018 net.cpp:100] Creating Layer conv11/dw/scale
I1015 10:56:52.083824 15018 net.cpp:434] conv11/dw/scale <- conv11/dw
I1015 10:56:52.083828 15018 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1015 10:56:52.083874 15018 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 10:56:52.083989 15018 net.cpp:150] Setting up conv11/dw/scale
I1015 10:56:52.083997 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.083998 15018 net.cpp:165] Memory required for data: 264192064
I1015 10:56:52.084003 15018 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1015 10:56:52.084007 15018 net.cpp:100] Creating Layer conv11/dw/relu
I1015 10:56:52.084010 15018 net.cpp:434] conv11/dw/relu <- conv11/dw
I1015 10:56:52.084013 15018 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1015 10:56:52.084389 15018 net.cpp:150] Setting up conv11/dw/relu
I1015 10:56:52.084400 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.084403 15018 net.cpp:165] Memory required for data: 265420864
I1015 10:56:52.084405 15018 layer_factory.hpp:77] Creating layer conv11
I1015 10:56:52.084412 15018 net.cpp:100] Creating Layer conv11
I1015 10:56:52.084415 15018 net.cpp:434] conv11 <- conv11/dw
I1015 10:56:52.084419 15018 net.cpp:408] conv11 -> conv11
I1015 10:56:52.089038 15018 net.cpp:150] Setting up conv11
I1015 10:56:52.089052 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.089056 15018 net.cpp:165] Memory required for data: 266649664
I1015 10:56:52.089059 15018 layer_factory.hpp:77] Creating layer conv11/bn
I1015 10:56:52.089066 15018 net.cpp:100] Creating Layer conv11/bn
I1015 10:56:52.089068 15018 net.cpp:434] conv11/bn <- conv11
I1015 10:56:52.089072 15018 net.cpp:395] conv11/bn -> conv11 (in-place)
I1015 10:56:52.089287 15018 net.cpp:150] Setting up conv11/bn
I1015 10:56:52.089293 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.089296 15018 net.cpp:165] Memory required for data: 267878464
I1015 10:56:52.089301 15018 layer_factory.hpp:77] Creating layer conv11/scale
I1015 10:56:52.089306 15018 net.cpp:100] Creating Layer conv11/scale
I1015 10:56:52.089308 15018 net.cpp:434] conv11/scale <- conv11
I1015 10:56:52.089313 15018 net.cpp:395] conv11/scale -> conv11 (in-place)
I1015 10:56:52.089368 15018 layer_factory.hpp:77] Creating layer conv11/scale
I1015 10:56:52.089522 15018 net.cpp:150] Setting up conv11/scale
I1015 10:56:52.089530 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.089534 15018 net.cpp:165] Memory required for data: 269107264
I1015 10:56:52.089540 15018 layer_factory.hpp:77] Creating layer conv11/relu
I1015 10:56:52.089545 15018 net.cpp:100] Creating Layer conv11/relu
I1015 10:56:52.089550 15018 net.cpp:434] conv11/relu <- conv11
I1015 10:56:52.089555 15018 net.cpp:395] conv11/relu -> conv11 (in-place)
I1015 10:56:52.090359 15018 net.cpp:150] Setting up conv11/relu
I1015 10:56:52.090371 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090373 15018 net.cpp:165] Memory required for data: 270336064
I1015 10:56:52.090378 15018 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1015 10:56:52.090387 15018 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1015 10:56:52.090391 15018 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1015 10:56:52.090399 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1015 10:56:52.090409 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1015 10:56:52.090418 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1015 10:56:52.090425 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1015 10:56:52.090428 15018 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1015 10:56:52.090548 15018 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1015 10:56:52.090557 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090560 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090564 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090569 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090574 15018 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 10:56:52.090576 15018 net.cpp:165] Memory required for data: 276480064
I1015 10:56:52.090580 15018 layer_factory.hpp:77] Creating layer conv12/dw
I1015 10:56:52.090590 15018 net.cpp:100] Creating Layer conv12/dw
I1015 10:56:52.090595 15018 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1015 10:56:52.090602 15018 net.cpp:408] conv12/dw -> conv12/dw
I1015 10:56:52.090878 15018 net.cpp:150] Setting up conv12/dw
I1015 10:56:52.090886 15018 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 10:56:52.090888 15018 net.cpp:165] Memory required for data: 276787264
I1015 10:56:52.090893 15018 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1015 10:56:52.090899 15018 net.cpp:100] Creating Layer conv12/dw/bn
I1015 10:56:52.090903 15018 net.cpp:434] conv12/dw/bn <- conv12/dw
I1015 10:56:52.090909 15018 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1015 10:56:52.091161 15018 net.cpp:150] Setting up conv12/dw/bn
I1015 10:56:52.091171 15018 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 10:56:52.091172 15018 net.cpp:165] Memory required for data: 277094464
I1015 10:56:52.091179 15018 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 10:56:52.091187 15018 net.cpp:100] Creating Layer conv12/dw/scale
I1015 10:56:52.091190 15018 net.cpp:434] conv12/dw/scale <- conv12/dw
I1015 10:56:52.091197 15018 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1015 10:56:52.091258 15018 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 10:56:52.091399 15018 net.cpp:150] Setting up conv12/dw/scale
I1015 10:56:52.091408 15018 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 10:56:52.091411 15018 net.cpp:165] Memory required for data: 277401664
I1015 10:56:52.091418 15018 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1015 10:56:52.091423 15018 net.cpp:100] Creating Layer conv12/dw/relu
I1015 10:56:52.091428 15018 net.cpp:434] conv12/dw/relu <- conv12/dw
I1015 10:56:52.091434 15018 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1015 10:56:52.091828 15018 net.cpp:150] Setting up conv12/dw/relu
I1015 10:56:52.091840 15018 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 10:56:52.091842 15018 net.cpp:165] Memory required for data: 277708864
I1015 10:56:52.091846 15018 layer_factory.hpp:77] Creating layer conv12
I1015 10:56:52.091856 15018 net.cpp:100] Creating Layer conv12
I1015 10:56:52.091861 15018 net.cpp:434] conv12 <- conv12/dw
I1015 10:56:52.091867 15018 net.cpp:408] conv12 -> conv12
I1015 10:56:52.098388 15018 net.cpp:150] Setting up conv12
I1015 10:56:52.098402 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.098404 15018 net.cpp:165] Memory required for data: 278323264
I1015 10:56:52.098409 15018 layer_factory.hpp:77] Creating layer conv12/bn
I1015 10:56:52.098415 15018 net.cpp:100] Creating Layer conv12/bn
I1015 10:56:52.098418 15018 net.cpp:434] conv12/bn <- conv12
I1015 10:56:52.098423 15018 net.cpp:395] conv12/bn -> conv12 (in-place)
I1015 10:56:52.098664 15018 net.cpp:150] Setting up conv12/bn
I1015 10:56:52.098673 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.098675 15018 net.cpp:165] Memory required for data: 278937664
I1015 10:56:52.098681 15018 layer_factory.hpp:77] Creating layer conv12/scale
I1015 10:56:52.098690 15018 net.cpp:100] Creating Layer conv12/scale
I1015 10:56:52.098695 15018 net.cpp:434] conv12/scale <- conv12
I1015 10:56:52.098701 15018 net.cpp:395] conv12/scale -> conv12 (in-place)
I1015 10:56:52.098759 15018 layer_factory.hpp:77] Creating layer conv12/scale
I1015 10:56:52.098907 15018 net.cpp:150] Setting up conv12/scale
I1015 10:56:52.098919 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.098922 15018 net.cpp:165] Memory required for data: 279552064
I1015 10:56:52.098929 15018 layer_factory.hpp:77] Creating layer conv12/relu
I1015 10:56:52.098937 15018 net.cpp:100] Creating Layer conv12/relu
I1015 10:56:52.098939 15018 net.cpp:434] conv12/relu <- conv12
I1015 10:56:52.098943 15018 net.cpp:395] conv12/relu -> conv12 (in-place)
I1015 10:56:52.099345 15018 net.cpp:150] Setting up conv12/relu
I1015 10:56:52.099355 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.099359 15018 net.cpp:165] Memory required for data: 280166464
I1015 10:56:52.099364 15018 layer_factory.hpp:77] Creating layer conv13/dw
I1015 10:56:52.099373 15018 net.cpp:100] Creating Layer conv13/dw
I1015 10:56:52.099376 15018 net.cpp:434] conv13/dw <- conv12
I1015 10:56:52.099383 15018 net.cpp:408] conv13/dw -> conv13/dw
I1015 10:56:52.099700 15018 net.cpp:150] Setting up conv13/dw
I1015 10:56:52.099709 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.099714 15018 net.cpp:165] Memory required for data: 280780864
I1015 10:56:52.099719 15018 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1015 10:56:52.099722 15018 net.cpp:100] Creating Layer conv13/dw/bn
I1015 10:56:52.099725 15018 net.cpp:434] conv13/dw/bn <- conv13/dw
I1015 10:56:52.099730 15018 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1015 10:56:52.099961 15018 net.cpp:150] Setting up conv13/dw/bn
I1015 10:56:52.099969 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.099972 15018 net.cpp:165] Memory required for data: 281395264
I1015 10:56:52.099979 15018 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 10:56:52.099985 15018 net.cpp:100] Creating Layer conv13/dw/scale
I1015 10:56:52.099988 15018 net.cpp:434] conv13/dw/scale <- conv13/dw
I1015 10:56:52.099995 15018 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1015 10:56:52.100044 15018 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 10:56:52.100189 15018 net.cpp:150] Setting up conv13/dw/scale
I1015 10:56:52.100198 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.100201 15018 net.cpp:165] Memory required for data: 282009664
I1015 10:56:52.100208 15018 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1015 10:56:52.100211 15018 net.cpp:100] Creating Layer conv13/dw/relu
I1015 10:56:52.100215 15018 net.cpp:434] conv13/dw/relu <- conv13/dw
I1015 10:56:52.100221 15018 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1015 10:56:52.100973 15018 net.cpp:150] Setting up conv13/dw/relu
I1015 10:56:52.100986 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.100989 15018 net.cpp:165] Memory required for data: 282624064
I1015 10:56:52.100993 15018 layer_factory.hpp:77] Creating layer conv13
I1015 10:56:52.101002 15018 net.cpp:100] Creating Layer conv13
I1015 10:56:52.101006 15018 net.cpp:434] conv13 <- conv13/dw
I1015 10:56:52.101013 15018 net.cpp:408] conv13 -> conv13
I1015 10:56:52.112349 15018 net.cpp:150] Setting up conv13
I1015 10:56:52.112366 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.112371 15018 net.cpp:165] Memory required for data: 283238464
I1015 10:56:52.112380 15018 layer_factory.hpp:77] Creating layer conv13/bn
I1015 10:56:52.112390 15018 net.cpp:100] Creating Layer conv13/bn
I1015 10:56:52.112393 15018 net.cpp:434] conv13/bn <- conv13
I1015 10:56:52.112398 15018 net.cpp:395] conv13/bn -> conv13 (in-place)
I1015 10:56:52.113395 15018 net.cpp:150] Setting up conv13/bn
I1015 10:56:52.113425 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.113430 15018 net.cpp:165] Memory required for data: 283852864
I1015 10:56:52.113448 15018 layer_factory.hpp:77] Creating layer conv13/scale
I1015 10:56:52.113464 15018 net.cpp:100] Creating Layer conv13/scale
I1015 10:56:52.113472 15018 net.cpp:434] conv13/scale <- conv13
I1015 10:56:52.113487 15018 net.cpp:395] conv13/scale -> conv13 (in-place)
I1015 10:56:52.113590 15018 layer_factory.hpp:77] Creating layer conv13/scale
I1015 10:56:52.113903 15018 net.cpp:150] Setting up conv13/scale
I1015 10:56:52.113919 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.113924 15018 net.cpp:165] Memory required for data: 284467264
I1015 10:56:52.113936 15018 layer_factory.hpp:77] Creating layer conv13/relu
I1015 10:56:52.113946 15018 net.cpp:100] Creating Layer conv13/relu
I1015 10:56:52.113952 15018 net.cpp:434] conv13/relu <- conv13
I1015 10:56:52.113961 15018 net.cpp:395] conv13/relu -> conv13 (in-place)
I1015 10:56:52.114969 15018 net.cpp:150] Setting up conv13/relu
I1015 10:56:52.114994 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115000 15018 net.cpp:165] Memory required for data: 285081664
I1015 10:56:52.115005 15018 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1015 10:56:52.115018 15018 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1015 10:56:52.115025 15018 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1015 10:56:52.115038 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1015 10:56:52.115053 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1015 10:56:52.115069 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1015 10:56:52.115080 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1015 10:56:52.115092 15018 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1015 10:56:52.115298 15018 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1015 10:56:52.115312 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115320 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115327 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115334 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115342 15018 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 10:56:52.115347 15018 net.cpp:165] Memory required for data: 288153664
I1015 10:56:52.115353 15018 layer_factory.hpp:77] Creating layer conv14_1
I1015 10:56:52.115370 15018 net.cpp:100] Creating Layer conv14_1
I1015 10:56:52.115378 15018 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1015 10:56:52.115391 15018 net.cpp:408] conv14_1 -> conv14_1
I1015 10:56:52.123893 15018 net.cpp:150] Setting up conv14_1
I1015 10:56:52.123924 15018 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 10:56:52.123930 15018 net.cpp:165] Memory required for data: 288307264
I1015 10:56:52.123939 15018 layer_factory.hpp:77] Creating layer conv14_1/bn
I1015 10:56:52.123950 15018 net.cpp:100] Creating Layer conv14_1/bn
I1015 10:56:52.123955 15018 net.cpp:434] conv14_1/bn <- conv14_1
I1015 10:56:52.123966 15018 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1015 10:56:52.124361 15018 net.cpp:150] Setting up conv14_1/bn
I1015 10:56:52.124373 15018 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 10:56:52.124377 15018 net.cpp:165] Memory required for data: 288460864
I1015 10:56:52.124388 15018 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 10:56:52.124400 15018 net.cpp:100] Creating Layer conv14_1/scale
I1015 10:56:52.124405 15018 net.cpp:434] conv14_1/scale <- conv14_1
I1015 10:56:52.124411 15018 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1015 10:56:52.124485 15018 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 10:56:52.124734 15018 net.cpp:150] Setting up conv14_1/scale
I1015 10:56:52.124748 15018 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 10:56:52.124752 15018 net.cpp:165] Memory required for data: 288614464
I1015 10:56:52.124760 15018 layer_factory.hpp:77] Creating layer conv14_1/relu
I1015 10:56:52.124768 15018 net.cpp:100] Creating Layer conv14_1/relu
I1015 10:56:52.124773 15018 net.cpp:434] conv14_1/relu <- conv14_1
I1015 10:56:52.124780 15018 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1015 10:56:52.125533 15018 net.cpp:150] Setting up conv14_1/relu
I1015 10:56:52.125550 15018 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 10:56:52.125555 15018 net.cpp:165] Memory required for data: 288768064
I1015 10:56:52.125558 15018 layer_factory.hpp:77] Creating layer conv14_2
I1015 10:56:52.125573 15018 net.cpp:100] Creating Layer conv14_2
I1015 10:56:52.125578 15018 net.cpp:434] conv14_2 <- conv14_1
I1015 10:56:52.125589 15018 net.cpp:408] conv14_2 -> conv14_2
I1015 10:56:52.140231 15018 net.cpp:150] Setting up conv14_2
I1015 10:56:52.140251 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.140254 15018 net.cpp:165] Memory required for data: 288849984
I1015 10:56:52.140260 15018 layer_factory.hpp:77] Creating layer conv14_2/bn
I1015 10:56:52.140269 15018 net.cpp:100] Creating Layer conv14_2/bn
I1015 10:56:52.140272 15018 net.cpp:434] conv14_2/bn <- conv14_2
I1015 10:56:52.140277 15018 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1015 10:56:52.140525 15018 net.cpp:150] Setting up conv14_2/bn
I1015 10:56:52.140533 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.140537 15018 net.cpp:165] Memory required for data: 288931904
I1015 10:56:52.140542 15018 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 10:56:52.140547 15018 net.cpp:100] Creating Layer conv14_2/scale
I1015 10:56:52.140550 15018 net.cpp:434] conv14_2/scale <- conv14_2
I1015 10:56:52.140554 15018 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1015 10:56:52.140599 15018 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 10:56:52.140753 15018 net.cpp:150] Setting up conv14_2/scale
I1015 10:56:52.140760 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.140763 15018 net.cpp:165] Memory required for data: 289013824
I1015 10:56:52.140767 15018 layer_factory.hpp:77] Creating layer conv14_2/relu
I1015 10:56:52.140774 15018 net.cpp:100] Creating Layer conv14_2/relu
I1015 10:56:52.140776 15018 net.cpp:434] conv14_2/relu <- conv14_2
I1015 10:56:52.140780 15018 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1015 10:56:52.141566 15018 net.cpp:150] Setting up conv14_2/relu
I1015 10:56:52.141577 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.141580 15018 net.cpp:165] Memory required for data: 289095744
I1015 10:56:52.141583 15018 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1015 10:56:52.141590 15018 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1015 10:56:52.141593 15018 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1015 10:56:52.141599 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1015 10:56:52.141607 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1015 10:56:52.141610 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1015 10:56:52.141615 15018 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1015 10:56:52.141693 15018 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1015 10:56:52.141698 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.141701 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.141705 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.141706 15018 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 10:56:52.141710 15018 net.cpp:165] Memory required for data: 289423424
I1015 10:56:52.141711 15018 layer_factory.hpp:77] Creating layer conv15_1
I1015 10:56:52.141721 15018 net.cpp:100] Creating Layer conv15_1
I1015 10:56:52.141723 15018 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1015 10:56:52.141728 15018 net.cpp:408] conv15_1 -> conv15_1
I1015 10:56:52.145236 15018 net.cpp:150] Setting up conv15_1
I1015 10:56:52.145254 15018 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 10:56:52.145257 15018 net.cpp:165] Memory required for data: 289443904
I1015 10:56:52.145263 15018 layer_factory.hpp:77] Creating layer conv15_1/bn
I1015 10:56:52.145269 15018 net.cpp:100] Creating Layer conv15_1/bn
I1015 10:56:52.145273 15018 net.cpp:434] conv15_1/bn <- conv15_1
I1015 10:56:52.145279 15018 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1015 10:56:52.145517 15018 net.cpp:150] Setting up conv15_1/bn
I1015 10:56:52.145526 15018 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 10:56:52.145529 15018 net.cpp:165] Memory required for data: 289464384
I1015 10:56:52.145534 15018 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 10:56:52.145543 15018 net.cpp:100] Creating Layer conv15_1/scale
I1015 10:56:52.145546 15018 net.cpp:434] conv15_1/scale <- conv15_1
I1015 10:56:52.145550 15018 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1015 10:56:52.145597 15018 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 10:56:52.145747 15018 net.cpp:150] Setting up conv15_1/scale
I1015 10:56:52.145756 15018 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 10:56:52.145758 15018 net.cpp:165] Memory required for data: 289484864
I1015 10:56:52.145764 15018 layer_factory.hpp:77] Creating layer conv15_1/relu
I1015 10:56:52.145769 15018 net.cpp:100] Creating Layer conv15_1/relu
I1015 10:56:52.145772 15018 net.cpp:434] conv15_1/relu <- conv15_1
I1015 10:56:52.145777 15018 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1015 10:56:52.146175 15018 net.cpp:150] Setting up conv15_1/relu
I1015 10:56:52.146185 15018 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 10:56:52.146188 15018 net.cpp:165] Memory required for data: 289505344
I1015 10:56:52.146190 15018 layer_factory.hpp:77] Creating layer conv15_2
I1015 10:56:52.146199 15018 net.cpp:100] Creating Layer conv15_2
I1015 10:56:52.146203 15018 net.cpp:434] conv15_2 <- conv15_1
I1015 10:56:52.146209 15018 net.cpp:408] conv15_2 -> conv15_2
I1015 10:56:52.151619 15018 net.cpp:150] Setting up conv15_2
I1015 10:56:52.151634 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.151638 15018 net.cpp:165] Memory required for data: 289517632
I1015 10:56:52.151643 15018 layer_factory.hpp:77] Creating layer conv15_2/bn
I1015 10:56:52.151666 15018 net.cpp:100] Creating Layer conv15_2/bn
I1015 10:56:52.151670 15018 net.cpp:434] conv15_2/bn <- conv15_2
I1015 10:56:52.151674 15018 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1015 10:56:52.151901 15018 net.cpp:150] Setting up conv15_2/bn
I1015 10:56:52.151909 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.151911 15018 net.cpp:165] Memory required for data: 289529920
I1015 10:56:52.151927 15018 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 10:56:52.151935 15018 net.cpp:100] Creating Layer conv15_2/scale
I1015 10:56:52.151938 15018 net.cpp:434] conv15_2/scale <- conv15_2
I1015 10:56:52.151942 15018 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1015 10:56:52.151993 15018 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 10:56:52.152117 15018 net.cpp:150] Setting up conv15_2/scale
I1015 10:56:52.152124 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152127 15018 net.cpp:165] Memory required for data: 289542208
I1015 10:56:52.152132 15018 layer_factory.hpp:77] Creating layer conv15_2/relu
I1015 10:56:52.152137 15018 net.cpp:100] Creating Layer conv15_2/relu
I1015 10:56:52.152139 15018 net.cpp:434] conv15_2/relu <- conv15_2
I1015 10:56:52.152143 15018 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1015 10:56:52.152550 15018 net.cpp:150] Setting up conv15_2/relu
I1015 10:56:52.152560 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152562 15018 net.cpp:165] Memory required for data: 289554496
I1015 10:56:52.152566 15018 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1015 10:56:52.152575 15018 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1015 10:56:52.152578 15018 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1015 10:56:52.152585 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1015 10:56:52.152590 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1015 10:56:52.152595 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1015 10:56:52.152599 15018 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1015 10:56:52.152683 15018 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1015 10:56:52.152689 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152693 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152695 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152698 15018 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 10:56:52.152699 15018 net.cpp:165] Memory required for data: 289603648
I1015 10:56:52.152703 15018 layer_factory.hpp:77] Creating layer conv16_1
I1015 10:56:52.152709 15018 net.cpp:100] Creating Layer conv16_1
I1015 10:56:52.152712 15018 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1015 10:56:52.152719 15018 net.cpp:408] conv16_1 -> conv16_1
I1015 10:56:52.154834 15018 net.cpp:150] Setting up conv16_1
I1015 10:56:52.154846 15018 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 10:56:52.154850 15018 net.cpp:165] Memory required for data: 289609792
I1015 10:56:52.154853 15018 layer_factory.hpp:77] Creating layer conv16_1/bn
I1015 10:56:52.154860 15018 net.cpp:100] Creating Layer conv16_1/bn
I1015 10:56:52.154862 15018 net.cpp:434] conv16_1/bn <- conv16_1
I1015 10:56:52.154866 15018 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1015 10:56:52.155089 15018 net.cpp:150] Setting up conv16_1/bn
I1015 10:56:52.155097 15018 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 10:56:52.155099 15018 net.cpp:165] Memory required for data: 289615936
I1015 10:56:52.155107 15018 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 10:56:52.155113 15018 net.cpp:100] Creating Layer conv16_1/scale
I1015 10:56:52.155117 15018 net.cpp:434] conv16_1/scale <- conv16_1
I1015 10:56:52.155120 15018 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1015 10:56:52.155165 15018 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 10:56:52.155292 15018 net.cpp:150] Setting up conv16_1/scale
I1015 10:56:52.155302 15018 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 10:56:52.155304 15018 net.cpp:165] Memory required for data: 289622080
I1015 10:56:52.155308 15018 layer_factory.hpp:77] Creating layer conv16_1/relu
I1015 10:56:52.155313 15018 net.cpp:100] Creating Layer conv16_1/relu
I1015 10:56:52.155315 15018 net.cpp:434] conv16_1/relu <- conv16_1
I1015 10:56:52.155318 15018 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1015 10:56:52.155716 15018 net.cpp:150] Setting up conv16_1/relu
I1015 10:56:52.155728 15018 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 10:56:52.155731 15018 net.cpp:165] Memory required for data: 289628224
I1015 10:56:52.155735 15018 layer_factory.hpp:77] Creating layer conv16_2
I1015 10:56:52.155745 15018 net.cpp:100] Creating Layer conv16_2
I1015 10:56:52.155747 15018 net.cpp:434] conv16_2 <- conv16_1
I1015 10:56:52.155752 15018 net.cpp:408] conv16_2 -> conv16_2
I1015 10:56:52.160802 15018 net.cpp:150] Setting up conv16_2
I1015 10:56:52.160816 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.160818 15018 net.cpp:165] Memory required for data: 289632320
I1015 10:56:52.160825 15018 layer_factory.hpp:77] Creating layer conv16_2/bn
I1015 10:56:52.160830 15018 net.cpp:100] Creating Layer conv16_2/bn
I1015 10:56:52.160833 15018 net.cpp:434] conv16_2/bn <- conv16_2
I1015 10:56:52.160837 15018 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1015 10:56:52.161057 15018 net.cpp:150] Setting up conv16_2/bn
I1015 10:56:52.161064 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.161067 15018 net.cpp:165] Memory required for data: 289636416
I1015 10:56:52.161072 15018 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 10:56:52.161079 15018 net.cpp:100] Creating Layer conv16_2/scale
I1015 10:56:52.161082 15018 net.cpp:434] conv16_2/scale <- conv16_2
I1015 10:56:52.161085 15018 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1015 10:56:52.161128 15018 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 10:56:52.161268 15018 net.cpp:150] Setting up conv16_2/scale
I1015 10:56:52.161275 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.161278 15018 net.cpp:165] Memory required for data: 289640512
I1015 10:56:52.161283 15018 layer_factory.hpp:77] Creating layer conv16_2/relu
I1015 10:56:52.161291 15018 net.cpp:100] Creating Layer conv16_2/relu
I1015 10:56:52.161293 15018 net.cpp:434] conv16_2/relu <- conv16_2
I1015 10:56:52.161298 15018 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1015 10:56:52.162065 15018 net.cpp:150] Setting up conv16_2/relu
I1015 10:56:52.162080 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.162082 15018 net.cpp:165] Memory required for data: 289644608
I1015 10:56:52.162086 15018 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1015 10:56:52.162091 15018 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1015 10:56:52.162093 15018 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1015 10:56:52.162099 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1015 10:56:52.162106 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1015 10:56:52.162111 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1015 10:56:52.162115 15018 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1015 10:56:52.162202 15018 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1015 10:56:52.162210 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.162214 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.162217 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.162221 15018 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 10:56:52.162223 15018 net.cpp:165] Memory required for data: 289660992
I1015 10:56:52.162225 15018 layer_factory.hpp:77] Creating layer conv17_1
I1015 10:56:52.162235 15018 net.cpp:100] Creating Layer conv17_1
I1015 10:56:52.162238 15018 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1015 10:56:52.162243 15018 net.cpp:408] conv17_1 -> conv17_1
I1015 10:56:52.164225 15018 net.cpp:150] Setting up conv17_1
I1015 10:56:52.164237 15018 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 10:56:52.164239 15018 net.cpp:165] Memory required for data: 289662016
I1015 10:56:52.164245 15018 layer_factory.hpp:77] Creating layer conv17_1/bn
I1015 10:56:52.164253 15018 net.cpp:100] Creating Layer conv17_1/bn
I1015 10:56:52.164258 15018 net.cpp:434] conv17_1/bn <- conv17_1
I1015 10:56:52.164263 15018 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1015 10:56:52.164505 15018 net.cpp:150] Setting up conv17_1/bn
I1015 10:56:52.164511 15018 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 10:56:52.164515 15018 net.cpp:165] Memory required for data: 289663040
I1015 10:56:52.164520 15018 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 10:56:52.164525 15018 net.cpp:100] Creating Layer conv17_1/scale
I1015 10:56:52.164527 15018 net.cpp:434] conv17_1/scale <- conv17_1
I1015 10:56:52.164531 15018 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1015 10:56:52.164593 15018 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 10:56:52.164748 15018 net.cpp:150] Setting up conv17_1/scale
I1015 10:56:52.164757 15018 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 10:56:52.164759 15018 net.cpp:165] Memory required for data: 289664064
I1015 10:56:52.164763 15018 layer_factory.hpp:77] Creating layer conv17_1/relu
I1015 10:56:52.164768 15018 net.cpp:100] Creating Layer conv17_1/relu
I1015 10:56:52.164770 15018 net.cpp:434] conv17_1/relu <- conv17_1
I1015 10:56:52.164777 15018 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1015 10:56:52.165192 15018 net.cpp:150] Setting up conv17_1/relu
I1015 10:56:52.165202 15018 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 10:56:52.165205 15018 net.cpp:165] Memory required for data: 289665088
I1015 10:56:52.165207 15018 layer_factory.hpp:77] Creating layer conv17_2
I1015 10:56:52.165215 15018 net.cpp:100] Creating Layer conv17_2
I1015 10:56:52.165218 15018 net.cpp:434] conv17_2 <- conv17_1
I1015 10:56:52.165225 15018 net.cpp:408] conv17_2 -> conv17_2
I1015 10:56:52.168725 15018 net.cpp:150] Setting up conv17_2
I1015 10:56:52.168738 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.168741 15018 net.cpp:165] Memory required for data: 289665600
I1015 10:56:52.168746 15018 layer_factory.hpp:77] Creating layer conv17_2/bn
I1015 10:56:52.168751 15018 net.cpp:100] Creating Layer conv17_2/bn
I1015 10:56:52.168754 15018 net.cpp:434] conv17_2/bn <- conv17_2
I1015 10:56:52.168759 15018 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1015 10:56:52.169000 15018 net.cpp:150] Setting up conv17_2/bn
I1015 10:56:52.169008 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169010 15018 net.cpp:165] Memory required for data: 289666112
I1015 10:56:52.169016 15018 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 10:56:52.169021 15018 net.cpp:100] Creating Layer conv17_2/scale
I1015 10:56:52.169024 15018 net.cpp:434] conv17_2/scale <- conv17_2
I1015 10:56:52.169029 15018 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1015 10:56:52.169071 15018 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 10:56:52.169215 15018 net.cpp:150] Setting up conv17_2/scale
I1015 10:56:52.169224 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169225 15018 net.cpp:165] Memory required for data: 289666624
I1015 10:56:52.169230 15018 layer_factory.hpp:77] Creating layer conv17_2/relu
I1015 10:56:52.169236 15018 net.cpp:100] Creating Layer conv17_2/relu
I1015 10:56:52.169241 15018 net.cpp:434] conv17_2/relu <- conv17_2
I1015 10:56:52.169248 15018 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1015 10:56:52.169668 15018 net.cpp:150] Setting up conv17_2/relu
I1015 10:56:52.169678 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169682 15018 net.cpp:165] Memory required for data: 289667136
I1015 10:56:52.169683 15018 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1015 10:56:52.169688 15018 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1015 10:56:52.169692 15018 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1015 10:56:52.169697 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1015 10:56:52.169703 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1015 10:56:52.169709 15018 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1015 10:56:52.169800 15018 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1015 10:56:52.169809 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169814 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169819 15018 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 10:56:52.169822 15018 net.cpp:165] Memory required for data: 289668672
I1015 10:56:52.169827 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1015 10:56:52.169842 15018 net.cpp:100] Creating Layer conv11_mbox_loc
I1015 10:56:52.169847 15018 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1015 10:56:52.169855 15018 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1015 10:56:52.171912 15018 net.cpp:150] Setting up conv11_mbox_loc
I1015 10:56:52.171926 15018 net.cpp:157] Top shape: 1 12 20 30 (7200)
I1015 10:56:52.171927 15018 net.cpp:165] Memory required for data: 289697472
I1015 10:56:52.171933 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1015 10:56:52.171941 15018 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1015 10:56:52.171944 15018 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1015 10:56:52.171948 15018 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1015 10:56:52.172068 15018 net.cpp:150] Setting up conv11_mbox_loc_perm
I1015 10:56:52.172075 15018 net.cpp:157] Top shape: 1 20 30 12 (7200)
I1015 10:56:52.172078 15018 net.cpp:165] Memory required for data: 289726272
I1015 10:56:52.172081 15018 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1015 10:56:52.172086 15018 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1015 10:56:52.172089 15018 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1015 10:56:52.172096 15018 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1015 10:56:52.172123 15018 net.cpp:150] Setting up conv11_mbox_loc_flat
I1015 10:56:52.172128 15018 net.cpp:157] Top shape: 1 7200 (7200)
I1015 10:56:52.172130 15018 net.cpp:165] Memory required for data: 289755072
I1015 10:56:52.172132 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1015 10:56:52.172140 15018 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1015 10:56:52.172143 15018 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1015 10:56:52.172149 15018 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1015 10:56:52.174146 15018 net.cpp:150] Setting up conv11_mbox_conf_new
I1015 10:56:52.174158 15018 net.cpp:157] Top shape: 1 9 20 30 (5400)
I1015 10:56:52.174161 15018 net.cpp:165] Memory required for data: 289776672
I1015 10:56:52.174167 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1015 10:56:52.174175 15018 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1015 10:56:52.174177 15018 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1015 10:56:52.174181 15018 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1015 10:56:52.174300 15018 net.cpp:150] Setting up conv11_mbox_conf_perm
I1015 10:56:52.174306 15018 net.cpp:157] Top shape: 1 20 30 9 (5400)
I1015 10:56:52.174309 15018 net.cpp:165] Memory required for data: 289798272
I1015 10:56:52.174310 15018 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1015 10:56:52.174316 15018 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1015 10:56:52.174319 15018 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1015 10:56:52.174322 15018 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1015 10:56:52.174350 15018 net.cpp:150] Setting up conv11_mbox_conf_flat
I1015 10:56:52.174355 15018 net.cpp:157] Top shape: 1 5400 (5400)
I1015 10:56:52.174357 15018 net.cpp:165] Memory required for data: 289819872
I1015 10:56:52.174360 15018 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1015 10:56:52.174366 15018 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1015 10:56:52.174369 15018 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1015 10:56:52.174373 15018 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1015 10:56:52.174379 15018 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1015 10:56:52.174407 15018 net.cpp:150] Setting up conv11_mbox_priorbox
I1015 10:56:52.174412 15018 net.cpp:157] Top shape: 1 2 7200 (14400)
I1015 10:56:52.174414 15018 net.cpp:165] Memory required for data: 289877472
I1015 10:56:52.174417 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1015 10:56:52.174425 15018 net.cpp:100] Creating Layer conv13_mbox_loc
I1015 10:56:52.174428 15018 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1015 10:56:52.174433 15018 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1015 10:56:52.176744 15018 net.cpp:150] Setting up conv13_mbox_loc
I1015 10:56:52.176757 15018 net.cpp:157] Top shape: 1 24 10 15 (3600)
I1015 10:56:52.176760 15018 net.cpp:165] Memory required for data: 289891872
I1015 10:56:52.176766 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1015 10:56:52.176771 15018 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1015 10:56:52.176774 15018 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1015 10:56:52.176780 15018 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1015 10:56:52.176903 15018 net.cpp:150] Setting up conv13_mbox_loc_perm
I1015 10:56:52.176908 15018 net.cpp:157] Top shape: 1 10 15 24 (3600)
I1015 10:56:52.176911 15018 net.cpp:165] Memory required for data: 289906272
I1015 10:56:52.176913 15018 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1015 10:56:52.176918 15018 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1015 10:56:52.176920 15018 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1015 10:56:52.176925 15018 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1015 10:56:52.176951 15018 net.cpp:150] Setting up conv13_mbox_loc_flat
I1015 10:56:52.176955 15018 net.cpp:157] Top shape: 1 3600 (3600)
I1015 10:56:52.176957 15018 net.cpp:165] Memory required for data: 289920672
I1015 10:56:52.176960 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1015 10:56:52.176970 15018 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1015 10:56:52.176972 15018 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1015 10:56:52.176978 15018 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1015 10:56:52.179013 15018 net.cpp:150] Setting up conv13_mbox_conf_new
I1015 10:56:52.179026 15018 net.cpp:157] Top shape: 1 18 10 15 (2700)
I1015 10:56:52.179028 15018 net.cpp:165] Memory required for data: 289931472
I1015 10:56:52.179034 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1015 10:56:52.179039 15018 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1015 10:56:52.179042 15018 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1015 10:56:52.179049 15018 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1015 10:56:52.179167 15018 net.cpp:150] Setting up conv13_mbox_conf_perm
I1015 10:56:52.179173 15018 net.cpp:157] Top shape: 1 10 15 18 (2700)
I1015 10:56:52.179177 15018 net.cpp:165] Memory required for data: 289942272
I1015 10:56:52.179178 15018 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1015 10:56:52.179183 15018 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1015 10:56:52.179188 15018 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1015 10:56:52.179191 15018 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1015 10:56:52.179219 15018 net.cpp:150] Setting up conv13_mbox_conf_flat
I1015 10:56:52.179224 15018 net.cpp:157] Top shape: 1 2700 (2700)
I1015 10:56:52.179225 15018 net.cpp:165] Memory required for data: 289953072
I1015 10:56:52.179229 15018 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1015 10:56:52.179234 15018 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1015 10:56:52.179236 15018 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1015 10:56:52.179240 15018 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1015 10:56:52.179244 15018 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1015 10:56:52.179273 15018 net.cpp:150] Setting up conv13_mbox_priorbox
I1015 10:56:52.179277 15018 net.cpp:157] Top shape: 1 2 3600 (7200)
I1015 10:56:52.179280 15018 net.cpp:165] Memory required for data: 289981872
I1015 10:56:52.179281 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1015 10:56:52.179289 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1015 10:56:52.179292 15018 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1015 10:56:52.179297 15018 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1015 10:56:52.181336 15018 net.cpp:150] Setting up conv14_2_mbox_loc
I1015 10:56:52.181347 15018 net.cpp:157] Top shape: 1 24 5 8 (960)
I1015 10:56:52.181350 15018 net.cpp:165] Memory required for data: 289985712
I1015 10:56:52.181355 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1015 10:56:52.181362 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1015 10:56:52.181365 15018 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1015 10:56:52.181371 15018 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1015 10:56:52.181491 15018 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1015 10:56:52.181496 15018 net.cpp:157] Top shape: 1 5 8 24 (960)
I1015 10:56:52.181499 15018 net.cpp:165] Memory required for data: 289989552
I1015 10:56:52.181501 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1015 10:56:52.181506 15018 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1015 10:56:52.181509 15018 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1015 10:56:52.181514 15018 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1015 10:56:52.181541 15018 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1015 10:56:52.181545 15018 net.cpp:157] Top shape: 1 960 (960)
I1015 10:56:52.181547 15018 net.cpp:165] Memory required for data: 289993392
I1015 10:56:52.181550 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1015 10:56:52.181557 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1015 10:56:52.181560 15018 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1015 10:56:52.181566 15018 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1015 10:56:52.183552 15018 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1015 10:56:52.183563 15018 net.cpp:157] Top shape: 1 18 5 8 (720)
I1015 10:56:52.183567 15018 net.cpp:165] Memory required for data: 289996272
I1015 10:56:52.183573 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1015 10:56:52.183578 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1015 10:56:52.183580 15018 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1015 10:56:52.183586 15018 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1015 10:56:52.183717 15018 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1015 10:56:52.183724 15018 net.cpp:157] Top shape: 1 5 8 18 (720)
I1015 10:56:52.183727 15018 net.cpp:165] Memory required for data: 289999152
I1015 10:56:52.183728 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1015 10:56:52.183733 15018 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1015 10:56:52.183735 15018 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1015 10:56:52.183740 15018 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1015 10:56:52.183768 15018 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1015 10:56:52.183773 15018 net.cpp:157] Top shape: 1 720 (720)
I1015 10:56:52.183775 15018 net.cpp:165] Memory required for data: 290002032
I1015 10:56:52.183778 15018 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1015 10:56:52.183782 15018 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1015 10:56:52.183785 15018 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1015 10:56:52.183789 15018 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1015 10:56:52.183794 15018 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1015 10:56:52.183821 15018 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1015 10:56:52.183825 15018 net.cpp:157] Top shape: 1 2 960 (1920)
I1015 10:56:52.183827 15018 net.cpp:165] Memory required for data: 290009712
I1015 10:56:52.183830 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1015 10:56:52.183836 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1015 10:56:52.183840 15018 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1015 10:56:52.183845 15018 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1015 10:56:52.185806 15018 net.cpp:150] Setting up conv15_2_mbox_loc
I1015 10:56:52.185817 15018 net.cpp:157] Top shape: 1 24 3 4 (288)
I1015 10:56:52.185819 15018 net.cpp:165] Memory required for data: 290010864
I1015 10:56:52.185825 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1015 10:56:52.185830 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1015 10:56:52.185833 15018 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1015 10:56:52.185840 15018 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1015 10:56:52.185961 15018 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1015 10:56:52.185966 15018 net.cpp:157] Top shape: 1 3 4 24 (288)
I1015 10:56:52.185967 15018 net.cpp:165] Memory required for data: 290012016
I1015 10:56:52.185969 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1015 10:56:52.185974 15018 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1015 10:56:52.185976 15018 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1015 10:56:52.185981 15018 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1015 10:56:52.186009 15018 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1015 10:56:52.186013 15018 net.cpp:157] Top shape: 1 288 (288)
I1015 10:56:52.186015 15018 net.cpp:165] Memory required for data: 290013168
I1015 10:56:52.186018 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1015 10:56:52.186026 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1015 10:56:52.186029 15018 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1015 10:56:52.186035 15018 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1015 10:56:52.188205 15018 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1015 10:56:52.188217 15018 net.cpp:157] Top shape: 1 18 3 4 (216)
I1015 10:56:52.188220 15018 net.cpp:165] Memory required for data: 290014032
I1015 10:56:52.188225 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1015 10:56:52.188232 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1015 10:56:52.188235 15018 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1015 10:56:52.188239 15018 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1015 10:56:52.188359 15018 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1015 10:56:52.188364 15018 net.cpp:157] Top shape: 1 3 4 18 (216)
I1015 10:56:52.188366 15018 net.cpp:165] Memory required for data: 290014896
I1015 10:56:52.188369 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1015 10:56:52.188374 15018 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1015 10:56:52.188376 15018 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1015 10:56:52.188380 15018 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1015 10:56:52.188408 15018 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1015 10:56:52.188412 15018 net.cpp:157] Top shape: 1 216 (216)
I1015 10:56:52.188414 15018 net.cpp:165] Memory required for data: 290015760
I1015 10:56:52.188417 15018 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1015 10:56:52.188423 15018 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1015 10:56:52.188426 15018 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1015 10:56:52.188431 15018 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1015 10:56:52.188434 15018 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1015 10:56:52.188464 15018 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1015 10:56:52.188468 15018 net.cpp:157] Top shape: 1 2 288 (576)
I1015 10:56:52.188470 15018 net.cpp:165] Memory required for data: 290018064
I1015 10:56:52.188473 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1015 10:56:52.188482 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1015 10:56:52.188484 15018 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1015 10:56:52.188490 15018 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1015 10:56:52.190723 15018 net.cpp:150] Setting up conv16_2_mbox_loc
I1015 10:56:52.190737 15018 net.cpp:157] Top shape: 1 24 2 2 (96)
I1015 10:56:52.190739 15018 net.cpp:165] Memory required for data: 290018448
I1015 10:56:52.190745 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1015 10:56:52.190752 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1015 10:56:52.190755 15018 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1015 10:56:52.190762 15018 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1015 10:56:52.190969 15018 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1015 10:56:52.190981 15018 net.cpp:157] Top shape: 1 2 2 24 (96)
I1015 10:56:52.190984 15018 net.cpp:165] Memory required for data: 290018832
I1015 10:56:52.190987 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1015 10:56:52.190994 15018 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1015 10:56:52.190996 15018 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1015 10:56:52.191002 15018 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1015 10:56:52.191040 15018 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1015 10:56:52.191047 15018 net.cpp:157] Top shape: 1 96 (96)
I1015 10:56:52.191049 15018 net.cpp:165] Memory required for data: 290019216
I1015 10:56:52.191051 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1015 10:56:52.191062 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1015 10:56:52.191066 15018 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1015 10:56:52.191073 15018 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1015 10:56:52.193204 15018 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1015 10:56:52.193217 15018 net.cpp:157] Top shape: 1 18 2 2 (72)
I1015 10:56:52.193218 15018 net.cpp:165] Memory required for data: 290019504
I1015 10:56:52.193224 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1015 10:56:52.193230 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1015 10:56:52.193233 15018 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1015 10:56:52.193239 15018 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1015 10:56:52.193462 15018 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1015 10:56:52.193473 15018 net.cpp:157] Top shape: 1 2 2 18 (72)
I1015 10:56:52.193476 15018 net.cpp:165] Memory required for data: 290019792
I1015 10:56:52.193480 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1015 10:56:52.193487 15018 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1015 10:56:52.193492 15018 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1015 10:56:52.193500 15018 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1015 10:56:52.193540 15018 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1015 10:56:52.193547 15018 net.cpp:157] Top shape: 1 72 (72)
I1015 10:56:52.193549 15018 net.cpp:165] Memory required for data: 290020080
I1015 10:56:52.193552 15018 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1015 10:56:52.193560 15018 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1015 10:56:52.193565 15018 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1015 10:56:52.193572 15018 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1015 10:56:52.193578 15018 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1015 10:56:52.193624 15018 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1015 10:56:52.193630 15018 net.cpp:157] Top shape: 1 2 96 (192)
I1015 10:56:52.193632 15018 net.cpp:165] Memory required for data: 290020848
I1015 10:56:52.193636 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1015 10:56:52.193647 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1015 10:56:52.193655 15018 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1015 10:56:52.193661 15018 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1015 10:56:52.195787 15018 net.cpp:150] Setting up conv17_2_mbox_loc
I1015 10:56:52.195799 15018 net.cpp:157] Top shape: 1 24 1 1 (24)
I1015 10:56:52.195801 15018 net.cpp:165] Memory required for data: 290020944
I1015 10:56:52.195807 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1015 10:56:52.195814 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1015 10:56:52.195817 15018 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1015 10:56:52.195822 15018 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1015 10:56:52.196035 15018 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1015 10:56:52.196046 15018 net.cpp:157] Top shape: 1 1 1 24 (24)
I1015 10:56:52.196049 15018 net.cpp:165] Memory required for data: 290021040
I1015 10:56:52.196053 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1015 10:56:52.196058 15018 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1015 10:56:52.196061 15018 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1015 10:56:52.196065 15018 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1015 10:56:52.196105 15018 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1015 10:56:52.196111 15018 net.cpp:157] Top shape: 1 24 (24)
I1015 10:56:52.196113 15018 net.cpp:165] Memory required for data: 290021136
I1015 10:56:52.196116 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1015 10:56:52.196125 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1015 10:56:52.196130 15018 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1015 10:56:52.196141 15018 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1015 10:56:52.198326 15018 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1015 10:56:52.198339 15018 net.cpp:157] Top shape: 1 18 1 1 (18)
I1015 10:56:52.198343 15018 net.cpp:165] Memory required for data: 290021208
I1015 10:56:52.198348 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1015 10:56:52.198355 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1015 10:56:52.198359 15018 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1015 10:56:52.198364 15018 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1015 10:56:52.198580 15018 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1015 10:56:52.198590 15018 net.cpp:157] Top shape: 1 1 1 18 (18)
I1015 10:56:52.198591 15018 net.cpp:165] Memory required for data: 290021280
I1015 10:56:52.198595 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1015 10:56:52.198599 15018 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1015 10:56:52.198603 15018 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1015 10:56:52.198607 15018 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1015 10:56:52.198648 15018 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1015 10:56:52.198654 15018 net.cpp:157] Top shape: 1 18 (18)
I1015 10:56:52.198657 15018 net.cpp:165] Memory required for data: 290021352
I1015 10:56:52.198658 15018 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1015 10:56:52.198667 15018 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1015 10:56:52.198673 15018 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1015 10:56:52.198678 15018 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1015 10:56:52.198686 15018 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1015 10:56:52.198729 15018 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1015 10:56:52.198740 15018 net.cpp:157] Top shape: 1 2 24 (48)
I1015 10:56:52.198741 15018 net.cpp:165] Memory required for data: 290021544
I1015 10:56:52.198745 15018 layer_factory.hpp:77] Creating layer mbox_loc
I1015 10:56:52.198753 15018 net.cpp:100] Creating Layer mbox_loc
I1015 10:56:52.198758 15018 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1015 10:56:52.198765 15018 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1015 10:56:52.198768 15018 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1015 10:56:52.198772 15018 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1015 10:56:52.198777 15018 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1015 10:56:52.198782 15018 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1015 10:56:52.198789 15018 net.cpp:408] mbox_loc -> mbox_loc
I1015 10:56:52.198832 15018 net.cpp:150] Setting up mbox_loc
I1015 10:56:52.198837 15018 net.cpp:157] Top shape: 1 12168 (12168)
I1015 10:56:52.198839 15018 net.cpp:165] Memory required for data: 290070216
I1015 10:56:52.198843 15018 layer_factory.hpp:77] Creating layer mbox_conf
I1015 10:56:52.198850 15018 net.cpp:100] Creating Layer mbox_conf
I1015 10:56:52.198855 15018 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1015 10:56:52.198860 15018 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1015 10:56:52.198864 15018 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1015 10:56:52.198868 15018 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1015 10:56:52.198873 15018 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1015 10:56:52.198877 15018 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1015 10:56:52.198884 15018 net.cpp:408] mbox_conf -> mbox_conf
I1015 10:56:52.198926 15018 net.cpp:150] Setting up mbox_conf
I1015 10:56:52.198935 15018 net.cpp:157] Top shape: 1 9126 (9126)
I1015 10:56:52.198937 15018 net.cpp:165] Memory required for data: 290106720
I1015 10:56:52.198941 15018 layer_factory.hpp:77] Creating layer mbox_priorbox
I1015 10:56:52.198946 15018 net.cpp:100] Creating Layer mbox_priorbox
I1015 10:56:52.198949 15018 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1015 10:56:52.198954 15018 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1015 10:56:52.198961 15018 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1015 10:56:52.198966 15018 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1015 10:56:52.198969 15018 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1015 10:56:52.198972 15018 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1015 10:56:52.198976 15018 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1015 10:56:52.199020 15018 net.cpp:150] Setting up mbox_priorbox
I1015 10:56:52.199028 15018 net.cpp:157] Top shape: 1 2 12168 (24336)
I1015 10:56:52.199029 15018 net.cpp:165] Memory required for data: 290204064
I1015 10:56:52.199033 15018 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I1015 10:56:52.199041 15018 net.cpp:100] Creating Layer mbox_conf_reshape
I1015 10:56:52.199046 15018 net.cpp:434] mbox_conf_reshape <- mbox_conf
I1015 10:56:52.199054 15018 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I1015 10:56:52.199096 15018 net.cpp:150] Setting up mbox_conf_reshape
I1015 10:56:52.199105 15018 net.cpp:157] Top shape: 1 3042 3 (9126)
I1015 10:56:52.199107 15018 net.cpp:165] Memory required for data: 290240568
I1015 10:56:52.199110 15018 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I1015 10:56:52.199120 15018 net.cpp:100] Creating Layer mbox_conf_softmax
I1015 10:56:52.199123 15018 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I1015 10:56:52.199132 15018 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I1015 10:56:52.200280 15018 net.cpp:150] Setting up mbox_conf_softmax
I1015 10:56:52.200297 15018 net.cpp:157] Top shape: 1 3042 3 (9126)
I1015 10:56:52.200302 15018 net.cpp:165] Memory required for data: 290277072
I1015 10:56:52.200306 15018 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I1015 10:56:52.200311 15018 net.cpp:100] Creating Layer mbox_conf_flatten
I1015 10:56:52.200315 15018 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I1015 10:56:52.200322 15018 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I1015 10:56:52.200367 15018 net.cpp:150] Setting up mbox_conf_flatten
I1015 10:56:52.200376 15018 net.cpp:157] Top shape: 1 9126 (9126)
I1015 10:56:52.200381 15018 net.cpp:165] Memory required for data: 290313576
I1015 10:56:52.200386 15018 layer_factory.hpp:77] Creating layer detection_out
I1015 10:56:52.200394 15018 net.cpp:100] Creating Layer detection_out
I1015 10:56:52.200398 15018 net.cpp:434] detection_out <- mbox_loc
I1015 10:56:52.200404 15018 net.cpp:434] detection_out <- mbox_conf_flatten
I1015 10:56:52.200409 15018 net.cpp:434] detection_out <- mbox_priorbox
I1015 10:56:52.200418 15018 net.cpp:408] detection_out -> detection_out
I1015 10:56:52.200517 15018 net.cpp:150] Setting up detection_out
I1015 10:56:52.200531 15018 net.cpp:157] Top shape: 1 1 1 7 (7)
I1015 10:56:52.200534 15018 net.cpp:165] Memory required for data: 290313604
I1015 10:56:52.200537 15018 layer_factory.hpp:77] Creating layer detection_eval
I1015 10:56:52.200543 15018 net.cpp:100] Creating Layer detection_eval
I1015 10:56:52.200548 15018 net.cpp:434] detection_eval <- detection_out
I1015 10:56:52.200553 15018 net.cpp:434] detection_eval <- label
I1015 10:56:52.200562 15018 net.cpp:408] detection_eval -> detection_eval
I1015 10:56:52.200639 15018 net.cpp:150] Setting up detection_eval
I1015 10:56:52.200647 15018 net.cpp:157] Top shape: 1 1 3 5 (15)
I1015 10:56:52.200649 15018 net.cpp:165] Memory required for data: 290313664
I1015 10:56:52.200651 15018 layer_factory.hpp:77] Creating layer score_32
I1015 10:56:52.200660 15018 net.cpp:100] Creating Layer score_32
I1015 10:56:52.200666 15018 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1015 10:56:52.200675 15018 net.cpp:408] score_32 -> score_32
I1015 10:56:52.202863 15018 net.cpp:150] Setting up score_32
I1015 10:56:52.202875 15018 net.cpp:157] Top shape: 1 2 10 15 (300)
I1015 10:56:52.202878 15018 net.cpp:165] Memory required for data: 290314864
I1015 10:56:52.202883 15018 layer_factory.hpp:77] Creating layer upscore_16
I1015 10:56:52.202890 15018 net.cpp:100] Creating Layer upscore_16
I1015 10:56:52.202893 15018 net.cpp:434] upscore_16 <- score_32
I1015 10:56:52.202899 15018 net.cpp:408] upscore_16 -> upscore_16
I1015 10:56:52.203256 15018 net.cpp:150] Setting up upscore_16
I1015 10:56:52.203265 15018 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 10:56:52.203267 15018 net.cpp:165] Memory required for data: 290319664
I1015 10:56:52.203272 15018 layer_factory.hpp:77] Creating layer score_16
I1015 10:56:52.203279 15018 net.cpp:100] Creating Layer score_16
I1015 10:56:52.203281 15018 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1015 10:56:52.203285 15018 net.cpp:408] score_16 -> score_16
I1015 10:56:52.206146 15018 net.cpp:150] Setting up score_16
I1015 10:56:52.206162 15018 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 10:56:52.206167 15018 net.cpp:165] Memory required for data: 290324464
I1015 10:56:52.206176 15018 layer_factory.hpp:77] Creating layer fuse_16
I1015 10:56:52.206184 15018 net.cpp:100] Creating Layer fuse_16
I1015 10:56:52.206188 15018 net.cpp:434] fuse_16 <- upscore_16
I1015 10:56:52.206194 15018 net.cpp:434] fuse_16 <- score_16
I1015 10:56:52.206202 15018 net.cpp:408] fuse_16 -> fuse_16
I1015 10:56:52.206282 15018 net.cpp:150] Setting up fuse_16
I1015 10:56:52.206291 15018 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 10:56:52.206295 15018 net.cpp:165] Memory required for data: 290329264
I1015 10:56:52.206300 15018 layer_factory.hpp:77] Creating layer upscore_8
I1015 10:56:52.206307 15018 net.cpp:100] Creating Layer upscore_8
I1015 10:56:52.206312 15018 net.cpp:434] upscore_8 <- fuse_16
I1015 10:56:52.206318 15018 net.cpp:408] upscore_8 -> upscore_8
I1015 10:56:52.206740 15018 net.cpp:150] Setting up upscore_8
I1015 10:56:52.206753 15018 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 10:56:52.206756 15018 net.cpp:165] Memory required for data: 290348464
I1015 10:56:52.206763 15018 layer_factory.hpp:77] Creating layer score_8
I1015 10:56:52.206773 15018 net.cpp:100] Creating Layer score_8
I1015 10:56:52.206776 15018 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1015 10:56:52.206782 15018 net.cpp:408] score_8 -> score_8
I1015 10:56:52.209750 15018 net.cpp:150] Setting up score_8
I1015 10:56:52.209762 15018 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 10:56:52.209765 15018 net.cpp:165] Memory required for data: 290367664
I1015 10:56:52.209770 15018 layer_factory.hpp:77] Creating layer fuse_8
I1015 10:56:52.209775 15018 net.cpp:100] Creating Layer fuse_8
I1015 10:56:52.209779 15018 net.cpp:434] fuse_8 <- upscore_8
I1015 10:56:52.209782 15018 net.cpp:434] fuse_8 <- score_8
I1015 10:56:52.209787 15018 net.cpp:408] fuse_8 -> fuse_8
I1015 10:56:52.209820 15018 net.cpp:150] Setting up fuse_8
I1015 10:56:52.209827 15018 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 10:56:52.209831 15018 net.cpp:165] Memory required for data: 290386864
I1015 10:56:52.209836 15018 layer_factory.hpp:77] Creating layer upscore_4
I1015 10:56:52.209846 15018 net.cpp:100] Creating Layer upscore_4
I1015 10:56:52.209851 15018 net.cpp:434] upscore_4 <- fuse_8
I1015 10:56:52.209859 15018 net.cpp:408] upscore_4 -> upscore_4
I1015 10:56:52.210278 15018 net.cpp:150] Setting up upscore_4
I1015 10:56:52.210289 15018 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 10:56:52.210290 15018 net.cpp:165] Memory required for data: 290463664
I1015 10:56:52.210294 15018 layer_factory.hpp:77] Creating layer score_4
I1015 10:56:52.210301 15018 net.cpp:100] Creating Layer score_4
I1015 10:56:52.210304 15018 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1015 10:56:52.210309 15018 net.cpp:408] score_4 -> score_4
I1015 10:56:52.212345 15018 net.cpp:150] Setting up score_4
I1015 10:56:52.212358 15018 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 10:56:52.212360 15018 net.cpp:165] Memory required for data: 290540464
I1015 10:56:52.212366 15018 layer_factory.hpp:77] Creating layer fuse_4
I1015 10:56:52.212371 15018 net.cpp:100] Creating Layer fuse_4
I1015 10:56:52.212374 15018 net.cpp:434] fuse_4 <- upscore_4
I1015 10:56:52.212378 15018 net.cpp:434] fuse_4 <- score_4
I1015 10:56:52.212383 15018 net.cpp:408] fuse_4 -> fuse_4
I1015 10:56:52.212417 15018 net.cpp:150] Setting up fuse_4
I1015 10:56:52.212425 15018 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 10:56:52.212429 15018 net.cpp:165] Memory required for data: 290617264
I1015 10:56:52.212432 15018 layer_factory.hpp:77] Creating layer upscore
I1015 10:56:52.212441 15018 net.cpp:100] Creating Layer upscore
I1015 10:56:52.212446 15018 net.cpp:434] upscore <- fuse_4
I1015 10:56:52.212453 15018 net.cpp:408] upscore -> upscore
I1015 10:56:52.212884 15018 net.cpp:150] Setting up upscore
I1015 10:56:52.212896 15018 net.cpp:157] Top shape: 1 2 331 491 (325042)
I1015 10:56:52.212899 15018 net.cpp:165] Memory required for data: 291917432
I1015 10:56:52.212903 15018 layer_factory.hpp:77] Creating layer score
I1015 10:56:52.212909 15018 net.cpp:100] Creating Layer score
I1015 10:56:52.212913 15018 net.cpp:434] score <- upscore
I1015 10:56:52.212915 15018 net.cpp:434] score <- data_data_0_split_7
I1015 10:56:52.212921 15018 net.cpp:408] score -> score
I1015 10:56:52.212962 15018 net.cpp:150] Setting up score
I1015 10:56:52.212968 15018 net.cpp:157] Top shape: 1 2 320 480 (307200)
I1015 10:56:52.212970 15018 net.cpp:165] Memory required for data: 293146232
I1015 10:56:52.212973 15018 layer_factory.hpp:77] Creating layer seg_loss
I1015 10:56:52.212978 15018 net.cpp:100] Creating Layer seg_loss
I1015 10:56:52.212981 15018 net.cpp:434] seg_loss <- score
I1015 10:56:52.212985 15018 net.cpp:434] seg_loss <- label_seg
I1015 10:56:52.212990 15018 net.cpp:408] seg_loss -> seg_loss
I1015 10:56:52.212996 15018 layer_factory.hpp:77] Creating layer seg_loss
I1015 10:56:52.214670 15018 net.cpp:150] Setting up seg_loss
I1015 10:56:52.214682 15018 net.cpp:157] Top shape: (1)
I1015 10:56:52.214685 15018 net.cpp:160]     with loss weight 1
I1015 10:56:52.214692 15018 net.cpp:165] Memory required for data: 293146236
I1015 10:56:52.214696 15018 net.cpp:226] seg_loss needs backward computation.
I1015 10:56:52.214699 15018 net.cpp:226] score needs backward computation.
I1015 10:56:52.214702 15018 net.cpp:226] upscore needs backward computation.
I1015 10:56:52.214704 15018 net.cpp:226] fuse_4 needs backward computation.
I1015 10:56:52.214707 15018 net.cpp:226] score_4 needs backward computation.
I1015 10:56:52.214709 15018 net.cpp:226] upscore_4 needs backward computation.
I1015 10:56:52.214713 15018 net.cpp:226] fuse_8 needs backward computation.
I1015 10:56:52.214716 15018 net.cpp:226] score_8 needs backward computation.
I1015 10:56:52.214720 15018 net.cpp:226] upscore_8 needs backward computation.
I1015 10:56:52.214721 15018 net.cpp:226] fuse_16 needs backward computation.
I1015 10:56:52.214725 15018 net.cpp:226] score_16 needs backward computation.
I1015 10:56:52.214728 15018 net.cpp:226] upscore_16 needs backward computation.
I1015 10:56:52.214732 15018 net.cpp:226] score_32 needs backward computation.
I1015 10:56:52.214736 15018 net.cpp:228] detection_eval does not need backward computation.
I1015 10:56:52.214741 15018 net.cpp:228] detection_out does not need backward computation.
I1015 10:56:52.214746 15018 net.cpp:228] mbox_conf_flatten does not need backward computation.
I1015 10:56:52.214751 15018 net.cpp:228] mbox_conf_softmax does not need backward computation.
I1015 10:56:52.214754 15018 net.cpp:228] mbox_conf_reshape does not need backward computation.
I1015 10:56:52.214758 15018 net.cpp:228] mbox_priorbox does not need backward computation.
I1015 10:56:52.214766 15018 net.cpp:228] mbox_conf does not need backward computation.
I1015 10:56:52.214771 15018 net.cpp:228] mbox_loc does not need backward computation.
I1015 10:56:52.214777 15018 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1015 10:56:52.214782 15018 net.cpp:228] conv17_2_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214787 15018 net.cpp:228] conv17_2_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214792 15018 net.cpp:228] conv17_2_mbox_conf_new does not need backward computation.
I1015 10:56:52.214797 15018 net.cpp:228] conv17_2_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214799 15018 net.cpp:228] conv17_2_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214803 15018 net.cpp:228] conv17_2_mbox_loc does not need backward computation.
I1015 10:56:52.214808 15018 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1015 10:56:52.214813 15018 net.cpp:228] conv16_2_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214818 15018 net.cpp:228] conv16_2_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214821 15018 net.cpp:228] conv16_2_mbox_conf_new does not need backward computation.
I1015 10:56:52.214825 15018 net.cpp:228] conv16_2_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214828 15018 net.cpp:228] conv16_2_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214833 15018 net.cpp:228] conv16_2_mbox_loc does not need backward computation.
I1015 10:56:52.214838 15018 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1015 10:56:52.214843 15018 net.cpp:228] conv15_2_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214846 15018 net.cpp:228] conv15_2_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214849 15018 net.cpp:228] conv15_2_mbox_conf_new does not need backward computation.
I1015 10:56:52.214853 15018 net.cpp:228] conv15_2_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214856 15018 net.cpp:228] conv15_2_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214860 15018 net.cpp:228] conv15_2_mbox_loc does not need backward computation.
I1015 10:56:52.214866 15018 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1015 10:56:52.214872 15018 net.cpp:228] conv14_2_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214875 15018 net.cpp:228] conv14_2_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214879 15018 net.cpp:228] conv14_2_mbox_conf_new does not need backward computation.
I1015 10:56:52.214881 15018 net.cpp:228] conv14_2_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214884 15018 net.cpp:228] conv14_2_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214889 15018 net.cpp:228] conv14_2_mbox_loc does not need backward computation.
I1015 10:56:52.214893 15018 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1015 10:56:52.214898 15018 net.cpp:228] conv13_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214903 15018 net.cpp:228] conv13_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214906 15018 net.cpp:228] conv13_mbox_conf_new does not need backward computation.
I1015 10:56:52.214910 15018 net.cpp:228] conv13_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214912 15018 net.cpp:228] conv13_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214920 15018 net.cpp:228] conv13_mbox_loc does not need backward computation.
I1015 10:56:52.214924 15018 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1015 10:56:52.214929 15018 net.cpp:228] conv11_mbox_conf_flat does not need backward computation.
I1015 10:56:52.214934 15018 net.cpp:228] conv11_mbox_conf_perm does not need backward computation.
I1015 10:56:52.214938 15018 net.cpp:228] conv11_mbox_conf_new does not need backward computation.
I1015 10:56:52.214942 15018 net.cpp:228] conv11_mbox_loc_flat does not need backward computation.
I1015 10:56:52.214944 15018 net.cpp:228] conv11_mbox_loc_perm does not need backward computation.
I1015 10:56:52.214947 15018 net.cpp:228] conv11_mbox_loc does not need backward computation.
I1015 10:56:52.214951 15018 net.cpp:228] conv17_2_conv17_2/relu_0_split does not need backward computation.
I1015 10:56:52.214956 15018 net.cpp:228] conv17_2/relu does not need backward computation.
I1015 10:56:52.214960 15018 net.cpp:228] conv17_2/scale does not need backward computation.
I1015 10:56:52.214964 15018 net.cpp:228] conv17_2/bn does not need backward computation.
I1015 10:56:52.214967 15018 net.cpp:228] conv17_2 does not need backward computation.
I1015 10:56:52.214972 15018 net.cpp:228] conv17_1/relu does not need backward computation.
I1015 10:56:52.214973 15018 net.cpp:228] conv17_1/scale does not need backward computation.
I1015 10:56:52.214977 15018 net.cpp:228] conv17_1/bn does not need backward computation.
I1015 10:56:52.214978 15018 net.cpp:228] conv17_1 does not need backward computation.
I1015 10:56:52.214984 15018 net.cpp:228] conv16_2_conv16_2/relu_0_split does not need backward computation.
I1015 10:56:52.214988 15018 net.cpp:228] conv16_2/relu does not need backward computation.
I1015 10:56:52.214993 15018 net.cpp:228] conv16_2/scale does not need backward computation.
I1015 10:56:52.214996 15018 net.cpp:228] conv16_2/bn does not need backward computation.
I1015 10:56:52.215000 15018 net.cpp:228] conv16_2 does not need backward computation.
I1015 10:56:52.215003 15018 net.cpp:228] conv16_1/relu does not need backward computation.
I1015 10:56:52.215005 15018 net.cpp:228] conv16_1/scale does not need backward computation.
I1015 10:56:52.215008 15018 net.cpp:228] conv16_1/bn does not need backward computation.
I1015 10:56:52.215013 15018 net.cpp:228] conv16_1 does not need backward computation.
I1015 10:56:52.215018 15018 net.cpp:228] conv15_2_conv15_2/relu_0_split does not need backward computation.
I1015 10:56:52.215021 15018 net.cpp:228] conv15_2/relu does not need backward computation.
I1015 10:56:52.215025 15018 net.cpp:228] conv15_2/scale does not need backward computation.
I1015 10:56:52.215029 15018 net.cpp:228] conv15_2/bn does not need backward computation.
I1015 10:56:52.215031 15018 net.cpp:228] conv15_2 does not need backward computation.
I1015 10:56:52.215034 15018 net.cpp:228] conv15_1/relu does not need backward computation.
I1015 10:56:52.215039 15018 net.cpp:228] conv15_1/scale does not need backward computation.
I1015 10:56:52.215042 15018 net.cpp:228] conv15_1/bn does not need backward computation.
I1015 10:56:52.215047 15018 net.cpp:228] conv15_1 does not need backward computation.
I1015 10:56:52.215051 15018 net.cpp:228] conv14_2_conv14_2/relu_0_split does not need backward computation.
I1015 10:56:52.215054 15018 net.cpp:228] conv14_2/relu does not need backward computation.
I1015 10:56:52.215057 15018 net.cpp:228] conv14_2/scale does not need backward computation.
I1015 10:56:52.215059 15018 net.cpp:228] conv14_2/bn does not need backward computation.
I1015 10:56:52.215062 15018 net.cpp:228] conv14_2 does not need backward computation.
I1015 10:56:52.215066 15018 net.cpp:228] conv14_1/relu does not need backward computation.
I1015 10:56:52.215070 15018 net.cpp:228] conv14_1/scale does not need backward computation.
I1015 10:56:52.215075 15018 net.cpp:228] conv14_1/bn does not need backward computation.
I1015 10:56:52.215078 15018 net.cpp:228] conv14_1 does not need backward computation.
I1015 10:56:52.215082 15018 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1015 10:56:52.215085 15018 net.cpp:226] conv13/relu needs backward computation.
I1015 10:56:52.215088 15018 net.cpp:226] conv13/scale needs backward computation.
I1015 10:56:52.215091 15018 net.cpp:226] conv13/bn needs backward computation.
I1015 10:56:52.215096 15018 net.cpp:226] conv13 needs backward computation.
I1015 10:56:52.215102 15018 net.cpp:226] conv13/dw/relu needs backward computation.
I1015 10:56:52.215106 15018 net.cpp:226] conv13/dw/scale needs backward computation.
I1015 10:56:52.215111 15018 net.cpp:226] conv13/dw/bn needs backward computation.
I1015 10:56:52.215112 15018 net.cpp:226] conv13/dw needs backward computation.
I1015 10:56:52.215116 15018 net.cpp:226] conv12/relu needs backward computation.
I1015 10:56:52.215119 15018 net.cpp:226] conv12/scale needs backward computation.
I1015 10:56:52.215123 15018 net.cpp:226] conv12/bn needs backward computation.
I1015 10:56:52.215127 15018 net.cpp:226] conv12 needs backward computation.
I1015 10:56:52.215131 15018 net.cpp:226] conv12/dw/relu needs backward computation.
I1015 10:56:52.215134 15018 net.cpp:226] conv12/dw/scale needs backward computation.
I1015 10:56:52.215137 15018 net.cpp:226] conv12/dw/bn needs backward computation.
I1015 10:56:52.215139 15018 net.cpp:226] conv12/dw needs backward computation.
I1015 10:56:52.215142 15018 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1015 10:56:52.215145 15018 net.cpp:226] conv11/relu needs backward computation.
I1015 10:56:52.215149 15018 net.cpp:226] conv11/scale needs backward computation.
I1015 10:56:52.215153 15018 net.cpp:226] conv11/bn needs backward computation.
I1015 10:56:52.215157 15018 net.cpp:226] conv11 needs backward computation.
I1015 10:56:52.215162 15018 net.cpp:226] conv11/dw/relu needs backward computation.
I1015 10:56:52.215164 15018 net.cpp:226] conv11/dw/scale needs backward computation.
I1015 10:56:52.215167 15018 net.cpp:226] conv11/dw/bn needs backward computation.
I1015 10:56:52.215169 15018 net.cpp:226] conv11/dw needs backward computation.
I1015 10:56:52.215171 15018 net.cpp:226] conv10/relu needs backward computation.
I1015 10:56:52.215175 15018 net.cpp:226] conv10/scale needs backward computation.
I1015 10:56:52.215179 15018 net.cpp:226] conv10/bn needs backward computation.
I1015 10:56:52.215184 15018 net.cpp:226] conv10 needs backward computation.
I1015 10:56:52.215188 15018 net.cpp:226] conv10/dw/relu needs backward computation.
I1015 10:56:52.215191 15018 net.cpp:226] conv10/dw/scale needs backward computation.
I1015 10:56:52.215193 15018 net.cpp:226] conv10/dw/bn needs backward computation.
I1015 10:56:52.215196 15018 net.cpp:226] conv10/dw needs backward computation.
I1015 10:56:52.215199 15018 net.cpp:226] conv9/relu needs backward computation.
I1015 10:56:52.215204 15018 net.cpp:226] conv9/scale needs backward computation.
I1015 10:56:52.215207 15018 net.cpp:226] conv9/bn needs backward computation.
I1015 10:56:52.215211 15018 net.cpp:226] conv9 needs backward computation.
I1015 10:56:52.215215 15018 net.cpp:226] conv9/dw/relu needs backward computation.
I1015 10:56:52.215219 15018 net.cpp:226] conv9/dw/scale needs backward computation.
I1015 10:56:52.215220 15018 net.cpp:226] conv9/dw/bn needs backward computation.
I1015 10:56:52.215224 15018 net.cpp:226] conv9/dw needs backward computation.
I1015 10:56:52.215225 15018 net.cpp:226] conv8/relu needs backward computation.
I1015 10:56:52.215229 15018 net.cpp:226] conv8/scale needs backward computation.
I1015 10:56:52.215234 15018 net.cpp:226] conv8/bn needs backward computation.
I1015 10:56:52.215237 15018 net.cpp:226] conv8 needs backward computation.
I1015 10:56:52.215241 15018 net.cpp:226] conv8/dw/relu needs backward computation.
I1015 10:56:52.215245 15018 net.cpp:226] conv8/dw/scale needs backward computation.
I1015 10:56:52.215247 15018 net.cpp:226] conv8/dw/bn needs backward computation.
I1015 10:56:52.215250 15018 net.cpp:226] conv8/dw needs backward computation.
I1015 10:56:52.215253 15018 net.cpp:226] conv7/relu needs backward computation.
I1015 10:56:52.215257 15018 net.cpp:226] conv7/scale needs backward computation.
I1015 10:56:52.215261 15018 net.cpp:226] conv7/bn needs backward computation.
I1015 10:56:52.215265 15018 net.cpp:226] conv7 needs backward computation.
I1015 10:56:52.215270 15018 net.cpp:226] conv7/dw/relu needs backward computation.
I1015 10:56:52.215273 15018 net.cpp:226] conv7/dw/scale needs backward computation.
I1015 10:56:52.215276 15018 net.cpp:226] conv7/dw/bn needs backward computation.
I1015 10:56:52.215278 15018 net.cpp:226] conv7/dw needs backward computation.
I1015 10:56:52.215281 15018 net.cpp:226] conv6/relu needs backward computation.
I1015 10:56:52.215286 15018 net.cpp:226] conv6/scale needs backward computation.
I1015 10:56:52.215289 15018 net.cpp:226] conv6/bn needs backward computation.
I1015 10:56:52.215293 15018 net.cpp:226] conv6 needs backward computation.
I1015 10:56:52.215297 15018 net.cpp:226] conv6/dw/relu needs backward computation.
I1015 10:56:52.215301 15018 net.cpp:226] conv6/dw/scale needs backward computation.
I1015 10:56:52.215306 15018 net.cpp:226] conv6/dw/bn needs backward computation.
I1015 10:56:52.215308 15018 net.cpp:226] conv6/dw needs backward computation.
I1015 10:56:52.215312 15018 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1015 10:56:52.215314 15018 net.cpp:226] conv5/relu needs backward computation.
I1015 10:56:52.215317 15018 net.cpp:226] conv5/scale needs backward computation.
I1015 10:56:52.215322 15018 net.cpp:226] conv5/bn needs backward computation.
I1015 10:56:52.215324 15018 net.cpp:226] conv5 needs backward computation.
I1015 10:56:52.215329 15018 net.cpp:226] conv5/dw/relu needs backward computation.
I1015 10:56:52.215333 15018 net.cpp:226] conv5/dw/scale needs backward computation.
I1015 10:56:52.215337 15018 net.cpp:226] conv5/dw/bn needs backward computation.
I1015 10:56:52.215339 15018 net.cpp:226] conv5/dw needs backward computation.
I1015 10:56:52.215342 15018 net.cpp:226] conv4/relu needs backward computation.
I1015 10:56:52.215344 15018 net.cpp:226] conv4/scale needs backward computation.
I1015 10:56:52.215348 15018 net.cpp:226] conv4/bn needs backward computation.
I1015 10:56:52.215350 15018 net.cpp:226] conv4 needs backward computation.
I1015 10:56:52.215355 15018 net.cpp:226] conv4/dw/relu needs backward computation.
I1015 10:56:52.215361 15018 net.cpp:226] conv4/dw/scale needs backward computation.
I1015 10:56:52.215365 15018 net.cpp:226] conv4/dw/bn needs backward computation.
I1015 10:56:52.215368 15018 net.cpp:226] conv4/dw needs backward computation.
I1015 10:56:52.215370 15018 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1015 10:56:52.215373 15018 net.cpp:226] conv3/relu needs backward computation.
I1015 10:56:52.215378 15018 net.cpp:226] conv3/scale needs backward computation.
I1015 10:56:52.215381 15018 net.cpp:226] conv3/bn needs backward computation.
I1015 10:56:52.215385 15018 net.cpp:226] conv3 needs backward computation.
I1015 10:56:52.215389 15018 net.cpp:226] conv3/dw/relu needs backward computation.
I1015 10:56:52.215394 15018 net.cpp:226] conv3/dw/scale needs backward computation.
I1015 10:56:52.215395 15018 net.cpp:226] conv3/dw/bn needs backward computation.
I1015 10:56:52.215397 15018 net.cpp:226] conv3/dw needs backward computation.
I1015 10:56:52.215401 15018 net.cpp:226] conv2/relu needs backward computation.
I1015 10:56:52.215405 15018 net.cpp:226] conv2/scale needs backward computation.
I1015 10:56:52.215409 15018 net.cpp:226] conv2/bn needs backward computation.
I1015 10:56:52.215412 15018 net.cpp:226] conv2 needs backward computation.
I1015 10:56:52.215416 15018 net.cpp:226] conv2/dw/relu needs backward computation.
I1015 10:56:52.215420 15018 net.cpp:226] conv2/dw/scale needs backward computation.
I1015 10:56:52.215422 15018 net.cpp:226] conv2/dw/bn needs backward computation.
I1015 10:56:52.215425 15018 net.cpp:226] conv2/dw needs backward computation.
I1015 10:56:52.215426 15018 net.cpp:226] conv1/relu needs backward computation.
I1015 10:56:52.215430 15018 net.cpp:226] conv1/scale needs backward computation.
I1015 10:56:52.215433 15018 net.cpp:226] conv1/bn needs backward computation.
I1015 10:56:52.215437 15018 net.cpp:226] conv1 needs backward computation.
I1015 10:56:52.215441 15018 net.cpp:226] conv1/dw/relu needs backward computation.
I1015 10:56:52.215445 15018 net.cpp:226] conv1/dw/scale needs backward computation.
I1015 10:56:52.215450 15018 net.cpp:226] conv1/dw/bn needs backward computation.
I1015 10:56:52.215451 15018 net.cpp:226] conv1/dw needs backward computation.
I1015 10:56:52.215453 15018 net.cpp:226] conv0/relu needs backward computation.
I1015 10:56:52.215456 15018 net.cpp:226] conv0/scale needs backward computation.
I1015 10:56:52.215461 15018 net.cpp:226] conv0/bn needs backward computation.
I1015 10:56:52.215464 15018 net.cpp:226] conv0 needs backward computation.
I1015 10:56:52.215471 15018 net.cpp:228] data_data_0_split does not need backward computation.
I1015 10:56:52.215476 15018 net.cpp:228] data does not need backward computation.
I1015 10:56:52.215479 15018 net.cpp:270] This network produces output detection_eval
I1015 10:56:52.215482 15018 net.cpp:270] This network produces output seg_loss
I1015 10:56:52.215610 15018 net.cpp:283] Network initialization done.
I1015 10:56:52.216188 15018 solver.cpp:75] Solver scaffolding done.
I1015 10:56:52.670405 15018 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: pretrained/mobilenet_iter_73000.caffemodel
I1015 10:56:52.670459 15018 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 10:56:52.677726 15018 net.cpp:761] Ignoring source layer conv11_mbox_conf
I1015 10:56:52.677798 15018 net.cpp:761] Ignoring source layer conv13_mbox_conf
I1015 10:56:52.677830 15018 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I1015 10:56:52.677853 15018 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I1015 10:56:52.677873 15018 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I1015 10:56:52.677889 15018 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I1015 10:56:53.240283 15018 solver.cpp:243] Iteration 0, loss = 24.3519
I1015 10:56:53.240329 15018 solver.cpp:259]     Train net output #0: mbox_loss = 23.6587 (* 1 = 23.6587 loss)
I1015 10:56:53.240335 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.693147 (* 1 = 0.693147 loss)
I1015 10:56:53.240340 15018 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I1015 10:56:56.013738 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 10:57:04.465427 15018 solver.cpp:243] Iteration 20, loss = 8.8434
I1015 10:57:04.465461 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.07681 (* 1 = 8.07681 loss)
I1015 10:57:04.465466 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.399162 (* 1 = 0.399162 loss)
I1015 10:57:04.465472 15018 sgd_solver.cpp:138] Iteration 20, lr = 0.0005
I1015 10:57:16.791312 15018 solver.cpp:243] Iteration 40, loss = 8.4209
I1015 10:57:16.791357 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.86124 (* 1 = 8.86124 loss)
I1015 10:57:16.791363 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.214706 (* 1 = 0.214706 loss)
I1015 10:57:16.791368 15018 sgd_solver.cpp:138] Iteration 40, lr = 0.0005
I1015 10:57:29.016858 15018 solver.cpp:243] Iteration 60, loss = 7.07608
I1015 10:57:29.016888 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.0409 (* 1 = 6.0409 loss)
I1015 10:57:29.016896 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.159609 (* 1 = 0.159609 loss)
I1015 10:57:29.016901 15018 sgd_solver.cpp:138] Iteration 60, lr = 0.0005
I1015 10:57:41.116087 15018 solver.cpp:243] Iteration 80, loss = 7.82778
I1015 10:57:41.116119 15018 solver.cpp:259]     Train net output #0: mbox_loss = 10.4542 (* 1 = 10.4542 loss)
I1015 10:57:41.116127 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.14072 (* 1 = 0.14072 loss)
I1015 10:57:41.116132 15018 sgd_solver.cpp:138] Iteration 80, lr = 0.0005
I1015 10:57:53.133267 15018 solver.cpp:243] Iteration 100, loss = 8.06069
I1015 10:57:53.133297 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.33032 (* 1 = 7.33032 loss)
I1015 10:57:53.133304 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.189834 (* 1 = 0.189834 loss)
I1015 10:57:53.133309 15018 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I1015 10:58:05.277171 15018 solver.cpp:243] Iteration 120, loss = 7.11187
I1015 10:58:05.277220 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.27364 (* 1 = 6.27364 loss)
I1015 10:58:05.277225 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127751 (* 1 = 0.127751 loss)
I1015 10:58:05.277231 15018 sgd_solver.cpp:138] Iteration 120, lr = 0.0005
I1015 10:58:17.048297 15018 solver.cpp:243] Iteration 140, loss = 7.02451
I1015 10:58:17.048336 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.87209 (* 1 = 5.87209 loss)
I1015 10:58:17.048343 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.156772 (* 1 = 0.156772 loss)
I1015 10:58:17.048349 15018 sgd_solver.cpp:138] Iteration 140, lr = 0.0005
I1015 10:58:28.770772 15018 solver.cpp:243] Iteration 160, loss = 6.99309
I1015 10:58:28.770804 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.35998 (* 1 = 5.35998 loss)
I1015 10:58:28.770810 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.116931 (* 1 = 0.116931 loss)
I1015 10:58:28.770817 15018 sgd_solver.cpp:138] Iteration 160, lr = 0.0005
I1015 10:58:40.616338 15018 solver.cpp:243] Iteration 180, loss = 6.98558
I1015 10:58:40.616370 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.69355 (* 1 = 7.69355 loss)
I1015 10:58:40.616376 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.219835 (* 1 = 0.219835 loss)
I1015 10:58:40.616381 15018 sgd_solver.cpp:138] Iteration 180, lr = 0.0005
I1015 10:58:52.802760 15018 solver.cpp:243] Iteration 200, loss = 8.82649
I1015 10:58:52.802793 15018 solver.cpp:259]     Train net output #0: mbox_loss = 10.7694 (* 1 = 10.7694 loss)
I1015 10:58:52.802799 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.139124 (* 1 = 0.139124 loss)
I1015 10:58:52.802804 15018 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I1015 10:59:05.126760 15018 solver.cpp:243] Iteration 220, loss = 8.35431
I1015 10:59:05.126791 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.88198 (* 1 = 8.88198 loss)
I1015 10:59:05.126797 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.161882 (* 1 = 0.161882 loss)
I1015 10:59:05.126803 15018 sgd_solver.cpp:138] Iteration 220, lr = 0.0005
I1015 10:59:17.447541 15018 solver.cpp:243] Iteration 240, loss = 9.10769
I1015 10:59:17.447576 15018 solver.cpp:259]     Train net output #0: mbox_loss = 10.4944 (* 1 = 10.4944 loss)
I1015 10:59:17.447583 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.155632 (* 1 = 0.155632 loss)
I1015 10:59:17.447589 15018 sgd_solver.cpp:138] Iteration 240, lr = 0.0005
I1015 10:59:29.635396 15018 solver.cpp:243] Iteration 260, loss = 8.2534
I1015 10:59:29.635428 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.80092 (* 1 = 7.80092 loss)
I1015 10:59:29.635434 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.191953 (* 1 = 0.191953 loss)
I1015 10:59:29.635440 15018 sgd_solver.cpp:138] Iteration 260, lr = 0.0005
I1015 10:59:41.870832 15018 solver.cpp:243] Iteration 280, loss = 6.48434
I1015 10:59:41.870865 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.34521 (* 1 = 6.34521 loss)
I1015 10:59:41.870872 15018 solver.cpp:259]     Train net output #1: seg_loss = 2.02143 (* 1 = 2.02143 loss)
I1015 10:59:41.870877 15018 sgd_solver.cpp:138] Iteration 280, lr = 0.0005
I1015 10:59:54.120168 15018 solver.cpp:243] Iteration 300, loss = 6.50447
I1015 10:59:54.120201 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.36409 (* 1 = 3.36409 loss)
I1015 10:59:54.120208 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.219907 (* 1 = 0.219907 loss)
I1015 10:59:54.120214 15018 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I1015 11:00:06.210494 15018 solver.cpp:243] Iteration 320, loss = 5.50122
I1015 11:00:06.210525 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.82773 (* 1 = 4.82773 loss)
I1015 11:00:06.210531 15018 solver.cpp:259]     Train net output #1: seg_loss = 1.16135 (* 1 = 1.16135 loss)
I1015 11:00:06.210536 15018 sgd_solver.cpp:138] Iteration 320, lr = 0.0005
I1015 11:00:18.470836 15018 solver.cpp:243] Iteration 340, loss = 6.24841
I1015 11:00:18.470868 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.19843 (* 1 = 8.19843 loss)
I1015 11:00:18.470875 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.155041 (* 1 = 0.155041 loss)
I1015 11:00:18.470880 15018 sgd_solver.cpp:138] Iteration 340, lr = 0.0005
I1015 11:00:30.723809 15018 solver.cpp:243] Iteration 360, loss = 6.47139
I1015 11:00:30.723841 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.6809 (* 1 = 6.6809 loss)
I1015 11:00:30.723848 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.185224 (* 1 = 0.185224 loss)
I1015 11:00:30.723853 15018 sgd_solver.cpp:138] Iteration 360, lr = 0.0005
I1015 11:00:43.126152 15018 solver.cpp:243] Iteration 380, loss = 6.0811
I1015 11:00:43.126188 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.78947 (* 1 = 4.78947 loss)
I1015 11:00:43.126194 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.354011 (* 1 = 0.354011 loss)
I1015 11:00:43.126199 15018 sgd_solver.cpp:138] Iteration 380, lr = 0.0005
I1015 11:00:55.509493 15018 solver.cpp:243] Iteration 400, loss = 6.76023
I1015 11:00:55.509523 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.3633 (* 1 = 4.3633 loss)
I1015 11:00:55.509529 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.217661 (* 1 = 0.217661 loss)
I1015 11:00:55.509536 15018 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I1015 11:01:07.844301 15018 solver.cpp:243] Iteration 420, loss = 7.46725
I1015 11:01:07.844336 15018 solver.cpp:259]     Train net output #0: mbox_loss = 9.98381 (* 1 = 9.98381 loss)
I1015 11:01:07.844343 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.277724 (* 1 = 0.277724 loss)
I1015 11:01:07.844349 15018 sgd_solver.cpp:138] Iteration 420, lr = 0.0005
I1015 11:01:20.369628 15018 solver.cpp:243] Iteration 440, loss = 4.98438
I1015 11:01:20.369660 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.1549 (* 1 = 6.1549 loss)
I1015 11:01:20.369668 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12807 (* 1 = 0.12807 loss)
I1015 11:01:20.369673 15018 sgd_solver.cpp:138] Iteration 440, lr = 0.0005
I1015 11:01:32.783748 15018 solver.cpp:243] Iteration 460, loss = 6.00427
I1015 11:01:32.783782 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.86352 (* 1 = 2.86352 loss)
I1015 11:01:32.783788 15018 solver.cpp:259]     Train net output #1: seg_loss = 1.27026 (* 1 = 1.27026 loss)
I1015 11:01:32.783793 15018 sgd_solver.cpp:138] Iteration 460, lr = 0.0005
I1015 11:01:45.211143 15018 solver.cpp:243] Iteration 480, loss = 6.47984
I1015 11:01:45.211179 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.32378 (* 1 = 4.32378 loss)
I1015 11:01:45.211187 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.966408 (* 1 = 0.966408 loss)
I1015 11:01:45.211195 15018 sgd_solver.cpp:138] Iteration 480, lr = 0.0005
I1015 11:01:56.996407 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_500.caffemodel
I1015 11:01:57.300660 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_500.solverstate
I1015 11:01:57.911583 15018 solver.cpp:243] Iteration 500, loss = 5.37157
I1015 11:01:57.911613 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.31614 (* 1 = 6.31614 loss)
I1015 11:01:57.911620 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.172491 (* 1 = 0.172491 loss)
I1015 11:01:57.911626 15018 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I1015 11:02:09.698688 15018 solver.cpp:243] Iteration 520, loss = 5.6868
I1015 11:02:09.698721 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.41961 (* 1 = 4.41961 loss)
I1015 11:02:09.698729 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.11184 (* 1 = 0.11184 loss)
I1015 11:02:09.698734 15018 sgd_solver.cpp:138] Iteration 520, lr = 0.0005
I1015 11:02:21.951917 15018 solver.cpp:243] Iteration 540, loss = 6.47236
I1015 11:02:21.951948 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.35714 (* 1 = 6.35714 loss)
I1015 11:02:21.951954 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.16362 (* 1 = 0.16362 loss)
I1015 11:02:21.951961 15018 sgd_solver.cpp:138] Iteration 540, lr = 0.0005
I1015 11:02:33.890125 15018 solver.cpp:243] Iteration 560, loss = 5.70153
I1015 11:02:33.890172 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.92164 (* 1 = 4.92164 loss)
I1015 11:02:33.890178 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.150382 (* 1 = 0.150382 loss)
I1015 11:02:33.890184 15018 sgd_solver.cpp:138] Iteration 560, lr = 0.0005
I1015 11:02:46.183600 15018 solver.cpp:243] Iteration 580, loss = 6.43559
I1015 11:02:46.183643 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.57445 (* 1 = 5.57445 loss)
I1015 11:02:46.183655 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.156175 (* 1 = 0.156175 loss)
I1015 11:02:46.183660 15018 sgd_solver.cpp:138] Iteration 580, lr = 0.0005
I1015 11:02:58.475471 15018 solver.cpp:243] Iteration 600, loss = 5.33765
I1015 11:02:58.475500 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.69627 (* 1 = 6.69627 loss)
I1015 11:02:58.475507 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115121 (* 1 = 0.115121 loss)
I1015 11:02:58.475512 15018 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I1015 11:03:10.649194 15018 solver.cpp:243] Iteration 620, loss = 6.59511
I1015 11:03:10.649226 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.91415 (* 1 = 4.91415 loss)
I1015 11:03:10.649232 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.176757 (* 1 = 0.176757 loss)
I1015 11:03:10.649238 15018 sgd_solver.cpp:138] Iteration 620, lr = 0.0005
I1015 11:03:22.761689 15018 solver.cpp:243] Iteration 640, loss = 6.55602
I1015 11:03:22.761725 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.70221 (* 1 = 6.70221 loss)
I1015 11:03:22.761734 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.166024 (* 1 = 0.166024 loss)
I1015 11:03:22.761742 15018 sgd_solver.cpp:138] Iteration 640, lr = 0.0005
I1015 11:03:34.858768 15018 solver.cpp:243] Iteration 660, loss = 6.17154
I1015 11:03:34.858800 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.7402 (* 1 = 5.7402 loss)
I1015 11:03:34.858806 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.182973 (* 1 = 0.182973 loss)
I1015 11:03:34.858811 15018 sgd_solver.cpp:138] Iteration 660, lr = 0.0005
I1015 11:03:46.677773 15018 solver.cpp:243] Iteration 680, loss = 6.19756
I1015 11:03:46.677808 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.82721 (* 1 = 6.82721 loss)
I1015 11:03:46.677814 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106762 (* 1 = 0.106762 loss)
I1015 11:03:46.677820 15018 sgd_solver.cpp:138] Iteration 680, lr = 0.0005
I1015 11:03:58.410976 15018 solver.cpp:243] Iteration 700, loss = 6.00854
I1015 11:03:58.411008 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.90485 (* 1 = 5.90485 loss)
I1015 11:03:58.411015 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107394 (* 1 = 0.107394 loss)
I1015 11:03:58.411020 15018 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I1015 11:04:10.292212 15018 solver.cpp:243] Iteration 720, loss = 5.57891
I1015 11:04:10.292243 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.9938 (* 1 = 5.9938 loss)
I1015 11:04:10.292249 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.17699 (* 1 = 0.17699 loss)
I1015 11:04:10.292255 15018 sgd_solver.cpp:138] Iteration 720, lr = 0.0005
I1015 11:04:22.661628 15018 solver.cpp:243] Iteration 740, loss = 7.16624
I1015 11:04:22.661659 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.40311 (* 1 = 5.40311 loss)
I1015 11:04:22.661665 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.123686 (* 1 = 0.123686 loss)
I1015 11:04:22.661670 15018 sgd_solver.cpp:138] Iteration 740, lr = 0.0005
I1015 11:04:35.079140 15018 solver.cpp:243] Iteration 760, loss = 7.45248
I1015 11:04:35.079174 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.55756 (* 1 = 7.55756 loss)
I1015 11:04:35.079180 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.140533 (* 1 = 0.140533 loss)
I1015 11:04:35.079186 15018 sgd_solver.cpp:138] Iteration 760, lr = 0.0005
I1015 11:04:47.484696 15018 solver.cpp:243] Iteration 780, loss = 7.93416
I1015 11:04:47.484728 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.41505 (* 1 = 6.41505 loss)
I1015 11:04:47.484735 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.215343 (* 1 = 0.215343 loss)
I1015 11:04:47.484740 15018 sgd_solver.cpp:138] Iteration 780, lr = 0.0005
I1015 11:04:59.791288 15018 solver.cpp:243] Iteration 800, loss = 7.30227
I1015 11:04:59.791319 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.6577 (* 1 = 5.6577 loss)
I1015 11:04:59.791326 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.108179 (* 1 = 0.108179 loss)
I1015 11:04:59.791332 15018 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I1015 11:05:11.930203 15018 solver.cpp:243] Iteration 820, loss = 5.76812
I1015 11:05:11.930236 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.35141 (* 1 = 6.35141 loss)
I1015 11:05:11.930243 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.173496 (* 1 = 0.173496 loss)
I1015 11:05:11.930248 15018 sgd_solver.cpp:138] Iteration 820, lr = 0.0005
I1015 11:05:24.106145 15018 solver.cpp:243] Iteration 840, loss = 6.01116
I1015 11:05:24.106176 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.20065 (* 1 = 7.20065 loss)
I1015 11:05:24.106184 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.195753 (* 1 = 0.195753 loss)
I1015 11:05:24.106189 15018 sgd_solver.cpp:138] Iteration 840, lr = 0.0005
I1015 11:05:36.264412 15018 solver.cpp:243] Iteration 860, loss = 5.43338
I1015 11:05:36.264446 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.39156 (* 1 = 3.39156 loss)
I1015 11:05:36.264451 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.193669 (* 1 = 0.193669 loss)
I1015 11:05:36.264457 15018 sgd_solver.cpp:138] Iteration 860, lr = 0.0005
I1015 11:05:48.530057 15018 solver.cpp:243] Iteration 880, loss = 5.37059
I1015 11:05:48.530092 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.90347 (* 1 = 2.90347 loss)
I1015 11:05:48.530098 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.205875 (* 1 = 0.205875 loss)
I1015 11:05:48.530103 15018 sgd_solver.cpp:138] Iteration 880, lr = 0.0005
I1015 11:06:00.721961 15018 solver.cpp:243] Iteration 900, loss = 5.62558
I1015 11:06:00.721993 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.51068 (* 1 = 5.51068 loss)
I1015 11:06:00.721999 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.204386 (* 1 = 0.204386 loss)
I1015 11:06:00.722007 15018 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I1015 11:06:13.068197 15018 solver.cpp:243] Iteration 920, loss = 5.67885
I1015 11:06:13.068230 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.37361 (* 1 = 4.37361 loss)
I1015 11:06:13.068236 15018 solver.cpp:259]     Train net output #1: seg_loss = 3.21996 (* 1 = 3.21996 loss)
I1015 11:06:13.068241 15018 sgd_solver.cpp:138] Iteration 920, lr = 0.0005
I1015 11:06:25.429548 15018 solver.cpp:243] Iteration 940, loss = 5.82132
I1015 11:06:25.429589 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.77811 (* 1 = 6.77811 loss)
I1015 11:06:25.429600 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.216583 (* 1 = 0.216583 loss)
I1015 11:06:25.429606 15018 sgd_solver.cpp:138] Iteration 940, lr = 0.0005
I1015 11:06:37.801759 15018 solver.cpp:243] Iteration 960, loss = 6.50985
I1015 11:06:37.801791 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.0527 (* 1 = 5.0527 loss)
I1015 11:06:37.801797 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.186076 (* 1 = 0.186076 loss)
I1015 11:06:37.801802 15018 sgd_solver.cpp:138] Iteration 960, lr = 0.0005
I1015 11:06:50.021436 15018 solver.cpp:243] Iteration 980, loss = 4.10448
I1015 11:06:50.021469 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.28927 (* 1 = 4.28927 loss)
I1015 11:06:50.021476 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117803 (* 1 = 0.117803 loss)
I1015 11:06:50.021482 15018 sgd_solver.cpp:138] Iteration 980, lr = 0.0005
I1015 11:07:02.015612 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1000.caffemodel
I1015 11:07:02.784027 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1000.solverstate
I1015 11:07:02.988467 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 11:07:05.507290 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:08:43.937575 15018 solver.cpp:243] Iteration 1000, loss = 5.77264
I1015 11:08:43.937613 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.55547 (* 1 = 5.55547 loss)
I1015 11:08:43.937619 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.217165 (* 1 = 0.217165 loss)
I1015 11:08:43.937625 15018 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I1015 11:08:55.266147 15018 solver.cpp:243] Iteration 1020, loss = 5.62817
I1015 11:08:55.266186 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.50658 (* 1 = 8.50658 loss)
I1015 11:08:55.266192 15018 solver.cpp:259]     Train net output #1: seg_loss = 2.79368 (* 1 = 2.79368 loss)
I1015 11:08:55.266199 15018 sgd_solver.cpp:138] Iteration 1020, lr = 0.0005
I1015 11:09:07.488278 15018 solver.cpp:243] Iteration 1040, loss = 5.15409
I1015 11:09:07.488309 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.80028 (* 1 = 3.80028 loss)
I1015 11:09:07.488315 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103406 (* 1 = 0.103406 loss)
I1015 11:09:07.488322 15018 sgd_solver.cpp:138] Iteration 1040, lr = 0.0005
I1015 11:09:19.730661 15018 solver.cpp:243] Iteration 1060, loss = 5.69802
I1015 11:09:19.730691 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.07274 (* 1 = 5.07274 loss)
I1015 11:09:19.730696 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.124303 (* 1 = 0.124303 loss)
I1015 11:09:19.730702 15018 sgd_solver.cpp:138] Iteration 1060, lr = 0.0005
I1015 11:09:31.839169 15018 solver.cpp:243] Iteration 1080, loss = 5.79575
I1015 11:09:31.839200 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.99557 (* 1 = 5.99557 loss)
I1015 11:09:31.839206 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.153956 (* 1 = 0.153956 loss)
I1015 11:09:31.839211 15018 sgd_solver.cpp:138] Iteration 1080, lr = 0.0005
I1015 11:09:43.864679 15018 solver.cpp:243] Iteration 1100, loss = 6.19101
I1015 11:09:43.864711 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.40629 (* 1 = 3.40629 loss)
I1015 11:09:43.864717 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0998304 (* 1 = 0.0998304 loss)
I1015 11:09:43.864722 15018 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I1015 11:09:56.051009 15018 solver.cpp:243] Iteration 1120, loss = 6.05111
I1015 11:09:56.051043 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.4819 (* 1 = 7.4819 loss)
I1015 11:09:56.051048 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.243261 (* 1 = 0.243261 loss)
I1015 11:09:56.051055 15018 sgd_solver.cpp:138] Iteration 1120, lr = 0.0005
I1015 11:10:08.326333 15018 solver.cpp:243] Iteration 1140, loss = 4.80141
I1015 11:10:08.326364 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.04401 (* 1 = 5.04401 loss)
I1015 11:10:08.326370 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.114798 (* 1 = 0.114798 loss)
I1015 11:10:08.326376 15018 sgd_solver.cpp:138] Iteration 1140, lr = 0.0005
I1015 11:10:20.553063 15018 solver.cpp:243] Iteration 1160, loss = 5.93825
I1015 11:10:20.553134 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.87604 (* 1 = 6.87604 loss)
I1015 11:10:20.553145 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0988441 (* 1 = 0.0988441 loss)
I1015 11:10:20.553153 15018 sgd_solver.cpp:138] Iteration 1160, lr = 0.0005
I1015 11:10:32.876067 15018 solver.cpp:243] Iteration 1180, loss = 6.06881
I1015 11:10:32.876098 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.81617 (* 1 = 6.81617 loss)
I1015 11:10:32.876104 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.183894 (* 1 = 0.183894 loss)
I1015 11:10:32.876111 15018 sgd_solver.cpp:138] Iteration 1180, lr = 0.0005
I1015 11:10:45.209236 15018 solver.cpp:243] Iteration 1200, loss = 5.71308
I1015 11:10:45.209269 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.01908 (* 1 = 6.01908 loss)
I1015 11:10:45.209275 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117609 (* 1 = 0.117609 loss)
I1015 11:10:45.209280 15018 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I1015 11:10:57.145195 15018 solver.cpp:243] Iteration 1220, loss = 5.68798
I1015 11:10:57.145225 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.83426 (* 1 = 5.83426 loss)
I1015 11:10:57.145231 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12052 (* 1 = 0.12052 loss)
I1015 11:10:57.145236 15018 sgd_solver.cpp:138] Iteration 1220, lr = 0.0005
I1015 11:11:08.824650 15018 solver.cpp:243] Iteration 1240, loss = 5.53997
I1015 11:11:08.824683 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.994 (* 1 = 3.994 loss)
I1015 11:11:08.824692 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0903548 (* 1 = 0.0903548 loss)
I1015 11:11:08.824714 15018 sgd_solver.cpp:138] Iteration 1240, lr = 0.0005
I1015 11:11:20.630548 15018 solver.cpp:243] Iteration 1260, loss = 5.01329
I1015 11:11:20.630580 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.15717 (* 1 = 6.15717 loss)
I1015 11:11:20.630589 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.171414 (* 1 = 0.171414 loss)
I1015 11:11:20.630614 15018 sgd_solver.cpp:138] Iteration 1260, lr = 0.0005
I1015 11:11:32.945914 15018 solver.cpp:243] Iteration 1280, loss = 6.78714
I1015 11:11:32.945960 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.85127 (* 1 = 6.85127 loss)
I1015 11:11:32.945967 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.139083 (* 1 = 0.139083 loss)
I1015 11:11:32.945972 15018 sgd_solver.cpp:138] Iteration 1280, lr = 0.0005
I1015 11:11:45.204207 15018 solver.cpp:243] Iteration 1300, loss = 6.75476
I1015 11:11:45.204257 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.71695 (* 1 = 8.71695 loss)
I1015 11:11:45.204264 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.191569 (* 1 = 0.191569 loss)
I1015 11:11:45.204272 15018 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I1015 11:11:57.580379 15018 solver.cpp:243] Iteration 1320, loss = 7.5993
I1015 11:11:57.580415 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.65643 (* 1 = 8.65643 loss)
I1015 11:11:57.580423 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.150661 (* 1 = 0.150661 loss)
I1015 11:11:57.580446 15018 sgd_solver.cpp:138] Iteration 1320, lr = 0.0005
I1015 11:12:09.740582 15018 solver.cpp:243] Iteration 1340, loss = 7.22353
I1015 11:12:09.740618 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.73312 (* 1 = 7.73312 loss)
I1015 11:12:09.740626 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.29488 (* 1 = 0.29488 loss)
I1015 11:12:09.740634 15018 sgd_solver.cpp:138] Iteration 1340, lr = 0.0005
I1015 11:12:21.785111 15018 solver.cpp:243] Iteration 1360, loss = 5.63286
I1015 11:12:21.785146 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.86196 (* 1 = 3.86196 loss)
I1015 11:12:21.785154 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.116503 (* 1 = 0.116503 loss)
I1015 11:12:21.785161 15018 sgd_solver.cpp:138] Iteration 1360, lr = 0.0005
I1015 11:12:34.224079 15018 solver.cpp:243] Iteration 1380, loss = 5.98819
I1015 11:12:34.224140 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.01528 (* 1 = 4.01528 loss)
I1015 11:12:34.224146 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.205097 (* 1 = 0.205097 loss)
I1015 11:12:34.224151 15018 sgd_solver.cpp:138] Iteration 1380, lr = 0.0005
I1015 11:12:46.338065 15018 solver.cpp:243] Iteration 1400, loss = 4.99643
I1015 11:12:46.338095 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.04794 (* 1 = 3.04794 loss)
I1015 11:12:46.338100 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.158218 (* 1 = 0.158218 loss)
I1015 11:12:46.338106 15018 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I1015 11:12:58.682760 15018 solver.cpp:243] Iteration 1420, loss = 5.5402
I1015 11:12:58.682796 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.78578 (* 1 = 3.78578 loss)
I1015 11:12:58.682804 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.222709 (* 1 = 0.222709 loss)
I1015 11:12:58.682812 15018 sgd_solver.cpp:138] Iteration 1420, lr = 0.0005
I1015 11:13:10.827864 15018 solver.cpp:243] Iteration 1440, loss = 4.95766
I1015 11:13:10.827898 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.87362 (* 1 = 2.87362 loss)
I1015 11:13:10.827905 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110107 (* 1 = 0.110107 loss)
I1015 11:13:10.827929 15018 sgd_solver.cpp:138] Iteration 1440, lr = 0.0005
I1015 11:13:23.182445 15018 solver.cpp:243] Iteration 1460, loss = 5.66311
I1015 11:13:23.182478 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.48512 (* 1 = 5.48512 loss)
I1015 11:13:23.182483 15018 solver.cpp:259]     Train net output #1: seg_loss = 3.11357 (* 1 = 3.11357 loss)
I1015 11:13:23.182489 15018 sgd_solver.cpp:138] Iteration 1460, lr = 0.0005
I1015 11:13:35.601078 15018 solver.cpp:243] Iteration 1480, loss = 4.98596
I1015 11:13:35.601126 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.8764 (* 1 = 4.8764 loss)
I1015 11:13:35.601132 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125022 (* 1 = 0.125022 loss)
I1015 11:13:35.601137 15018 sgd_solver.cpp:138] Iteration 1480, lr = 0.0005
I1015 11:13:47.546900 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1500.caffemodel
I1015 11:13:48.628077 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1500.solverstate
I1015 11:13:49.749142 15018 solver.cpp:243] Iteration 1500, loss = 6.04332
I1015 11:13:49.749176 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.24482 (* 1 = 3.24482 loss)
I1015 11:13:49.749183 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.145412 (* 1 = 0.145412 loss)
I1015 11:13:49.749188 15018 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I1015 11:14:00.706652 15018 solver.cpp:243] Iteration 1520, loss = 3.86825
I1015 11:14:00.706687 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.93187 (* 1 = 2.93187 loss)
I1015 11:14:00.706696 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0920674 (* 1 = 0.0920674 loss)
I1015 11:14:00.706704 15018 sgd_solver.cpp:138] Iteration 1520, lr = 0.0005
I1015 11:14:06.163875 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:14:12.879156 15018 solver.cpp:243] Iteration 1540, loss = 5.46153
I1015 11:14:12.879190 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.05456 (* 1 = 5.05456 loss)
I1015 11:14:12.879199 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120429 (* 1 = 0.120429 loss)
I1015 11:14:12.879222 15018 sgd_solver.cpp:138] Iteration 1540, lr = 0.0005
I1015 11:14:25.190418 15018 solver.cpp:243] Iteration 1560, loss = 4.01281
I1015 11:14:25.190451 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.81894 (* 1 = 2.81894 loss)
I1015 11:14:25.190459 15018 solver.cpp:259]     Train net output #1: seg_loss = 1.6309 (* 1 = 1.6309 loss)
I1015 11:14:25.190482 15018 sgd_solver.cpp:138] Iteration 1560, lr = 0.0005
I1015 11:14:37.186221 15018 solver.cpp:243] Iteration 1580, loss = 4.89722
I1015 11:14:37.186257 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.89757 (* 1 = 2.89757 loss)
I1015 11:14:37.186266 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.122439 (* 1 = 0.122439 loss)
I1015 11:14:37.186288 15018 sgd_solver.cpp:138] Iteration 1580, lr = 0.0005
I1015 11:14:49.198166 15018 solver.cpp:243] Iteration 1600, loss = 5.47846
I1015 11:14:49.198204 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.39088 (* 1 = 2.39088 loss)
I1015 11:14:49.198212 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0830088 (* 1 = 0.0830088 loss)
I1015 11:14:49.198220 15018 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I1015 11:15:01.167946 15018 solver.cpp:243] Iteration 1620, loss = 5.97321
I1015 11:15:01.167980 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.33414 (* 1 = 6.33414 loss)
I1015 11:15:01.167989 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.143269 (* 1 = 0.143269 loss)
I1015 11:15:01.168011 15018 sgd_solver.cpp:138] Iteration 1620, lr = 0.0005
I1015 11:15:12.952531 15018 solver.cpp:243] Iteration 1640, loss = 6.06425
I1015 11:15:12.952566 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.72055 (* 1 = 4.72055 loss)
I1015 11:15:12.952575 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112556 (* 1 = 0.112556 loss)
I1015 11:15:12.952599 15018 sgd_solver.cpp:138] Iteration 1640, lr = 0.0005
I1015 11:15:24.863319 15018 solver.cpp:243] Iteration 1660, loss = 5.13698
I1015 11:15:24.863353 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.23903 (* 1 = 6.23903 loss)
I1015 11:15:24.863361 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.264004 (* 1 = 0.264004 loss)
I1015 11:15:24.863384 15018 sgd_solver.cpp:138] Iteration 1660, lr = 0.0005
I1015 11:15:36.893420 15018 solver.cpp:243] Iteration 1680, loss = 4.80656
I1015 11:15:36.893453 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.21459 (* 1 = 2.21459 loss)
I1015 11:15:36.893462 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106455 (* 1 = 0.106455 loss)
I1015 11:15:36.893470 15018 sgd_solver.cpp:138] Iteration 1680, lr = 0.0005
I1015 11:15:48.896100 15018 solver.cpp:243] Iteration 1700, loss = 5.40643
I1015 11:15:48.896150 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.88751 (* 1 = 4.88751 loss)
I1015 11:15:48.896157 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0918961 (* 1 = 0.0918961 loss)
I1015 11:15:48.896162 15018 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I1015 11:16:00.780697 15018 solver.cpp:243] Iteration 1720, loss = 5.20226
I1015 11:16:00.780730 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.6806 (* 1 = 6.6806 loss)
I1015 11:16:00.780735 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.126347 (* 1 = 0.126347 loss)
I1015 11:16:00.780740 15018 sgd_solver.cpp:138] Iteration 1720, lr = 0.0005
I1015 11:16:12.728118 15018 solver.cpp:243] Iteration 1740, loss = 5.1693
I1015 11:16:12.728149 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.6231 (* 1 = 6.6231 loss)
I1015 11:16:12.728157 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.144946 (* 1 = 0.144946 loss)
I1015 11:16:12.728161 15018 sgd_solver.cpp:138] Iteration 1740, lr = 0.0005
I1015 11:16:24.471326 15018 solver.cpp:243] Iteration 1760, loss = 5.0919
I1015 11:16:24.471359 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.78368 (* 1 = 5.78368 loss)
I1015 11:16:24.471365 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0880588 (* 1 = 0.0880588 loss)
I1015 11:16:24.471371 15018 sgd_solver.cpp:138] Iteration 1760, lr = 0.0005
I1015 11:16:36.053462 15018 solver.cpp:243] Iteration 1780, loss = 5.68339
I1015 11:16:36.053496 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.31028 (* 1 = 4.31028 loss)
I1015 11:16:36.053503 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0710607 (* 1 = 0.0710607 loss)
I1015 11:16:36.053508 15018 sgd_solver.cpp:138] Iteration 1780, lr = 0.0005
I1015 11:16:47.771912 15018 solver.cpp:243] Iteration 1800, loss = 4.74107
I1015 11:16:47.771958 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.71709 (* 1 = 5.71709 loss)
I1015 11:16:47.771965 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.184634 (* 1 = 0.184634 loss)
I1015 11:16:47.771971 15018 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I1015 11:16:59.947902 15018 solver.cpp:243] Iteration 1820, loss = 6.08982
I1015 11:16:59.947952 15018 solver.cpp:259]     Train net output #0: mbox_loss = 9.61315 (* 1 = 9.61315 loss)
I1015 11:16:59.947958 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.16653 (* 1 = 0.16653 loss)
I1015 11:16:59.947964 15018 sgd_solver.cpp:138] Iteration 1820, lr = 0.0005
I1015 11:17:12.044270 15018 solver.cpp:243] Iteration 1840, loss = 5.97877
I1015 11:17:12.044309 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.10566 (* 1 = 5.10566 loss)
I1015 11:17:12.044318 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.114019 (* 1 = 0.114019 loss)
I1015 11:17:12.044325 15018 sgd_solver.cpp:138] Iteration 1840, lr = 0.0005
I1015 11:17:24.199069 15018 solver.cpp:243] Iteration 1860, loss = 7.15614
I1015 11:17:24.199106 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.93474 (* 1 = 5.93474 loss)
I1015 11:17:24.199131 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125009 (* 1 = 0.125009 loss)
I1015 11:17:24.199137 15018 sgd_solver.cpp:138] Iteration 1860, lr = 0.0005
I1015 11:17:36.341377 15018 solver.cpp:243] Iteration 1880, loss = 6.38239
I1015 11:17:36.341413 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.52503 (* 1 = 2.52503 loss)
I1015 11:17:36.341421 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.161157 (* 1 = 0.161157 loss)
I1015 11:17:36.341429 15018 sgd_solver.cpp:138] Iteration 1880, lr = 0.0005
I1015 11:17:48.201813 15018 solver.cpp:243] Iteration 1900, loss = 6.10838
I1015 11:17:48.201860 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.34505 (* 1 = 4.34505 loss)
I1015 11:17:48.201866 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.224578 (* 1 = 0.224578 loss)
I1015 11:17:48.201872 15018 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I1015 11:18:00.156033 15018 solver.cpp:243] Iteration 1920, loss = 5.08759
I1015 11:18:00.156072 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.46244 (* 1 = 5.46244 loss)
I1015 11:18:00.156080 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.155102 (* 1 = 0.155102 loss)
I1015 11:18:00.156085 15018 sgd_solver.cpp:138] Iteration 1920, lr = 0.0005
I1015 11:18:12.063976 15018 solver.cpp:243] Iteration 1940, loss = 4.51308
I1015 11:18:12.064008 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.41916 (* 1 = 6.41916 loss)
I1015 11:18:12.064014 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.135627 (* 1 = 0.135627 loss)
I1015 11:18:12.064019 15018 sgd_solver.cpp:138] Iteration 1940, lr = 0.0005
I1015 11:18:24.067888 15018 solver.cpp:243] Iteration 1960, loss = 5.82155
I1015 11:18:24.067939 15018 solver.cpp:259]     Train net output #0: mbox_loss = 8.20858 (* 1 = 8.20858 loss)
I1015 11:18:24.067945 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106605 (* 1 = 0.106605 loss)
I1015 11:18:24.067950 15018 sgd_solver.cpp:138] Iteration 1960, lr = 0.0005
I1015 11:18:36.046185 15018 solver.cpp:243] Iteration 1980, loss = 5.32769
I1015 11:18:36.046232 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.29871 (* 1 = 5.29871 loss)
I1015 11:18:36.046238 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.143931 (* 1 = 0.143931 loss)
I1015 11:18:36.046244 15018 sgd_solver.cpp:138] Iteration 1980, lr = 0.0005
I1015 11:18:47.665729 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2000.caffemodel
I1015 11:18:47.906692 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2000.solverstate
I1015 11:18:48.096326 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 11:20:26.023563 15018 solver.cpp:243] Iteration 2000, loss = 4.23952
I1015 11:20:26.023593 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.07684 (* 1 = 4.07684 loss)
I1015 11:20:26.023599 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.162677 (* 1 = 0.162677 loss)
I1015 11:20:26.023605 15018 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I1015 11:20:37.168630 15018 solver.cpp:243] Iteration 2020, loss = 4.77552
I1015 11:20:37.168676 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.42217 (* 1 = 3.42217 loss)
I1015 11:20:37.168684 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115715 (* 1 = 0.115715 loss)
I1015 11:20:37.168689 15018 sgd_solver.cpp:138] Iteration 2020, lr = 0.0005
I1015 11:20:48.721138 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:20:49.263263 15018 solver.cpp:243] Iteration 2040, loss = 6.46392
I1015 11:20:49.263295 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.28498 (* 1 = 6.28498 loss)
I1015 11:20:49.263301 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112676 (* 1 = 0.112676 loss)
I1015 11:20:49.263308 15018 sgd_solver.cpp:138] Iteration 2040, lr = 0.0005
I1015 11:21:01.321895 15018 solver.cpp:243] Iteration 2060, loss = 3.84936
I1015 11:21:01.321928 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.12004 (* 1 = 2.12004 loss)
I1015 11:21:01.321934 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0832029 (* 1 = 0.0832029 loss)
I1015 11:21:01.321939 15018 sgd_solver.cpp:138] Iteration 2060, lr = 0.0005
I1015 11:21:13.430423 15018 solver.cpp:243] Iteration 2080, loss = 5.25359
I1015 11:21:13.430455 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.7758 (* 1 = 2.7758 loss)
I1015 11:21:13.430461 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0968182 (* 1 = 0.0968182 loss)
I1015 11:21:13.430466 15018 sgd_solver.cpp:138] Iteration 2080, lr = 0.0005
I1015 11:21:25.730316 15018 solver.cpp:243] Iteration 2100, loss = 3.95068
I1015 11:21:25.730365 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.59297 (* 1 = 3.59297 loss)
I1015 11:21:25.730370 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12319 (* 1 = 0.12319 loss)
I1015 11:21:25.730376 15018 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I1015 11:21:37.702131 15018 solver.cpp:243] Iteration 2120, loss = 5.2114
I1015 11:21:37.702178 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.69227 (* 1 = 4.69227 loss)
I1015 11:21:37.702183 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.084012 (* 1 = 0.084012 loss)
I1015 11:21:37.702189 15018 sgd_solver.cpp:138] Iteration 2120, lr = 0.0005
I1015 11:21:49.811628 15018 solver.cpp:243] Iteration 2140, loss = 5.87338
I1015 11:21:49.811662 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.72716 (* 1 = 5.72716 loss)
I1015 11:21:49.811668 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0838494 (* 1 = 0.0838494 loss)
I1015 11:21:49.811674 15018 sgd_solver.cpp:138] Iteration 2140, lr = 0.0005
I1015 11:22:01.772958 15018 solver.cpp:243] Iteration 2160, loss = 5.94312
I1015 11:22:01.773008 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.20566 (* 1 = 6.20566 loss)
I1015 11:22:01.773015 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.136922 (* 1 = 0.136922 loss)
I1015 11:22:01.773020 15018 sgd_solver.cpp:138] Iteration 2160, lr = 0.0005
I1015 11:22:13.594687 15018 solver.cpp:243] Iteration 2180, loss = 5.9035
I1015 11:22:13.594738 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.52875 (* 1 = 3.52875 loss)
I1015 11:22:13.594743 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.141504 (* 1 = 0.141504 loss)
I1015 11:22:13.594749 15018 sgd_solver.cpp:138] Iteration 2180, lr = 0.0005
I1015 11:22:25.514343 15018 solver.cpp:243] Iteration 2200, loss = 4.97012
I1015 11:22:25.514394 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.60933 (* 1 = 3.60933 loss)
I1015 11:22:25.514400 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.1321 (* 1 = 0.1321 loss)
I1015 11:22:25.514405 15018 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I1015 11:22:37.526667 15018 solver.cpp:243] Iteration 2220, loss = 4.9746
I1015 11:22:37.526716 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.77865 (* 1 = 2.77865 loss)
I1015 11:22:37.526723 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0938265 (* 1 = 0.0938265 loss)
I1015 11:22:37.526729 15018 sgd_solver.cpp:138] Iteration 2220, lr = 0.0005
I1015 11:22:49.499681 15018 solver.cpp:243] Iteration 2240, loss = 5.00183
I1015 11:22:49.499730 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15536 (* 1 = 3.15536 loss)
I1015 11:22:49.499737 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.151891 (* 1 = 0.151891 loss)
I1015 11:22:49.499742 15018 sgd_solver.cpp:138] Iteration 2240, lr = 0.0005
I1015 11:23:01.353842 15018 solver.cpp:243] Iteration 2260, loss = 4.47635
I1015 11:23:01.353893 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.52704 (* 1 = 3.52704 loss)
I1015 11:23:01.353899 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106825 (* 1 = 0.106825 loss)
I1015 11:23:01.353904 15018 sgd_solver.cpp:138] Iteration 2260, lr = 0.0005
I1015 11:23:13.288002 15018 solver.cpp:243] Iteration 2280, loss = 4.98119
I1015 11:23:13.288038 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.78065 (* 1 = 3.78065 loss)
I1015 11:23:13.288043 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.172648 (* 1 = 0.172648 loss)
I1015 11:23:13.288048 15018 sgd_solver.cpp:138] Iteration 2280, lr = 0.0005
I1015 11:23:25.083559 15018 solver.cpp:243] Iteration 2300, loss = 4.64356
I1015 11:23:25.083592 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.5031 (* 1 = 4.5031 loss)
I1015 11:23:25.083598 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0970749 (* 1 = 0.0970749 loss)
I1015 11:23:25.083604 15018 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I1015 11:23:36.598012 15018 solver.cpp:243] Iteration 2320, loss = 5.06832
I1015 11:23:36.598059 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.34449 (* 1 = 6.34449 loss)
I1015 11:23:36.598065 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0780445 (* 1 = 0.0780445 loss)
I1015 11:23:36.598071 15018 sgd_solver.cpp:138] Iteration 2320, lr = 0.0005
I1015 11:23:48.185016 15018 solver.cpp:243] Iteration 2340, loss = 4.67368
I1015 11:23:48.185050 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.71324 (* 1 = 5.71324 loss)
I1015 11:23:48.185056 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0914632 (* 1 = 0.0914632 loss)
I1015 11:23:48.185061 15018 sgd_solver.cpp:138] Iteration 2340, lr = 0.0005
I1015 11:24:00.404866 15018 solver.cpp:243] Iteration 2360, loss = 5.41199
I1015 11:24:00.404917 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.23444 (* 1 = 4.23444 loss)
I1015 11:24:00.404922 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12252 (* 1 = 0.12252 loss)
I1015 11:24:00.404927 15018 sgd_solver.cpp:138] Iteration 2360, lr = 0.0005
I1015 11:24:12.576930 15018 solver.cpp:243] Iteration 2380, loss = 5.69368
I1015 11:24:12.576964 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.33105 (* 1 = 6.33105 loss)
I1015 11:24:12.576970 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112443 (* 1 = 0.112443 loss)
I1015 11:24:12.576975 15018 sgd_solver.cpp:138] Iteration 2380, lr = 0.0005
I1015 11:24:24.732302 15018 solver.cpp:243] Iteration 2400, loss = 6.89183
I1015 11:24:24.732336 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.52604 (* 1 = 7.52604 loss)
I1015 11:24:24.732342 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0955947 (* 1 = 0.0955947 loss)
I1015 11:24:24.732347 15018 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I1015 11:24:36.824805 15018 solver.cpp:243] Iteration 2420, loss = 6.32586
I1015 11:24:36.824838 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.02347 (* 1 = 6.02347 loss)
I1015 11:24:36.824844 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112235 (* 1 = 0.112235 loss)
I1015 11:24:36.824851 15018 sgd_solver.cpp:138] Iteration 2420, lr = 0.0005
I1015 11:24:48.784302 15018 solver.cpp:243] Iteration 2440, loss = 6.22713
I1015 11:24:48.784366 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.08283 (* 1 = 4.08283 loss)
I1015 11:24:48.784373 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.145753 (* 1 = 0.145753 loss)
I1015 11:24:48.784379 15018 sgd_solver.cpp:138] Iteration 2440, lr = 0.0005
I1015 11:25:00.734760 15018 solver.cpp:243] Iteration 2460, loss = 4.31308
I1015 11:25:00.734796 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.24922 (* 1 = 3.24922 loss)
I1015 11:25:00.734802 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0933488 (* 1 = 0.0933488 loss)
I1015 11:25:00.734807 15018 sgd_solver.cpp:138] Iteration 2460, lr = 0.0005
I1015 11:25:12.676134 15018 solver.cpp:243] Iteration 2480, loss = 3.94306
I1015 11:25:12.676169 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.95599 (* 1 = 3.95599 loss)
I1015 11:25:12.676177 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101264 (* 1 = 0.101264 loss)
I1015 11:25:12.676182 15018 sgd_solver.cpp:138] Iteration 2480, lr = 0.0005
I1015 11:25:24.148103 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2500.caffemodel
I1015 11:25:24.911176 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2500.solverstate
I1015 11:25:25.507767 15018 solver.cpp:243] Iteration 2500, loss = 5.35491
I1015 11:25:25.507812 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.75449 (* 1 = 6.75449 loss)
I1015 11:25:25.507818 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101642 (* 1 = 0.101642 loss)
I1015 11:25:25.507824 15018 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I1015 11:25:36.788070 15018 solver.cpp:243] Iteration 2520, loss = 5.06071
I1015 11:25:36.788116 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.26919 (* 1 = 3.26919 loss)
I1015 11:25:36.788122 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0988894 (* 1 = 0.0988894 loss)
I1015 11:25:36.788128 15018 sgd_solver.cpp:138] Iteration 2520, lr = 0.0005
I1015 11:25:48.978327 15018 solver.cpp:243] Iteration 2540, loss = 5.15332
I1015 11:25:48.978359 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.4143 (* 1 = 3.4143 loss)
I1015 11:25:48.978365 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.156055 (* 1 = 0.156055 loss)
I1015 11:25:48.978370 15018 sgd_solver.cpp:138] Iteration 2540, lr = 0.0005
I1015 11:26:01.190943 15018 solver.cpp:243] Iteration 2560, loss = 5.44447
I1015 11:26:01.190991 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.72579 (* 1 = 3.72579 loss)
I1015 11:26:01.190997 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.119971 (* 1 = 0.119971 loss)
I1015 11:26:01.191004 15018 sgd_solver.cpp:138] Iteration 2560, lr = 0.0005
I1015 11:26:13.334329 15018 solver.cpp:243] Iteration 2580, loss = 5.83313
I1015 11:26:13.334376 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.26604 (* 1 = 6.26604 loss)
I1015 11:26:13.334383 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.180973 (* 1 = 0.180973 loss)
I1015 11:26:13.334389 15018 sgd_solver.cpp:138] Iteration 2580, lr = 0.0005
I1015 11:26:25.400691 15018 solver.cpp:243] Iteration 2600, loss = 4.08159
I1015 11:26:25.400722 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.15086 (* 1 = 4.15086 loss)
I1015 11:26:25.400728 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120279 (* 1 = 0.120279 loss)
I1015 11:26:25.400734 15018 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I1015 11:26:37.495002 15018 solver.cpp:243] Iteration 2620, loss = 5.0004
I1015 11:26:37.495038 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.30187 (* 1 = 4.30187 loss)
I1015 11:26:37.495048 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102735 (* 1 = 0.102735 loss)
I1015 11:26:37.495055 15018 sgd_solver.cpp:138] Iteration 2620, lr = 0.0005
I1015 11:26:49.806366 15018 solver.cpp:243] Iteration 2640, loss = 3.63879
I1015 11:26:49.806402 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.4281 (* 1 = 2.4281 loss)
I1015 11:26:49.806427 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101549 (* 1 = 0.101549 loss)
I1015 11:26:49.806434 15018 sgd_solver.cpp:138] Iteration 2640, lr = 0.0005
I1015 11:27:01.763166 15018 solver.cpp:243] Iteration 2660, loss = 4.81682
I1015 11:27:01.763202 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.56562 (* 1 = 1.56562 loss)
I1015 11:27:01.763211 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.1106 (* 1 = 0.1106 loss)
I1015 11:27:01.763219 15018 sgd_solver.cpp:138] Iteration 2660, lr = 0.0005
I1015 11:27:13.826380 15018 solver.cpp:243] Iteration 2680, loss = 5.487
I1015 11:27:13.826416 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.60066 (* 1 = 7.60066 loss)
I1015 11:27:13.826426 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0869275 (* 1 = 0.0869275 loss)
I1015 11:27:13.826432 15018 sgd_solver.cpp:138] Iteration 2680, lr = 0.0005
I1015 11:27:25.689510 15018 solver.cpp:243] Iteration 2700, loss = 5.5146
I1015 11:27:25.689544 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.02271 (* 1 = 4.02271 loss)
I1015 11:27:25.689553 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.11109 (* 1 = 0.11109 loss)
I1015 11:27:25.689561 15018 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I1015 11:27:37.546631 15018 solver.cpp:243] Iteration 2720, loss = 5.9288
I1015 11:27:37.546665 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.9184 (* 1 = 2.9184 loss)
I1015 11:27:37.546675 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0742228 (* 1 = 0.0742228 loss)
I1015 11:27:37.546699 15018 sgd_solver.cpp:138] Iteration 2720, lr = 0.0005
I1015 11:27:49.364398 15018 solver.cpp:243] Iteration 2740, loss = 5.13716
I1015 11:27:49.364431 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.21762 (* 1 = 5.21762 loss)
I1015 11:27:49.364439 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.109161 (* 1 = 0.109161 loss)
I1015 11:27:49.364464 15018 sgd_solver.cpp:138] Iteration 2740, lr = 0.0005
I1015 11:28:01.355206 15018 solver.cpp:243] Iteration 2760, loss = 5.14599
I1015 11:28:01.355242 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.86647 (* 1 = 6.86647 loss)
I1015 11:28:01.355249 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111659 (* 1 = 0.111659 loss)
I1015 11:28:01.355273 15018 sgd_solver.cpp:138] Iteration 2760, lr = 0.0005
I1015 11:28:13.338187 15018 solver.cpp:243] Iteration 2780, loss = 5.07067
I1015 11:28:13.338222 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.82611 (* 1 = 3.82611 loss)
I1015 11:28:13.338230 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0892255 (* 1 = 0.0892255 loss)
I1015 11:28:13.338253 15018 sgd_solver.cpp:138] Iteration 2780, lr = 0.0005
I1015 11:28:25.202877 15018 solver.cpp:243] Iteration 2800, loss = 4.22966
I1015 11:28:25.202914 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.31575 (* 1 = 4.31575 loss)
I1015 11:28:25.202924 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104058 (* 1 = 0.104058 loss)
I1015 11:28:25.202946 15018 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I1015 11:28:37.160730 15018 solver.cpp:243] Iteration 2820, loss = 5.00289
I1015 11:28:37.160764 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.47429 (* 1 = 6.47429 loss)
I1015 11:28:37.160789 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105887 (* 1 = 0.105887 loss)
I1015 11:28:37.160796 15018 sgd_solver.cpp:138] Iteration 2820, lr = 0.0005
I1015 11:28:48.948227 15018 solver.cpp:243] Iteration 2840, loss = 4.35735
I1015 11:28:48.948264 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.21268 (* 1 = 3.21268 loss)
I1015 11:28:48.948273 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.090171 (* 1 = 0.090171 loss)
I1015 11:28:48.948297 15018 sgd_solver.cpp:138] Iteration 2840, lr = 0.0005
I1015 11:29:00.533907 15018 solver.cpp:243] Iteration 2860, loss = 4.61928
I1015 11:29:00.533942 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.11335 (* 1 = 6.11335 loss)
I1015 11:29:00.533951 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103977 (* 1 = 0.103977 loss)
I1015 11:29:00.533974 15018 sgd_solver.cpp:138] Iteration 2860, lr = 0.0005
I1015 11:29:12.123385 15018 solver.cpp:243] Iteration 2880, loss = 4.24839
I1015 11:29:12.123422 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.72128 (* 1 = 2.72128 loss)
I1015 11:29:12.123431 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.085306 (* 1 = 0.085306 loss)
I1015 11:29:12.123440 15018 sgd_solver.cpp:138] Iteration 2880, lr = 0.0005
I1015 11:29:24.232631 15018 solver.cpp:243] Iteration 2900, loss = 5.13003
I1015 11:29:24.232663 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.93105 (* 1 = 7.93105 loss)
I1015 11:29:24.232671 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125019 (* 1 = 0.125019 loss)
I1015 11:29:24.232694 15018 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I1015 11:29:36.304528 15018 solver.cpp:243] Iteration 2920, loss = 5.58811
I1015 11:29:36.304565 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.26789 (* 1 = 7.26789 loss)
I1015 11:29:36.304574 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.179065 (* 1 = 0.179065 loss)
I1015 11:29:36.304596 15018 sgd_solver.cpp:138] Iteration 2920, lr = 0.0005
I1015 11:29:48.508384 15018 solver.cpp:243] Iteration 2940, loss = 6.46614
I1015 11:29:48.508419 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.95155 (* 1 = 6.95155 loss)
I1015 11:29:48.508428 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.126754 (* 1 = 0.126754 loss)
I1015 11:29:48.508451 15018 sgd_solver.cpp:138] Iteration 2940, lr = 0.0005
I1015 11:30:00.594295 15018 solver.cpp:243] Iteration 2960, loss = 6.25218
I1015 11:30:00.594331 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.11402 (* 1 = 5.11402 loss)
I1015 11:30:00.594339 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.180631 (* 1 = 0.180631 loss)
I1015 11:30:00.594348 15018 sgd_solver.cpp:138] Iteration 2960, lr = 0.0005
I1015 11:30:12.542126 15018 solver.cpp:243] Iteration 2980, loss = 6.1741
I1015 11:30:12.542163 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.68352 (* 1 = 5.68352 loss)
I1015 11:30:12.542172 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.274759 (* 1 = 0.274759 loss)
I1015 11:30:12.542196 15018 sgd_solver.cpp:138] Iteration 2980, lr = 0.0005
I1015 11:30:23.982383 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3000.caffemodel
I1015 11:30:24.222769 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3000.solverstate
I1015 11:30:24.445726 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 11:30:33.392439 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:32:03.053469 15018 solver.cpp:243] Iteration 3000, loss = 5.00638
I1015 11:32:03.053505 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.85761 (* 1 = 4.85761 loss)
I1015 11:32:03.053514 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.148766 (* 1 = 0.148766 loss)
I1015 11:32:03.053524 15018 sgd_solver.cpp:138] Iteration 3000, lr = 0.0005
I1015 11:32:13.960484 15018 solver.cpp:243] Iteration 3020, loss = 3.93423
I1015 11:32:13.960520 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.40882 (* 1 = 4.40882 loss)
I1015 11:32:13.960528 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0900792 (* 1 = 0.0900792 loss)
I1015 11:32:13.960552 15018 sgd_solver.cpp:138] Iteration 3020, lr = 0.0005
I1015 11:32:25.942278 15018 solver.cpp:243] Iteration 3040, loss = 5.31944
I1015 11:32:25.942313 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.79197 (* 1 = 3.79197 loss)
I1015 11:32:25.942322 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.146356 (* 1 = 0.146356 loss)
I1015 11:32:25.942344 15018 sgd_solver.cpp:138] Iteration 3040, lr = 0.0005
I1015 11:32:37.899408 15018 solver.cpp:243] Iteration 3060, loss = 5.23903
I1015 11:32:37.899446 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.01389 (* 1 = 7.01389 loss)
I1015 11:32:37.899453 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0962446 (* 1 = 0.0962446 loss)
I1015 11:32:37.899477 15018 sgd_solver.cpp:138] Iteration 3060, lr = 0.0005
I1015 11:32:50.047118 15018 solver.cpp:243] Iteration 3080, loss = 5.03285
I1015 11:32:50.047168 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.26692 (* 1 = 5.26692 loss)
I1015 11:32:50.047174 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.249549 (* 1 = 0.249549 loss)
I1015 11:32:50.047179 15018 sgd_solver.cpp:138] Iteration 3080, lr = 0.0005
I1015 11:33:02.158020 15018 solver.cpp:243] Iteration 3100, loss = 4.9537
I1015 11:33:02.158072 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.02677 (* 1 = 6.02677 loss)
I1015 11:33:02.158078 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.143942 (* 1 = 0.143942 loss)
I1015 11:33:02.158084 15018 sgd_solver.cpp:138] Iteration 3100, lr = 0.0005
I1015 11:33:14.281924 15018 solver.cpp:243] Iteration 3120, loss = 5.54719
I1015 11:33:14.281958 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.82781 (* 1 = 6.82781 loss)
I1015 11:33:14.281967 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0924777 (* 1 = 0.0924777 loss)
I1015 11:33:14.281991 15018 sgd_solver.cpp:138] Iteration 3120, lr = 0.0005
I1015 11:33:26.378844 15018 solver.cpp:243] Iteration 3140, loss = 3.65112
I1015 11:33:26.378880 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.135 (* 1 = 5.135 loss)
I1015 11:33:26.378903 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117435 (* 1 = 0.117435 loss)
I1015 11:33:26.378911 15018 sgd_solver.cpp:138] Iteration 3140, lr = 0.0005
I1015 11:33:38.492861 15018 solver.cpp:243] Iteration 3160, loss = 4.42723
I1015 11:33:38.492898 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.61441 (* 1 = 4.61441 loss)
I1015 11:33:38.492908 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102926 (* 1 = 0.102926 loss)
I1015 11:33:38.492930 15018 sgd_solver.cpp:138] Iteration 3160, lr = 0.0005
I1015 11:33:50.774585 15018 solver.cpp:243] Iteration 3180, loss = 3.59505
I1015 11:33:50.774619 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.73493 (* 1 = 4.73493 loss)
I1015 11:33:50.774643 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.138482 (* 1 = 0.138482 loss)
I1015 11:33:50.774652 15018 sgd_solver.cpp:138] Iteration 3180, lr = 0.0005
I1015 11:34:02.805816 15018 solver.cpp:243] Iteration 3200, loss = 5.03266
I1015 11:34:02.805850 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.5456 (* 1 = 4.5456 loss)
I1015 11:34:02.805856 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0938469 (* 1 = 0.0938469 loss)
I1015 11:34:02.805862 15018 sgd_solver.cpp:138] Iteration 3200, lr = 0.0005
I1015 11:34:14.856009 15018 solver.cpp:243] Iteration 3220, loss = 4.48767
I1015 11:34:14.856058 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.05849 (* 1 = 7.05849 loss)
I1015 11:34:14.856065 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.627885 (* 1 = 0.627885 loss)
I1015 11:34:14.856070 15018 sgd_solver.cpp:138] Iteration 3220, lr = 0.0005
I1015 11:34:26.756685 15018 solver.cpp:243] Iteration 3240, loss = 5.24394
I1015 11:34:26.756731 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.14153 (* 1 = 6.14153 loss)
I1015 11:34:26.756737 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.146642 (* 1 = 0.146642 loss)
I1015 11:34:26.756743 15018 sgd_solver.cpp:138] Iteration 3240, lr = 0.0005
I1015 11:34:38.639109 15018 solver.cpp:243] Iteration 3260, loss = 6.39663
I1015 11:34:38.639145 15018 solver.cpp:259]     Train net output #0: mbox_loss = 10.5855 (* 1 = 10.5855 loss)
I1015 11:34:38.639151 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0980297 (* 1 = 0.0980297 loss)
I1015 11:34:38.639158 15018 sgd_solver.cpp:138] Iteration 3260, lr = 0.0005
I1015 11:34:50.478219 15018 solver.cpp:243] Iteration 3280, loss = 5.10235
I1015 11:34:50.478266 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.77417 (* 1 = 5.77417 loss)
I1015 11:34:50.478272 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120637 (* 1 = 0.120637 loss)
I1015 11:34:50.478278 15018 sgd_solver.cpp:138] Iteration 3280, lr = 0.0005
I1015 11:35:02.509413 15018 solver.cpp:243] Iteration 3300, loss = 4.9554
I1015 11:35:02.509443 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.61554 (* 1 = 3.61554 loss)
I1015 11:35:02.509447 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0717271 (* 1 = 0.0717271 loss)
I1015 11:35:02.509454 15018 sgd_solver.cpp:138] Iteration 3300, lr = 0.0005
I1015 11:35:14.490804 15018 solver.cpp:243] Iteration 3320, loss = 5.02623
I1015 11:35:14.490839 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.09964 (* 1 = 6.09964 loss)
I1015 11:35:14.490844 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0865054 (* 1 = 0.0865054 loss)
I1015 11:35:14.490850 15018 sgd_solver.cpp:138] Iteration 3320, lr = 0.0005
I1015 11:35:26.324868 15018 solver.cpp:243] Iteration 3340, loss = 4.1436
I1015 11:35:26.324899 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.95442 (* 1 = 6.95442 loss)
I1015 11:35:26.324905 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0662585 (* 1 = 0.0662585 loss)
I1015 11:35:26.324911 15018 sgd_solver.cpp:138] Iteration 3340, lr = 0.0005
I1015 11:35:38.287623 15018 solver.cpp:243] Iteration 3360, loss = 4.72374
I1015 11:35:38.287672 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.4928 (* 1 = 4.4928 loss)
I1015 11:35:38.287678 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0792365 (* 1 = 0.0792365 loss)
I1015 11:35:38.287684 15018 sgd_solver.cpp:138] Iteration 3360, lr = 0.0005
I1015 11:35:50.035992 15018 solver.cpp:243] Iteration 3380, loss = 4.45977
I1015 11:35:50.036041 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.39452 (* 1 = 4.39452 loss)
I1015 11:35:50.036047 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12205 (* 1 = 0.12205 loss)
I1015 11:35:50.036053 15018 sgd_solver.cpp:138] Iteration 3380, lr = 0.0005
I1015 11:36:01.585907 15018 solver.cpp:243] Iteration 3400, loss = 4.48835
I1015 11:36:01.585953 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.63944 (* 1 = 5.63944 loss)
I1015 11:36:01.585959 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0906652 (* 1 = 0.0906652 loss)
I1015 11:36:01.585965 15018 sgd_solver.cpp:138] Iteration 3400, lr = 0.0005
I1015 11:36:13.207676 15018 solver.cpp:243] Iteration 3420, loss = 4.24903
I1015 11:36:13.207725 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.35684 (* 1 = 3.35684 loss)
I1015 11:36:13.207731 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0989031 (* 1 = 0.0989031 loss)
I1015 11:36:13.207736 15018 sgd_solver.cpp:138] Iteration 3420, lr = 0.0005
I1015 11:36:25.428340 15018 solver.cpp:243] Iteration 3440, loss = 4.79343
I1015 11:36:25.428373 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.67429 (* 1 = 3.67429 loss)
I1015 11:36:25.428380 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.318484 (* 1 = 0.318484 loss)
I1015 11:36:25.428385 15018 sgd_solver.cpp:138] Iteration 3440, lr = 0.0005
I1015 11:36:37.547332 15018 solver.cpp:243] Iteration 3460, loss = 4.8141
I1015 11:36:37.547380 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.90912 (* 1 = 4.90912 loss)
I1015 11:36:37.547386 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110672 (* 1 = 0.110672 loss)
I1015 11:36:37.547392 15018 sgd_solver.cpp:138] Iteration 3460, lr = 0.0005
I1015 11:36:49.762126 15018 solver.cpp:243] Iteration 3480, loss = 6.17835
I1015 11:36:49.762161 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.13463 (* 1 = 5.13463 loss)
I1015 11:36:49.762166 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0922958 (* 1 = 0.0922958 loss)
I1015 11:36:49.762172 15018 sgd_solver.cpp:138] Iteration 3480, lr = 0.0005
I1015 11:37:01.361632 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3500.caffemodel
I1015 11:37:02.178328 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3500.solverstate
I1015 11:37:02.752817 15018 solver.cpp:243] Iteration 3500, loss = 6.43741
I1015 11:37:02.752869 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.80199 (* 1 = 6.80199 loss)
I1015 11:37:02.752874 15018 solver.cpp:259]     Train net output #1: seg_loss = 1.57242 (* 1 = 1.57242 loss)
I1015 11:37:02.752880 15018 sgd_solver.cpp:138] Iteration 3500, lr = 0.0005
I1015 11:37:13.979456 15018 solver.cpp:243] Iteration 3520, loss = 5.62758
I1015 11:37:13.979490 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.6773 (* 1 = 5.6773 loss)
I1015 11:37:13.979495 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0843934 (* 1 = 0.0843934 loss)
I1015 11:37:13.979501 15018 sgd_solver.cpp:138] Iteration 3520, lr = 0.0005
I1015 11:37:26.103266 15018 solver.cpp:243] Iteration 3540, loss = 5.234
I1015 11:37:26.103299 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.11386 (* 1 = 4.11386 loss)
I1015 11:37:26.103305 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120166 (* 1 = 0.120166 loss)
I1015 11:37:26.103312 15018 sgd_solver.cpp:138] Iteration 3540, lr = 0.0005
I1015 11:37:37.647555 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:37:38.155094 15018 solver.cpp:243] Iteration 3560, loss = 3.85799
I1015 11:37:38.155143 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.40657 (* 1 = 3.40657 loss)
I1015 11:37:38.155148 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.094214 (* 1 = 0.094214 loss)
I1015 11:37:38.155154 15018 sgd_solver.cpp:138] Iteration 3560, lr = 0.0005
I1015 11:37:50.290897 15018 solver.cpp:243] Iteration 3580, loss = 4.33624
I1015 11:37:50.290930 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.33708 (* 1 = 3.33708 loss)
I1015 11:37:50.290935 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.10131 (* 1 = 0.10131 loss)
I1015 11:37:50.290941 15018 sgd_solver.cpp:138] Iteration 3580, lr = 0.0005
I1015 11:38:02.366696 15018 solver.cpp:243] Iteration 3600, loss = 5.24654
I1015 11:38:02.366731 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.76231 (* 1 = 3.76231 loss)
I1015 11:38:02.366737 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0907806 (* 1 = 0.0907806 loss)
I1015 11:38:02.366742 15018 sgd_solver.cpp:138] Iteration 3600, lr = 0.0005
I1015 11:38:14.615347 15018 solver.cpp:243] Iteration 3620, loss = 5.00727
I1015 11:38:14.615380 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.44286 (* 1 = 3.44286 loss)
I1015 11:38:14.615386 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.189118 (* 1 = 0.189118 loss)
I1015 11:38:14.615391 15018 sgd_solver.cpp:138] Iteration 3620, lr = 0.0005
I1015 11:38:26.842523 15018 solver.cpp:243] Iteration 3640, loss = 4.30073
I1015 11:38:26.842557 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.83037 (* 1 = 2.83037 loss)
I1015 11:38:26.842563 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0963999 (* 1 = 0.0963999 loss)
I1015 11:38:26.842569 15018 sgd_solver.cpp:138] Iteration 3640, lr = 0.0005
I1015 11:38:38.945467 15018 solver.cpp:243] Iteration 3660, loss = 5.03268
I1015 11:38:38.945502 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.7921 (* 1 = 4.7921 loss)
I1015 11:38:38.945509 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0858528 (* 1 = 0.0858528 loss)
I1015 11:38:38.945514 15018 sgd_solver.cpp:138] Iteration 3660, lr = 0.0005
I1015 11:38:51.097558 15018 solver.cpp:243] Iteration 3680, loss = 3.61837
I1015 11:38:51.097592 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.0556 (* 1 = 3.0556 loss)
I1015 11:38:51.097599 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.100669 (* 1 = 0.100669 loss)
I1015 11:38:51.097604 15018 sgd_solver.cpp:138] Iteration 3680, lr = 0.0005
I1015 11:39:03.240797 15018 solver.cpp:243] Iteration 3700, loss = 3.92171
I1015 11:39:03.240829 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.18692 (* 1 = 5.18692 loss)
I1015 11:39:03.240835 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125229 (* 1 = 0.125229 loss)
I1015 11:39:03.240840 15018 sgd_solver.cpp:138] Iteration 3700, lr = 0.0005
I1015 11:39:15.655218 15018 solver.cpp:243] Iteration 3720, loss = 3.42051
I1015 11:39:15.655251 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.70343 (* 1 = 2.70343 loss)
I1015 11:39:15.655256 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.129598 (* 1 = 0.129598 loss)
I1015 11:39:15.655263 15018 sgd_solver.cpp:138] Iteration 3720, lr = 0.0005
I1015 11:39:28.071914 15018 solver.cpp:243] Iteration 3740, loss = 4.4475
I1015 11:39:28.071947 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.00674 (* 1 = 5.00674 loss)
I1015 11:39:28.071954 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0888094 (* 1 = 0.0888094 loss)
I1015 11:39:28.071960 15018 sgd_solver.cpp:138] Iteration 3740, lr = 0.0005
I1015 11:39:40.164975 15018 solver.cpp:243] Iteration 3760, loss = 3.74148
I1015 11:39:40.165009 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.73325 (* 1 = 4.73325 loss)
I1015 11:39:40.165014 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.14743 (* 1 = 0.14743 loss)
I1015 11:39:40.165020 15018 sgd_solver.cpp:138] Iteration 3760, lr = 0.0005
I1015 11:39:52.097522 15018 solver.cpp:243] Iteration 3780, loss = 4.58974
I1015 11:39:52.097553 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.33482 (* 1 = 4.33482 loss)
I1015 11:39:52.097560 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.189112 (* 1 = 0.189112 loss)
I1015 11:39:52.097565 15018 sgd_solver.cpp:138] Iteration 3780, lr = 0.0005
I1015 11:40:04.036018 15018 solver.cpp:243] Iteration 3800, loss = 5.89695
I1015 11:40:04.036049 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.85674 (* 1 = 6.85674 loss)
I1015 11:40:04.036056 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.109293 (* 1 = 0.109293 loss)
I1015 11:40:04.036061 15018 sgd_solver.cpp:138] Iteration 3800, lr = 0.0005
I1015 11:40:15.870223 15018 solver.cpp:243] Iteration 3820, loss = 4.91957
I1015 11:40:15.870257 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.40649 (* 1 = 6.40649 loss)
I1015 11:40:15.870263 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.141915 (* 1 = 0.141915 loss)
I1015 11:40:15.870270 15018 sgd_solver.cpp:138] Iteration 3820, lr = 0.0005
I1015 11:40:27.919881 15018 solver.cpp:243] Iteration 3840, loss = 4.98698
I1015 11:40:27.919914 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.3479 (* 1 = 3.3479 loss)
I1015 11:40:27.919919 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.118816 (* 1 = 0.118816 loss)
I1015 11:40:27.919925 15018 sgd_solver.cpp:138] Iteration 3840, lr = 0.0005
I1015 11:40:39.971312 15018 solver.cpp:243] Iteration 3860, loss = 4.56867
I1015 11:40:39.971343 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.89586 (* 1 = 1.89586 loss)
I1015 11:40:39.971349 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0970015 (* 1 = 0.0970015 loss)
I1015 11:40:39.971354 15018 sgd_solver.cpp:138] Iteration 3860, lr = 0.0005
I1015 11:40:51.802722 15018 solver.cpp:243] Iteration 3880, loss = 3.9698
I1015 11:40:51.802769 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.18187 (* 1 = 4.18187 loss)
I1015 11:40:51.802775 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0859522 (* 1 = 0.0859522 loss)
I1015 11:40:51.802781 15018 sgd_solver.cpp:138] Iteration 3880, lr = 0.0005
I1015 11:41:03.737283 15018 solver.cpp:243] Iteration 3900, loss = 4.54723
I1015 11:41:03.737334 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.79538 (* 1 = 2.79538 loss)
I1015 11:41:03.737341 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101865 (* 1 = 0.101865 loss)
I1015 11:41:03.737346 15018 sgd_solver.cpp:138] Iteration 3900, lr = 0.0005
I1015 11:41:15.564194 15018 solver.cpp:243] Iteration 3920, loss = 4.20742
I1015 11:41:15.564241 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.12066 (* 1 = 4.12066 loss)
I1015 11:41:15.564247 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.159856 (* 1 = 0.159856 loss)
I1015 11:41:15.564252 15018 sgd_solver.cpp:138] Iteration 3920, lr = 0.0005
I1015 11:41:27.246356 15018 solver.cpp:243] Iteration 3940, loss = 4.4181
I1015 11:41:27.246388 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.97085 (* 1 = 4.97085 loss)
I1015 11:41:27.246394 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0940477 (* 1 = 0.0940477 loss)
I1015 11:41:27.246399 15018 sgd_solver.cpp:138] Iteration 3940, lr = 0.0005
I1015 11:41:38.961855 15018 solver.cpp:243] Iteration 3960, loss = 4.08352
I1015 11:41:38.961887 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.71646 (* 1 = 4.71646 loss)
I1015 11:41:38.961894 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105743 (* 1 = 0.105743 loss)
I1015 11:41:38.961899 15018 sgd_solver.cpp:138] Iteration 3960, lr = 0.0005
I1015 11:41:51.129829 15018 solver.cpp:243] Iteration 3980, loss = 4.79666
I1015 11:41:51.129860 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5977 (* 1 = 2.5977 loss)
I1015 11:41:51.129866 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0821894 (* 1 = 0.0821894 loss)
I1015 11:41:51.129871 15018 sgd_solver.cpp:138] Iteration 3980, lr = 0.0005
I1015 11:42:02.986351 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4000.caffemodel
I1015 11:42:03.868780 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4000.solverstate
I1015 11:42:04.075814 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 11:43:43.411671 15018 solver.cpp:243] Iteration 4000, loss = 5.96251
I1015 11:43:43.411703 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.78649 (* 1 = 5.78649 loss)
I1015 11:43:43.411710 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.176017 (* 1 = 0.176017 loss)
I1015 11:43:43.411715 15018 sgd_solver.cpp:138] Iteration 4000, lr = 0.0005
I1015 11:43:54.787220 15018 solver.cpp:243] Iteration 4020, loss = 5.97344
I1015 11:43:54.787262 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.08611 (* 1 = 7.08611 loss)
I1015 11:43:54.787272 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.118088 (* 1 = 0.118088 loss)
I1015 11:43:54.787281 15018 sgd_solver.cpp:138] Iteration 4020, lr = 0.0005
I1015 11:44:07.289038 15018 solver.cpp:243] Iteration 4040, loss = 6.41169
I1015 11:44:07.289083 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.81634 (* 1 = 7.81634 loss)
I1015 11:44:07.289088 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.108148 (* 1 = 0.108148 loss)
I1015 11:44:07.289094 15018 sgd_solver.cpp:138] Iteration 4040, lr = 0.0005
I1015 11:44:19.509315 15018 solver.cpp:243] Iteration 4060, loss = 5.89822
I1015 11:44:19.509366 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.51818 (* 1 = 7.51818 loss)
I1015 11:44:19.509372 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.185565 (* 1 = 0.185565 loss)
I1015 11:44:19.509378 15018 sgd_solver.cpp:138] Iteration 4060, lr = 0.0005
I1015 11:44:25.567718 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:44:31.642179 15018 solver.cpp:243] Iteration 4080, loss = 4.9961
I1015 11:44:31.642212 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.65167 (* 1 = 2.65167 loss)
I1015 11:44:31.642220 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103832 (* 1 = 0.103832 loss)
I1015 11:44:31.642225 15018 sgd_solver.cpp:138] Iteration 4080, lr = 0.0005
I1015 11:44:43.582329 15018 solver.cpp:243] Iteration 4100, loss = 3.77742
I1015 11:44:43.582376 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.37341 (* 1 = 3.37341 loss)
I1015 11:44:43.582383 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078549 (* 1 = 0.078549 loss)
I1015 11:44:43.582388 15018 sgd_solver.cpp:138] Iteration 4100, lr = 0.0005
I1015 11:44:55.603368 15018 solver.cpp:243] Iteration 4120, loss = 3.58611
I1015 11:44:55.603413 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.06305 (* 1 = 4.06305 loss)
I1015 11:44:55.603420 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.121768 (* 1 = 0.121768 loss)
I1015 11:44:55.603425 15018 sgd_solver.cpp:138] Iteration 4120, lr = 0.0005
I1015 11:45:07.621577 15018 solver.cpp:243] Iteration 4140, loss = 5.58543
I1015 11:45:07.621615 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.67562 (* 1 = 3.67562 loss)
I1015 11:45:07.621625 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0715263 (* 1 = 0.0715263 loss)
I1015 11:45:07.621634 15018 sgd_solver.cpp:138] Iteration 4140, lr = 0.0005
I1015 11:45:19.944721 15018 solver.cpp:243] Iteration 4160, loss = 4.78191
I1015 11:45:19.944757 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.35289 (* 1 = 6.35289 loss)
I1015 11:45:19.944764 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127858 (* 1 = 0.127858 loss)
I1015 11:45:19.944770 15018 sgd_solver.cpp:138] Iteration 4160, lr = 0.0005
I1015 11:45:32.175532 15018 solver.cpp:243] Iteration 4180, loss = 4.28581
I1015 11:45:32.175567 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.05503 (* 1 = 6.05503 loss)
I1015 11:45:32.175576 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.145819 (* 1 = 0.145819 loss)
I1015 11:45:32.175585 15018 sgd_solver.cpp:138] Iteration 4180, lr = 0.0005
I1015 11:45:44.445497 15018 solver.cpp:243] Iteration 4200, loss = 5.06538
I1015 11:45:44.445531 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.81283 (* 1 = 3.81283 loss)
I1015 11:45:44.445540 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.121493 (* 1 = 0.121493 loss)
I1015 11:45:44.445547 15018 sgd_solver.cpp:138] Iteration 4200, lr = 0.0005
I1015 11:45:56.784709 15018 solver.cpp:243] Iteration 4220, loss = 3.8876
I1015 11:45:56.784742 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.74933 (* 1 = 3.74933 loss)
I1015 11:45:56.784749 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0950828 (* 1 = 0.0950828 loss)
I1015 11:45:56.784754 15018 sgd_solver.cpp:138] Iteration 4220, lr = 0.0005
I1015 11:46:09.011687 15018 solver.cpp:243] Iteration 4240, loss = 3.59121
I1015 11:46:09.011719 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.99827 (* 1 = 4.99827 loss)
I1015 11:46:09.011725 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.135357 (* 1 = 0.135357 loss)
I1015 11:46:09.011731 15018 sgd_solver.cpp:138] Iteration 4240, lr = 0.0005
I1015 11:46:21.470233 15018 solver.cpp:243] Iteration 4260, loss = 3.91984
I1015 11:46:21.470266 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.16973 (* 1 = 2.16973 loss)
I1015 11:46:21.470273 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0973789 (* 1 = 0.0973789 loss)
I1015 11:46:21.470279 15018 sgd_solver.cpp:138] Iteration 4260, lr = 0.0005
I1015 11:46:33.782433 15018 solver.cpp:243] Iteration 4280, loss = 4.12318
I1015 11:46:33.782462 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.09135 (* 1 = 5.09135 loss)
I1015 11:46:33.782469 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0926168 (* 1 = 0.0926168 loss)
I1015 11:46:33.782474 15018 sgd_solver.cpp:138] Iteration 4280, lr = 0.0005
I1015 11:46:45.962007 15018 solver.cpp:243] Iteration 4300, loss = 3.46962
I1015 11:46:45.962054 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.78054 (* 1 = 2.78054 loss)
I1015 11:46:45.962060 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102078 (* 1 = 0.102078 loss)
I1015 11:46:45.962065 15018 sgd_solver.cpp:138] Iteration 4300, lr = 0.0005
I1015 11:46:58.164352 15018 solver.cpp:243] Iteration 4320, loss = 3.99454
I1015 11:46:58.164399 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.2851 (* 1 = 5.2851 loss)
I1015 11:46:58.164405 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.154071 (* 1 = 0.154071 loss)
I1015 11:46:58.164412 15018 sgd_solver.cpp:138] Iteration 4320, lr = 0.0005
I1015 11:47:10.385879 15018 solver.cpp:243] Iteration 4340, loss = 5.23083
I1015 11:47:10.385912 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.98135 (* 1 = 3.98135 loss)
I1015 11:47:10.385922 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0905796 (* 1 = 0.0905796 loss)
I1015 11:47:10.385929 15018 sgd_solver.cpp:138] Iteration 4340, lr = 0.0005
I1015 11:47:22.438520 15018 solver.cpp:243] Iteration 4360, loss = 4.5829
I1015 11:47:22.438552 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.74731 (* 1 = 2.74731 loss)
I1015 11:47:22.438558 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.100245 (* 1 = 0.100245 loss)
I1015 11:47:22.438563 15018 sgd_solver.cpp:138] Iteration 4360, lr = 0.0005
I1015 11:47:34.628008 15018 solver.cpp:243] Iteration 4380, loss = 5.05957
I1015 11:47:34.628042 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.41169 (* 1 = 5.41169 loss)
I1015 11:47:34.628051 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.169074 (* 1 = 0.169074 loss)
I1015 11:47:34.628059 15018 sgd_solver.cpp:138] Iteration 4380, lr = 0.0005
I1015 11:47:46.804594 15018 solver.cpp:243] Iteration 4400, loss = 4.49219
I1015 11:47:46.804626 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.89203 (* 1 = 2.89203 loss)
I1015 11:47:46.804632 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0915583 (* 1 = 0.0915583 loss)
I1015 11:47:46.804638 15018 sgd_solver.cpp:138] Iteration 4400, lr = 0.0005
I1015 11:47:58.877228 15018 solver.cpp:243] Iteration 4420, loss = 4.0755
I1015 11:47:58.877262 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.34721 (* 1 = 3.34721 loss)
I1015 11:47:58.877271 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0750498 (* 1 = 0.0750498 loss)
I1015 11:47:58.877279 15018 sgd_solver.cpp:138] Iteration 4420, lr = 0.0005
I1015 11:48:11.002657 15018 solver.cpp:243] Iteration 4440, loss = 4.46611
I1015 11:48:11.002703 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.0385 (* 1 = 4.0385 loss)
I1015 11:48:11.002710 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0851856 (* 1 = 0.0851856 loss)
I1015 11:48:11.002715 15018 sgd_solver.cpp:138] Iteration 4440, lr = 0.0005
I1015 11:48:23.075533 15018 solver.cpp:243] Iteration 4460, loss = 4.03609
I1015 11:48:23.075572 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.96258 (* 1 = 2.96258 loss)
I1015 11:48:23.075577 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.130327 (* 1 = 0.130327 loss)
I1015 11:48:23.075582 15018 sgd_solver.cpp:138] Iteration 4460, lr = 0.0005
I1015 11:48:34.941421 15018 solver.cpp:243] Iteration 4480, loss = 4.22163
I1015 11:48:34.941452 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.23896 (* 1 = 4.23896 loss)
I1015 11:48:34.941458 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.124466 (* 1 = 0.124466 loss)
I1015 11:48:34.941464 15018 sgd_solver.cpp:138] Iteration 4480, lr = 0.0005
I1015 11:48:46.152424 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4500.caffemodel
I1015 11:48:46.468902 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4500.solverstate
I1015 11:48:47.122839 15018 solver.cpp:243] Iteration 4500, loss = 3.8171
I1015 11:48:47.122872 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.65593 (* 1 = 4.65593 loss)
I1015 11:48:47.122879 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101393 (* 1 = 0.101393 loss)
I1015 11:48:47.122885 15018 sgd_solver.cpp:138] Iteration 4500, lr = 0.0005
I1015 11:48:58.819257 15018 solver.cpp:243] Iteration 4520, loss = 4.77834
I1015 11:48:58.819291 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.08298 (* 1 = 4.08298 loss)
I1015 11:48:58.819298 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0982961 (* 1 = 0.0982961 loss)
I1015 11:48:58.819303 15018 sgd_solver.cpp:138] Iteration 4520, lr = 0.0005
I1015 11:49:11.240337 15018 solver.cpp:243] Iteration 4540, loss = 4.74154
I1015 11:49:11.240380 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.30623 (* 1 = 4.30623 loss)
I1015 11:49:11.240392 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0857634 (* 1 = 0.0857634 loss)
I1015 11:49:11.240401 15018 sgd_solver.cpp:138] Iteration 4540, lr = 0.0005
I1015 11:49:23.652601 15018 solver.cpp:243] Iteration 4560, loss = 5.67283
I1015 11:49:23.652662 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.93514 (* 1 = 6.93514 loss)
I1015 11:49:23.652668 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.191065 (* 1 = 0.191065 loss)
I1015 11:49:23.652673 15018 sgd_solver.cpp:138] Iteration 4560, lr = 0.0005
I1015 11:49:35.993902 15018 solver.cpp:243] Iteration 4580, loss = 5.92945
I1015 11:49:35.993953 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.25594 (* 1 = 3.25594 loss)
I1015 11:49:35.993963 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102041 (* 1 = 0.102041 loss)
I1015 11:49:35.993970 15018 sgd_solver.cpp:138] Iteration 4580, lr = 0.0005
I1015 11:49:48.086951 15018 solver.cpp:243] Iteration 4600, loss = 5.51505
I1015 11:49:48.086994 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.12909 (* 1 = 5.12909 loss)
I1015 11:49:48.087002 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134556 (* 1 = 0.134556 loss)
I1015 11:49:48.087007 15018 sgd_solver.cpp:138] Iteration 4600, lr = 0.0005
I1015 11:50:00.159093 15018 solver.cpp:243] Iteration 4620, loss = 5.25053
I1015 11:50:00.159126 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.12515 (* 1 = 4.12515 loss)
I1015 11:50:00.159133 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106032 (* 1 = 0.106032 loss)
I1015 11:50:00.159139 15018 sgd_solver.cpp:138] Iteration 4620, lr = 0.0005
I1015 11:50:12.401916 15018 solver.cpp:243] Iteration 4640, loss = 3.73055
I1015 11:50:12.401948 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.6987 (* 1 = 2.6987 loss)
I1015 11:50:12.401955 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0651173 (* 1 = 0.0651173 loss)
I1015 11:50:12.401962 15018 sgd_solver.cpp:138] Iteration 4640, lr = 0.0005
I1015 11:50:24.729753 15018 solver.cpp:243] Iteration 4660, loss = 3.47072
I1015 11:50:24.729785 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.5542 (* 1 = 5.5542 loss)
I1015 11:50:24.729792 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.116484 (* 1 = 0.116484 loss)
I1015 11:50:24.729799 15018 sgd_solver.cpp:138] Iteration 4660, lr = 0.0005
I1015 11:50:36.885694 15018 solver.cpp:243] Iteration 4680, loss = 5.33921
I1015 11:50:36.885727 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.88158 (* 1 = 6.88158 loss)
I1015 11:50:36.885737 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0641327 (* 1 = 0.0641327 loss)
I1015 11:50:36.885759 15018 sgd_solver.cpp:138] Iteration 4680, lr = 0.0005
I1015 11:50:49.144227 15018 solver.cpp:243] Iteration 4700, loss = 4.6312
I1015 11:50:49.144273 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.7623 (* 1 = 4.7623 loss)
I1015 11:50:49.144280 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0935924 (* 1 = 0.0935924 loss)
I1015 11:50:49.144285 15018 sgd_solver.cpp:138] Iteration 4700, lr = 0.0005
I1015 11:51:01.535791 15018 solver.cpp:243] Iteration 4720, loss = 4.27649
I1015 11:51:01.535836 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.18563 (* 1 = 5.18563 loss)
I1015 11:51:01.535842 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.13813 (* 1 = 0.13813 loss)
I1015 11:51:01.535847 15018 sgd_solver.cpp:138] Iteration 4720, lr = 0.0005
I1015 11:51:13.907191 15018 solver.cpp:243] Iteration 4740, loss = 4.76918
I1015 11:51:13.907222 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.43282 (* 1 = 6.43282 loss)
I1015 11:51:13.907227 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.138169 (* 1 = 0.138169 loss)
I1015 11:51:13.907233 15018 sgd_solver.cpp:138] Iteration 4740, lr = 0.0005
I1015 11:51:26.179440 15018 solver.cpp:243] Iteration 4760, loss = 3.84854
I1015 11:51:26.179468 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.27173 (* 1 = 3.27173 loss)
I1015 11:51:26.179474 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105661 (* 1 = 0.105661 loss)
I1015 11:51:26.179481 15018 sgd_solver.cpp:138] Iteration 4760, lr = 0.0005
I1015 11:51:38.456573 15018 solver.cpp:243] Iteration 4780, loss = 3.01932
I1015 11:51:38.456604 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.95916 (* 1 = 3.95916 loss)
I1015 11:51:38.456611 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.130696 (* 1 = 0.130696 loss)
I1015 11:51:38.456616 15018 sgd_solver.cpp:138] Iteration 4780, lr = 0.0005
I1015 11:51:50.896453 15018 solver.cpp:243] Iteration 4800, loss = 4.22709
I1015 11:51:50.896499 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.14952 (* 1 = 2.14952 loss)
I1015 11:51:50.896507 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.398813 (* 1 = 0.398813 loss)
I1015 11:51:50.896512 15018 sgd_solver.cpp:138] Iteration 4800, lr = 0.0005
I1015 11:52:03.310853 15018 solver.cpp:243] Iteration 4820, loss = 4.97991
I1015 11:52:03.310884 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.81826 (* 1 = 5.81826 loss)
I1015 11:52:03.310891 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.140464 (* 1 = 0.140464 loss)
I1015 11:52:03.310896 15018 sgd_solver.cpp:138] Iteration 4820, lr = 0.0005
I1015 11:52:15.469763 15018 solver.cpp:243] Iteration 4840, loss = 3.58267
I1015 11:52:15.469810 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.73118 (* 1 = 5.73118 loss)
I1015 11:52:15.469816 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0773788 (* 1 = 0.0773788 loss)
I1015 11:52:15.469822 15018 sgd_solver.cpp:138] Iteration 4840, lr = 0.0005
I1015 11:52:27.621098 15018 solver.cpp:243] Iteration 4860, loss = 3.21129
I1015 11:52:27.621129 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.37455 (* 1 = 4.37455 loss)
I1015 11:52:27.621135 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.119025 (* 1 = 0.119025 loss)
I1015 11:52:27.621140 15018 sgd_solver.cpp:138] Iteration 4860, lr = 0.0005
I1015 11:52:39.678058 15018 solver.cpp:243] Iteration 4880, loss = 5.18161
I1015 11:52:39.678105 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.24124 (* 1 = 6.24124 loss)
I1015 11:52:39.678112 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0977227 (* 1 = 0.0977227 loss)
I1015 11:52:39.678117 15018 sgd_solver.cpp:138] Iteration 4880, lr = 0.0005
I1015 11:52:51.442214 15018 solver.cpp:243] Iteration 4900, loss = 4.5074
I1015 11:52:51.442261 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.76106 (* 1 = 4.76106 loss)
I1015 11:52:51.442267 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.171938 (* 1 = 0.171938 loss)
I1015 11:52:51.442279 15018 sgd_solver.cpp:138] Iteration 4900, lr = 0.0005
I1015 11:53:03.730188 15018 solver.cpp:243] Iteration 4920, loss = 4.76562
I1015 11:53:03.730240 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.97701 (* 1 = 3.97701 loss)
I1015 11:53:03.730250 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.217053 (* 1 = 0.217053 loss)
I1015 11:53:03.730258 15018 sgd_solver.cpp:138] Iteration 4920, lr = 0.0005
I1015 11:53:16.050613 15018 solver.cpp:243] Iteration 4940, loss = 3.99917
I1015 11:53:16.050647 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.10678 (* 1 = 3.10678 loss)
I1015 11:53:16.050653 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0811205 (* 1 = 0.0811205 loss)
I1015 11:53:16.050660 15018 sgd_solver.cpp:138] Iteration 4940, lr = 0.0005
I1015 11:53:28.114457 15018 solver.cpp:243] Iteration 4960, loss = 4.14923
I1015 11:53:28.114488 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.88298 (* 1 = 1.88298 loss)
I1015 11:53:28.114495 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0641438 (* 1 = 0.0641438 loss)
I1015 11:53:28.114501 15018 sgd_solver.cpp:138] Iteration 4960, lr = 0.0005
I1015 11:53:40.138232 15018 solver.cpp:243] Iteration 4980, loss = 4.57976
I1015 11:53:40.138265 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.78132 (* 1 = 4.78132 loss)
I1015 11:53:40.138272 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0817425 (* 1 = 0.0817425 loss)
I1015 11:53:40.138278 15018 sgd_solver.cpp:138] Iteration 4980, lr = 0.0005
I1015 11:53:51.703527 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5000.caffemodel
I1015 11:53:51.947042 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5000.solverstate
I1015 11:53:52.133530 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 11:54:06.729506 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 11:55:31.676609 15018 solver.cpp:243] Iteration 5000, loss = 2.62088
I1015 11:55:31.676643 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.48642 (* 1 = 2.48642 loss)
I1015 11:55:31.676650 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134462 (* 1 = 0.134462 loss)
I1015 11:55:31.676656 15018 sgd_solver.cpp:138] Iteration 5000, lr = 0.0005
I1015 11:55:42.254493 15018 solver.cpp:243] Iteration 5020, loss = 3.93146
I1015 11:55:42.254537 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.97928 (* 1 = 2.97928 loss)
I1015 11:55:42.254544 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0786303 (* 1 = 0.0786303 loss)
I1015 11:55:42.254549 15018 sgd_solver.cpp:138] Iteration 5020, lr = 0.0005
I1015 11:55:54.097244 15018 solver.cpp:243] Iteration 5040, loss = 3.68854
I1015 11:55:54.097292 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.30837 (* 1 = 4.30837 loss)
I1015 11:55:54.097299 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0580435 (* 1 = 0.0580435 loss)
I1015 11:55:54.097304 15018 sgd_solver.cpp:138] Iteration 5040, lr = 0.0005
I1015 11:56:06.295572 15018 solver.cpp:243] Iteration 5060, loss = 4.60957
I1015 11:56:06.295609 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.06844 (* 1 = 4.06844 loss)
I1015 11:56:06.295616 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0920862 (* 1 = 0.0920862 loss)
I1015 11:56:06.295622 15018 sgd_solver.cpp:138] Iteration 5060, lr = 0.0005
I1015 11:56:18.461052 15018 solver.cpp:243] Iteration 5080, loss = 4.73252
I1015 11:56:18.461099 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.71421 (* 1 = 4.71421 loss)
I1015 11:56:18.461105 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.07375 (* 1 = 0.07375 loss)
I1015 11:56:18.461112 15018 sgd_solver.cpp:138] Iteration 5080, lr = 0.0005
I1015 11:56:30.788975 15018 solver.cpp:243] Iteration 5100, loss = 5.37928
I1015 11:56:30.789007 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.20738 (* 1 = 5.20738 loss)
I1015 11:56:30.789013 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117555 (* 1 = 0.117555 loss)
I1015 11:56:30.789018 15018 sgd_solver.cpp:138] Iteration 5100, lr = 0.0005
I1015 11:56:43.098803 15018 solver.cpp:243] Iteration 5120, loss = 6.21743
I1015 11:56:43.098850 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.2995 (* 1 = 6.2995 loss)
I1015 11:56:43.098856 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0867451 (* 1 = 0.0867451 loss)
I1015 11:56:43.098861 15018 sgd_solver.cpp:138] Iteration 5120, lr = 0.0005
I1015 11:56:55.344936 15018 solver.cpp:243] Iteration 5140, loss = 5.3675
I1015 11:56:55.344974 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.87998 (* 1 = 3.87998 loss)
I1015 11:56:55.344980 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.131448 (* 1 = 0.131448 loss)
I1015 11:56:55.344986 15018 sgd_solver.cpp:138] Iteration 5140, lr = 0.0005
I1015 11:57:07.635450 15018 solver.cpp:243] Iteration 5160, loss = 4.96827
I1015 11:57:07.635496 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.45671 (* 1 = 2.45671 loss)
I1015 11:57:07.635504 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.171974 (* 1 = 0.171974 loss)
I1015 11:57:07.635509 15018 sgd_solver.cpp:138] Iteration 5160, lr = 0.0005
I1015 11:57:20.008437 15018 solver.cpp:243] Iteration 5180, loss = 3.82145
I1015 11:57:20.008486 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.06742 (* 1 = 3.06742 loss)
I1015 11:57:20.008491 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0793125 (* 1 = 0.0793125 loss)
I1015 11:57:20.008497 15018 sgd_solver.cpp:138] Iteration 5180, lr = 0.0005
I1015 11:57:32.209728 15018 solver.cpp:243] Iteration 5200, loss = 3.65735
I1015 11:57:32.209774 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.74794 (* 1 = 2.74794 loss)
I1015 11:57:32.209780 15018 solver.cpp:259]     Train net output #1: seg_loss = 4.36072 (* 1 = 4.36072 loss)
I1015 11:57:32.209786 15018 sgd_solver.cpp:138] Iteration 5200, lr = 0.0005
I1015 11:57:44.361390 15018 solver.cpp:243] Iteration 5220, loss = 4.63311
I1015 11:57:44.361423 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.47274 (* 1 = 5.47274 loss)
I1015 11:57:44.361428 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0718637 (* 1 = 0.0718637 loss)
I1015 11:57:44.361433 15018 sgd_solver.cpp:138] Iteration 5220, lr = 0.0005
I1015 11:57:56.453770 15018 solver.cpp:243] Iteration 5240, loss = 4.15867
I1015 11:57:56.453817 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.5976 (* 1 = 4.5976 loss)
I1015 11:57:56.453824 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.141177 (* 1 = 0.141177 loss)
I1015 11:57:56.453830 15018 sgd_solver.cpp:138] Iteration 5240, lr = 0.0005
I1015 11:58:08.610502 15018 solver.cpp:243] Iteration 5260, loss = 3.8989
I1015 11:58:08.610548 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.69672 (* 1 = 7.69672 loss)
I1015 11:58:08.610555 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0897335 (* 1 = 0.0897335 loss)
I1015 11:58:08.610561 15018 sgd_solver.cpp:138] Iteration 5260, lr = 0.0005
I1015 11:58:20.846756 15018 solver.cpp:243] Iteration 5280, loss = 4.42325
I1015 11:58:20.846787 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.30628 (* 1 = 3.30628 loss)
I1015 11:58:20.846793 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.135399 (* 1 = 0.135399 loss)
I1015 11:58:20.846799 15018 sgd_solver.cpp:138] Iteration 5280, lr = 0.0005
I1015 11:58:33.016835 15018 solver.cpp:243] Iteration 5300, loss = 3.79892
I1015 11:58:33.016868 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.41954 (* 1 = 4.41954 loss)
I1015 11:58:33.016875 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0792746 (* 1 = 0.0792746 loss)
I1015 11:58:33.016880 15018 sgd_solver.cpp:138] Iteration 5300, lr = 0.0005
I1015 11:58:45.038041 15018 solver.cpp:243] Iteration 5320, loss = 2.46204
I1015 11:58:45.038074 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.56313 (* 1 = 2.56313 loss)
I1015 11:58:45.038080 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0828806 (* 1 = 0.0828806 loss)
I1015 11:58:45.038086 15018 sgd_solver.cpp:138] Iteration 5320, lr = 0.0005
I1015 11:58:57.316236 15018 solver.cpp:243] Iteration 5340, loss = 3.71271
I1015 11:58:57.316283 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.58065 (* 1 = 2.58065 loss)
I1015 11:58:57.316289 15018 solver.cpp:259]     Train net output #1: seg_loss = 1.0112 (* 1 = 1.0112 loss)
I1015 11:58:57.316294 15018 sgd_solver.cpp:138] Iteration 5340, lr = 0.0005
I1015 11:59:09.546981 15018 solver.cpp:243] Iteration 5360, loss = 4.25394
I1015 11:59:09.547029 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.10791 (* 1 = 2.10791 loss)
I1015 11:59:09.547035 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0870607 (* 1 = 0.0870607 loss)
I1015 11:59:09.547040 15018 sgd_solver.cpp:138] Iteration 5360, lr = 0.0005
I1015 11:59:21.517961 15018 solver.cpp:243] Iteration 5380, loss = 2.9339
I1015 11:59:21.518007 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.61369 (* 1 = 2.61369 loss)
I1015 11:59:21.518013 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0714315 (* 1 = 0.0714315 loss)
I1015 11:59:21.518018 15018 sgd_solver.cpp:138] Iteration 5380, lr = 0.0005
I1015 11:59:33.464226 15018 solver.cpp:243] Iteration 5400, loss = 2.95571
I1015 11:59:33.464270 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.76678 (* 1 = 2.76678 loss)
I1015 11:59:33.464277 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.109699 (* 1 = 0.109699 loss)
I1015 11:59:33.464283 15018 sgd_solver.cpp:138] Iteration 5400, lr = 0.0005
I1015 11:59:45.452349 15018 solver.cpp:243] Iteration 5420, loss = 4.68709
I1015 11:59:45.452399 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.58679 (* 1 = 4.58679 loss)
I1015 11:59:45.452404 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.122151 (* 1 = 0.122151 loss)
I1015 11:59:45.452410 15018 sgd_solver.cpp:138] Iteration 5420, lr = 0.0005
I1015 11:59:57.154707 15018 solver.cpp:243] Iteration 5440, loss = 4.26549
I1015 11:59:57.154742 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.10684 (* 1 = 5.10684 loss)
I1015 11:59:57.154747 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.11305 (* 1 = 0.11305 loss)
I1015 11:59:57.154754 15018 sgd_solver.cpp:138] Iteration 5440, lr = 0.0005
I1015 12:00:09.440176 15018 solver.cpp:243] Iteration 5460, loss = 4.19284
I1015 12:00:09.440208 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.31259 (* 1 = 4.31259 loss)
I1015 12:00:09.440215 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0952296 (* 1 = 0.0952296 loss)
I1015 12:00:09.440222 15018 sgd_solver.cpp:138] Iteration 5460, lr = 0.0005
I1015 12:00:21.662708 15018 solver.cpp:243] Iteration 5480, loss = 3.62385
I1015 12:00:21.662755 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.33334 (* 1 = 3.33334 loss)
I1015 12:00:21.662762 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.113067 (* 1 = 0.113067 loss)
I1015 12:00:21.662768 15018 sgd_solver.cpp:138] Iteration 5480, lr = 0.0005
I1015 12:00:33.196959 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5500.caffemodel
I1015 12:00:33.495257 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5500.solverstate
I1015 12:00:34.113965 15018 solver.cpp:243] Iteration 5500, loss = 4.22715
I1015 12:00:34.113998 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.70813 (* 1 = 3.70813 loss)
I1015 12:00:34.114006 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.067009 (* 1 = 0.067009 loss)
I1015 12:00:34.114012 15018 sgd_solver.cpp:138] Iteration 5500, lr = 0.0005
I1015 12:00:45.999078 15018 solver.cpp:243] Iteration 5520, loss = 4.45634
I1015 12:00:45.999126 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.40311 (* 1 = 3.40311 loss)
I1015 12:00:45.999131 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0755234 (* 1 = 0.0755234 loss)
I1015 12:00:45.999137 15018 sgd_solver.cpp:138] Iteration 5520, lr = 0.0005
I1015 12:00:58.375077 15018 solver.cpp:243] Iteration 5540, loss = 4.26224
I1015 12:00:58.375126 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.97946 (* 1 = 2.97946 loss)
I1015 12:00:58.375133 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0985854 (* 1 = 0.0985854 loss)
I1015 12:00:58.375138 15018 sgd_solver.cpp:138] Iteration 5540, lr = 0.0005
I1015 12:01:10.304275 15018 solver.cpp:243] Iteration 5560, loss = 4.1663
I1015 12:01:10.304308 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.87453 (* 1 = 2.87453 loss)
I1015 12:01:10.304316 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.137193 (* 1 = 0.137193 loss)
I1015 12:01:10.304320 15018 sgd_solver.cpp:138] Iteration 5560, lr = 0.0005
I1015 12:01:22.191372 15018 solver.cpp:243] Iteration 5580, loss = 3.55238
I1015 12:01:22.191403 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.01682 (* 1 = 2.01682 loss)
I1015 12:01:22.191409 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0952496 (* 1 = 0.0952496 loss)
I1015 12:01:22.191416 15018 sgd_solver.cpp:138] Iteration 5580, lr = 0.0005
I1015 12:01:26.335127 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:01:34.079234 15018 solver.cpp:243] Iteration 5600, loss = 4.48864
I1015 12:01:34.079267 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.67136 (* 1 = 4.67136 loss)
I1015 12:01:34.079273 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.119116 (* 1 = 0.119116 loss)
I1015 12:01:34.079279 15018 sgd_solver.cpp:138] Iteration 5600, lr = 0.0005
I1015 12:01:46.340973 15018 solver.cpp:243] Iteration 5620, loss = 4.92515
I1015 12:01:46.341002 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.58605 (* 1 = 4.58605 loss)
I1015 12:01:46.341007 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.157423 (* 1 = 0.157423 loss)
I1015 12:01:46.341013 15018 sgd_solver.cpp:138] Iteration 5620, lr = 0.0005
I1015 12:01:58.695385 15018 solver.cpp:243] Iteration 5640, loss = 5.21627
I1015 12:01:58.695420 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.84435 (* 1 = 4.84435 loss)
I1015 12:01:58.695426 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.10927 (* 1 = 0.10927 loss)
I1015 12:01:58.695432 15018 sgd_solver.cpp:138] Iteration 5640, lr = 0.0005
I1015 12:02:11.014742 15018 solver.cpp:243] Iteration 5660, loss = 6.02433
I1015 12:02:11.014772 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.67988 (* 1 = 6.67988 loss)
I1015 12:02:11.014778 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102799 (* 1 = 0.102799 loss)
I1015 12:02:11.014786 15018 sgd_solver.cpp:138] Iteration 5660, lr = 0.0005
I1015 12:02:23.041321 15018 solver.cpp:243] Iteration 5680, loss = 5.17548
I1015 12:02:23.041373 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.5978 (* 1 = 4.5978 loss)
I1015 12:02:23.041378 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.129116 (* 1 = 0.129116 loss)
I1015 12:02:23.041385 15018 sgd_solver.cpp:138] Iteration 5680, lr = 0.0005
I1015 12:02:34.998157 15018 solver.cpp:243] Iteration 5700, loss = 4.73514
I1015 12:02:34.998188 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.3928 (* 1 = 3.3928 loss)
I1015 12:02:34.998210 15018 solver.cpp:259]     Train net output #1: seg_loss = 2.49847 (* 1 = 2.49847 loss)
I1015 12:02:34.998216 15018 sgd_solver.cpp:138] Iteration 5700, lr = 0.0005
I1015 12:02:46.992239 15018 solver.cpp:243] Iteration 5720, loss = 4.37271
I1015 12:02:46.992270 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.02847 (* 1 = 4.02847 loss)
I1015 12:02:46.992277 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101205 (* 1 = 0.101205 loss)
I1015 12:02:46.992282 15018 sgd_solver.cpp:138] Iteration 5720, lr = 0.0005
I1015 12:02:59.035126 15018 solver.cpp:243] Iteration 5740, loss = 3.20386
I1015 12:02:59.035156 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.97371 (* 1 = 1.97371 loss)
I1015 12:02:59.035162 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.998448 (* 1 = 0.998448 loss)
I1015 12:02:59.035168 15018 sgd_solver.cpp:138] Iteration 5740, lr = 0.0005
I1015 12:03:11.632436 15018 solver.cpp:243] Iteration 5760, loss = 4.32842
I1015 12:03:11.632472 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.73436 (* 1 = 4.73436 loss)
I1015 12:03:11.632477 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0782768 (* 1 = 0.0782768 loss)
I1015 12:03:11.632483 15018 sgd_solver.cpp:138] Iteration 5760, lr = 0.0005
I1015 12:03:23.972291 15018 solver.cpp:243] Iteration 5780, loss = 4.16412
I1015 12:03:23.972322 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.13801 (* 1 = 4.13801 loss)
I1015 12:03:23.972328 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.152232 (* 1 = 0.152232 loss)
I1015 12:03:23.972334 15018 sgd_solver.cpp:138] Iteration 5780, lr = 0.0005
I1015 12:03:36.157294 15018 solver.cpp:243] Iteration 5800, loss = 3.28789
I1015 12:03:36.157335 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.4549 (* 1 = 2.4549 loss)
I1015 12:03:36.157356 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101953 (* 1 = 0.101953 loss)
I1015 12:03:36.157362 15018 sgd_solver.cpp:138] Iteration 5800, lr = 0.0005
I1015 12:03:48.268055 15018 solver.cpp:243] Iteration 5820, loss = 3.88606
I1015 12:03:48.268087 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.54955 (* 1 = 5.54955 loss)
I1015 12:03:48.268093 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105747 (* 1 = 0.105747 loss)
I1015 12:03:48.268115 15018 sgd_solver.cpp:138] Iteration 5820, lr = 0.0005
I1015 12:04:00.437693 15018 solver.cpp:243] Iteration 5840, loss = 3.96324
I1015 12:04:00.437726 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.41773 (* 1 = 2.41773 loss)
I1015 12:04:00.437731 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103702 (* 1 = 0.103702 loss)
I1015 12:04:00.437737 15018 sgd_solver.cpp:138] Iteration 5840, lr = 0.0005
I1015 12:04:12.404628 15018 solver.cpp:243] Iteration 5860, loss = 2.46637
I1015 12:04:12.404662 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.41984 (* 1 = 2.41984 loss)
I1015 12:04:12.404669 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0731857 (* 1 = 0.0731857 loss)
I1015 12:04:12.404675 15018 sgd_solver.cpp:138] Iteration 5860, lr = 0.0005
I1015 12:04:24.689879 15018 solver.cpp:243] Iteration 5880, loss = 3.47541
I1015 12:04:24.689915 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.33471 (* 1 = 3.33471 loss)
I1015 12:04:24.689921 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.122194 (* 1 = 0.122194 loss)
I1015 12:04:24.689929 15018 sgd_solver.cpp:138] Iteration 5880, lr = 0.0005
I1015 12:04:36.964812 15018 solver.cpp:243] Iteration 5900, loss = 3.93501
I1015 12:04:36.964845 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.07759 (* 1 = 3.07759 loss)
I1015 12:04:36.964851 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.196728 (* 1 = 0.196728 loss)
I1015 12:04:36.964857 15018 sgd_solver.cpp:138] Iteration 5900, lr = 0.0005
I1015 12:04:48.860324 15018 solver.cpp:243] Iteration 5920, loss = 2.86261
I1015 12:04:48.860360 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.16966 (* 1 = 1.16966 loss)
I1015 12:04:48.860366 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0646461 (* 1 = 0.0646461 loss)
I1015 12:04:48.860373 15018 sgd_solver.cpp:138] Iteration 5920, lr = 0.0005
I1015 12:05:00.771412 15018 solver.cpp:243] Iteration 5940, loss = 3.26384
I1015 12:05:00.771447 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.04961 (* 1 = 4.04961 loss)
I1015 12:05:00.771452 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.160488 (* 1 = 0.160488 loss)
I1015 12:05:00.771458 15018 sgd_solver.cpp:138] Iteration 5940, lr = 0.0005
I1015 12:05:12.754839 15018 solver.cpp:243] Iteration 5960, loss = 4.19275
I1015 12:05:12.754873 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.44676 (* 1 = 3.44676 loss)
I1015 12:05:12.754878 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105905 (* 1 = 0.105905 loss)
I1015 12:05:12.754884 15018 sgd_solver.cpp:138] Iteration 5960, lr = 0.0005
I1015 12:05:24.388860 15018 solver.cpp:243] Iteration 5980, loss = 3.94112
I1015 12:05:24.388895 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.00894 (* 1 = 5.00894 loss)
I1015 12:05:24.388900 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0954081 (* 1 = 0.0954081 loss)
I1015 12:05:24.388906 15018 sgd_solver.cpp:138] Iteration 5980, lr = 0.0005
I1015 12:05:35.906324 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6000.caffemodel
I1015 12:05:36.710855 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6000.solverstate
I1015 12:05:36.907691 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 12:07:15.665783 15018 solver.cpp:243] Iteration 6000, loss = 4.88986
I1015 12:07:15.665817 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.76244 (* 1 = 4.76244 loss)
I1015 12:07:15.665822 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127418 (* 1 = 0.127418 loss)
I1015 12:07:15.665828 15018 sgd_solver.cpp:138] Iteration 6000, lr = 0.0005
I1015 12:07:26.710216 15018 solver.cpp:243] Iteration 6020, loss = 3.53024
I1015 12:07:26.710248 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.39266 (* 1 = 5.39266 loss)
I1015 12:07:26.710273 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0735149 (* 1 = 0.0735149 loss)
I1015 12:07:26.710279 15018 sgd_solver.cpp:138] Iteration 6020, lr = 0.0005
I1015 12:07:38.635938 15018 solver.cpp:243] Iteration 6040, loss = 4.26173
I1015 12:07:38.635974 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.11664 (* 1 = 5.11664 loss)
I1015 12:07:38.635983 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107972 (* 1 = 0.107972 loss)
I1015 12:07:38.635991 15018 sgd_solver.cpp:138] Iteration 6040, lr = 0.0005
I1015 12:07:50.521014 15018 solver.cpp:243] Iteration 6060, loss = 4.24077
I1015 12:07:50.521049 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.91656 (* 1 = 4.91656 loss)
I1015 12:07:50.521059 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0813618 (* 1 = 0.0813618 loss)
I1015 12:07:50.521066 15018 sgd_solver.cpp:138] Iteration 6060, lr = 0.0005
I1015 12:08:02.449157 15018 solver.cpp:243] Iteration 6080, loss = 3.97408
I1015 12:08:02.449193 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.30269 (* 1 = 4.30269 loss)
I1015 12:08:02.449203 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120489 (* 1 = 0.120489 loss)
I1015 12:08:02.449225 15018 sgd_solver.cpp:138] Iteration 6080, lr = 0.0005
I1015 12:08:12.415881 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:08:14.056766 15018 solver.cpp:243] Iteration 6100, loss = 3.79106
I1015 12:08:14.056802 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.63129 (* 1 = 3.63129 loss)
I1015 12:08:14.056810 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.145493 (* 1 = 0.145493 loss)
I1015 12:08:14.056833 15018 sgd_solver.cpp:138] Iteration 6100, lr = 0.0005
I1015 12:08:25.615247 15018 solver.cpp:243] Iteration 6120, loss = 3.66606
I1015 12:08:25.615283 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.82784 (* 1 = 4.82784 loss)
I1015 12:08:25.615290 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0708978 (* 1 = 0.0708978 loss)
I1015 12:08:25.615314 15018 sgd_solver.cpp:138] Iteration 6120, lr = 0.0005
I1015 12:08:37.345510 15018 solver.cpp:243] Iteration 6140, loss = 4.07678
I1015 12:08:37.345543 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.55373 (* 1 = 5.55373 loss)
I1015 12:08:37.345549 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.140225 (* 1 = 0.140225 loss)
I1015 12:08:37.345556 15018 sgd_solver.cpp:138] Iteration 6140, lr = 0.0005
I1015 12:08:49.414126 15018 solver.cpp:243] Iteration 6160, loss = 5.17622
I1015 12:08:49.414160 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.01949 (* 1 = 3.01949 loss)
I1015 12:08:49.414165 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.063647 (* 1 = 0.063647 loss)
I1015 12:08:49.414170 15018 sgd_solver.cpp:138] Iteration 6160, lr = 0.0005
I1015 12:09:01.658128 15018 solver.cpp:243] Iteration 6180, loss = 5.02852
I1015 12:09:01.658177 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.83173 (* 1 = 4.83173 loss)
I1015 12:09:01.658183 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.245257 (* 1 = 0.245257 loss)
I1015 12:09:01.658188 15018 sgd_solver.cpp:138] Iteration 6180, lr = 0.0005
I1015 12:09:13.810820 15018 solver.cpp:243] Iteration 6200, loss = 5.71507
I1015 12:09:13.810853 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.51506 (* 1 = 5.51506 loss)
I1015 12:09:13.810858 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0847935 (* 1 = 0.0847935 loss)
I1015 12:09:13.810865 15018 sgd_solver.cpp:138] Iteration 6200, lr = 0.0005
I1015 12:09:25.819703 15018 solver.cpp:243] Iteration 6220, loss = 4.74438
I1015 12:09:25.819736 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.51908 (* 1 = 3.51908 loss)
I1015 12:09:25.819741 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0683944 (* 1 = 0.0683944 loss)
I1015 12:09:25.819747 15018 sgd_solver.cpp:138] Iteration 6220, lr = 0.0005
I1015 12:09:37.750190 15018 solver.cpp:243] Iteration 6240, loss = 4.23785
I1015 12:09:37.750223 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.97623 (* 1 = 5.97623 loss)
I1015 12:09:37.750229 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.165504 (* 1 = 0.165504 loss)
I1015 12:09:37.750236 15018 sgd_solver.cpp:138] Iteration 6240, lr = 0.0005
I1015 12:09:49.703153 15018 solver.cpp:243] Iteration 6260, loss = 3.79769
I1015 12:09:49.703188 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.17513 (* 1 = 4.17513 loss)
I1015 12:09:49.703194 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117773 (* 1 = 0.117773 loss)
I1015 12:09:49.703199 15018 sgd_solver.cpp:138] Iteration 6260, lr = 0.0005
I1015 12:10:01.608242 15018 solver.cpp:243] Iteration 6280, loss = 3.16513
I1015 12:10:01.608275 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.73582 (* 1 = 1.73582 loss)
I1015 12:10:01.608281 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.307346 (* 1 = 0.307346 loss)
I1015 12:10:01.608287 15018 sgd_solver.cpp:138] Iteration 6280, lr = 0.0005
I1015 12:10:13.630795 15018 solver.cpp:243] Iteration 6300, loss = 3.98328
I1015 12:10:13.630846 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.79462 (* 1 = 4.79462 loss)
I1015 12:10:13.630851 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0752368 (* 1 = 0.0752368 loss)
I1015 12:10:13.630858 15018 sgd_solver.cpp:138] Iteration 6300, lr = 0.0005
I1015 12:10:25.627959 15018 solver.cpp:243] Iteration 6320, loss = 3.85579
I1015 12:10:25.628010 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.54272 (* 1 = 3.54272 loss)
I1015 12:10:25.628015 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0874117 (* 1 = 0.0874117 loss)
I1015 12:10:25.628022 15018 sgd_solver.cpp:138] Iteration 6320, lr = 0.0005
I1015 12:10:37.766738 15018 solver.cpp:243] Iteration 6340, loss = 3.67564
I1015 12:10:37.766788 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.95148 (* 1 = 2.95148 loss)
I1015 12:10:37.766794 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0762171 (* 1 = 0.0762171 loss)
I1015 12:10:37.766800 15018 sgd_solver.cpp:138] Iteration 6340, lr = 0.0005
I1015 12:10:49.915463 15018 solver.cpp:243] Iteration 6360, loss = 3.97368
I1015 12:10:49.915511 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.46048 (* 1 = 2.46048 loss)
I1015 12:10:49.915518 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.139432 (* 1 = 0.139432 loss)
I1015 12:10:49.915524 15018 sgd_solver.cpp:138] Iteration 6360, lr = 0.0005
I1015 12:11:02.088399 15018 solver.cpp:243] Iteration 6380, loss = 4.09209
I1015 12:11:02.088449 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.54973 (* 1 = 2.54973 loss)
I1015 12:11:02.088454 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134494 (* 1 = 0.134494 loss)
I1015 12:11:02.088460 15018 sgd_solver.cpp:138] Iteration 6380, lr = 0.0005
I1015 12:11:14.105530 15018 solver.cpp:243] Iteration 6400, loss = 2.50014
I1015 12:11:14.105566 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.86774 (* 1 = 4.86774 loss)
I1015 12:11:14.105571 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0777717 (* 1 = 0.0777717 loss)
I1015 12:11:14.105577 15018 sgd_solver.cpp:138] Iteration 6400, lr = 0.0005
I1015 12:11:26.296345 15018 solver.cpp:243] Iteration 6420, loss = 3.44006
I1015 12:11:26.296393 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.67245 (* 1 = 1.67245 loss)
I1015 12:11:26.296399 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.369413 (* 1 = 0.369413 loss)
I1015 12:11:26.296406 15018 sgd_solver.cpp:138] Iteration 6420, lr = 0.0005
I1015 12:11:38.549067 15018 solver.cpp:243] Iteration 6440, loss = 4.08653
I1015 12:11:38.549115 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.58675 (* 1 = 1.58675 loss)
I1015 12:11:38.549121 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.294517 (* 1 = 0.294517 loss)
I1015 12:11:38.549126 15018 sgd_solver.cpp:138] Iteration 6440, lr = 0.0005
I1015 12:11:50.508908 15018 solver.cpp:243] Iteration 6460, loss = 3.17309
I1015 12:11:50.508940 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.64195 (* 1 = 3.64195 loss)
I1015 12:11:50.508946 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0842684 (* 1 = 0.0842684 loss)
I1015 12:11:50.508954 15018 sgd_solver.cpp:138] Iteration 6460, lr = 0.0005
I1015 12:12:02.441272 15018 solver.cpp:243] Iteration 6480, loss = 3.01592
I1015 12:12:02.441319 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.72159 (* 1 = 1.72159 loss)
I1015 12:12:02.441325 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0757162 (* 1 = 0.0757162 loss)
I1015 12:12:02.441335 15018 sgd_solver.cpp:138] Iteration 6480, lr = 0.0005
I1015 12:12:13.923696 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6500.caffemodel
I1015 12:12:14.185082 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6500.solverstate
I1015 12:12:14.771872 15018 solver.cpp:243] Iteration 6500, loss = 4.5664
I1015 12:12:14.771908 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.10227 (* 1 = 6.10227 loss)
I1015 12:12:14.771916 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111854 (* 1 = 0.111854 loss)
I1015 12:12:14.771939 15018 sgd_solver.cpp:138] Iteration 6500, lr = 0.0005
I1015 12:12:26.156244 15018 solver.cpp:243] Iteration 6520, loss = 3.54298
I1015 12:12:26.156280 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.23482 (* 1 = 4.23482 loss)
I1015 12:12:26.156289 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0695883 (* 1 = 0.0695883 loss)
I1015 12:12:26.156297 15018 sgd_solver.cpp:138] Iteration 6520, lr = 0.0005
I1015 12:12:38.163720 15018 solver.cpp:243] Iteration 6540, loss = 3.80155
I1015 12:12:38.163756 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.21148 (* 1 = 3.21148 loss)
I1015 12:12:38.163765 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.117636 (* 1 = 0.117636 loss)
I1015 12:12:38.163774 15018 sgd_solver.cpp:138] Iteration 6540, lr = 0.0005
I1015 12:12:50.245645 15018 solver.cpp:243] Iteration 6560, loss = 3.34265
I1015 12:12:50.245697 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.98594 (* 1 = 4.98594 loss)
I1015 12:12:50.245723 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0810918 (* 1 = 0.0810918 loss)
I1015 12:12:50.245729 15018 sgd_solver.cpp:138] Iteration 6560, lr = 0.0005
I1015 12:13:02.107928 15018 solver.cpp:243] Iteration 6580, loss = 3.98932
I1015 12:13:02.107964 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.81135 (* 1 = 3.81135 loss)
I1015 12:13:02.107972 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0923721 (* 1 = 0.0923721 loss)
I1015 12:13:02.107995 15018 sgd_solver.cpp:138] Iteration 6580, lr = 0.0005
I1015 12:13:13.941579 15018 solver.cpp:243] Iteration 6600, loss = 4.26375
I1015 12:13:13.941617 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.03303 (* 1 = 5.03303 loss)
I1015 12:13:13.941627 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0986001 (* 1 = 0.0986001 loss)
I1015 12:13:13.941633 15018 sgd_solver.cpp:138] Iteration 6600, lr = 0.0005
I1015 12:13:25.887068 15018 solver.cpp:243] Iteration 6620, loss = 4.17167
I1015 12:13:25.887104 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.78445 (* 1 = 4.78445 loss)
I1015 12:13:25.887111 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0730372 (* 1 = 0.0730372 loss)
I1015 12:13:25.887135 15018 sgd_solver.cpp:138] Iteration 6620, lr = 0.0005
I1015 12:13:37.479615 15018 solver.cpp:243] Iteration 6640, loss = 3.68893
I1015 12:13:37.479652 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15861 (* 1 = 3.15861 loss)
I1015 12:13:37.479677 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0689977 (* 1 = 0.0689977 loss)
I1015 12:13:37.479686 15018 sgd_solver.cpp:138] Iteration 6640, lr = 0.0005
I1015 12:13:49.062588 15018 solver.cpp:243] Iteration 6660, loss = 3.70123
I1015 12:13:49.062623 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.03526 (* 1 = 3.03526 loss)
I1015 12:13:49.062631 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0618441 (* 1 = 0.0618441 loss)
I1015 12:13:49.062654 15018 sgd_solver.cpp:138] Iteration 6660, lr = 0.0005
I1015 12:14:00.769250 15018 solver.cpp:243] Iteration 6680, loss = 3.48632
I1015 12:14:00.769286 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.15766 (* 1 = 5.15766 loss)
I1015 12:14:00.769295 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.093823 (* 1 = 0.093823 loss)
I1015 12:14:00.769318 15018 sgd_solver.cpp:138] Iteration 6680, lr = 0.0005
I1015 12:14:12.844184 15018 solver.cpp:243] Iteration 6700, loss = 5.17983
I1015 12:14:12.844220 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.52851 (* 1 = 6.52851 loss)
I1015 12:14:12.844228 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0696125 (* 1 = 0.0696125 loss)
I1015 12:14:12.844251 15018 sgd_solver.cpp:138] Iteration 6700, lr = 0.0005
I1015 12:14:24.982950 15018 solver.cpp:243] Iteration 6720, loss = 4.72052
I1015 12:14:24.982985 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.95583 (* 1 = 2.95583 loss)
I1015 12:14:24.982995 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0733872 (* 1 = 0.0733872 loss)
I1015 12:14:24.983017 15018 sgd_solver.cpp:138] Iteration 6720, lr = 0.0005
I1015 12:14:37.143456 15018 solver.cpp:243] Iteration 6740, loss = 5.34476
I1015 12:14:37.143492 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.00902 (* 1 = 4.00902 loss)
I1015 12:14:37.143501 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.121792 (* 1 = 0.121792 loss)
I1015 12:14:37.143509 15018 sgd_solver.cpp:138] Iteration 6740, lr = 0.0005
I1015 12:14:49.158511 15018 solver.cpp:243] Iteration 6760, loss = 4.94545
I1015 12:14:49.158563 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.84695 (* 1 = 5.84695 loss)
I1015 12:14:49.158572 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.122228 (* 1 = 0.122228 loss)
I1015 12:14:49.158581 15018 sgd_solver.cpp:138] Iteration 6760, lr = 0.0005
I1015 12:15:01.034389 15018 solver.cpp:243] Iteration 6780, loss = 3.73879
I1015 12:15:01.034423 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.81495 (* 1 = 6.81495 loss)
I1015 12:15:01.034432 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0761374 (* 1 = 0.0761374 loss)
I1015 12:15:01.034456 15018 sgd_solver.cpp:138] Iteration 6780, lr = 0.0005
I1015 12:15:12.984875 15018 solver.cpp:243] Iteration 6800, loss = 3.66127
I1015 12:15:12.984911 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.6573 (* 1 = 3.6573 loss)
I1015 12:15:12.984920 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.146104 (* 1 = 0.146104 loss)
I1015 12:15:12.984943 15018 sgd_solver.cpp:138] Iteration 6800, lr = 0.0005
I1015 12:15:24.823408 15018 solver.cpp:243] Iteration 6820, loss = 2.97472
I1015 12:15:24.823442 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.1956 (* 1 = 1.1956 loss)
I1015 12:15:24.823451 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.11875 (* 1 = 0.11875 loss)
I1015 12:15:24.823474 15018 sgd_solver.cpp:138] Iteration 6820, lr = 0.0005
I1015 12:15:36.912708 15018 solver.cpp:243] Iteration 6840, loss = 3.65517
I1015 12:15:36.912744 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.0018 (* 1 = 5.0018 loss)
I1015 12:15:36.912752 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.122984 (* 1 = 0.122984 loss)
I1015 12:15:36.912760 15018 sgd_solver.cpp:138] Iteration 6840, lr = 0.0005
I1015 12:15:48.881759 15018 solver.cpp:243] Iteration 6860, loss = 3.59786
I1015 12:15:48.881795 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.5036 (* 1 = 3.5036 loss)
I1015 12:15:48.881804 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.163008 (* 1 = 0.163008 loss)
I1015 12:15:48.881811 15018 sgd_solver.cpp:138] Iteration 6860, lr = 0.0005
I1015 12:16:01.069310 15018 solver.cpp:243] Iteration 6880, loss = 3.17535
I1015 12:16:01.069351 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.89599 (* 1 = 1.89599 loss)
I1015 12:16:01.069360 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112092 (* 1 = 0.112092 loss)
I1015 12:16:01.069368 15018 sgd_solver.cpp:138] Iteration 6880, lr = 0.0005
I1015 12:16:13.182683 15018 solver.cpp:243] Iteration 6900, loss = 4.08501
I1015 12:16:13.182720 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.16474 (* 1 = 6.16474 loss)
I1015 12:16:13.182730 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0971729 (* 1 = 0.0971729 loss)
I1015 12:16:13.182754 15018 sgd_solver.cpp:138] Iteration 6900, lr = 0.0005
I1015 12:16:25.263922 15018 solver.cpp:243] Iteration 6920, loss = 4.0115
I1015 12:16:25.263959 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.83533 (* 1 = 3.83533 loss)
I1015 12:16:25.263968 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0911073 (* 1 = 0.0911073 loss)
I1015 12:16:25.263976 15018 sgd_solver.cpp:138] Iteration 6920, lr = 0.0005
I1015 12:16:37.185832 15018 solver.cpp:243] Iteration 6940, loss = 2.23573
I1015 12:16:37.185868 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.20447 (* 1 = 2.20447 loss)
I1015 12:16:37.185878 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0873906 (* 1 = 0.0873906 loss)
I1015 12:16:37.185899 15018 sgd_solver.cpp:138] Iteration 6940, lr = 0.0005
I1015 12:16:49.361263 15018 solver.cpp:243] Iteration 6960, loss = 3.93279
I1015 12:16:49.361299 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.4427 (* 1 = 5.4427 loss)
I1015 12:16:49.361307 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127926 (* 1 = 0.127926 loss)
I1015 12:16:49.361335 15018 sgd_solver.cpp:138] Iteration 6960, lr = 0.0005
I1015 12:17:01.594563 15018 solver.cpp:243] Iteration 6980, loss = 3.90172
I1015 12:17:01.594597 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.00578 (* 1 = 3.00578 loss)
I1015 12:17:01.594606 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.239149 (* 1 = 0.239149 loss)
I1015 12:17:01.594614 15018 sgd_solver.cpp:138] Iteration 6980, lr = 0.0005
I1015 12:17:12.990834 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7000.caffemodel
I1015 12:17:13.756016 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7000.solverstate
I1015 12:17:13.952728 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 12:17:33.293300 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:18:51.526165 15018 solver.cpp:243] Iteration 7000, loss = 1.92448
I1015 12:18:51.526201 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.85259 (* 1 = 1.85259 loss)
I1015 12:18:51.526206 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0718899 (* 1 = 0.0718899 loss)
I1015 12:18:51.526211 15018 sgd_solver.cpp:138] Iteration 7000, lr = 0.0005
I1015 12:19:02.480902 15018 solver.cpp:243] Iteration 7020, loss = 3.36755
I1015 12:19:02.480950 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.05803 (* 1 = 2.05803 loss)
I1015 12:19:02.480957 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0676251 (* 1 = 0.0676251 loss)
I1015 12:19:02.480962 15018 sgd_solver.cpp:138] Iteration 7020, lr = 0.0005
I1015 12:19:14.347003 15018 solver.cpp:243] Iteration 7040, loss = 4.34665
I1015 12:19:14.347050 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.07388 (* 1 = 6.07388 loss)
I1015 12:19:14.347057 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.092773 (* 1 = 0.092773 loss)
I1015 12:19:14.347062 15018 sgd_solver.cpp:138] Iteration 7040, lr = 0.0005
I1015 12:19:26.071867 15018 solver.cpp:243] Iteration 7060, loss = 3.47906
I1015 12:19:26.071916 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.05453 (* 1 = 3.05453 loss)
I1015 12:19:26.071923 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0838936 (* 1 = 0.0838936 loss)
I1015 12:19:26.071928 15018 sgd_solver.cpp:138] Iteration 7060, lr = 0.0005
I1015 12:19:38.023357 15018 solver.cpp:243] Iteration 7080, loss = 3.83938
I1015 12:19:38.023406 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.16666 (* 1 = 3.16666 loss)
I1015 12:19:38.023412 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.109823 (* 1 = 0.109823 loss)
I1015 12:19:38.023417 15018 sgd_solver.cpp:138] Iteration 7080, lr = 0.0005
I1015 12:19:50.073607 15018 solver.cpp:243] Iteration 7100, loss = 2.83325
I1015 12:19:50.073642 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.43387 (* 1 = 2.43387 loss)
I1015 12:19:50.073647 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0919861 (* 1 = 0.0919861 loss)
I1015 12:19:50.073653 15018 sgd_solver.cpp:138] Iteration 7100, lr = 0.0005
I1015 12:20:01.997797 15018 solver.cpp:243] Iteration 7120, loss = 4.16806
I1015 12:20:01.997844 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.13917 (* 1 = 4.13917 loss)
I1015 12:20:01.997851 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0962421 (* 1 = 0.0962421 loss)
I1015 12:20:01.997856 15018 sgd_solver.cpp:138] Iteration 7120, lr = 0.0005
I1015 12:20:13.801772 15018 solver.cpp:243] Iteration 7140, loss = 4.1034
I1015 12:20:13.801807 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.45705 (* 1 = 2.45705 loss)
I1015 12:20:13.801815 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0907782 (* 1 = 0.0907782 loss)
I1015 12:20:13.801820 15018 sgd_solver.cpp:138] Iteration 7140, lr = 0.0005
I1015 12:20:25.792500 15018 solver.cpp:243] Iteration 7160, loss = 3.87417
I1015 12:20:25.792536 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.42564 (* 1 = 3.42564 loss)
I1015 12:20:25.792541 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0799619 (* 1 = 0.0799619 loss)
I1015 12:20:25.792547 15018 sgd_solver.cpp:138] Iteration 7160, lr = 0.0005
I1015 12:20:37.482520 15018 solver.cpp:243] Iteration 7180, loss = 3.56158
I1015 12:20:37.482586 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.1889 (* 1 = 4.1889 loss)
I1015 12:20:37.482592 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0725069 (* 1 = 0.0725069 loss)
I1015 12:20:37.482599 15018 sgd_solver.cpp:138] Iteration 7180, lr = 0.0005
I1015 12:20:49.046103 15018 solver.cpp:243] Iteration 7200, loss = 3.49213
I1015 12:20:49.046135 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.20339 (* 1 = 2.20339 loss)
I1015 12:20:49.046141 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0603266 (* 1 = 0.0603266 loss)
I1015 12:20:49.046146 15018 sgd_solver.cpp:138] Iteration 7200, lr = 0.0005
I1015 12:21:00.758967 15018 solver.cpp:243] Iteration 7220, loss = 3.00211
I1015 12:21:00.759016 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.59909 (* 1 = 3.59909 loss)
I1015 12:21:00.759023 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0942023 (* 1 = 0.0942023 loss)
I1015 12:21:00.759028 15018 sgd_solver.cpp:138] Iteration 7220, lr = 0.0005
I1015 12:21:12.920015 15018 solver.cpp:243] Iteration 7240, loss = 4.66123
I1015 12:21:12.920063 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.5977 (* 1 = 3.5977 loss)
I1015 12:21:12.920069 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0899604 (* 1 = 0.0899604 loss)
I1015 12:21:12.920075 15018 sgd_solver.cpp:138] Iteration 7240, lr = 0.0005
I1015 12:21:25.044634 15018 solver.cpp:243] Iteration 7260, loss = 4.56506
I1015 12:21:25.044684 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.9321 (* 1 = 3.9321 loss)
I1015 12:21:25.044690 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115655 (* 1 = 0.115655 loss)
I1015 12:21:25.044697 15018 sgd_solver.cpp:138] Iteration 7260, lr = 0.0005
I1015 12:21:37.228976 15018 solver.cpp:243] Iteration 7280, loss = 5.3684
I1015 12:21:37.229023 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.81292 (* 1 = 7.81292 loss)
I1015 12:21:37.229029 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0893522 (* 1 = 0.0893522 loss)
I1015 12:21:37.229035 15018 sgd_solver.cpp:138] Iteration 7280, lr = 0.0005
I1015 12:21:49.295961 15018 solver.cpp:243] Iteration 7300, loss = 4.92319
I1015 12:21:49.296010 15018 solver.cpp:259]     Train net output #0: mbox_loss = 7.32835 (* 1 = 7.32835 loss)
I1015 12:21:49.296015 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134096 (* 1 = 0.134096 loss)
I1015 12:21:49.296021 15018 sgd_solver.cpp:138] Iteration 7300, lr = 0.0005
I1015 12:22:01.202487 15018 solver.cpp:243] Iteration 7320, loss = 3.70793
I1015 12:22:01.202523 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.19628 (* 1 = 3.19628 loss)
I1015 12:22:01.202529 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112173 (* 1 = 0.112173 loss)
I1015 12:22:01.202535 15018 sgd_solver.cpp:138] Iteration 7320, lr = 0.0005
I1015 12:22:13.119691 15018 solver.cpp:243] Iteration 7340, loss = 3.17026
I1015 12:22:13.119740 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.53133 (* 1 = 2.53133 loss)
I1015 12:22:13.119747 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107371 (* 1 = 0.107371 loss)
I1015 12:22:13.119752 15018 sgd_solver.cpp:138] Iteration 7340, lr = 0.0005
I1015 12:22:24.990916 15018 solver.cpp:243] Iteration 7360, loss = 3.33226
I1015 12:22:24.990965 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.33459 (* 1 = 4.33459 loss)
I1015 12:22:24.990972 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115452 (* 1 = 0.115452 loss)
I1015 12:22:24.990978 15018 sgd_solver.cpp:138] Iteration 7360, lr = 0.0005
I1015 12:22:37.024837 15018 solver.cpp:243] Iteration 7380, loss = 3.61504
I1015 12:22:37.024885 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.34559 (* 1 = 2.34559 loss)
I1015 12:22:37.024891 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0975201 (* 1 = 0.0975201 loss)
I1015 12:22:37.024897 15018 sgd_solver.cpp:138] Iteration 7380, lr = 0.0005
I1015 12:22:48.993836 15018 solver.cpp:243] Iteration 7400, loss = 3.38948
I1015 12:22:48.993870 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.41624 (* 1 = 4.41624 loss)
I1015 12:22:48.993875 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.652532 (* 1 = 0.652532 loss)
I1015 12:22:48.993880 15018 sgd_solver.cpp:138] Iteration 7400, lr = 0.0005
I1015 12:23:01.238696 15018 solver.cpp:243] Iteration 7420, loss = 3.12193
I1015 12:23:01.238730 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.78852 (* 1 = 2.78852 loss)
I1015 12:23:01.238736 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.164844 (* 1 = 0.164844 loss)
I1015 12:23:01.238741 15018 sgd_solver.cpp:138] Iteration 7420, lr = 0.0005
I1015 12:23:13.428656 15018 solver.cpp:243] Iteration 7440, loss = 3.48527
I1015 12:23:13.428705 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.58356 (* 1 = 3.58356 loss)
I1015 12:23:13.428712 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125102 (* 1 = 0.125102 loss)
I1015 12:23:13.428717 15018 sgd_solver.cpp:138] Iteration 7440, lr = 0.0005
I1015 12:23:25.576854 15018 solver.cpp:243] Iteration 7460, loss = 3.91283
I1015 12:23:25.576903 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.81528 (* 1 = 3.81528 loss)
I1015 12:23:25.576910 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.167951 (* 1 = 0.167951 loss)
I1015 12:23:25.576915 15018 sgd_solver.cpp:138] Iteration 7460, lr = 0.0005
I1015 12:23:37.574018 15018 solver.cpp:243] Iteration 7480, loss = 2.23811
I1015 12:23:37.574067 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.599 (* 1 = 1.599 loss)
I1015 12:23:37.574074 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0860475 (* 1 = 0.0860475 loss)
I1015 12:23:37.574079 15018 sgd_solver.cpp:138] Iteration 7480, lr = 0.0005
I1015 12:23:49.238106 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7500.caffemodel
I1015 12:23:49.575251 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7500.solverstate
I1015 12:23:50.173024 15018 solver.cpp:243] Iteration 7500, loss = 3.7738
I1015 12:23:50.173071 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.58754 (* 1 = 4.58754 loss)
I1015 12:23:50.173077 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102836 (* 1 = 0.102836 loss)
I1015 12:23:50.173084 15018 sgd_solver.cpp:138] Iteration 7500, lr = 0.0005
I1015 12:24:02.166576 15018 solver.cpp:243] Iteration 7520, loss = 2.92892
I1015 12:24:02.166627 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.75547 (* 1 = 5.75547 loss)
I1015 12:24:02.166633 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.543277 (* 1 = 0.543277 loss)
I1015 12:24:02.166640 15018 sgd_solver.cpp:138] Iteration 7520, lr = 0.0005
I1015 12:24:14.100510 15018 solver.cpp:243] Iteration 7540, loss = 3.00301
I1015 12:24:14.100558 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.30594 (* 1 = 4.30594 loss)
I1015 12:24:14.100564 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104377 (* 1 = 0.104377 loss)
I1015 12:24:14.100570 15018 sgd_solver.cpp:138] Iteration 7540, lr = 0.0005
I1015 12:24:26.045730 15018 solver.cpp:243] Iteration 7560, loss = 3.3674
I1015 12:24:26.045780 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.771125 (* 1 = 0.771125 loss)
I1015 12:24:26.045786 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0826436 (* 1 = 0.0826436 loss)
I1015 12:24:26.045792 15018 sgd_solver.cpp:138] Iteration 7560, lr = 0.0005
I1015 12:24:38.003348 15018 solver.cpp:243] Iteration 7580, loss = 3.89568
I1015 12:24:38.003396 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.04185 (* 1 = 3.04185 loss)
I1015 12:24:38.003402 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0908838 (* 1 = 0.0908838 loss)
I1015 12:24:38.003409 15018 sgd_solver.cpp:138] Iteration 7580, lr = 0.0005
I1015 12:24:49.774961 15018 solver.cpp:243] Iteration 7600, loss = 4.36732
I1015 12:24:49.775010 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.12281 (* 1 = 5.12281 loss)
I1015 12:24:49.775017 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0587892 (* 1 = 0.0587892 loss)
I1015 12:24:49.775023 15018 sgd_solver.cpp:138] Iteration 7600, lr = 0.0005
I1015 12:24:56.354851 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:25:01.682083 15018 solver.cpp:243] Iteration 7620, loss = 3.45577
I1015 12:25:01.682132 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.56839 (* 1 = 2.56839 loss)
I1015 12:25:01.682138 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.184977 (* 1 = 0.184977 loss)
I1015 12:25:01.682144 15018 sgd_solver.cpp:138] Iteration 7620, lr = 0.0005
I1015 12:25:13.708950 15018 solver.cpp:243] Iteration 7640, loss = 2.81649
I1015 12:25:13.708981 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.40224 (* 1 = 1.40224 loss)
I1015 12:25:13.708990 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0925398 (* 1 = 0.0925398 loss)
I1015 12:25:13.708997 15018 sgd_solver.cpp:138] Iteration 7640, lr = 0.0005
I1015 12:25:25.695008 15018 solver.cpp:243] Iteration 7660, loss = 3.6153
I1015 12:25:25.695039 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.60816 (* 1 = 4.60816 loss)
I1015 12:25:25.695045 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.073946 (* 1 = 0.073946 loss)
I1015 12:25:25.695051 15018 sgd_solver.cpp:138] Iteration 7660, lr = 0.0005
I1015 12:25:37.599830 15018 solver.cpp:243] Iteration 7680, loss = 3.79506
I1015 12:25:37.599865 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.92742 (* 1 = 4.92742 loss)
I1015 12:25:37.599874 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0774618 (* 1 = 0.0774618 loss)
I1015 12:25:37.599897 15018 sgd_solver.cpp:138] Iteration 7680, lr = 0.0005
I1015 12:25:49.546371 15018 solver.cpp:243] Iteration 7700, loss = 3.64066
I1015 12:25:49.546420 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.35656 (* 1 = 4.35656 loss)
I1015 12:25:49.546427 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.114111 (* 1 = 0.114111 loss)
I1015 12:25:49.546432 15018 sgd_solver.cpp:138] Iteration 7700, lr = 0.0005
I1015 12:26:01.231833 15018 solver.cpp:243] Iteration 7720, loss = 3.54494
I1015 12:26:01.231880 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.4175 (* 1 = 2.4175 loss)
I1015 12:26:01.231887 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0785573 (* 1 = 0.0785573 loss)
I1015 12:26:01.231892 15018 sgd_solver.cpp:138] Iteration 7720, lr = 0.0005
I1015 12:26:12.769969 15018 solver.cpp:243] Iteration 7740, loss = 3.42236
I1015 12:26:12.770009 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.04202 (* 1 = 2.04202 loss)
I1015 12:26:12.770018 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0605555 (* 1 = 0.0605555 loss)
I1015 12:26:12.770025 15018 sgd_solver.cpp:138] Iteration 7740, lr = 0.0005
I1015 12:26:24.451230 15018 solver.cpp:243] Iteration 7760, loss = 2.94905
I1015 12:26:24.451279 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.79253 (* 1 = 2.79253 loss)
I1015 12:26:24.451287 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.138656 (* 1 = 0.138656 loss)
I1015 12:26:24.451292 15018 sgd_solver.cpp:138] Iteration 7760, lr = 0.0005
I1015 12:26:36.568759 15018 solver.cpp:243] Iteration 7780, loss = 4.41428
I1015 12:26:36.568809 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.17563 (* 1 = 4.17563 loss)
I1015 12:26:36.568815 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0730893 (* 1 = 0.0730893 loss)
I1015 12:26:36.568821 15018 sgd_solver.cpp:138] Iteration 7780, lr = 0.0005
I1015 12:26:48.688603 15018 solver.cpp:243] Iteration 7800, loss = 4.12797
I1015 12:26:48.688648 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.76698 (* 1 = 3.76698 loss)
I1015 12:26:48.688655 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0744979 (* 1 = 0.0744979 loss)
I1015 12:26:48.688661 15018 sgd_solver.cpp:138] Iteration 7800, lr = 0.0005
I1015 12:27:00.886883 15018 solver.cpp:243] Iteration 7820, loss = 5.01854
I1015 12:27:00.886930 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.20064 (* 1 = 4.20064 loss)
I1015 12:27:00.886937 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.125934 (* 1 = 0.125934 loss)
I1015 12:27:00.886942 15018 sgd_solver.cpp:138] Iteration 7820, lr = 0.0005
I1015 12:27:12.960180 15018 solver.cpp:243] Iteration 7840, loss = 4.63897
I1015 12:27:12.960227 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.609 (* 1 = 4.609 loss)
I1015 12:27:12.960233 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0724949 (* 1 = 0.0724949 loss)
I1015 12:27:12.960239 15018 sgd_solver.cpp:138] Iteration 7840, lr = 0.0005
I1015 12:27:24.821090 15018 solver.cpp:243] Iteration 7860, loss = 3.86034
I1015 12:27:24.821139 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.50412 (* 1 = 1.50412 loss)
I1015 12:27:24.821146 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.182046 (* 1 = 0.182046 loss)
I1015 12:27:24.821152 15018 sgd_solver.cpp:138] Iteration 7860, lr = 0.0005
I1015 12:27:36.761365 15018 solver.cpp:243] Iteration 7880, loss = 3.66258
I1015 12:27:36.761399 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.485 (* 1 = 5.485 loss)
I1015 12:27:36.761404 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0920259 (* 1 = 0.0920259 loss)
I1015 12:27:36.761410 15018 sgd_solver.cpp:138] Iteration 7880, lr = 0.0005
I1015 12:27:48.632297 15018 solver.cpp:243] Iteration 7900, loss = 3.25943
I1015 12:27:48.632344 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.06499 (* 1 = 5.06499 loss)
I1015 12:27:48.632350 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.166614 (* 1 = 0.166614 loss)
I1015 12:27:48.632355 15018 sgd_solver.cpp:138] Iteration 7900, lr = 0.0005
I1015 12:28:00.692452 15018 solver.cpp:243] Iteration 7920, loss = 4.09104
I1015 12:28:00.692502 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.62057 (* 1 = 1.62057 loss)
I1015 12:28:00.692507 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103251 (* 1 = 0.103251 loss)
I1015 12:28:00.692513 15018 sgd_solver.cpp:138] Iteration 7920, lr = 0.0005
I1015 12:28:12.655135 15018 solver.cpp:243] Iteration 7940, loss = 3.0918
I1015 12:28:12.655184 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.81446 (* 1 = 1.81446 loss)
I1015 12:28:12.655190 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127512 (* 1 = 0.127512 loss)
I1015 12:28:12.655196 15018 sgd_solver.cpp:138] Iteration 7940, lr = 0.0005
I1015 12:28:24.832104 15018 solver.cpp:243] Iteration 7960, loss = 3.20156
I1015 12:28:24.832154 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.52059 (* 1 = 2.52059 loss)
I1015 12:28:24.832160 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.113418 (* 1 = 0.113418 loss)
I1015 12:28:24.832165 15018 sgd_solver.cpp:138] Iteration 7960, lr = 0.0005
I1015 12:28:36.970937 15018 solver.cpp:243] Iteration 7980, loss = 3.39232
I1015 12:28:36.970988 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.59859 (* 1 = 4.59859 loss)
I1015 12:28:36.970994 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.081024 (* 1 = 0.081024 loss)
I1015 12:28:36.971000 15018 sgd_solver.cpp:138] Iteration 7980, lr = 0.0005
I1015 12:28:48.547641 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8000.caffemodel
I1015 12:28:49.286952 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8000.solverstate
I1015 12:28:49.486897 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 12:30:28.455633 15018 solver.cpp:243] Iteration 8000, loss = 4.49252
I1015 12:30:28.455667 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.365 (* 1 = 4.365 loss)
I1015 12:30:28.455674 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127515 (* 1 = 0.127515 loss)
I1015 12:30:28.455680 15018 sgd_solver.cpp:138] Iteration 8000, lr = 0.0005
I1015 12:30:39.433398 15018 solver.cpp:243] Iteration 8020, loss = 2.14132
I1015 12:30:39.433437 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.563882 (* 1 = 0.563882 loss)
I1015 12:30:39.433444 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0794097 (* 1 = 0.0794097 loss)
I1015 12:30:39.433449 15018 sgd_solver.cpp:138] Iteration 8020, lr = 0.0005
I1015 12:30:51.526908 15018 solver.cpp:243] Iteration 8040, loss = 3.53177
I1015 12:30:51.526942 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.62725 (* 1 = 1.62725 loss)
I1015 12:30:51.526948 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0639773 (* 1 = 0.0639773 loss)
I1015 12:30:51.526954 15018 sgd_solver.cpp:138] Iteration 8040, lr = 0.0005
I1015 12:31:03.799697 15018 solver.cpp:243] Iteration 8060, loss = 2.34828
I1015 12:31:03.799731 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.48437 (* 1 = 3.48437 loss)
I1015 12:31:03.799737 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0787546 (* 1 = 0.0787546 loss)
I1015 12:31:03.799743 15018 sgd_solver.cpp:138] Iteration 8060, lr = 0.0005
I1015 12:31:15.785995 15018 solver.cpp:243] Iteration 8080, loss = 3.09082
I1015 12:31:15.786044 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.46754 (* 1 = 2.46754 loss)
I1015 12:31:15.786051 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0906824 (* 1 = 0.0906824 loss)
I1015 12:31:15.786056 15018 sgd_solver.cpp:138] Iteration 8080, lr = 0.0005
I1015 12:31:27.776334 15018 solver.cpp:243] Iteration 8100, loss = 3.50308
I1015 12:31:27.776367 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.11595 (* 1 = 2.11595 loss)
I1015 12:31:27.776373 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0700643 (* 1 = 0.0700643 loss)
I1015 12:31:27.776378 15018 sgd_solver.cpp:138] Iteration 8100, lr = 0.0005
I1015 12:31:39.713027 15018 solver.cpp:243] Iteration 8120, loss = 4.10449
I1015 12:31:39.713069 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.63381 (* 1 = 2.63381 loss)
I1015 12:31:39.713076 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.072721 (* 1 = 0.072721 loss)
I1015 12:31:39.713083 15018 sgd_solver.cpp:138] Iteration 8120, lr = 0.0005
I1015 12:31:40.393101 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:31:51.574002 15018 solver.cpp:243] Iteration 8140, loss = 4.36579
I1015 12:31:51.574050 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.50998 (* 1 = 3.50998 loss)
I1015 12:31:51.574056 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0997797 (* 1 = 0.0997797 loss)
I1015 12:31:51.574062 15018 sgd_solver.cpp:138] Iteration 8140, lr = 0.0005
I1015 12:32:03.476721 15018 solver.cpp:243] Iteration 8160, loss = 3.18679
I1015 12:32:03.476755 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.54405 (* 1 = 3.54405 loss)
I1015 12:32:03.476763 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107765 (* 1 = 0.107765 loss)
I1015 12:32:03.476768 15018 sgd_solver.cpp:138] Iteration 8160, lr = 0.0005
I1015 12:32:15.521538 15018 solver.cpp:243] Iteration 8180, loss = 3.3223
I1015 12:32:15.521574 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.77623 (* 1 = 2.77623 loss)
I1015 12:32:15.521584 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105468 (* 1 = 0.105468 loss)
I1015 12:32:15.521591 15018 sgd_solver.cpp:138] Iteration 8180, lr = 0.0005
I1015 12:32:27.498211 15018 solver.cpp:243] Iteration 8200, loss = 3.51636
I1015 12:32:27.498266 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.18653 (* 1 = 3.18653 loss)
I1015 12:32:27.498276 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0897259 (* 1 = 0.0897259 loss)
I1015 12:32:27.498282 15018 sgd_solver.cpp:138] Iteration 8200, lr = 0.0005
I1015 12:32:39.335330 15018 solver.cpp:243] Iteration 8220, loss = 3.04203
I1015 12:32:39.335361 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.61936 (* 1 = 3.61936 loss)
I1015 12:32:39.335367 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0892079 (* 1 = 0.0892079 loss)
I1015 12:32:39.335372 15018 sgd_solver.cpp:138] Iteration 8220, lr = 0.0005
I1015 12:32:51.260980 15018 solver.cpp:243] Iteration 8240, loss = 3.3518
I1015 12:32:51.261029 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.07026 (* 1 = 3.07026 loss)
I1015 12:32:51.261035 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0914427 (* 1 = 0.0914427 loss)
I1015 12:32:51.261041 15018 sgd_solver.cpp:138] Iteration 8240, lr = 0.0005
I1015 12:33:03.018255 15018 solver.cpp:243] Iteration 8260, loss = 3.14738
I1015 12:33:03.018304 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.85818 (* 1 = 3.85818 loss)
I1015 12:33:03.018311 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0642435 (* 1 = 0.0642435 loss)
I1015 12:33:03.018317 15018 sgd_solver.cpp:138] Iteration 8260, lr = 0.0005
I1015 12:33:14.546911 15018 solver.cpp:243] Iteration 8280, loss = 3.59615
I1015 12:33:14.546947 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.06175 (* 1 = 5.06175 loss)
I1015 12:33:14.546952 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0581643 (* 1 = 0.0581643 loss)
I1015 12:33:14.546958 15018 sgd_solver.cpp:138] Iteration 8280, lr = 0.0005
I1015 12:33:26.157632 15018 solver.cpp:243] Iteration 8300, loss = 2.84639
I1015 12:33:26.157665 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15165 (* 1 = 3.15165 loss)
I1015 12:33:26.157670 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0803074 (* 1 = 0.0803074 loss)
I1015 12:33:26.157676 15018 sgd_solver.cpp:138] Iteration 8300, lr = 0.0005
I1015 12:33:38.263217 15018 solver.cpp:243] Iteration 8320, loss = 3.65237
I1015 12:33:38.263249 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.21767 (* 1 = 6.21767 loss)
I1015 12:33:38.263257 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111809 (* 1 = 0.111809 loss)
I1015 12:33:38.263262 15018 sgd_solver.cpp:138] Iteration 8320, lr = 0.0005
I1015 12:33:50.325759 15018 solver.cpp:243] Iteration 8340, loss = 3.99588
I1015 12:33:50.325793 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.54342 (* 1 = 5.54342 loss)
I1015 12:33:50.325798 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0789168 (* 1 = 0.0789168 loss)
I1015 12:33:50.325804 15018 sgd_solver.cpp:138] Iteration 8340, lr = 0.0005
I1015 12:34:02.470329 15018 solver.cpp:243] Iteration 8360, loss = 5.08949
I1015 12:34:02.470376 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.69796 (* 1 = 5.69796 loss)
I1015 12:34:02.470382 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0978577 (* 1 = 0.0978577 loss)
I1015 12:34:02.470387 15018 sgd_solver.cpp:138] Iteration 8360, lr = 0.0005
I1015 12:34:14.577651 15018 solver.cpp:243] Iteration 8380, loss = 4.3584
I1015 12:34:14.577714 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.83624 (* 1 = 4.83624 loss)
I1015 12:34:14.577721 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.089706 (* 1 = 0.089706 loss)
I1015 12:34:14.577726 15018 sgd_solver.cpp:138] Iteration 8380, lr = 0.0005
I1015 12:34:26.439986 15018 solver.cpp:243] Iteration 8400, loss = 4.44509
I1015 12:34:26.440033 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.83403 (* 1 = 2.83403 loss)
I1015 12:34:26.440039 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0896062 (* 1 = 0.0896062 loss)
I1015 12:34:26.440045 15018 sgd_solver.cpp:138] Iteration 8400, lr = 0.0005
I1015 12:34:38.428354 15018 solver.cpp:243] Iteration 8420, loss = 2.96626
I1015 12:34:38.428387 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.52025 (* 1 = 6.52025 loss)
I1015 12:34:38.428393 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0923402 (* 1 = 0.0923402 loss)
I1015 12:34:38.428398 15018 sgd_solver.cpp:138] Iteration 8420, lr = 0.0005
I1015 12:34:50.319175 15018 solver.cpp:243] Iteration 8440, loss = 2.74356
I1015 12:34:50.319221 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.39447 (* 1 = 3.39447 loss)
I1015 12:34:50.319227 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12489 (* 1 = 0.12489 loss)
I1015 12:34:50.319233 15018 sgd_solver.cpp:138] Iteration 8440, lr = 0.0005
I1015 12:35:02.305812 15018 solver.cpp:243] Iteration 8460, loss = 3.65381
I1015 12:35:02.305861 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.62681 (* 1 = 4.62681 loss)
I1015 12:35:02.305867 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0949404 (* 1 = 0.0949404 loss)
I1015 12:35:02.305872 15018 sgd_solver.cpp:138] Iteration 8460, lr = 0.0005
I1015 12:35:14.297545 15018 solver.cpp:243] Iteration 8480, loss = 3.40538
I1015 12:35:14.297580 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.37096 (* 1 = 4.37096 loss)
I1015 12:35:14.297586 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.109346 (* 1 = 0.109346 loss)
I1015 12:35:14.297591 15018 sgd_solver.cpp:138] Iteration 8480, lr = 0.0005
I1015 12:35:25.932440 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8500.caffemodel
I1015 12:35:26.696699 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8500.solverstate
I1015 12:35:27.290541 15018 solver.cpp:243] Iteration 8500, loss = 3.25338
I1015 12:35:27.290588 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.37862 (* 1 = 1.37862 loss)
I1015 12:35:27.290594 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0899127 (* 1 = 0.0899127 loss)
I1015 12:35:27.290601 15018 sgd_solver.cpp:138] Iteration 8500, lr = 0.0005
I1015 12:35:38.703968 15018 solver.cpp:243] Iteration 8520, loss = 3.54736
I1015 12:35:38.704017 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.07926 (* 1 = 1.07926 loss)
I1015 12:35:38.704023 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.100943 (* 1 = 0.100943 loss)
I1015 12:35:38.704030 15018 sgd_solver.cpp:138] Iteration 8520, lr = 0.0005
I1015 12:35:50.818337 15018 solver.cpp:243] Iteration 8540, loss = 4.07237
I1015 12:35:50.818387 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.05995 (* 1 = 4.05995 loss)
I1015 12:35:50.818392 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.113131 (* 1 = 0.113131 loss)
I1015 12:35:50.818398 15018 sgd_solver.cpp:138] Iteration 8540, lr = 0.0005
I1015 12:36:02.877447 15018 solver.cpp:243] Iteration 8560, loss = 2.53168
I1015 12:36:02.877482 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.02772 (* 1 = 2.02772 loss)
I1015 12:36:02.877488 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.114653 (* 1 = 0.114653 loss)
I1015 12:36:02.877494 15018 sgd_solver.cpp:138] Iteration 8560, lr = 0.0005
I1015 12:36:14.939200 15018 solver.cpp:243] Iteration 8580, loss = 3.69636
I1015 12:36:14.939249 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.595 (* 1 = 2.595 loss)
I1015 12:36:14.939255 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106305 (* 1 = 0.106305 loss)
I1015 12:36:14.939260 15018 sgd_solver.cpp:138] Iteration 8580, lr = 0.0005
I1015 12:36:27.233683 15018 solver.cpp:243] Iteration 8600, loss = 2.54507
I1015 12:36:27.233729 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.49872 (* 1 = 4.49872 loss)
I1015 12:36:27.233736 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134982 (* 1 = 0.134982 loss)
I1015 12:36:27.233741 15018 sgd_solver.cpp:138] Iteration 8600, lr = 0.0005
I1015 12:36:39.177677 15018 solver.cpp:243] Iteration 8620, loss = 3.26429
I1015 12:36:39.177726 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.89916 (* 1 = 2.89916 loss)
I1015 12:36:39.177733 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0725295 (* 1 = 0.0725295 loss)
I1015 12:36:39.177739 15018 sgd_solver.cpp:138] Iteration 8620, lr = 0.0005
I1015 12:36:51.235874 15018 solver.cpp:243] Iteration 8640, loss = 3.59776
I1015 12:36:51.235924 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.57657 (* 1 = 4.57657 loss)
I1015 12:36:51.235930 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0792034 (* 1 = 0.0792034 loss)
I1015 12:36:51.235936 15018 sgd_solver.cpp:138] Iteration 8640, lr = 0.0005
I1015 12:37:03.128759 15018 solver.cpp:243] Iteration 8660, loss = 4.00468
I1015 12:37:03.128795 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15276 (* 1 = 3.15276 loss)
I1015 12:37:03.128801 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0947003 (* 1 = 0.0947003 loss)
I1015 12:37:03.128808 15018 sgd_solver.cpp:138] Iteration 8660, lr = 0.0005
I1015 12:37:14.926646 15018 solver.cpp:243] Iteration 8680, loss = 4.02309
I1015 12:37:14.926694 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.48357 (* 1 = 3.48357 loss)
I1015 12:37:14.926700 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0921096 (* 1 = 0.0921096 loss)
I1015 12:37:14.926707 15018 sgd_solver.cpp:138] Iteration 8680, lr = 0.0005
I1015 12:37:26.757362 15018 solver.cpp:243] Iteration 8700, loss = 3.38968
I1015 12:37:26.757395 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.66147 (* 1 = 3.66147 loss)
I1015 12:37:26.757401 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0944332 (* 1 = 0.0944332 loss)
I1015 12:37:26.757407 15018 sgd_solver.cpp:138] Iteration 8700, lr = 0.0005
I1015 12:37:38.725952 15018 solver.cpp:243] Iteration 8720, loss = 3.64858
I1015 12:37:38.725986 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.2534 (* 1 = 4.2534 loss)
I1015 12:37:38.725992 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0868456 (* 1 = 0.0868456 loss)
I1015 12:37:38.725997 15018 sgd_solver.cpp:138] Iteration 8720, lr = 0.0005
I1015 12:37:50.666738 15018 solver.cpp:243] Iteration 8740, loss = 3.61005
I1015 12:37:50.666785 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.85634 (* 1 = 3.85634 loss)
I1015 12:37:50.666791 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0845029 (* 1 = 0.0845029 loss)
I1015 12:37:50.666797 15018 sgd_solver.cpp:138] Iteration 8740, lr = 0.0005
I1015 12:38:02.507225 15018 solver.cpp:243] Iteration 8760, loss = 2.9973
I1015 12:38:02.507272 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.4386 (* 1 = 3.4386 loss)
I1015 12:38:02.507279 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0701584 (* 1 = 0.0701584 loss)
I1015 12:38:02.507285 15018 sgd_solver.cpp:138] Iteration 8760, lr = 0.0005
I1015 12:38:14.429986 15018 solver.cpp:243] Iteration 8780, loss = 3.33425
I1015 12:38:14.430049 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.97043 (* 1 = 2.97043 loss)
I1015 12:38:14.430057 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0939055 (* 1 = 0.0939055 loss)
I1015 12:38:14.430063 15018 sgd_solver.cpp:138] Iteration 8780, lr = 0.0005
I1015 12:38:26.155501 15018 solver.cpp:243] Iteration 8800, loss = 3.05758
I1015 12:38:26.155550 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.42436 (* 1 = 3.42436 loss)
I1015 12:38:26.155556 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0735993 (* 1 = 0.0735993 loss)
I1015 12:38:26.155561 15018 sgd_solver.cpp:138] Iteration 8800, lr = 0.0005
I1015 12:38:37.719923 15018 solver.cpp:243] Iteration 8820, loss = 3.13694
I1015 12:38:37.719971 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.58995 (* 1 = 3.58995 loss)
I1015 12:38:37.719979 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0689545 (* 1 = 0.0689545 loss)
I1015 12:38:37.719983 15018 sgd_solver.cpp:138] Iteration 8820, lr = 0.0005
I1015 12:38:49.261016 15018 solver.cpp:243] Iteration 8840, loss = 2.68197
I1015 12:38:49.261065 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.68666 (* 1 = 3.68666 loss)
I1015 12:38:49.261070 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0674723 (* 1 = 0.0674723 loss)
I1015 12:38:49.261076 15018 sgd_solver.cpp:138] Iteration 8840, lr = 0.0005
I1015 12:39:01.363520 15018 solver.cpp:243] Iteration 8860, loss = 3.54912
I1015 12:39:01.363569 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.73109 (* 1 = 3.73109 loss)
I1015 12:39:01.363576 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0854404 (* 1 = 0.0854404 loss)
I1015 12:39:01.363581 15018 sgd_solver.cpp:138] Iteration 8860, lr = 0.0005
I1015 12:39:13.382328 15018 solver.cpp:243] Iteration 8880, loss = 3.54566
I1015 12:39:13.382378 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.90909 (* 1 = 3.90909 loss)
I1015 12:39:13.382385 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0887116 (* 1 = 0.0887116 loss)
I1015 12:39:13.382390 15018 sgd_solver.cpp:138] Iteration 8880, lr = 0.0005
I1015 12:39:25.561678 15018 solver.cpp:243] Iteration 8900, loss = 4.98533
I1015 12:39:25.561727 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.8492 (* 1 = 3.8492 loss)
I1015 12:39:25.561733 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.126254 (* 1 = 0.126254 loss)
I1015 12:39:25.561738 15018 sgd_solver.cpp:138] Iteration 8900, lr = 0.0005
I1015 12:39:37.610477 15018 solver.cpp:243] Iteration 8920, loss = 4.35052
I1015 12:39:37.610512 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.4534 (* 1 = 2.4534 loss)
I1015 12:39:37.610517 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105855 (* 1 = 0.105855 loss)
I1015 12:39:37.610525 15018 sgd_solver.cpp:138] Iteration 8920, lr = 0.0005
I1015 12:39:49.508611 15018 solver.cpp:243] Iteration 8940, loss = 4.52688
I1015 12:39:49.508646 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.69413 (* 1 = 4.69413 loss)
I1015 12:39:49.508652 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.370864 (* 1 = 0.370864 loss)
I1015 12:39:49.508658 15018 sgd_solver.cpp:138] Iteration 8940, lr = 0.0005
I1015 12:40:01.449470 15018 solver.cpp:243] Iteration 8960, loss = 2.77473
I1015 12:40:01.449506 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.71741 (* 1 = 2.71741 loss)
I1015 12:40:01.449512 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.095928 (* 1 = 0.095928 loss)
I1015 12:40:01.449517 15018 sgd_solver.cpp:138] Iteration 8960, lr = 0.0005
I1015 12:40:13.380329 15018 solver.cpp:243] Iteration 8980, loss = 2.70013
I1015 12:40:13.380379 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.54643 (* 1 = 3.54643 loss)
I1015 12:40:13.380385 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0764275 (* 1 = 0.0764275 loss)
I1015 12:40:13.380391 15018 sgd_solver.cpp:138] Iteration 8980, lr = 0.0005
I1015 12:40:24.869485 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9000.caffemodel
I1015 12:40:25.670446 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9000.solverstate
I1015 12:40:25.897536 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 12:40:51.205194 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:42:03.684486 15018 solver.cpp:243] Iteration 9000, loss = 2.63985
I1015 12:42:03.684521 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.50575 (* 1 = 2.50575 loss)
I1015 12:42:03.684527 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.134102 (* 1 = 0.134102 loss)
I1015 12:42:03.684533 15018 sgd_solver.cpp:138] Iteration 9000, lr = 0.0005
I1015 12:42:14.433612 15018 solver.cpp:243] Iteration 9020, loss = 3.62661
I1015 12:42:14.433645 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.1087 (* 1 = 3.1087 loss)
I1015 12:42:14.433651 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0581366 (* 1 = 0.0581366 loss)
I1015 12:42:14.433657 15018 sgd_solver.cpp:138] Iteration 9020, lr = 0.0005
I1015 12:42:26.628959 15018 solver.cpp:243] Iteration 9040, loss = 3.35924
I1015 12:42:26.629009 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.63837 (* 1 = 2.63837 loss)
I1015 12:42:26.629014 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105279 (* 1 = 0.105279 loss)
I1015 12:42:26.629020 15018 sgd_solver.cpp:138] Iteration 9040, lr = 0.0005
I1015 12:42:38.831773 15018 solver.cpp:243] Iteration 9060, loss = 3.73417
I1015 12:42:38.831822 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.31453 (* 1 = 3.31453 loss)
I1015 12:42:38.831830 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.128763 (* 1 = 0.128763 loss)
I1015 12:42:38.831835 15018 sgd_solver.cpp:138] Iteration 9060, lr = 0.0005
I1015 12:42:50.969687 15018 solver.cpp:243] Iteration 9080, loss = 3.55889
I1015 12:42:50.969722 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.47414 (* 1 = 2.47414 loss)
I1015 12:42:50.969728 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.096356 (* 1 = 0.096356 loss)
I1015 12:42:50.969734 15018 sgd_solver.cpp:138] Iteration 9080, lr = 0.0005
I1015 12:43:03.021281 15018 solver.cpp:243] Iteration 9100, loss = 2.45183
I1015 12:43:03.021335 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.60808 (* 1 = 1.60808 loss)
I1015 12:43:03.021342 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0774777 (* 1 = 0.0774777 loss)
I1015 12:43:03.021348 15018 sgd_solver.cpp:138] Iteration 9100, lr = 0.0005
I1015 12:43:15.150840 15018 solver.cpp:243] Iteration 9120, loss = 3.30021
I1015 12:43:15.150887 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.59688 (* 1 = 4.59688 loss)
I1015 12:43:15.150893 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0666974 (* 1 = 0.0666974 loss)
I1015 12:43:15.150899 15018 sgd_solver.cpp:138] Iteration 9120, lr = 0.0005
I1015 12:43:27.466979 15018 solver.cpp:243] Iteration 9140, loss = 2.30443
I1015 12:43:27.467034 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.1598 (* 1 = 3.1598 loss)
I1015 12:43:27.467041 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0678582 (* 1 = 0.0678582 loss)
I1015 12:43:27.467046 15018 sgd_solver.cpp:138] Iteration 9140, lr = 0.0005
I1015 12:43:39.465549 15018 solver.cpp:243] Iteration 9160, loss = 3.1779
I1015 12:43:39.465584 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.42296 (* 1 = 2.42296 loss)
I1015 12:43:39.465590 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0760548 (* 1 = 0.0760548 loss)
I1015 12:43:39.465596 15018 sgd_solver.cpp:138] Iteration 9160, lr = 0.0005
I1015 12:43:51.479796 15018 solver.cpp:243] Iteration 9180, loss = 3.10303
I1015 12:43:51.479830 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.96009 (* 1 = 2.96009 loss)
I1015 12:43:51.479836 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111415 (* 1 = 0.111415 loss)
I1015 12:43:51.479843 15018 sgd_solver.cpp:138] Iteration 9180, lr = 0.0005
I1015 12:44:03.381705 15018 solver.cpp:243] Iteration 9200, loss = 3.71008
I1015 12:44:03.381739 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.20057 (* 1 = 4.20057 loss)
I1015 12:44:03.381745 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.148227 (* 1 = 0.148227 loss)
I1015 12:44:03.381752 15018 sgd_solver.cpp:138] Iteration 9200, lr = 0.0005
I1015 12:44:15.226832 15018 solver.cpp:243] Iteration 9220, loss = 4.22579
I1015 12:44:15.226882 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.25602 (* 1 = 2.25602 loss)
I1015 12:44:15.226888 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0651345 (* 1 = 0.0651345 loss)
I1015 12:44:15.226894 15018 sgd_solver.cpp:138] Iteration 9220, lr = 0.0005
I1015 12:44:27.071308 15018 solver.cpp:243] Iteration 9240, loss = 3.59464
I1015 12:44:27.071359 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.66618 (* 1 = 2.66618 loss)
I1015 12:44:27.071367 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102541 (* 1 = 0.102541 loss)
I1015 12:44:27.071372 15018 sgd_solver.cpp:138] Iteration 9240, lr = 0.0005
I1015 12:44:39.048486 15018 solver.cpp:243] Iteration 9260, loss = 3.35228
I1015 12:44:39.048535 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.26531 (* 1 = 2.26531 loss)
I1015 12:44:39.048542 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0598179 (* 1 = 0.0598179 loss)
I1015 12:44:39.048547 15018 sgd_solver.cpp:138] Iteration 9260, lr = 0.0005
I1015 12:44:51.086715 15018 solver.cpp:243] Iteration 9280, loss = 3.65123
I1015 12:44:51.086764 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.26398 (* 1 = 4.26398 loss)
I1015 12:44:51.086771 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0613963 (* 1 = 0.0613963 loss)
I1015 12:44:51.086776 15018 sgd_solver.cpp:138] Iteration 9280, lr = 0.0005
I1015 12:45:02.933580 15018 solver.cpp:243] Iteration 9300, loss = 2.71808
I1015 12:45:02.933614 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.645 (* 1 = 3.645 loss)
I1015 12:45:02.933619 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0813877 (* 1 = 0.0813877 loss)
I1015 12:45:02.933624 15018 sgd_solver.cpp:138] Iteration 9300, lr = 0.0005
I1015 12:45:14.956531 15018 solver.cpp:243] Iteration 9320, loss = 3.24779
I1015 12:45:14.956578 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.03141 (* 1 = 4.03141 loss)
I1015 12:45:14.956584 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104635 (* 1 = 0.104635 loss)
I1015 12:45:14.956590 15018 sgd_solver.cpp:138] Iteration 9320, lr = 0.0005
I1015 12:45:26.762846 15018 solver.cpp:243] Iteration 9340, loss = 3.2172
I1015 12:45:26.762895 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.71279 (* 1 = 3.71279 loss)
I1015 12:45:26.762902 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0545933 (* 1 = 0.0545933 loss)
I1015 12:45:26.762907 15018 sgd_solver.cpp:138] Iteration 9340, lr = 0.0005
I1015 12:45:38.359724 15018 solver.cpp:243] Iteration 9360, loss = 3.10241
I1015 12:45:38.359771 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.29206 (* 1 = 4.29206 loss)
I1015 12:45:38.359777 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0704536 (* 1 = 0.0704536 loss)
I1015 12:45:38.359783 15018 sgd_solver.cpp:138] Iteration 9360, lr = 0.0005
I1015 12:45:49.916402 15018 solver.cpp:243] Iteration 9380, loss = 2.68678
I1015 12:45:49.916450 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.92065 (* 1 = 1.92065 loss)
I1015 12:45:49.916457 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.085219 (* 1 = 0.085219 loss)
I1015 12:45:49.916463 15018 sgd_solver.cpp:138] Iteration 9380, lr = 0.0005
I1015 12:46:02.038391 15018 solver.cpp:243] Iteration 9400, loss = 3.26965
I1015 12:46:02.038439 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.62993 (* 1 = 4.62993 loss)
I1015 12:46:02.038445 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0870013 (* 1 = 0.0870013 loss)
I1015 12:46:02.038451 15018 sgd_solver.cpp:138] Iteration 9400, lr = 0.0005
I1015 12:46:14.097282 15018 solver.cpp:243] Iteration 9420, loss = 3.33043
I1015 12:46:14.097335 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5481 (* 1 = 2.5481 loss)
I1015 12:46:14.097342 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0809222 (* 1 = 0.0809222 loss)
I1015 12:46:14.097347 15018 sgd_solver.cpp:138] Iteration 9420, lr = 0.0005
I1015 12:46:26.314018 15018 solver.cpp:243] Iteration 9440, loss = 4.6586
I1015 12:46:26.314066 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.61481 (* 1 = 4.61481 loss)
I1015 12:46:26.314072 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.123344 (* 1 = 0.123344 loss)
I1015 12:46:26.314077 15018 sgd_solver.cpp:138] Iteration 9440, lr = 0.0005
I1015 12:46:38.390440 15018 solver.cpp:243] Iteration 9460, loss = 4.47632
I1015 12:46:38.390471 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.0668 (* 1 = 4.0668 loss)
I1015 12:46:38.390477 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.487101 (* 1 = 0.487101 loss)
I1015 12:46:38.390482 15018 sgd_solver.cpp:138] Iteration 9460, lr = 0.0005
I1015 12:46:50.383533 15018 solver.cpp:243] Iteration 9480, loss = 4.36687
I1015 12:46:50.383579 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15917 (* 1 = 3.15917 loss)
I1015 12:46:50.383584 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0847814 (* 1 = 0.0847814 loss)
I1015 12:46:50.383589 15018 sgd_solver.cpp:138] Iteration 9480, lr = 0.0005
I1015 12:47:01.820664 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9500.caffemodel
I1015 12:47:02.080725 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9500.solverstate
I1015 12:47:02.675103 15018 solver.cpp:243] Iteration 9500, loss = 2.86962
I1015 12:47:02.675150 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.85396 (* 1 = 2.85396 loss)
I1015 12:47:02.675158 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0826703 (* 1 = 0.0826703 loss)
I1015 12:47:02.675163 15018 sgd_solver.cpp:138] Iteration 9500, lr = 0.0005
I1015 12:47:14.363214 15018 solver.cpp:243] Iteration 9520, loss = 2.60822
I1015 12:47:14.363245 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.57946 (* 1 = 2.57946 loss)
I1015 12:47:14.363251 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0903104 (* 1 = 0.0903104 loss)
I1015 12:47:14.363256 15018 sgd_solver.cpp:138] Iteration 9520, lr = 0.0005
I1015 12:47:26.440598 15018 solver.cpp:243] Iteration 9540, loss = 3.02006
I1015 12:47:26.440635 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.60674 (* 1 = 5.60674 loss)
I1015 12:47:26.440642 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.088533 (* 1 = 0.088533 loss)
I1015 12:47:26.440649 15018 sgd_solver.cpp:138] Iteration 9540, lr = 0.0005
I1015 12:47:38.401091 15018 solver.cpp:243] Iteration 9560, loss = 3.44504
I1015 12:47:38.401154 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.59606 (* 1 = 1.59606 loss)
I1015 12:47:38.401161 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0676516 (* 1 = 0.0676516 loss)
I1015 12:47:38.401167 15018 sgd_solver.cpp:138] Iteration 9560, lr = 0.0005
I1015 12:47:50.571072 15018 solver.cpp:243] Iteration 9580, loss = 3.26418
I1015 12:47:50.571105 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.91255 (* 1 = 1.91255 loss)
I1015 12:47:50.571111 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0768556 (* 1 = 0.0768556 loss)
I1015 12:47:50.571116 15018 sgd_solver.cpp:138] Iteration 9580, lr = 0.0005
I1015 12:48:02.732439 15018 solver.cpp:243] Iteration 9600, loss = 3.33657
I1015 12:48:02.732486 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.15437 (* 1 = 4.15437 loss)
I1015 12:48:02.732491 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.138609 (* 1 = 0.138609 loss)
I1015 12:48:02.732497 15018 sgd_solver.cpp:138] Iteration 9600, lr = 0.0005
I1015 12:48:14.839565 15018 solver.cpp:243] Iteration 9620, loss = 3.43351
I1015 12:48:14.839597 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.25799 (* 1 = 3.25799 loss)
I1015 12:48:14.839604 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0716012 (* 1 = 0.0716012 loss)
I1015 12:48:14.839609 15018 sgd_solver.cpp:138] Iteration 9620, lr = 0.0005
I1015 12:48:25.803580 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:48:26.946768 15018 solver.cpp:243] Iteration 9640, loss = 2.27532
I1015 12:48:26.946799 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.07969 (* 1 = 1.07969 loss)
I1015 12:48:26.946806 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0921716 (* 1 = 0.0921716 loss)
I1015 12:48:26.946812 15018 sgd_solver.cpp:138] Iteration 9640, lr = 0.0005
I1015 12:48:39.050711 15018 solver.cpp:243] Iteration 9660, loss = 2.83012
I1015 12:48:39.050760 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.41858 (* 1 = 5.41858 loss)
I1015 12:48:39.050765 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0807403 (* 1 = 0.0807403 loss)
I1015 12:48:39.050771 15018 sgd_solver.cpp:138] Iteration 9660, lr = 0.0005
I1015 12:48:51.296377 15018 solver.cpp:243] Iteration 9680, loss = 2.18649
I1015 12:48:51.296427 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.39802 (* 1 = 1.39802 loss)
I1015 12:48:51.296433 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0943836 (* 1 = 0.0943836 loss)
I1015 12:48:51.296438 15018 sgd_solver.cpp:138] Iteration 9680, lr = 0.0005
I1015 12:49:03.330988 15018 solver.cpp:243] Iteration 9700, loss = 3.14792
I1015 12:49:03.331023 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.98039 (* 1 = 2.98039 loss)
I1015 12:49:03.331029 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0782704 (* 1 = 0.0782704 loss)
I1015 12:49:03.331035 15018 sgd_solver.cpp:138] Iteration 9700, lr = 0.0005
I1015 12:49:15.339197 15018 solver.cpp:243] Iteration 9720, loss = 2.62819
I1015 12:49:15.339228 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.13187 (* 1 = 3.13187 loss)
I1015 12:49:15.339234 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.47632 (* 1 = 0.47632 loss)
I1015 12:49:15.339239 15018 sgd_solver.cpp:138] Iteration 9720, lr = 0.0005
I1015 12:49:27.184741 15018 solver.cpp:243] Iteration 9740, loss = 3.54705
I1015 12:49:27.184773 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.4537 (* 1 = 3.4537 loss)
I1015 12:49:27.184779 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0954728 (* 1 = 0.0954728 loss)
I1015 12:49:27.184784 15018 sgd_solver.cpp:138] Iteration 9740, lr = 0.0005
I1015 12:49:39.056674 15018 solver.cpp:243] Iteration 9760, loss = 3.99998
I1015 12:49:39.056707 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.18521 (* 1 = 3.18521 loss)
I1015 12:49:39.056713 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.146997 (* 1 = 0.146997 loss)
I1015 12:49:39.056720 15018 sgd_solver.cpp:138] Iteration 9760, lr = 0.0005
I1015 12:49:50.887485 15018 solver.cpp:243] Iteration 9780, loss = 3.48103
I1015 12:49:50.887517 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.76477 (* 1 = 2.76477 loss)
I1015 12:49:50.887523 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107896 (* 1 = 0.107896 loss)
I1015 12:49:50.887528 15018 sgd_solver.cpp:138] Iteration 9780, lr = 0.0005
I1015 12:50:02.873215 15018 solver.cpp:243] Iteration 9800, loss = 3.5253
I1015 12:50:02.873248 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.50838 (* 1 = 2.50838 loss)
I1015 12:50:02.873255 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0823123 (* 1 = 0.0823123 loss)
I1015 12:50:02.873260 15018 sgd_solver.cpp:138] Iteration 9800, lr = 0.0005
I1015 12:50:14.864186 15018 solver.cpp:243] Iteration 9820, loss = 3.41872
I1015 12:50:14.864218 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.62521 (* 1 = 4.62521 loss)
I1015 12:50:14.864224 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0755805 (* 1 = 0.0755805 loss)
I1015 12:50:14.864230 15018 sgd_solver.cpp:138] Iteration 9820, lr = 0.0005
I1015 12:50:26.683387 15018 solver.cpp:243] Iteration 9840, loss = 2.77723
I1015 12:50:26.683437 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.86823 (* 1 = 2.86823 loss)
I1015 12:50:26.683444 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0691281 (* 1 = 0.0691281 loss)
I1015 12:50:26.683450 15018 sgd_solver.cpp:138] Iteration 9840, lr = 0.0005
I1015 12:50:38.602082 15018 solver.cpp:243] Iteration 9860, loss = 3.29146
I1015 12:50:38.602131 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.62298 (* 1 = 2.62298 loss)
I1015 12:50:38.602138 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0662987 (* 1 = 0.0662987 loss)
I1015 12:50:38.602144 15018 sgd_solver.cpp:138] Iteration 9860, lr = 0.0005
I1015 12:50:50.407171 15018 solver.cpp:243] Iteration 9880, loss = 3.04332
I1015 12:50:50.407218 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.31034 (* 1 = 3.31034 loss)
I1015 12:50:50.407241 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.190566 (* 1 = 0.190566 loss)
I1015 12:50:50.407246 15018 sgd_solver.cpp:138] Iteration 9880, lr = 0.0005
I1015 12:51:02.006855 15018 solver.cpp:243] Iteration 9900, loss = 2.91285
I1015 12:51:02.006906 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.35663 (* 1 = 2.35663 loss)
I1015 12:51:02.006911 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0662278 (* 1 = 0.0662278 loss)
I1015 12:51:02.006918 15018 sgd_solver.cpp:138] Iteration 9900, lr = 0.0005
I1015 12:51:13.503463 15018 solver.cpp:243] Iteration 9920, loss = 2.58769
I1015 12:51:13.503526 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.89784 (* 1 = 1.89784 loss)
I1015 12:51:13.503532 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0693275 (* 1 = 0.0693275 loss)
I1015 12:51:13.503540 15018 sgd_solver.cpp:138] Iteration 9920, lr = 0.0005
I1015 12:51:25.504770 15018 solver.cpp:243] Iteration 9940, loss = 3.31628
I1015 12:51:25.504820 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.21778 (* 1 = 4.21778 loss)
I1015 12:51:25.504827 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0678462 (* 1 = 0.0678462 loss)
I1015 12:51:25.504832 15018 sgd_solver.cpp:138] Iteration 9940, lr = 0.0005
I1015 12:51:37.537845 15018 solver.cpp:243] Iteration 9960, loss = 3.42945
I1015 12:51:37.537878 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.17121 (* 1 = 3.17121 loss)
I1015 12:51:37.537884 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0757158 (* 1 = 0.0757158 loss)
I1015 12:51:37.537890 15018 sgd_solver.cpp:138] Iteration 9960, lr = 0.0005
I1015 12:51:49.710086 15018 solver.cpp:243] Iteration 9980, loss = 4.52716
I1015 12:51:49.710136 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.23359 (* 1 = 4.23359 loss)
I1015 12:51:49.710142 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.091892 (* 1 = 0.091892 loss)
I1015 12:51:49.710148 15018 sgd_solver.cpp:138] Iteration 9980, lr = 0.0005
I1015 12:52:01.294343 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10000.caffemodel
I1015 12:52:02.077209 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10000.solverstate
I1015 12:52:02.276245 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 12:53:40.917393 15018 solver.cpp:243] Iteration 10000, loss = 3.05608
I1015 12:53:40.917428 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.98164 (* 1 = 2.98164 loss)
I1015 12:53:40.917434 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0744367 (* 1 = 0.0744367 loss)
I1015 12:53:40.917440 15018 sgd_solver.cpp:138] Iteration 10000, lr = 0.0005
I1015 12:53:51.674698 15018 solver.cpp:243] Iteration 10020, loss = 3.96492
I1015 12:53:51.674733 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.02067 (* 1 = 4.02067 loss)
I1015 12:53:51.674739 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0920934 (* 1 = 0.0920934 loss)
I1015 12:53:51.674746 15018 sgd_solver.cpp:138] Iteration 10020, lr = 0.0005
I1015 12:54:03.575603 15018 solver.cpp:243] Iteration 10040, loss = 3.34625
I1015 12:54:03.575652 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.68764 (* 1 = 1.68764 loss)
I1015 12:54:03.575659 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111345 (* 1 = 0.111345 loss)
I1015 12:54:03.575665 15018 sgd_solver.cpp:138] Iteration 10040, lr = 0.0005
I1015 12:54:15.524654 15018 solver.cpp:243] Iteration 10060, loss = 2.59697
I1015 12:54:15.524703 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.19402 (* 1 = 3.19402 loss)
I1015 12:54:15.524709 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103648 (* 1 = 0.103648 loss)
I1015 12:54:15.524715 15018 sgd_solver.cpp:138] Iteration 10060, lr = 0.0005
I1015 12:54:27.538033 15018 solver.cpp:243] Iteration 10080, loss = 2.51775
I1015 12:54:27.538081 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.39076 (* 1 = 5.39076 loss)
I1015 12:54:27.538089 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0780693 (* 1 = 0.0780693 loss)
I1015 12:54:27.538094 15018 sgd_solver.cpp:138] Iteration 10080, lr = 0.0005
I1015 12:54:39.483249 15018 solver.cpp:243] Iteration 10100, loss = 3.72338
I1015 12:54:39.483294 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.80891 (* 1 = 1.80891 loss)
I1015 12:54:39.483301 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0718831 (* 1 = 0.0718831 loss)
I1015 12:54:39.483307 15018 sgd_solver.cpp:138] Iteration 10100, lr = 0.0005
I1015 12:54:51.628811 15018 solver.cpp:243] Iteration 10120, loss = 3.37301
I1015 12:54:51.628860 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.24818 (* 1 = 3.24818 loss)
I1015 12:54:51.628866 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102529 (* 1 = 0.102529 loss)
I1015 12:54:51.628872 15018 sgd_solver.cpp:138] Iteration 10120, lr = 0.0005
I1015 12:55:03.806661 15018 solver.cpp:243] Iteration 10140, loss = 2.97502
I1015 12:55:03.806710 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.42753 (* 1 = 2.42753 loss)
I1015 12:55:03.806716 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0974063 (* 1 = 0.0974063 loss)
I1015 12:55:03.806722 15018 sgd_solver.cpp:138] Iteration 10140, lr = 0.0005
I1015 12:55:08.752465 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 12:55:15.962071 15018 solver.cpp:243] Iteration 10160, loss = 3.44182
I1015 12:55:15.962121 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.25631 (* 1 = 3.25631 loss)
I1015 12:55:15.962126 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104871 (* 1 = 0.104871 loss)
I1015 12:55:15.962132 15018 sgd_solver.cpp:138] Iteration 10160, lr = 0.0005
I1015 12:55:28.021391 15018 solver.cpp:243] Iteration 10180, loss = 2.44482
I1015 12:55:28.021426 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.21062 (* 1 = 2.21062 loss)
I1015 12:55:28.021433 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.132393 (* 1 = 0.132393 loss)
I1015 12:55:28.021438 15018 sgd_solver.cpp:138] Iteration 10180, lr = 0.0005
I1015 12:55:40.059089 15018 solver.cpp:243] Iteration 10200, loss = 2.53563
I1015 12:55:40.059135 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.51305 (* 1 = 3.51305 loss)
I1015 12:55:40.059141 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.189078 (* 1 = 0.189078 loss)
I1015 12:55:40.059146 15018 sgd_solver.cpp:138] Iteration 10200, lr = 0.0005
I1015 12:55:52.352232 15018 solver.cpp:243] Iteration 10220, loss = 2.26443
I1015 12:55:52.352295 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.27058 (* 1 = 1.27058 loss)
I1015 12:55:52.352303 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.069152 (* 1 = 0.069152 loss)
I1015 12:55:52.352308 15018 sgd_solver.cpp:138] Iteration 10220, lr = 0.0005
I1015 12:56:04.500427 15018 solver.cpp:243] Iteration 10240, loss = 2.93135
I1015 12:56:04.500475 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.67973 (* 1 = 2.67973 loss)
I1015 12:56:04.500483 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0633442 (* 1 = 0.0633442 loss)
I1015 12:56:04.500488 15018 sgd_solver.cpp:138] Iteration 10240, lr = 0.0005
I1015 12:56:16.444031 15018 solver.cpp:243] Iteration 10260, loss = 2.43126
I1015 12:56:16.444078 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.48093 (* 1 = 1.48093 loss)
I1015 12:56:16.444084 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0664352 (* 1 = 0.0664352 loss)
I1015 12:56:16.444090 15018 sgd_solver.cpp:138] Iteration 10260, lr = 0.0005
I1015 12:56:28.349623 15018 solver.cpp:243] Iteration 10280, loss = 3.28265
I1015 12:56:28.349655 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.91096 (* 1 = 3.91096 loss)
I1015 12:56:28.349661 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.116229 (* 1 = 0.116229 loss)
I1015 12:56:28.349668 15018 sgd_solver.cpp:138] Iteration 10280, lr = 0.0005
I1015 12:56:40.257485 15018 solver.cpp:243] Iteration 10300, loss = 3.83428
I1015 12:56:40.257516 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.83356 (* 1 = 5.83356 loss)
I1015 12:56:40.257522 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115221 (* 1 = 0.115221 loss)
I1015 12:56:40.257529 15018 sgd_solver.cpp:138] Iteration 10300, lr = 0.0005
I1015 12:56:52.003801 15018 solver.cpp:243] Iteration 10320, loss = 3.21579
I1015 12:56:52.003851 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.99093 (* 1 = 1.99093 loss)
I1015 12:56:52.003856 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.133353 (* 1 = 0.133353 loss)
I1015 12:56:52.003862 15018 sgd_solver.cpp:138] Iteration 10320, lr = 0.0005
I1015 12:57:04.015637 15018 solver.cpp:243] Iteration 10340, loss = 3.54011
I1015 12:57:04.015686 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.19192 (* 1 = 2.19192 loss)
I1015 12:57:04.015692 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120166 (* 1 = 0.120166 loss)
I1015 12:57:04.015698 15018 sgd_solver.cpp:138] Iteration 10340, lr = 0.0005
I1015 12:57:16.023597 15018 solver.cpp:243] Iteration 10360, loss = 3.40814
I1015 12:57:16.023645 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.55766 (* 1 = 2.55766 loss)
I1015 12:57:16.023651 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105549 (* 1 = 0.105549 loss)
I1015 12:57:16.023656 15018 sgd_solver.cpp:138] Iteration 10360, lr = 0.0005
I1015 12:57:27.829283 15018 solver.cpp:243] Iteration 10380, loss = 2.58706
I1015 12:57:27.829319 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.05928 (* 1 = 2.05928 loss)
I1015 12:57:27.829324 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0608382 (* 1 = 0.0608382 loss)
I1015 12:57:27.829334 15018 sgd_solver.cpp:138] Iteration 10380, lr = 0.0005
I1015 12:57:39.749627 15018 solver.cpp:243] Iteration 10400, loss = 3.2142
I1015 12:57:39.749661 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.43092 (* 1 = 3.43092 loss)
I1015 12:57:39.749667 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0803488 (* 1 = 0.0803488 loss)
I1015 12:57:39.749672 15018 sgd_solver.cpp:138] Iteration 10400, lr = 0.0005
I1015 12:57:51.553773 15018 solver.cpp:243] Iteration 10420, loss = 2.75298
I1015 12:57:51.553822 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.65233 (* 1 = 3.65233 loss)
I1015 12:57:51.553828 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.197819 (* 1 = 0.197819 loss)
I1015 12:57:51.553834 15018 sgd_solver.cpp:138] Iteration 10420, lr = 0.0005
I1015 12:58:03.215291 15018 solver.cpp:243] Iteration 10440, loss = 3.11348
I1015 12:58:03.215358 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.19122 (* 1 = 2.19122 loss)
I1015 12:58:03.215368 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0741759 (* 1 = 0.0741759 loss)
I1015 12:58:03.215375 15018 sgd_solver.cpp:138] Iteration 10440, lr = 0.0005
I1015 12:58:14.709959 15018 solver.cpp:243] Iteration 10460, loss = 2.55316
I1015 12:58:14.710007 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.64102 (* 1 = 2.64102 loss)
I1015 12:58:14.710014 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.061706 (* 1 = 0.061706 loss)
I1015 12:58:14.710021 15018 sgd_solver.cpp:138] Iteration 10460, lr = 0.0005
I1015 12:58:26.701917 15018 solver.cpp:243] Iteration 10480, loss = 3.2992
I1015 12:58:26.701951 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.4064 (* 1 = 3.4064 loss)
I1015 12:58:26.701958 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0837176 (* 1 = 0.0837176 loss)
I1015 12:58:26.701964 15018 sgd_solver.cpp:138] Iteration 10480, lr = 0.0005
I1015 12:58:38.260538 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10500.caffemodel
I1015 12:58:38.538333 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10500.solverstate
I1015 12:58:39.106747 15018 solver.cpp:243] Iteration 10500, loss = 3.32103
I1015 12:58:39.106798 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.81984 (* 1 = 2.81984 loss)
I1015 12:58:39.106804 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0940611 (* 1 = 0.0940611 loss)
I1015 12:58:39.106811 15018 sgd_solver.cpp:138] Iteration 10500, lr = 0.0005
I1015 12:58:51.024842 15018 solver.cpp:243] Iteration 10520, loss = 4.09955
I1015 12:58:51.024893 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.50831 (* 1 = 4.50831 loss)
I1015 12:58:51.024900 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.112981 (* 1 = 0.112981 loss)
I1015 12:58:51.024906 15018 sgd_solver.cpp:138] Iteration 10520, lr = 0.0005
I1015 12:59:03.111369 15018 solver.cpp:243] Iteration 10540, loss = 4.50433
I1015 12:59:03.111419 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.90353 (* 1 = 4.90353 loss)
I1015 12:59:03.111425 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.07642 (* 1 = 0.07642 loss)
I1015 12:59:03.111431 15018 sgd_solver.cpp:138] Iteration 10540, lr = 0.0005
I1015 12:59:14.984592 15018 solver.cpp:243] Iteration 10560, loss = 3.94755
I1015 12:59:14.984627 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.932 (* 1 = 3.932 loss)
I1015 12:59:14.984633 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.136305 (* 1 = 0.136305 loss)
I1015 12:59:14.984639 15018 sgd_solver.cpp:138] Iteration 10560, lr = 0.0005
I1015 12:59:26.830945 15018 solver.cpp:243] Iteration 10580, loss = 3.42682
I1015 12:59:26.830994 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.34315 (* 1 = 2.34315 loss)
I1015 12:59:26.831001 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0799421 (* 1 = 0.0799421 loss)
I1015 12:59:26.831007 15018 sgd_solver.cpp:138] Iteration 10580, lr = 0.0005
I1015 12:59:38.723572 15018 solver.cpp:243] Iteration 10600, loss = 2.52977
I1015 12:59:38.723621 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.30014 (* 1 = 2.30014 loss)
I1015 12:59:38.723628 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0782871 (* 1 = 0.0782871 loss)
I1015 12:59:38.723634 15018 sgd_solver.cpp:138] Iteration 10600, lr = 0.0005
I1015 12:59:50.656410 15018 solver.cpp:243] Iteration 10620, loss = 2.0092
I1015 12:59:50.656445 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.93512 (* 1 = 2.93512 loss)
I1015 12:59:50.656452 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0961836 (* 1 = 0.0961836 loss)
I1015 12:59:50.656461 15018 sgd_solver.cpp:138] Iteration 10620, lr = 0.0005
I1015 13:00:02.596439 15018 solver.cpp:243] Iteration 10640, loss = 3.74951
I1015 13:00:02.596474 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.56412 (* 1 = 1.56412 loss)
I1015 13:00:02.596480 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0646675 (* 1 = 0.0646675 loss)
I1015 13:00:02.596487 15018 sgd_solver.cpp:138] Iteration 10640, lr = 0.0005
I1015 13:00:14.659404 15018 solver.cpp:243] Iteration 10660, loss = 3.40437
I1015 13:00:14.659454 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.17074 (* 1 = 3.17074 loss)
I1015 13:00:14.659461 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.138383 (* 1 = 0.138383 loss)
I1015 13:00:14.659466 15018 sgd_solver.cpp:138] Iteration 10660, lr = 0.0005
I1015 13:00:26.804489 15018 solver.cpp:243] Iteration 10680, loss = 2.82072
I1015 13:00:26.804539 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.5976 (* 1 = 3.5976 loss)
I1015 13:00:26.804545 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0895476 (* 1 = 0.0895476 loss)
I1015 13:00:26.804551 15018 sgd_solver.cpp:138] Iteration 10680, lr = 0.0005
I1015 13:00:38.925925 15018 solver.cpp:243] Iteration 10700, loss = 3.45711
I1015 13:00:38.925958 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.96568 (* 1 = 3.96568 loss)
I1015 13:00:38.925964 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0978941 (* 1 = 0.0978941 loss)
I1015 13:00:38.925971 15018 sgd_solver.cpp:138] Iteration 10700, lr = 0.0005
I1015 13:00:50.966351 15018 solver.cpp:243] Iteration 10720, loss = 2.57004
I1015 13:00:50.966399 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.07035 (* 1 = 1.07035 loss)
I1015 13:00:50.966405 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0638378 (* 1 = 0.0638378 loss)
I1015 13:00:50.966411 15018 sgd_solver.cpp:138] Iteration 10720, lr = 0.0005
I1015 13:01:02.987753 15018 solver.cpp:243] Iteration 10740, loss = 2.12758
I1015 13:01:02.987802 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.91449 (* 1 = 2.91449 loss)
I1015 13:01:02.987808 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0726435 (* 1 = 0.0726435 loss)
I1015 13:01:02.987814 15018 sgd_solver.cpp:138] Iteration 10740, lr = 0.0005
I1015 13:01:15.231079 15018 solver.cpp:243] Iteration 10760, loss = 2.6466
I1015 13:01:15.231117 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.54218 (* 1 = 1.54218 loss)
I1015 13:01:15.231123 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0846068 (* 1 = 0.0846068 loss)
I1015 13:01:15.231129 15018 sgd_solver.cpp:138] Iteration 10760, lr = 0.0005
I1015 13:01:27.408391 15018 solver.cpp:243] Iteration 10780, loss = 3.23406
I1015 13:01:27.408427 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.64133 (* 1 = 3.64133 loss)
I1015 13:01:27.408433 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0939278 (* 1 = 0.0939278 loss)
I1015 13:01:27.408439 15018 sgd_solver.cpp:138] Iteration 10780, lr = 0.0005
I1015 13:01:39.369606 15018 solver.cpp:243] Iteration 10800, loss = 2.36227
I1015 13:01:39.369638 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.2956 (* 1 = 2.2956 loss)
I1015 13:01:39.369645 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0815034 (* 1 = 0.0815034 loss)
I1015 13:01:39.369652 15018 sgd_solver.cpp:138] Iteration 10800, lr = 0.0005
I1015 13:01:51.269266 15018 solver.cpp:243] Iteration 10820, loss = 2.54102
I1015 13:01:51.269332 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.19654 (* 1 = 4.19654 loss)
I1015 13:01:51.269340 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0948429 (* 1 = 0.0948429 loss)
I1015 13:01:51.269345 15018 sgd_solver.cpp:138] Iteration 10820, lr = 0.0005
I1015 13:02:03.183617 15018 solver.cpp:243] Iteration 10840, loss = 3.64454
I1015 13:02:03.183668 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.40982 (* 1 = 4.40982 loss)
I1015 13:02:03.183674 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.084791 (* 1 = 0.084791 loss)
I1015 13:02:03.183681 15018 sgd_solver.cpp:138] Iteration 10840, lr = 0.0005
I1015 13:02:14.926350 15018 solver.cpp:243] Iteration 10860, loss = 3.14509
I1015 13:02:14.926400 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.95871 (* 1 = 1.95871 loss)
I1015 13:02:14.926406 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103538 (* 1 = 0.103538 loss)
I1015 13:02:14.926414 15018 sgd_solver.cpp:138] Iteration 10860, lr = 0.0005
I1015 13:02:26.990541 15018 solver.cpp:243] Iteration 10880, loss = 3.56724
I1015 13:02:26.990591 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.69271 (* 1 = 4.69271 loss)
I1015 13:02:26.990597 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12547 (* 1 = 0.12547 loss)
I1015 13:02:26.990602 15018 sgd_solver.cpp:138] Iteration 10880, lr = 0.0005
I1015 13:02:38.978623 15018 solver.cpp:243] Iteration 10900, loss = 3.29095
I1015 13:02:38.978673 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.32842 (* 1 = 4.32842 loss)
I1015 13:02:38.978679 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0615141 (* 1 = 0.0615141 loss)
I1015 13:02:38.978685 15018 sgd_solver.cpp:138] Iteration 10900, lr = 0.0005
I1015 13:02:50.855856 15018 solver.cpp:243] Iteration 10920, loss = 2.83468
I1015 13:02:50.855890 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.42924 (* 1 = 1.42924 loss)
I1015 13:02:50.855895 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0734547 (* 1 = 0.0734547 loss)
I1015 13:02:50.855902 15018 sgd_solver.cpp:138] Iteration 10920, lr = 0.0005
I1015 13:03:02.790253 15018 solver.cpp:243] Iteration 10940, loss = 3.27635
I1015 13:03:02.790300 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15244 (* 1 = 3.15244 loss)
I1015 13:03:02.790307 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0708351 (* 1 = 0.0708351 loss)
I1015 13:03:02.790313 15018 sgd_solver.cpp:138] Iteration 10940, lr = 0.0005
I1015 13:03:14.653450 15018 solver.cpp:243] Iteration 10960, loss = 2.86441
I1015 13:03:14.653483 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.46662 (* 1 = 1.46662 loss)
I1015 13:03:14.653489 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078183 (* 1 = 0.078183 loss)
I1015 13:03:14.653496 15018 sgd_solver.cpp:138] Iteration 10960, lr = 0.0005
I1015 13:03:26.288233 15018 solver.cpp:243] Iteration 10980, loss = 2.89055
I1015 13:03:26.288281 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.42568 (* 1 = 2.42568 loss)
I1015 13:03:26.288287 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103879 (* 1 = 0.103879 loss)
I1015 13:03:26.288293 15018 sgd_solver.cpp:138] Iteration 10980, lr = 0.0005
I1015 13:03:37.329136 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11000.caffemodel
I1015 13:03:38.096748 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11000.solverstate
I1015 13:03:38.285447 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 13:04:08.130143 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:05:16.233880 15018 solver.cpp:243] Iteration 11000, loss = 3.12272
I1015 13:05:16.233914 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.06688 (* 1 = 3.06688 loss)
I1015 13:05:16.233920 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0558395 (* 1 = 0.0558395 loss)
I1015 13:05:16.233927 15018 sgd_solver.cpp:138] Iteration 11000, lr = 0.0005
I1015 13:05:27.136906 15018 solver.cpp:243] Iteration 11020, loss = 3.21583
I1015 13:05:27.136940 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.77144 (* 1 = 1.77144 loss)
I1015 13:05:27.136961 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0879206 (* 1 = 0.0879206 loss)
I1015 13:05:27.136968 15018 sgd_solver.cpp:138] Iteration 11020, lr = 0.0005
I1015 13:05:39.220182 15018 solver.cpp:243] Iteration 11040, loss = 3.49356
I1015 13:05:39.220216 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.98777 (* 1 = 3.98777 loss)
I1015 13:05:39.220223 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.076277 (* 1 = 0.076277 loss)
I1015 13:05:39.220229 15018 sgd_solver.cpp:138] Iteration 11040, lr = 0.0005
I1015 13:05:51.388259 15018 solver.cpp:243] Iteration 11060, loss = 4.0014
I1015 13:05:51.388310 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.90789 (* 1 = 4.90789 loss)
I1015 13:05:51.388316 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.137905 (* 1 = 0.137905 loss)
I1015 13:05:51.388324 15018 sgd_solver.cpp:138] Iteration 11060, lr = 0.0005
I1015 13:06:03.554656 15018 solver.cpp:243] Iteration 11080, loss = 4.6549
I1015 13:06:03.554704 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.87683 (* 1 = 2.87683 loss)
I1015 13:06:03.554710 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0788927 (* 1 = 0.0788927 loss)
I1015 13:06:03.554716 15018 sgd_solver.cpp:138] Iteration 11080, lr = 0.0005
I1015 13:06:15.519269 15018 solver.cpp:243] Iteration 11100, loss = 4.05306
I1015 13:06:15.519313 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.79194 (* 1 = 4.79194 loss)
I1015 13:06:15.519320 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.09509 (* 1 = 0.09509 loss)
I1015 13:06:15.519326 15018 sgd_solver.cpp:138] Iteration 11100, lr = 0.0005
I1015 13:06:27.459916 15018 solver.cpp:243] Iteration 11120, loss = 3.20869
I1015 13:06:27.459965 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.15827 (* 1 = 2.15827 loss)
I1015 13:06:27.459971 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.370107 (* 1 = 0.370107 loss)
I1015 13:06:27.459976 15018 sgd_solver.cpp:138] Iteration 11120, lr = 0.0005
I1015 13:06:39.430371 15018 solver.cpp:243] Iteration 11140, loss = 2.48097
I1015 13:06:39.430419 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.31652 (* 1 = 1.31652 loss)
I1015 13:06:39.430426 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0642839 (* 1 = 0.0642839 loss)
I1015 13:06:39.430433 15018 sgd_solver.cpp:138] Iteration 11140, lr = 0.0005
I1015 13:06:51.430431 15018 solver.cpp:243] Iteration 11160, loss = 1.69293
I1015 13:06:51.430462 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.63936 (* 1 = 2.63936 loss)
I1015 13:06:51.430469 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.108157 (* 1 = 0.108157 loss)
I1015 13:06:51.430474 15018 sgd_solver.cpp:138] Iteration 11160, lr = 0.0005
I1015 13:07:03.475968 15018 solver.cpp:243] Iteration 11180, loss = 3.24876
I1015 13:07:03.476018 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.59773 (* 1 = 2.59773 loss)
I1015 13:07:03.476024 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0682992 (* 1 = 0.0682992 loss)
I1015 13:07:03.476030 15018 sgd_solver.cpp:138] Iteration 11180, lr = 0.0005
I1015 13:07:15.521926 15018 solver.cpp:243] Iteration 11200, loss = 3.02688
I1015 13:07:15.521975 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.78696 (* 1 = 3.78696 loss)
I1015 13:07:15.521981 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103421 (* 1 = 0.103421 loss)
I1015 13:07:15.521987 15018 sgd_solver.cpp:138] Iteration 11200, lr = 0.0005
I1015 13:07:27.673702 15018 solver.cpp:243] Iteration 11220, loss = 2.59366
I1015 13:07:27.673748 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.27696 (* 1 = 4.27696 loss)
I1015 13:07:27.673753 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0790231 (* 1 = 0.0790231 loss)
I1015 13:07:27.673759 15018 sgd_solver.cpp:138] Iteration 11220, lr = 0.0005
I1015 13:07:39.788251 15018 solver.cpp:243] Iteration 11240, loss = 3.10125
I1015 13:07:39.788301 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.60035 (* 1 = 2.60035 loss)
I1015 13:07:39.788307 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0765633 (* 1 = 0.0765633 loss)
I1015 13:07:39.788313 15018 sgd_solver.cpp:138] Iteration 11240, lr = 0.0005
I1015 13:07:51.912727 15018 solver.cpp:243] Iteration 11260, loss = 2.47989
I1015 13:07:51.912765 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.27577 (* 1 = 2.27577 loss)
I1015 13:07:51.912771 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0618932 (* 1 = 0.0618932 loss)
I1015 13:07:51.912777 15018 sgd_solver.cpp:138] Iteration 11260, lr = 0.0005
I1015 13:08:03.951166 15018 solver.cpp:243] Iteration 11280, loss = 1.81464
I1015 13:08:03.951216 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.89375 (* 1 = 1.89375 loss)
I1015 13:08:03.951222 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0562653 (* 1 = 0.0562653 loss)
I1015 13:08:03.951228 15018 sgd_solver.cpp:138] Iteration 11280, lr = 0.0005
I1015 13:08:16.232906 15018 solver.cpp:243] Iteration 11300, loss = 2.74653
I1015 13:08:16.232944 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5654 (* 1 = 2.5654 loss)
I1015 13:08:16.232952 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.141305 (* 1 = 0.141305 loss)
I1015 13:08:16.232961 15018 sgd_solver.cpp:138] Iteration 11300, lr = 0.0005
I1015 13:08:28.374938 15018 solver.cpp:243] Iteration 11320, loss = 3.01522
I1015 13:08:28.374974 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.80081 (* 1 = 2.80081 loss)
I1015 13:08:28.374982 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111246 (* 1 = 0.111246 loss)
I1015 13:08:28.375006 15018 sgd_solver.cpp:138] Iteration 11320, lr = 0.0005
I1015 13:08:40.327957 15018 solver.cpp:243] Iteration 11340, loss = 2.20808
I1015 13:08:40.328001 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.77985 (* 1 = 3.77985 loss)
I1015 13:08:40.328006 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0788443 (* 1 = 0.0788443 loss)
I1015 13:08:40.328013 15018 sgd_solver.cpp:138] Iteration 11340, lr = 0.0005
I1015 13:08:52.306216 15018 solver.cpp:243] Iteration 11360, loss = 1.99947
I1015 13:08:52.306267 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.04403 (* 1 = 2.04403 loss)
I1015 13:08:52.306272 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.11891 (* 1 = 0.11891 loss)
I1015 13:08:52.306278 15018 sgd_solver.cpp:138] Iteration 11360, lr = 0.0005
I1015 13:09:04.256429 15018 solver.cpp:243] Iteration 11380, loss = 3.46256
I1015 13:09:04.256479 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.18687 (* 1 = 3.18687 loss)
I1015 13:09:04.256484 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0876395 (* 1 = 0.0876395 loss)
I1015 13:09:04.256491 15018 sgd_solver.cpp:138] Iteration 11380, lr = 0.0005
I1015 13:09:15.934903 15018 solver.cpp:243] Iteration 11400, loss = 3.12654
I1015 13:09:15.934952 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.06526 (* 1 = 3.06526 loss)
I1015 13:09:15.934958 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103993 (* 1 = 0.103993 loss)
I1015 13:09:15.934964 15018 sgd_solver.cpp:138] Iteration 11400, lr = 0.0005
I1015 13:09:27.957319 15018 solver.cpp:243] Iteration 11420, loss = 3.36523
I1015 13:09:27.957371 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.70421 (* 1 = 4.70421 loss)
I1015 13:09:27.957377 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0897657 (* 1 = 0.0897657 loss)
I1015 13:09:27.957384 15018 sgd_solver.cpp:138] Iteration 11420, lr = 0.0005
I1015 13:09:39.998797 15018 solver.cpp:243] Iteration 11440, loss = 2.66873
I1015 13:09:39.998845 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.55905 (* 1 = 3.55905 loss)
I1015 13:09:39.998852 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0629488 (* 1 = 0.0629488 loss)
I1015 13:09:39.998858 15018 sgd_solver.cpp:138] Iteration 11440, lr = 0.0005
I1015 13:09:51.850075 15018 solver.cpp:243] Iteration 11460, loss = 3.02046
I1015 13:09:51.850108 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.19476 (* 1 = 2.19476 loss)
I1015 13:09:51.850116 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0451509 (* 1 = 0.0451509 loss)
I1015 13:09:51.850121 15018 sgd_solver.cpp:138] Iteration 11460, lr = 0.0005
I1015 13:10:03.763159 15018 solver.cpp:243] Iteration 11480, loss = 3.35277
I1015 13:10:03.763207 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.86705 (* 1 = 1.86705 loss)
I1015 13:10:03.763214 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0707105 (* 1 = 0.0707105 loss)
I1015 13:10:03.763221 15018 sgd_solver.cpp:138] Iteration 11480, lr = 0.0005
I1015 13:10:15.192111 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11500.caffemodel
I1015 13:10:15.523656 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11500.solverstate
I1015 13:10:16.153290 15018 solver.cpp:243] Iteration 11500, loss = 3.30667
I1015 13:10:16.153321 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.71143 (* 1 = 2.71143 loss)
I1015 13:10:16.153327 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0674393 (* 1 = 0.0674393 loss)
I1015 13:10:16.153337 15018 sgd_solver.cpp:138] Iteration 11500, lr = 0.0005
I1015 13:10:27.304095 15018 solver.cpp:243] Iteration 11520, loss = 2.78257
I1015 13:10:27.304131 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.90967 (* 1 = 1.90967 loss)
I1015 13:10:27.304141 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0636543 (* 1 = 0.0636543 loss)
I1015 13:10:27.304164 15018 sgd_solver.cpp:138] Iteration 11520, lr = 0.0005
I1015 13:10:38.896526 15018 solver.cpp:243] Iteration 11540, loss = 2.33839
I1015 13:10:38.896564 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.783942 (* 1 = 0.783942 loss)
I1015 13:10:38.896571 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0653111 (* 1 = 0.0653111 loss)
I1015 13:10:38.896595 15018 sgd_solver.cpp:138] Iteration 11540, lr = 0.0005
I1015 13:10:50.715911 15018 solver.cpp:243] Iteration 11560, loss = 3.09006
I1015 13:10:50.715945 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.56012 (* 1 = 2.56012 loss)
I1015 13:10:50.715952 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.06618 (* 1 = 0.06618 loss)
I1015 13:10:50.715975 15018 sgd_solver.cpp:138] Iteration 11560, lr = 0.0005
I1015 13:11:02.786259 15018 solver.cpp:243] Iteration 11580, loss = 3.60943
I1015 13:11:02.786296 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.73407 (* 1 = 2.73407 loss)
I1015 13:11:02.786305 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0875695 (* 1 = 0.0875695 loss)
I1015 13:11:02.786327 15018 sgd_solver.cpp:138] Iteration 11580, lr = 0.0005
I1015 13:11:15.021644 15018 solver.cpp:243] Iteration 11600, loss = 3.93692
I1015 13:11:15.021694 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.73167 (* 1 = 5.73167 loss)
I1015 13:11:15.021704 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.114326 (* 1 = 0.114326 loss)
I1015 13:11:15.021726 15018 sgd_solver.cpp:138] Iteration 11600, lr = 0.0005
I1015 13:11:27.228032 15018 solver.cpp:243] Iteration 11620, loss = 4.47615
I1015 13:11:27.228082 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.3679 (* 1 = 5.3679 loss)
I1015 13:11:27.228088 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0752184 (* 1 = 0.0752184 loss)
I1015 13:11:27.228093 15018 sgd_solver.cpp:138] Iteration 11620, lr = 0.0005
I1015 13:11:39.186519 15018 solver.cpp:243] Iteration 11640, loss = 3.91341
I1015 13:11:39.186568 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.85912 (* 1 = 3.85912 loss)
I1015 13:11:39.186574 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0800559 (* 1 = 0.0800559 loss)
I1015 13:11:39.186580 15018 sgd_solver.cpp:138] Iteration 11640, lr = 0.0005
I1015 13:11:51.127020 15018 solver.cpp:243] Iteration 11660, loss = 3.34161
I1015 13:11:51.127055 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.90242 (* 1 = 2.90242 loss)
I1015 13:11:51.127061 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.312426 (* 1 = 0.312426 loss)
I1015 13:11:51.127068 15018 sgd_solver.cpp:138] Iteration 11660, lr = 0.0005
I1015 13:11:53.014875 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:12:03.095791 15018 solver.cpp:243] Iteration 11680, loss = 2.7607
I1015 13:12:03.095824 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.77217 (* 1 = 2.77217 loss)
I1015 13:12:03.095830 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0679881 (* 1 = 0.0679881 loss)
I1015 13:12:03.095835 15018 sgd_solver.cpp:138] Iteration 11680, lr = 0.0005
I1015 13:12:14.991062 15018 solver.cpp:243] Iteration 11700, loss = 1.82101
I1015 13:12:14.991111 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.21566 (* 1 = 1.21566 loss)
I1015 13:12:14.991117 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.032312 (* 1 = 0.032312 loss)
I1015 13:12:14.991122 15018 sgd_solver.cpp:138] Iteration 11700, lr = 0.0005
I1015 13:12:27.010792 15018 solver.cpp:243] Iteration 11720, loss = 3.23611
I1015 13:12:27.010840 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.27803 (* 1 = 5.27803 loss)
I1015 13:12:27.010848 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110329 (* 1 = 0.110329 loss)
I1015 13:12:27.010852 15018 sgd_solver.cpp:138] Iteration 11720, lr = 0.0005
I1015 13:12:39.032243 15018 solver.cpp:243] Iteration 11740, loss = 3.01053
I1015 13:12:39.032275 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.41838 (* 1 = 2.41838 loss)
I1015 13:12:39.032281 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0921674 (* 1 = 0.0921674 loss)
I1015 13:12:39.032286 15018 sgd_solver.cpp:138] Iteration 11740, lr = 0.0005
I1015 13:12:51.174000 15018 solver.cpp:243] Iteration 11760, loss = 2.10304
I1015 13:12:51.174047 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.86385 (* 1 = 1.86385 loss)
I1015 13:12:51.174053 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0969616 (* 1 = 0.0969616 loss)
I1015 13:12:51.174059 15018 sgd_solver.cpp:138] Iteration 11760, lr = 0.0005
I1015 13:13:03.317589 15018 solver.cpp:243] Iteration 11780, loss = 2.93331
I1015 13:13:03.317623 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.84369 (* 1 = 2.84369 loss)
I1015 13:13:03.317629 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0720568 (* 1 = 0.0720568 loss)
I1015 13:13:03.317636 15018 sgd_solver.cpp:138] Iteration 11780, lr = 0.0005
I1015 13:13:15.444034 15018 solver.cpp:243] Iteration 11800, loss = 2.69219
I1015 13:13:15.444082 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.45026 (* 1 = 1.45026 loss)
I1015 13:13:15.444089 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.073351 (* 1 = 0.073351 loss)
I1015 13:13:15.444094 15018 sgd_solver.cpp:138] Iteration 11800, lr = 0.0005
I1015 13:13:27.443886 15018 solver.cpp:243] Iteration 11820, loss = 1.55104
I1015 13:13:27.443933 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.63126 (* 1 = 1.63126 loss)
I1015 13:13:27.443940 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.105997 (* 1 = 0.105997 loss)
I1015 13:13:27.443945 15018 sgd_solver.cpp:138] Iteration 11820, lr = 0.0005
I1015 13:13:39.689066 15018 solver.cpp:243] Iteration 11840, loss = 2.52141
I1015 13:13:39.689101 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.83427 (* 1 = 1.83427 loss)
I1015 13:13:39.689107 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.212495 (* 1 = 0.212495 loss)
I1015 13:13:39.689112 15018 sgd_solver.cpp:138] Iteration 11840, lr = 0.0005
I1015 13:13:51.915668 15018 solver.cpp:243] Iteration 11860, loss = 2.97966
I1015 13:13:51.915717 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.79354 (* 1 = 2.79354 loss)
I1015 13:13:51.915724 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0765855 (* 1 = 0.0765855 loss)
I1015 13:13:51.915729 15018 sgd_solver.cpp:138] Iteration 11860, lr = 0.0005
I1015 13:14:03.873643 15018 solver.cpp:243] Iteration 11880, loss = 2.06431
I1015 13:14:03.873708 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.55488 (* 1 = 1.55488 loss)
I1015 13:14:03.873715 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0825618 (* 1 = 0.0825618 loss)
I1015 13:14:03.873721 15018 sgd_solver.cpp:138] Iteration 11880, lr = 0.0005
I1015 13:14:15.767637 15018 solver.cpp:243] Iteration 11900, loss = 2.1
I1015 13:14:15.767686 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.06942 (* 1 = 2.06942 loss)
I1015 13:14:15.767693 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.13448 (* 1 = 0.13448 loss)
I1015 13:14:15.767699 15018 sgd_solver.cpp:138] Iteration 11900, lr = 0.0005
I1015 13:14:27.707370 15018 solver.cpp:243] Iteration 11920, loss = 3.44784
I1015 13:14:27.707419 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.83396 (* 1 = 3.83396 loss)
I1015 13:14:27.707425 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0796503 (* 1 = 0.0796503 loss)
I1015 13:14:27.707432 15018 sgd_solver.cpp:138] Iteration 11920, lr = 0.0005
I1015 13:14:39.356618 15018 solver.cpp:243] Iteration 11940, loss = 2.76872
I1015 13:14:39.356667 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.33787 (* 1 = 3.33787 loss)
I1015 13:14:39.356673 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0721004 (* 1 = 0.0721004 loss)
I1015 13:14:39.356678 15018 sgd_solver.cpp:138] Iteration 11940, lr = 0.0005
I1015 13:14:51.416762 15018 solver.cpp:243] Iteration 11960, loss = 2.96309
I1015 13:14:51.416795 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.426 (* 1 = 3.426 loss)
I1015 13:14:51.416801 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.073919 (* 1 = 0.073919 loss)
I1015 13:14:51.416806 15018 sgd_solver.cpp:138] Iteration 11960, lr = 0.0005
I1015 13:15:03.427966 15018 solver.cpp:243] Iteration 11980, loss = 2.50093
I1015 13:15:03.428014 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.93087 (* 1 = 3.93087 loss)
I1015 13:15:03.428021 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0513514 (* 1 = 0.0513514 loss)
I1015 13:15:03.428027 15018 sgd_solver.cpp:138] Iteration 11980, lr = 0.0005
I1015 13:15:14.824270 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12000.caffemodel
I1015 13:15:15.657444 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12000.solverstate
I1015 13:15:15.855260 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 13:16:53.722954 15018 solver.cpp:243] Iteration 12000, loss = 1.77477
I1015 13:16:53.722987 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.69107 (* 1 = 1.69107 loss)
I1015 13:16:53.722993 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0836985 (* 1 = 0.0836985 loss)
I1015 13:16:53.723001 15018 sgd_solver.cpp:138] Iteration 12000, lr = 0.0005
I1015 13:17:04.476160 15018 solver.cpp:243] Iteration 12020, loss = 3.14253
I1015 13:17:04.476199 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.93225 (* 1 = 2.93225 loss)
I1015 13:17:04.476207 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0930416 (* 1 = 0.0930416 loss)
I1015 13:17:04.476212 15018 sgd_solver.cpp:138] Iteration 12020, lr = 0.0005
I1015 13:17:16.374486 15018 solver.cpp:243] Iteration 12040, loss = 3.12244
I1015 13:17:16.374536 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.3952 (* 1 = 4.3952 loss)
I1015 13:17:16.374542 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0778296 (* 1 = 0.0778296 loss)
I1015 13:17:16.374548 15018 sgd_solver.cpp:138] Iteration 12040, lr = 0.0005
I1015 13:17:27.950667 15018 solver.cpp:243] Iteration 12060, loss = 2.93742
I1015 13:17:27.950716 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.86944 (* 1 = 2.86944 loss)
I1015 13:17:27.950723 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078631 (* 1 = 0.078631 loss)
I1015 13:17:27.950729 15018 sgd_solver.cpp:138] Iteration 12060, lr = 0.0005
I1015 13:17:39.522150 15018 solver.cpp:243] Iteration 12080, loss = 2.60793
I1015 13:17:39.522199 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.05537 (* 1 = 2.05537 loss)
I1015 13:17:39.522205 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0671181 (* 1 = 0.0671181 loss)
I1015 13:17:39.522212 15018 sgd_solver.cpp:138] Iteration 12080, lr = 0.0005
I1015 13:17:51.295399 15018 solver.cpp:243] Iteration 12100, loss = 3.14645
I1015 13:17:51.295444 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.52786 (* 1 = 4.52786 loss)
I1015 13:17:51.295450 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111777 (* 1 = 0.111777 loss)
I1015 13:17:51.295456 15018 sgd_solver.cpp:138] Iteration 12100, lr = 0.0005
I1015 13:18:03.406651 15018 solver.cpp:243] Iteration 12120, loss = 3.52107
I1015 13:18:03.406700 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.47098 (* 1 = 1.47098 loss)
I1015 13:18:03.406707 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.077946 (* 1 = 0.077946 loss)
I1015 13:18:03.406713 15018 sgd_solver.cpp:138] Iteration 12120, lr = 0.0005
I1015 13:18:15.559921 15018 solver.cpp:243] Iteration 12140, loss = 3.85384
I1015 13:18:15.559969 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.6473 (* 1 = 3.6473 loss)
I1015 13:18:15.559975 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.128205 (* 1 = 0.128205 loss)
I1015 13:18:15.559981 15018 sgd_solver.cpp:138] Iteration 12140, lr = 0.0005
I1015 13:18:27.698011 15018 solver.cpp:243] Iteration 12160, loss = 4.46197
I1015 13:18:27.698061 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.29613 (* 1 = 4.29613 loss)
I1015 13:18:27.698068 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0651118 (* 1 = 0.0651118 loss)
I1015 13:18:27.698073 15018 sgd_solver.cpp:138] Iteration 12160, lr = 0.0005
I1015 13:18:36.249514 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:18:39.728435 15018 solver.cpp:243] Iteration 12180, loss = 3.78716
I1015 13:18:39.728477 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.95757 (* 1 = 3.95757 loss)
I1015 13:18:39.728484 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0759941 (* 1 = 0.0759941 loss)
I1015 13:18:39.728490 15018 sgd_solver.cpp:138] Iteration 12180, lr = 0.0005
I1015 13:18:51.683809 15018 solver.cpp:243] Iteration 12200, loss = 3.01003
I1015 13:18:51.683842 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.58632 (* 1 = 2.58632 loss)
I1015 13:18:51.683848 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.625414 (* 1 = 0.625414 loss)
I1015 13:18:51.683853 15018 sgd_solver.cpp:138] Iteration 12200, lr = 0.0005
I1015 13:19:03.677211 15018 solver.cpp:243] Iteration 12220, loss = 2.93783
I1015 13:19:03.677243 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.92714 (* 1 = 1.92714 loss)
I1015 13:19:03.677249 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0629704 (* 1 = 0.0629704 loss)
I1015 13:19:03.677255 15018 sgd_solver.cpp:138] Iteration 12220, lr = 0.0005
I1015 13:19:15.647841 15018 solver.cpp:243] Iteration 12240, loss = 1.99925
I1015 13:19:15.647891 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.816886 (* 1 = 0.816886 loss)
I1015 13:19:15.647897 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.242705 (* 1 = 0.242705 loss)
I1015 13:19:15.647902 15018 sgd_solver.cpp:138] Iteration 12240, lr = 0.0005
I1015 13:19:27.758785 15018 solver.cpp:243] Iteration 12260, loss = 2.99331
I1015 13:19:27.758826 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.7163 (* 1 = 3.7163 loss)
I1015 13:19:27.758833 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0759502 (* 1 = 0.0759502 loss)
I1015 13:19:27.758839 15018 sgd_solver.cpp:138] Iteration 12260, lr = 0.0005
I1015 13:19:39.753103 15018 solver.cpp:243] Iteration 12280, loss = 2.83407
I1015 13:19:39.753150 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.99546 (* 1 = 3.99546 loss)
I1015 13:19:39.753157 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0672735 (* 1 = 0.0672735 loss)
I1015 13:19:39.753163 15018 sgd_solver.cpp:138] Iteration 12280, lr = 0.0005
I1015 13:19:51.863991 15018 solver.cpp:243] Iteration 12300, loss = 2.12051
I1015 13:19:51.864040 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.61361 (* 1 = 1.61361 loss)
I1015 13:19:51.864046 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0828323 (* 1 = 0.0828323 loss)
I1015 13:19:51.864053 15018 sgd_solver.cpp:138] Iteration 12300, lr = 0.0005
I1015 13:20:04.011446 15018 solver.cpp:243] Iteration 12320, loss = 2.52629
I1015 13:20:04.011481 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.85425 (* 1 = 1.85425 loss)
I1015 13:20:04.011487 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0938595 (* 1 = 0.0938595 loss)
I1015 13:20:04.011492 15018 sgd_solver.cpp:138] Iteration 12320, lr = 0.0005
I1015 13:20:16.195768 15018 solver.cpp:243] Iteration 12340, loss = 2.93647
I1015 13:20:16.195801 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.57109 (* 1 = 1.57109 loss)
I1015 13:20:16.195807 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0923109 (* 1 = 0.0923109 loss)
I1015 13:20:16.195813 15018 sgd_solver.cpp:138] Iteration 12340, lr = 0.0005
I1015 13:20:28.217434 15018 solver.cpp:243] Iteration 12360, loss = 1.63291
I1015 13:20:28.217468 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.12573 (* 1 = 1.12573 loss)
I1015 13:20:28.217474 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0608406 (* 1 = 0.0608406 loss)
I1015 13:20:28.217480 15018 sgd_solver.cpp:138] Iteration 12360, lr = 0.0005
I1015 13:20:40.417425 15018 solver.cpp:243] Iteration 12380, loss = 2.61984
I1015 13:20:40.417459 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.93783 (* 1 = 2.93783 loss)
I1015 13:20:40.417466 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.431432 (* 1 = 0.431432 loss)
I1015 13:20:40.417471 15018 sgd_solver.cpp:138] Iteration 12380, lr = 0.0005
I1015 13:20:52.682893 15018 solver.cpp:243] Iteration 12400, loss = 2.68506
I1015 13:20:52.682927 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.84794 (* 1 = 1.84794 loss)
I1015 13:20:52.682934 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0898747 (* 1 = 0.0898747 loss)
I1015 13:20:52.682940 15018 sgd_solver.cpp:138] Iteration 12400, lr = 0.0005
I1015 13:21:04.621047 15018 solver.cpp:243] Iteration 12420, loss = 1.94662
I1015 13:21:04.621094 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.78663 (* 1 = 1.78663 loss)
I1015 13:21:04.621100 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0593682 (* 1 = 0.0593682 loss)
I1015 13:21:04.621106 15018 sgd_solver.cpp:138] Iteration 12420, lr = 0.0005
I1015 13:21:16.594086 15018 solver.cpp:243] Iteration 12440, loss = 2.16579
I1015 13:21:16.594135 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.509 (* 1 = 3.509 loss)
I1015 13:21:16.594141 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0685307 (* 1 = 0.0685307 loss)
I1015 13:21:16.594146 15018 sgd_solver.cpp:138] Iteration 12440, lr = 0.0005
I1015 13:21:28.622247 15018 solver.cpp:243] Iteration 12460, loss = 3.19932
I1015 13:21:28.622284 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.38005 (* 1 = 2.38005 loss)
I1015 13:21:28.622292 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0691926 (* 1 = 0.0691926 loss)
I1015 13:21:28.622297 15018 sgd_solver.cpp:138] Iteration 12460, lr = 0.0005
I1015 13:21:40.313172 15018 solver.cpp:243] Iteration 12480, loss = 2.43094
I1015 13:21:40.313220 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.42031 (* 1 = 3.42031 loss)
I1015 13:21:40.313227 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0749241 (* 1 = 0.0749241 loss)
I1015 13:21:40.313232 15018 sgd_solver.cpp:138] Iteration 12480, lr = 0.0005
I1015 13:21:51.829093 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12500.caffemodel
I1015 13:21:52.179531 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12500.solverstate
I1015 13:21:52.823037 15018 solver.cpp:243] Iteration 12500, loss = 2.96795
I1015 13:21:52.823078 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.15513 (* 1 = 3.15513 loss)
I1015 13:21:52.823086 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0940015 (* 1 = 0.0940015 loss)
I1015 13:21:52.823091 15018 sgd_solver.cpp:138] Iteration 12500, lr = 0.0005
I1015 13:22:04.608417 15018 solver.cpp:243] Iteration 12520, loss = 2.4347
I1015 13:22:04.608467 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.30039 (* 1 = 3.30039 loss)
I1015 13:22:04.608474 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0488795 (* 1 = 0.0488795 loss)
I1015 13:22:04.608479 15018 sgd_solver.cpp:138] Iteration 12520, lr = 0.0005
I1015 13:22:16.511297 15018 solver.cpp:243] Iteration 12540, loss = 3.04707
I1015 13:22:16.511344 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.26342 (* 1 = 5.26342 loss)
I1015 13:22:16.511350 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0632158 (* 1 = 0.0632158 loss)
I1015 13:22:16.511356 15018 sgd_solver.cpp:138] Iteration 12540, lr = 0.0005
I1015 13:22:28.365422 15018 solver.cpp:243] Iteration 12560, loss = 3.03862
I1015 13:22:28.365458 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.26867 (* 1 = 3.26867 loss)
I1015 13:22:28.365464 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0767171 (* 1 = 0.0767171 loss)
I1015 13:22:28.365469 15018 sgd_solver.cpp:138] Iteration 12560, lr = 0.0005
I1015 13:22:40.311156 15018 solver.cpp:243] Iteration 12580, loss = 2.8795
I1015 13:22:40.311205 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.23947 (* 1 = 2.23947 loss)
I1015 13:22:40.311213 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078461 (* 1 = 0.078461 loss)
I1015 13:22:40.311218 15018 sgd_solver.cpp:138] Iteration 12580, lr = 0.0005
I1015 13:22:51.935653 15018 solver.cpp:243] Iteration 12600, loss = 2.61188
I1015 13:22:51.935700 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.98449 (* 1 = 1.98449 loss)
I1015 13:22:51.935708 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.06662 (* 1 = 0.06662 loss)
I1015 13:22:51.935712 15018 sgd_solver.cpp:138] Iteration 12600, lr = 0.0005
I1015 13:23:03.539834 15018 solver.cpp:243] Iteration 12620, loss = 2.59855
I1015 13:23:03.539880 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.71486 (* 1 = 1.71486 loss)
I1015 13:23:03.539887 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.060531 (* 1 = 0.060531 loss)
I1015 13:23:03.539893 15018 sgd_solver.cpp:138] Iteration 12620, lr = 0.0005
I1015 13:23:15.241058 15018 solver.cpp:243] Iteration 12640, loss = 2.64778
I1015 13:23:15.241107 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.66018 (* 1 = 2.66018 loss)
I1015 13:23:15.241114 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0722092 (* 1 = 0.0722092 loss)
I1015 13:23:15.241119 15018 sgd_solver.cpp:138] Iteration 12640, lr = 0.0005
I1015 13:23:27.300670 15018 solver.cpp:243] Iteration 12660, loss = 4.09423
I1015 13:23:27.300704 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.27272 (* 1 = 4.27272 loss)
I1015 13:23:27.300710 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0717413 (* 1 = 0.0717413 loss)
I1015 13:23:27.300715 15018 sgd_solver.cpp:138] Iteration 12660, lr = 0.0005
I1015 13:23:39.480408 15018 solver.cpp:243] Iteration 12680, loss = 3.6508
I1015 13:23:39.480456 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.0932 (* 1 = 4.0932 loss)
I1015 13:23:39.480463 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0809373 (* 1 = 0.0809373 loss)
I1015 13:23:39.480469 15018 sgd_solver.cpp:138] Iteration 12680, lr = 0.0005
I1015 13:23:51.612457 15018 solver.cpp:243] Iteration 12700, loss = 4.2672
I1015 13:23:51.612504 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.4158 (* 1 = 4.4158 loss)
I1015 13:23:51.612510 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0989507 (* 1 = 0.0989507 loss)
I1015 13:23:51.612516 15018 sgd_solver.cpp:138] Iteration 12700, lr = 0.0005
I1015 13:24:03.635535 15018 solver.cpp:243] Iteration 12720, loss = 3.54882
I1015 13:24:03.635568 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.2125 (* 1 = 3.2125 loss)
I1015 13:24:03.635591 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0817633 (* 1 = 0.0817633 loss)
I1015 13:24:03.635596 15018 sgd_solver.cpp:138] Iteration 12720, lr = 0.0005
I1015 13:24:15.527365 15018 solver.cpp:243] Iteration 12740, loss = 2.90341
I1015 13:24:15.527400 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.48691 (* 1 = 3.48691 loss)
I1015 13:24:15.527405 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.54689 (* 1 = 0.54689 loss)
I1015 13:24:15.527411 15018 sgd_solver.cpp:138] Iteration 12740, lr = 0.0005
I1015 13:24:27.496764 15018 solver.cpp:243] Iteration 12760, loss = 2.71275
I1015 13:24:27.496800 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.53217 (* 1 = 1.53217 loss)
I1015 13:24:27.496807 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0898549 (* 1 = 0.0898549 loss)
I1015 13:24:27.496812 15018 sgd_solver.cpp:138] Iteration 12760, lr = 0.0005
I1015 13:24:39.359392 15018 solver.cpp:243] Iteration 12780, loss = 2.06097
I1015 13:24:39.359441 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.826143 (* 1 = 0.826143 loss)
I1015 13:24:39.359447 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.24363 (* 1 = 0.24363 loss)
I1015 13:24:39.359453 15018 sgd_solver.cpp:138] Iteration 12780, lr = 0.0005
I1015 13:24:51.415284 15018 solver.cpp:243] Iteration 12800, loss = 2.77995
I1015 13:24:51.415318 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.11565 (* 1 = 4.11565 loss)
I1015 13:24:51.415325 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.199093 (* 1 = 0.199093 loss)
I1015 13:24:51.415330 15018 sgd_solver.cpp:138] Iteration 12800, lr = 0.0005
I1015 13:25:03.425379 15018 solver.cpp:243] Iteration 12820, loss = 2.8259
I1015 13:25:03.425413 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.78607 (* 1 = 2.78607 loss)
I1015 13:25:03.425420 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.127878 (* 1 = 0.127878 loss)
I1015 13:25:03.425424 15018 sgd_solver.cpp:138] Iteration 12820, lr = 0.0005
I1015 13:25:15.599638 15018 solver.cpp:243] Iteration 12840, loss = 2.34685
I1015 13:25:15.599671 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.79005 (* 1 = 1.79005 loss)
I1015 13:25:15.599678 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.165187 (* 1 = 0.165187 loss)
I1015 13:25:15.599684 15018 sgd_solver.cpp:138] Iteration 12840, lr = 0.0005
I1015 13:25:27.764952 15018 solver.cpp:243] Iteration 12860, loss = 2.96898
I1015 13:25:27.764984 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.59916 (* 1 = 3.59916 loss)
I1015 13:25:27.764991 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0776307 (* 1 = 0.0776307 loss)
I1015 13:25:27.764997 15018 sgd_solver.cpp:138] Iteration 12860, lr = 0.0005
I1015 13:25:39.920737 15018 solver.cpp:243] Iteration 12880, loss = 3.00448
I1015 13:25:39.920769 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.98724 (* 1 = 3.98724 loss)
I1015 13:25:39.920776 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.106739 (* 1 = 0.106739 loss)
I1015 13:25:39.920781 15018 sgd_solver.cpp:138] Iteration 12880, lr = 0.0005
I1015 13:25:51.921691 15018 solver.cpp:243] Iteration 12900, loss = 1.53277
I1015 13:25:51.921739 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.44763 (* 1 = 2.44763 loss)
I1015 13:25:51.921746 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0714766 (* 1 = 0.0714766 loss)
I1015 13:25:51.921752 15018 sgd_solver.cpp:138] Iteration 12900, lr = 0.0005
I1015 13:26:04.119879 15018 solver.cpp:243] Iteration 12920, loss = 2.61659
I1015 13:26:04.119930 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.42557 (* 1 = 1.42557 loss)
I1015 13:26:04.119935 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.326672 (* 1 = 0.326672 loss)
I1015 13:26:04.119941 15018 sgd_solver.cpp:138] Iteration 12920, lr = 0.0005
I1015 13:26:16.377653 15018 solver.cpp:243] Iteration 12940, loss = 2.80824
I1015 13:26:16.377688 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.57461 (* 1 = 2.57461 loss)
I1015 13:26:16.377696 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.136918 (* 1 = 0.136918 loss)
I1015 13:26:16.377701 15018 sgd_solver.cpp:138] Iteration 12940, lr = 0.0005
I1015 13:26:28.296031 15018 solver.cpp:243] Iteration 12960, loss = 2.1028
I1015 13:26:28.296079 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.48597 (* 1 = 2.48597 loss)
I1015 13:26:28.296087 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0797467 (* 1 = 0.0797467 loss)
I1015 13:26:28.296092 15018 sgd_solver.cpp:138] Iteration 12960, lr = 0.0005
I1015 13:26:40.245813 15018 solver.cpp:243] Iteration 12980, loss = 2.30327
I1015 13:26:40.245863 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.79274 (* 1 = 1.79274 loss)
I1015 13:26:40.245870 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0500448 (* 1 = 0.0500448 loss)
I1015 13:26:40.245875 15018 sgd_solver.cpp:138] Iteration 12980, lr = 0.0005
I1015 13:26:51.683485 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13000.caffemodel
I1015 13:26:51.923496 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13000.solverstate
I1015 13:26:52.122895 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 13:27:27.930619 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:28:31.292788 15018 solver.cpp:243] Iteration 13000, loss = 3.35986
I1015 13:28:31.292821 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.29658 (* 1 = 3.29658 loss)
I1015 13:28:31.292827 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.063281 (* 1 = 0.063281 loss)
I1015 13:28:31.292834 15018 sgd_solver.cpp:138] Iteration 13000, lr = 0.0005
I1015 13:28:41.895944 15018 solver.cpp:243] Iteration 13020, loss = 2.49572
I1015 13:28:41.895980 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.46023 (* 1 = 2.46023 loss)
I1015 13:28:41.895987 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0636377 (* 1 = 0.0636377 loss)
I1015 13:28:41.895993 15018 sgd_solver.cpp:138] Iteration 13020, lr = 0.0005
I1015 13:28:53.913960 15018 solver.cpp:243] Iteration 13040, loss = 2.83556
I1015 13:28:53.914008 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.77496 (* 1 = 2.77496 loss)
I1015 13:28:53.914016 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.064429 (* 1 = 0.064429 loss)
I1015 13:28:53.914021 15018 sgd_solver.cpp:138] Iteration 13040, lr = 0.0005
I1015 13:29:05.941777 15018 solver.cpp:243] Iteration 13060, loss = 2.08517
I1015 13:29:05.941823 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.89462 (* 1 = 2.89462 loss)
I1015 13:29:05.941830 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.055048 (* 1 = 0.055048 loss)
I1015 13:29:05.941835 15018 sgd_solver.cpp:138] Iteration 13060, lr = 0.0005
I1015 13:29:17.842911 15018 solver.cpp:243] Iteration 13080, loss = 3.02345
I1015 13:29:17.842959 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.48071 (* 1 = 2.48071 loss)
I1015 13:29:17.842967 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0816151 (* 1 = 0.0816151 loss)
I1015 13:29:17.842972 15018 sgd_solver.cpp:138] Iteration 13080, lr = 0.0005
I1015 13:29:29.707180 15018 solver.cpp:243] Iteration 13100, loss = 3.07479
I1015 13:29:29.707226 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5619 (* 1 = 2.5619 loss)
I1015 13:29:29.707232 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0730042 (* 1 = 0.0730042 loss)
I1015 13:29:29.707238 15018 sgd_solver.cpp:138] Iteration 13100, lr = 0.0005
I1015 13:29:41.708902 15018 solver.cpp:243] Iteration 13120, loss = 2.9734
I1015 13:29:41.708951 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.85865 (* 1 = 1.85865 loss)
I1015 13:29:41.708958 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.146483 (* 1 = 0.146483 loss)
I1015 13:29:41.708964 15018 sgd_solver.cpp:138] Iteration 13120, lr = 0.0005
I1015 13:29:53.357038 15018 solver.cpp:243] Iteration 13140, loss = 2.66972
I1015 13:29:53.357081 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.65278 (* 1 = 2.65278 loss)
I1015 13:29:53.357089 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0577594 (* 1 = 0.0577594 loss)
I1015 13:29:53.357095 15018 sgd_solver.cpp:138] Iteration 13140, lr = 0.0005
I1015 13:30:04.918264 15018 solver.cpp:243] Iteration 13160, loss = 2.57843
I1015 13:30:04.918311 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.63801 (* 1 = 2.63801 loss)
I1015 13:30:04.918318 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0704801 (* 1 = 0.0704801 loss)
I1015 13:30:04.918323 15018 sgd_solver.cpp:138] Iteration 13160, lr = 0.0005
I1015 13:30:16.586988 15018 solver.cpp:243] Iteration 13180, loss = 2.34862
I1015 13:30:16.587038 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.43191 (* 1 = 2.43191 loss)
I1015 13:30:16.587044 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0887624 (* 1 = 0.0887624 loss)
I1015 13:30:16.587049 15018 sgd_solver.cpp:138] Iteration 13180, lr = 0.0005
I1015 13:30:28.713366 15018 solver.cpp:243] Iteration 13200, loss = 3.70155
I1015 13:30:28.713400 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.83366 (* 1 = 1.83366 loss)
I1015 13:30:28.713407 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0734684 (* 1 = 0.0734684 loss)
I1015 13:30:28.713412 15018 sgd_solver.cpp:138] Iteration 13200, lr = 0.0005
I1015 13:30:40.889729 15018 solver.cpp:243] Iteration 13220, loss = 3.53966
I1015 13:30:40.889776 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.34877 (* 1 = 4.34877 loss)
I1015 13:30:40.889783 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0732644 (* 1 = 0.0732644 loss)
I1015 13:30:40.889788 15018 sgd_solver.cpp:138] Iteration 13220, lr = 0.0005
I1015 13:30:53.068670 15018 solver.cpp:243] Iteration 13240, loss = 4.09474
I1015 13:30:53.068719 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.91655 (* 1 = 3.91655 loss)
I1015 13:30:53.068727 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.107217 (* 1 = 0.107217 loss)
I1015 13:30:53.068732 15018 sgd_solver.cpp:138] Iteration 13240, lr = 0.0005
I1015 13:31:05.145480 15018 solver.cpp:243] Iteration 13260, loss = 3.51611
I1015 13:31:05.145514 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.57274 (* 1 = 2.57274 loss)
I1015 13:31:05.145521 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0745618 (* 1 = 0.0745618 loss)
I1015 13:31:05.145527 15018 sgd_solver.cpp:138] Iteration 13260, lr = 0.0005
I1015 13:31:17.030930 15018 solver.cpp:243] Iteration 13280, loss = 2.57464
I1015 13:31:17.030962 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.76687 (* 1 = 1.76687 loss)
I1015 13:31:17.030969 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0797017 (* 1 = 0.0797017 loss)
I1015 13:31:17.030975 15018 sgd_solver.cpp:138] Iteration 13280, lr = 0.0005
I1015 13:31:29.022379 15018 solver.cpp:243] Iteration 13300, loss = 2.49271
I1015 13:31:29.022414 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.88225 (* 1 = 2.88225 loss)
I1015 13:31:29.022421 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110803 (* 1 = 0.110803 loss)
I1015 13:31:29.022428 15018 sgd_solver.cpp:138] Iteration 13300, lr = 0.0005
I1015 13:31:40.997776 15018 solver.cpp:243] Iteration 13320, loss = 2.22557
I1015 13:31:40.997825 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.45242 (* 1 = 1.45242 loss)
I1015 13:31:40.997833 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111159 (* 1 = 0.111159 loss)
I1015 13:31:40.997838 15018 sgd_solver.cpp:138] Iteration 13320, lr = 0.0005
I1015 13:31:53.092303 15018 solver.cpp:243] Iteration 13340, loss = 2.60211
I1015 13:31:53.092335 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.761236 (* 1 = 0.761236 loss)
I1015 13:31:53.092341 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078006 (* 1 = 0.078006 loss)
I1015 13:31:53.092347 15018 sgd_solver.cpp:138] Iteration 13340, lr = 0.0005
I1015 13:32:05.087090 15018 solver.cpp:243] Iteration 13360, loss = 2.50075
I1015 13:32:05.087137 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.18206 (* 1 = 3.18206 loss)
I1015 13:32:05.087143 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.119756 (* 1 = 0.119756 loss)
I1015 13:32:05.087149 15018 sgd_solver.cpp:138] Iteration 13360, lr = 0.0005
I1015 13:32:17.370368 15018 solver.cpp:243] Iteration 13380, loss = 2.22586
I1015 13:32:17.370400 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.48192 (* 1 = 2.48192 loss)
I1015 13:32:17.370407 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.335827 (* 1 = 0.335827 loss)
I1015 13:32:17.370412 15018 sgd_solver.cpp:138] Iteration 13380, lr = 0.0005
I1015 13:32:29.518769 15018 solver.cpp:243] Iteration 13400, loss = 2.71417
I1015 13:32:29.518817 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.35453 (* 1 = 3.35453 loss)
I1015 13:32:29.518823 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.173761 (* 1 = 0.173761 loss)
I1015 13:32:29.518829 15018 sgd_solver.cpp:138] Iteration 13400, lr = 0.0005
I1015 13:32:41.680593 15018 solver.cpp:243] Iteration 13420, loss = 2.97882
I1015 13:32:41.680624 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.25467 (* 1 = 2.25467 loss)
I1015 13:32:41.680630 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0916391 (* 1 = 0.0916391 loss)
I1015 13:32:41.680636 15018 sgd_solver.cpp:138] Iteration 13420, lr = 0.0005
I1015 13:32:53.741951 15018 solver.cpp:243] Iteration 13440, loss = 1.5442
I1015 13:32:53.741984 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.26362 (* 1 = 1.26362 loss)
I1015 13:32:53.741991 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0749099 (* 1 = 0.0749099 loss)
I1015 13:32:53.741997 15018 sgd_solver.cpp:138] Iteration 13440, lr = 0.0005
I1015 13:33:06.001298 15018 solver.cpp:243] Iteration 13460, loss = 2.74481
I1015 13:33:06.001350 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.38503 (* 1 = 2.38503 loss)
I1015 13:33:06.001358 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.12296 (* 1 = 0.12296 loss)
I1015 13:33:06.001364 15018 sgd_solver.cpp:138] Iteration 13460, lr = 0.0005
I1015 13:33:18.305368 15018 solver.cpp:243] Iteration 13480, loss = 2.53701
I1015 13:33:18.305400 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.57636 (* 1 = 5.57636 loss)
I1015 13:33:18.305408 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.84196 (* 1 = 0.84196 loss)
I1015 13:33:18.305413 15018 sgd_solver.cpp:138] Iteration 13480, lr = 0.0005
I1015 13:33:29.683768 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13500.caffemodel
I1015 13:33:30.481492 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13500.solverstate
I1015 13:33:31.068325 15018 solver.cpp:243] Iteration 13500, loss = 2.2069
I1015 13:33:31.068372 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.40355 (* 1 = 2.40355 loss)
I1015 13:33:31.068377 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0803092 (* 1 = 0.0803092 loss)
I1015 13:33:31.068382 15018 sgd_solver.cpp:138] Iteration 13500, lr = 0.0005
I1015 13:33:42.371551 15018 solver.cpp:243] Iteration 13520, loss = 2.48923
I1015 13:33:42.371582 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.1161 (* 1 = 1.1161 loss)
I1015 13:33:42.371588 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0663922 (* 1 = 0.0663922 loss)
I1015 13:33:42.371594 15018 sgd_solver.cpp:138] Iteration 13520, lr = 0.0005
I1015 13:33:54.348147 15018 solver.cpp:243] Iteration 13540, loss = 2.85178
I1015 13:33:54.348179 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.56219 (* 1 = 2.56219 loss)
I1015 13:33:54.348186 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103842 (* 1 = 0.103842 loss)
I1015 13:33:54.348191 15018 sgd_solver.cpp:138] Iteration 13540, lr = 0.0005
I1015 13:34:06.095706 15018 solver.cpp:243] Iteration 13560, loss = 2.74179
I1015 13:34:06.095755 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.43143 (* 1 = 1.43143 loss)
I1015 13:34:06.095762 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0502401 (* 1 = 0.0502401 loss)
I1015 13:34:06.095767 15018 sgd_solver.cpp:138] Iteration 13560, lr = 0.0005
I1015 13:34:17.995965 15018 solver.cpp:243] Iteration 13580, loss = 2.88295
I1015 13:34:17.996013 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.71053 (* 1 = 3.71053 loss)
I1015 13:34:17.996021 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.102481 (* 1 = 0.102481 loss)
I1015 13:34:17.996026 15018 sgd_solver.cpp:138] Iteration 13580, lr = 0.0005
I1015 13:34:30.001113 15018 solver.cpp:243] Iteration 13600, loss = 1.9976
I1015 13:34:30.001159 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.8643 (* 1 = 1.8643 loss)
I1015 13:34:30.001165 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0554834 (* 1 = 0.0554834 loss)
I1015 13:34:30.001171 15018 sgd_solver.cpp:138] Iteration 13600, lr = 0.0005
I1015 13:34:41.927752 15018 solver.cpp:243] Iteration 13620, loss = 2.89409
I1015 13:34:41.927799 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.95395 (* 1 = 2.95395 loss)
I1015 13:34:41.927805 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0515708 (* 1 = 0.0515708 loss)
I1015 13:34:41.927810 15018 sgd_solver.cpp:138] Iteration 13620, lr = 0.0005
I1015 13:34:53.794816 15018 solver.cpp:243] Iteration 13640, loss = 3.13619
I1015 13:34:53.794857 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.92714 (* 1 = 3.92714 loss)
I1015 13:34:53.794864 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0607695 (* 1 = 0.0607695 loss)
I1015 13:34:53.794870 15018 sgd_solver.cpp:138] Iteration 13640, lr = 0.0005
I1015 13:35:05.751178 15018 solver.cpp:243] Iteration 13660, loss = 2.90721
I1015 13:35:05.751210 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.47187 (* 1 = 3.47187 loss)
I1015 13:35:05.751216 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0658227 (* 1 = 0.0658227 loss)
I1015 13:35:05.751222 15018 sgd_solver.cpp:138] Iteration 13660, lr = 0.0005
I1015 13:35:17.424592 15018 solver.cpp:243] Iteration 13680, loss = 2.71294
I1015 13:35:17.424623 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.09166 (* 1 = 2.09166 loss)
I1015 13:35:17.424629 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0618894 (* 1 = 0.0618894 loss)
I1015 13:35:17.424636 15018 sgd_solver.cpp:138] Iteration 13680, lr = 0.0005
I1015 13:35:25.014166 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:35:28.967862 15018 solver.cpp:243] Iteration 13700, loss = 2.57762
I1015 13:35:28.967897 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.97916 (* 1 = 1.97916 loss)
I1015 13:35:28.967905 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0554153 (* 1 = 0.0554153 loss)
I1015 13:35:28.967909 15018 sgd_solver.cpp:138] Iteration 13700, lr = 0.0005
I1015 13:35:40.668915 15018 solver.cpp:243] Iteration 13720, loss = 2.19231
I1015 13:35:40.668963 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5155 (* 1 = 2.5155 loss)
I1015 13:35:40.668970 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0931682 (* 1 = 0.0931682 loss)
I1015 13:35:40.668975 15018 sgd_solver.cpp:138] Iteration 13720, lr = 0.0005
I1015 13:35:52.727731 15018 solver.cpp:243] Iteration 13740, loss = 3.36903
I1015 13:35:52.727762 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.18143 (* 1 = 3.18143 loss)
I1015 13:35:52.727769 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0985414 (* 1 = 0.0985414 loss)
I1015 13:35:52.727774 15018 sgd_solver.cpp:138] Iteration 13740, lr = 0.0005
I1015 13:36:04.848772 15018 solver.cpp:243] Iteration 13760, loss = 3.23703
I1015 13:36:04.848820 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.53792 (* 1 = 5.53792 loss)
I1015 13:36:04.848827 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0853983 (* 1 = 0.0853983 loss)
I1015 13:36:04.848832 15018 sgd_solver.cpp:138] Iteration 13760, lr = 0.0005
I1015 13:36:17.029927 15018 solver.cpp:243] Iteration 13780, loss = 3.9727
I1015 13:36:17.029978 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.02083 (* 1 = 4.02083 loss)
I1015 13:36:17.029983 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.140218 (* 1 = 0.140218 loss)
I1015 13:36:17.029989 15018 sgd_solver.cpp:138] Iteration 13780, lr = 0.0005
I1015 13:36:29.104691 15018 solver.cpp:243] Iteration 13800, loss = 3.50269
I1015 13:36:29.104741 15018 solver.cpp:259]     Train net output #0: mbox_loss = 5.1632 (* 1 = 5.1632 loss)
I1015 13:36:29.104748 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0924407 (* 1 = 0.0924407 loss)
I1015 13:36:29.104754 15018 sgd_solver.cpp:138] Iteration 13800, lr = 0.0005
I1015 13:36:40.964484 15018 solver.cpp:243] Iteration 13820, loss = 3.09324
I1015 13:36:40.964532 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.54791 (* 1 = 1.54791 loss)
I1015 13:36:40.964540 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0694135 (* 1 = 0.0694135 loss)
I1015 13:36:40.964545 15018 sgd_solver.cpp:138] Iteration 13820, lr = 0.0005
I1015 13:36:52.872077 15018 solver.cpp:243] Iteration 13840, loss = 2.25297
I1015 13:36:52.872112 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.46955 (* 1 = 1.46955 loss)
I1015 13:36:52.872117 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0825728 (* 1 = 0.0825728 loss)
I1015 13:36:52.872123 15018 sgd_solver.cpp:138] Iteration 13840, lr = 0.0005
I1015 13:37:04.757072 15018 solver.cpp:243] Iteration 13860, loss = 2.22856
I1015 13:37:04.757123 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.32852 (* 1 = 1.32852 loss)
I1015 13:37:04.757130 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0972422 (* 1 = 0.0972422 loss)
I1015 13:37:04.757136 15018 sgd_solver.cpp:138] Iteration 13860, lr = 0.0005
I1015 13:37:16.790838 15018 solver.cpp:243] Iteration 13880, loss = 2.75278
I1015 13:37:16.790871 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.620939 (* 1 = 0.620939 loss)
I1015 13:37:16.790877 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.101872 (* 1 = 0.101872 loss)
I1015 13:37:16.790884 15018 sgd_solver.cpp:138] Iteration 13880, lr = 0.0005
I1015 13:37:28.753304 15018 solver.cpp:243] Iteration 13900, loss = 2.18986
I1015 13:37:28.753358 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.453259 (* 1 = 0.453259 loss)
I1015 13:37:28.753365 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0880171 (* 1 = 0.0880171 loss)
I1015 13:37:28.753370 15018 sgd_solver.cpp:138] Iteration 13900, lr = 0.0005
I1015 13:37:40.923828 15018 solver.cpp:243] Iteration 13920, loss = 2.25714
I1015 13:37:40.923877 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.78511 (* 1 = 2.78511 loss)
I1015 13:37:40.923882 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.369095 (* 1 = 0.369095 loss)
I1015 13:37:40.923888 15018 sgd_solver.cpp:138] Iteration 13920, lr = 0.0005
I1015 13:37:53.067481 15018 solver.cpp:243] Iteration 13940, loss = 2.6865
I1015 13:37:53.067515 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.44419 (* 1 = 2.44419 loss)
I1015 13:37:53.067522 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0764053 (* 1 = 0.0764053 loss)
I1015 13:37:53.067528 15018 sgd_solver.cpp:138] Iteration 13940, lr = 0.0005
I1015 13:38:05.200881 15018 solver.cpp:243] Iteration 13960, loss = 2.94592
I1015 13:38:05.200928 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.16283 (* 1 = 1.16283 loss)
I1015 13:38:05.200934 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110146 (* 1 = 0.110146 loss)
I1015 13:38:05.200940 15018 sgd_solver.cpp:138] Iteration 13960, lr = 0.0005
I1015 13:38:17.248095 15018 solver.cpp:243] Iteration 13980, loss = 1.67685
I1015 13:38:17.248144 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.11395 (* 1 = 1.11395 loss)
I1015 13:38:17.248150 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0636602 (* 1 = 0.0636602 loss)
I1015 13:38:17.248155 15018 sgd_solver.cpp:138] Iteration 13980, lr = 0.0005
I1015 13:38:28.838294 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14000.caffemodel
I1015 13:38:29.663296 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14000.solverstate
I1015 13:38:29.855087 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 13:40:07.530371 15018 solver.cpp:243] Iteration 14000, loss = 2.08062
I1015 13:40:07.530407 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.0188 (* 1 = 2.0188 loss)
I1015 13:40:07.530413 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0618244 (* 1 = 0.0618244 loss)
I1015 13:40:07.530419 15018 sgd_solver.cpp:138] Iteration 14000, lr = 0.0005
I1015 13:40:18.751754 15018 solver.cpp:243] Iteration 14020, loss = 1.68793
I1015 13:40:18.751804 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.22304 (* 1 = 1.22304 loss)
I1015 13:40:18.751811 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.130965 (* 1 = 0.130965 loss)
I1015 13:40:18.751816 15018 sgd_solver.cpp:138] Iteration 14020, lr = 0.0005
I1015 13:40:30.730567 15018 solver.cpp:243] Iteration 14040, loss = 2.08337
I1015 13:40:30.730613 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.31547 (* 1 = 1.31547 loss)
I1015 13:40:30.730620 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.098174 (* 1 = 0.098174 loss)
I1015 13:40:30.730625 15018 sgd_solver.cpp:138] Iteration 14040, lr = 0.0005
I1015 13:40:42.711680 15018 solver.cpp:243] Iteration 14060, loss = 2.45769
I1015 13:40:42.711728 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.774382 (* 1 = 0.774382 loss)
I1015 13:40:42.711735 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0557326 (* 1 = 0.0557326 loss)
I1015 13:40:42.711740 15018 sgd_solver.cpp:138] Iteration 14060, lr = 0.0005
I1015 13:40:54.626787 15018 solver.cpp:243] Iteration 14080, loss = 3.1326
I1015 13:40:54.626819 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.71093 (* 1 = 2.71093 loss)
I1015 13:40:54.626826 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0716972 (* 1 = 0.0716972 loss)
I1015 13:40:54.626832 15018 sgd_solver.cpp:138] Iteration 14080, lr = 0.0005
I1015 13:41:06.484643 15018 solver.cpp:243] Iteration 14100, loss = 3.09625
I1015 13:41:06.484691 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.56845 (* 1 = 2.56845 loss)
I1015 13:41:06.484697 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0746053 (* 1 = 0.0746053 loss)
I1015 13:41:06.484704 15018 sgd_solver.cpp:138] Iteration 14100, lr = 0.0005
I1015 13:41:18.416859 15018 solver.cpp:243] Iteration 14120, loss = 2.48017
I1015 13:41:18.416905 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.40436 (* 1 = 2.40436 loss)
I1015 13:41:18.416913 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.120474 (* 1 = 0.120474 loss)
I1015 13:41:18.416918 15018 sgd_solver.cpp:138] Iteration 14120, lr = 0.0005
I1015 13:41:30.455925 15018 solver.cpp:243] Iteration 14140, loss = 2.2336
I1015 13:41:30.455973 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.505247 (* 1 = 0.505247 loss)
I1015 13:41:30.455979 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0727811 (* 1 = 0.0727811 loss)
I1015 13:41:30.455986 15018 sgd_solver.cpp:138] Iteration 14140, lr = 0.0005
I1015 13:41:42.393841 15018 solver.cpp:243] Iteration 14160, loss = 2.61984
I1015 13:41:42.393889 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.5223 (* 1 = 2.5223 loss)
I1015 13:41:42.393895 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0565397 (* 1 = 0.0565397 loss)
I1015 13:41:42.393900 15018 sgd_solver.cpp:138] Iteration 14160, lr = 0.0005
I1015 13:41:54.213016 15018 solver.cpp:243] Iteration 14180, loss = 2.62825
I1015 13:41:54.213065 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.54221 (* 1 = 3.54221 loss)
I1015 13:41:54.213071 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0742496 (* 1 = 0.0742496 loss)
I1015 13:41:54.213078 15018 sgd_solver.cpp:138] Iteration 14180, lr = 0.0005
I1015 13:42:06.170866 15018 solver.cpp:243] Iteration 14200, loss = 2.70793
I1015 13:42:06.170905 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.52871 (* 1 = 3.52871 loss)
I1015 13:42:06.170915 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.115384 (* 1 = 0.115384 loss)
I1015 13:42:06.170923 15018 sgd_solver.cpp:138] Iteration 14200, lr = 0.0005
I1015 13:42:07.475236 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:42:17.880847 15018 solver.cpp:243] Iteration 14220, loss = 2.58653
I1015 13:42:17.880883 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.24944 (* 1 = 3.24944 loss)
I1015 13:42:17.880892 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0525183 (* 1 = 0.0525183 loss)
I1015 13:42:17.880900 15018 sgd_solver.cpp:138] Iteration 14220, lr = 0.0005
I1015 13:42:29.423152 15018 solver.cpp:243] Iteration 14240, loss = 2.64393
I1015 13:42:29.423188 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.4416 (* 1 = 2.4416 loss)
I1015 13:42:29.423197 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0447921 (* 1 = 0.0447921 loss)
I1015 13:42:29.423204 15018 sgd_solver.cpp:138] Iteration 14240, lr = 0.0005
I1015 13:42:41.071887 15018 solver.cpp:243] Iteration 14260, loss = 2.1181
I1015 13:42:41.071924 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.31575 (* 1 = 2.31575 loss)
I1015 13:42:41.071933 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.124759 (* 1 = 0.124759 loss)
I1015 13:42:41.071941 15018 sgd_solver.cpp:138] Iteration 14260, lr = 0.0005
I1015 13:42:53.172781 15018 solver.cpp:243] Iteration 14280, loss = 3.21851
I1015 13:42:53.172816 15018 solver.cpp:259]     Train net output #0: mbox_loss = 6.05999 (* 1 = 6.05999 loss)
I1015 13:42:53.172825 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0840286 (* 1 = 0.0840286 loss)
I1015 13:42:53.172848 15018 sgd_solver.cpp:138] Iteration 14280, lr = 0.0005
I1015 13:43:05.229460 15018 solver.cpp:243] Iteration 14300, loss = 2.98794
I1015 13:43:05.229498 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.65676 (* 1 = 3.65676 loss)
I1015 13:43:05.229507 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0762322 (* 1 = 0.0762322 loss)
I1015 13:43:05.229516 15018 sgd_solver.cpp:138] Iteration 14300, lr = 0.0005
I1015 13:43:17.390159 15018 solver.cpp:243] Iteration 14320, loss = 3.94013
I1015 13:43:17.390197 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.95081 (* 1 = 3.95081 loss)
I1015 13:43:17.390205 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0794746 (* 1 = 0.0794746 loss)
I1015 13:43:17.390228 15018 sgd_solver.cpp:138] Iteration 14320, lr = 0.0005
I1015 13:43:29.517419 15018 solver.cpp:243] Iteration 14340, loss = 3.05895
I1015 13:43:29.517457 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.38654 (* 1 = 2.38654 loss)
I1015 13:43:29.517467 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0676685 (* 1 = 0.0676685 loss)
I1015 13:43:29.517474 15018 sgd_solver.cpp:138] Iteration 14340, lr = 0.0005
I1015 13:43:41.403513 15018 solver.cpp:243] Iteration 14360, loss = 3.17408
I1015 13:43:41.403551 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.80271 (* 1 = 1.80271 loss)
I1015 13:43:41.403559 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.111771 (* 1 = 0.111771 loss)
I1015 13:43:41.403568 15018 sgd_solver.cpp:138] Iteration 14360, lr = 0.0005
I1015 13:43:53.376140 15018 solver.cpp:243] Iteration 14380, loss = 2.33227
I1015 13:43:53.376176 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.43597 (* 1 = 2.43597 loss)
I1015 13:43:53.376184 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0861419 (* 1 = 0.0861419 loss)
I1015 13:43:53.376191 15018 sgd_solver.cpp:138] Iteration 14380, lr = 0.0005
I1015 13:44:05.257906 15018 solver.cpp:243] Iteration 14400, loss = 2.12029
I1015 13:44:05.257941 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.35082 (* 1 = 2.35082 loss)
I1015 13:44:05.257951 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0828377 (* 1 = 0.0828377 loss)
I1015 13:44:05.257958 15018 sgd_solver.cpp:138] Iteration 14400, lr = 0.0005
I1015 13:44:17.342687 15018 solver.cpp:243] Iteration 14420, loss = 3.15734
I1015 13:44:17.342734 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.28581 (* 1 = 4.28581 loss)
I1015 13:44:17.342742 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0554918 (* 1 = 0.0554918 loss)
I1015 13:44:17.342751 15018 sgd_solver.cpp:138] Iteration 14420, lr = 0.0005
I1015 13:44:29.359800 15018 solver.cpp:243] Iteration 14440, loss = 2.45298
I1015 13:44:29.359836 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.61568 (* 1 = 3.61568 loss)
I1015 13:44:29.359845 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104093 (* 1 = 0.104093 loss)
I1015 13:44:29.359853 15018 sgd_solver.cpp:138] Iteration 14440, lr = 0.0005
I1015 13:44:41.514605 15018 solver.cpp:243] Iteration 14460, loss = 2.36182
I1015 13:44:41.514643 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.989734 (* 1 = 0.989734 loss)
I1015 13:44:41.514652 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0770518 (* 1 = 0.0770518 loss)
I1015 13:44:41.514659 15018 sgd_solver.cpp:138] Iteration 14460, lr = 0.0005
I1015 13:44:53.650915 15018 solver.cpp:243] Iteration 14480, loss = 2.46649
I1015 13:44:53.650952 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.749272 (* 1 = 0.749272 loss)
I1015 13:44:53.650960 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0702655 (* 1 = 0.0702655 loss)
I1015 13:44:53.650969 15018 sgd_solver.cpp:138] Iteration 14480, lr = 0.0005
I1015 13:45:05.263634 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14500.caffemodel
I1015 13:45:06.044576 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14500.solverstate
I1015 13:45:06.614343 15018 solver.cpp:243] Iteration 14500, loss = 3.0228
I1015 13:45:06.614378 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.35266 (* 1 = 3.35266 loss)
I1015 13:45:06.614384 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.133505 (* 1 = 0.133505 loss)
I1015 13:45:06.614392 15018 sgd_solver.cpp:138] Iteration 14500, lr = 0.0005
I1015 13:45:17.997292 15018 solver.cpp:243] Iteration 14520, loss = 1.75333
I1015 13:45:17.997325 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.14054 (* 1 = 1.14054 loss)
I1015 13:45:17.997336 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.058137 (* 1 = 0.058137 loss)
I1015 13:45:17.997342 15018 sgd_solver.cpp:138] Iteration 14520, lr = 0.0005
I1015 13:45:30.152807 15018 solver.cpp:243] Iteration 14540, loss = 2.67092
I1015 13:45:30.152843 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.06871 (* 1 = 1.06871 loss)
I1015 13:45:30.152849 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0691713 (* 1 = 0.0691713 loss)
I1015 13:45:30.152855 15018 sgd_solver.cpp:138] Iteration 14540, lr = 0.0005
I1015 13:45:42.472687 15018 solver.cpp:243] Iteration 14560, loss = 1.62406
I1015 13:45:42.472740 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.30214 (* 1 = 1.30214 loss)
I1015 13:45:42.472748 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0917793 (* 1 = 0.0917793 loss)
I1015 13:45:42.472753 15018 sgd_solver.cpp:138] Iteration 14560, lr = 0.0005
I1015 13:45:54.409492 15018 solver.cpp:243] Iteration 14580, loss = 2.30144
I1015 13:45:54.409530 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.7631 (* 1 = 1.7631 loss)
I1015 13:45:54.409539 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0646683 (* 1 = 0.0646683 loss)
I1015 13:45:54.409548 15018 sgd_solver.cpp:138] Iteration 14580, lr = 0.0005
I1015 13:46:06.428259 15018 solver.cpp:243] Iteration 14600, loss = 2.78249
I1015 13:46:06.428297 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.79649 (* 1 = 2.79649 loss)
I1015 13:46:06.428304 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0615805 (* 1 = 0.0615805 loss)
I1015 13:46:06.428313 15018 sgd_solver.cpp:138] Iteration 14600, lr = 0.0005
I1015 13:46:18.334656 15018 solver.cpp:243] Iteration 14620, loss = 3.04541
I1015 13:46:18.334691 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.20335 (* 1 = 3.20335 loss)
I1015 13:46:18.334699 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.110991 (* 1 = 0.110991 loss)
I1015 13:46:18.334707 15018 sgd_solver.cpp:138] Iteration 14620, lr = 0.0005
I1015 13:46:30.136337 15018 solver.cpp:243] Iteration 14640, loss = 3.24551
I1015 13:46:30.136375 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.28453 (* 1 = 1.28453 loss)
I1015 13:46:30.136385 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0706215 (* 1 = 0.0706215 loss)
I1015 13:46:30.136407 15018 sgd_solver.cpp:138] Iteration 14640, lr = 0.0005
I1015 13:46:42.042078 15018 solver.cpp:243] Iteration 14660, loss = 2.40693
I1015 13:46:42.042117 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.01209 (* 1 = 2.01209 loss)
I1015 13:46:42.042127 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0805151 (* 1 = 0.0805151 loss)
I1015 13:46:42.042150 15018 sgd_solver.cpp:138] Iteration 14660, lr = 0.0005
I1015 13:46:54.057471 15018 solver.cpp:243] Iteration 14680, loss = 2.54391
I1015 13:46:54.057507 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.75936 (* 1 = 1.75936 loss)
I1015 13:46:54.057512 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0593513 (* 1 = 0.0593513 loss)
I1015 13:46:54.057518 15018 sgd_solver.cpp:138] Iteration 14680, lr = 0.0005
I1015 13:47:06.047284 15018 solver.cpp:243] Iteration 14700, loss = 2.59531
I1015 13:47:06.047319 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.81317 (* 1 = 1.81317 loss)
I1015 13:47:06.047325 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104945 (* 1 = 0.104945 loss)
I1015 13:47:06.047332 15018 sgd_solver.cpp:138] Iteration 14700, lr = 0.0005
I1015 13:47:17.873756 15018 solver.cpp:243] Iteration 14720, loss = 2.12128
I1015 13:47:17.873805 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.32676 (* 1 = 1.32676 loss)
I1015 13:47:17.873811 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0627439 (* 1 = 0.0627439 loss)
I1015 13:47:17.873816 15018 sgd_solver.cpp:138] Iteration 14720, lr = 0.0005
I1015 13:47:29.806684 15018 solver.cpp:243] Iteration 14740, loss = 2.503
I1015 13:47:29.806748 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.10204 (* 1 = 2.10204 loss)
I1015 13:47:29.806754 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0994354 (* 1 = 0.0994354 loss)
I1015 13:47:29.806761 15018 sgd_solver.cpp:138] Iteration 14740, lr = 0.0005
I1015 13:47:41.570747 15018 solver.cpp:243] Iteration 14760, loss = 2.18368
I1015 13:47:41.570796 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.3788 (* 1 = 2.3788 loss)
I1015 13:47:41.570801 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0734709 (* 1 = 0.0734709 loss)
I1015 13:47:41.570806 15018 sgd_solver.cpp:138] Iteration 14760, lr = 0.0005
I1015 13:47:53.125123 15018 solver.cpp:243] Iteration 14780, loss = 2.5406
I1015 13:47:53.125171 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.19655 (* 1 = 2.19655 loss)
I1015 13:47:53.125177 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0519954 (* 1 = 0.0519954 loss)
I1015 13:47:53.125183 15018 sgd_solver.cpp:138] Iteration 14780, lr = 0.0005
I1015 13:48:04.747524 15018 solver.cpp:243] Iteration 14800, loss = 1.93457
I1015 13:48:04.747575 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.52128 (* 1 = 2.52128 loss)
I1015 13:48:04.747581 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0462651 (* 1 = 0.0462651 loss)
I1015 13:48:04.747586 15018 sgd_solver.cpp:138] Iteration 14800, lr = 0.0005
I1015 13:48:16.860018 15018 solver.cpp:243] Iteration 14820, loss = 2.51759
I1015 13:48:16.860067 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.61792 (* 1 = 1.61792 loss)
I1015 13:48:16.860074 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.078243 (* 1 = 0.078243 loss)
I1015 13:48:16.860080 15018 sgd_solver.cpp:138] Iteration 14820, lr = 0.0005
I1015 13:48:28.941555 15018 solver.cpp:243] Iteration 14840, loss = 2.77721
I1015 13:48:28.941589 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.29596 (* 1 = 3.29596 loss)
I1015 13:48:28.941596 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0607326 (* 1 = 0.0607326 loss)
I1015 13:48:28.941601 15018 sgd_solver.cpp:138] Iteration 14840, lr = 0.0005
I1015 13:48:41.091223 15018 solver.cpp:243] Iteration 14860, loss = 3.88809
I1015 13:48:41.091256 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.74011 (* 1 = 3.74011 loss)
I1015 13:48:41.091264 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.255808 (* 1 = 0.255808 loss)
I1015 13:48:41.091269 15018 sgd_solver.cpp:138] Iteration 14860, lr = 0.0005
I1015 13:48:53.194527 15018 solver.cpp:243] Iteration 14880, loss = 3.19774
I1015 13:48:53.194576 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.21841 (* 1 = 3.21841 loss)
I1015 13:48:53.194581 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0597986 (* 1 = 0.0597986 loss)
I1015 13:48:53.194587 15018 sgd_solver.cpp:138] Iteration 14880, lr = 0.0005
I1015 13:49:05.065805 15018 solver.cpp:243] Iteration 14900, loss = 3.42754
I1015 13:49:05.065853 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.22684 (* 1 = 2.22684 loss)
I1015 13:49:05.065860 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.104283 (* 1 = 0.104283 loss)
I1015 13:49:05.065865 15018 sgd_solver.cpp:138] Iteration 14900, lr = 0.0005
I1015 13:49:17.005699 15018 solver.cpp:243] Iteration 14920, loss = 1.91722
I1015 13:49:17.005733 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.06802 (* 1 = 1.06802 loss)
I1015 13:49:17.005739 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0662729 (* 1 = 0.0662729 loss)
I1015 13:49:17.005744 15018 sgd_solver.cpp:138] Iteration 14920, lr = 0.0005
I1015 13:49:28.934823 15018 solver.cpp:243] Iteration 14940, loss = 1.97633
I1015 13:49:28.934855 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.21439 (* 1 = 2.21439 loss)
I1015 13:49:28.934861 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.079557 (* 1 = 0.079557 loss)
I1015 13:49:28.934867 15018 sgd_solver.cpp:138] Iteration 14940, lr = 0.0005
I1015 13:49:40.924562 15018 solver.cpp:243] Iteration 14960, loss = 2.56548
I1015 13:49:40.924597 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.01042 (* 1 = 3.01042 loss)
I1015 13:49:40.924602 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0765289 (* 1 = 0.0765289 loss)
I1015 13:49:40.924607 15018 sgd_solver.cpp:138] Iteration 14960, lr = 0.0005
I1015 13:49:52.858335 15018 solver.cpp:243] Iteration 14980, loss = 2.55467
I1015 13:49:52.858386 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.2412 (* 1 = 1.2412 loss)
I1015 13:49:52.858392 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0690788 (* 1 = 0.0690788 loss)
I1015 13:49:52.858397 15018 sgd_solver.cpp:138] Iteration 14980, lr = 0.0005
I1015 13:50:04.458793 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15000.caffemodel
I1015 13:50:05.208967 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15000.solverstate
I1015 13:50:05.411008 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 13:50:46.104530 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:51:43.944427 15018 solver.cpp:243] Iteration 15000, loss = 1.73629
I1015 13:51:43.944460 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.66576 (* 1 = 1.66576 loss)
I1015 13:51:43.944466 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0705352 (* 1 = 0.0705352 loss)
I1015 13:51:43.944473 15018 sgd_solver.cpp:138] Iteration 15000, lr = 0.0005
I1015 13:51:55.041563 15018 solver.cpp:243] Iteration 15020, loss = 2.78194
I1015 13:51:55.041595 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.95953 (* 1 = 1.95953 loss)
I1015 13:51:55.041601 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0860018 (* 1 = 0.0860018 loss)
I1015 13:51:55.041606 15018 sgd_solver.cpp:138] Iteration 15020, lr = 0.0005
I1015 13:52:07.220306 15018 solver.cpp:243] Iteration 15040, loss = 2.84329
I1015 13:52:07.220356 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.0436 (* 1 = 3.0436 loss)
I1015 13:52:07.220363 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0842558 (* 1 = 0.0842558 loss)
I1015 13:52:07.220368 15018 sgd_solver.cpp:138] Iteration 15040, lr = 0.0005
I1015 13:52:19.281826 15018 solver.cpp:243] Iteration 15060, loss = 1.8927
I1015 13:52:19.281875 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.08932 (* 1 = 2.08932 loss)
I1015 13:52:19.281883 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0692712 (* 1 = 0.0692712 loss)
I1015 13:52:19.281888 15018 sgd_solver.cpp:138] Iteration 15060, lr = 0.0005
I1015 13:52:31.353933 15018 solver.cpp:243] Iteration 15080, loss = 2.72883
I1015 13:52:31.353966 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.60399 (* 1 = 2.60399 loss)
I1015 13:52:31.353972 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0505331 (* 1 = 0.0505331 loss)
I1015 13:52:31.353978 15018 sgd_solver.cpp:138] Iteration 15080, lr = 0.0005
I1015 13:52:43.611670 15018 solver.cpp:243] Iteration 15100, loss = 1.56226
I1015 13:52:43.611706 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.07207 (* 1 = 1.07207 loss)
I1015 13:52:43.611711 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0543799 (* 1 = 0.0543799 loss)
I1015 13:52:43.611717 15018 sgd_solver.cpp:138] Iteration 15100, lr = 0.0005
I1015 13:52:55.583238 15018 solver.cpp:243] Iteration 15120, loss = 2.31359
I1015 13:52:55.583274 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.588127 (* 1 = 0.588127 loss)
I1015 13:52:55.583281 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0628113 (* 1 = 0.0628113 loss)
I1015 13:52:55.583287 15018 sgd_solver.cpp:138] Iteration 15120, lr = 0.0005
I1015 13:53:07.663058 15018 solver.cpp:243] Iteration 15140, loss = 2.40579
I1015 13:53:07.663111 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.25914 (* 1 = 2.25914 loss)
I1015 13:53:07.663117 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.076842 (* 1 = 0.076842 loss)
I1015 13:53:07.663123 15018 sgd_solver.cpp:138] Iteration 15140, lr = 0.0005
I1015 13:53:19.573925 15018 solver.cpp:243] Iteration 15160, loss = 2.8878
I1015 13:53:19.573976 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.46244 (* 1 = 3.46244 loss)
I1015 13:53:19.573982 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0775687 (* 1 = 0.0775687 loss)
I1015 13:53:19.573987 15018 sgd_solver.cpp:138] Iteration 15160, lr = 0.0005
I1015 13:53:31.396271 15018 solver.cpp:243] Iteration 15180, loss = 3.10194
I1015 13:53:31.396306 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.980532 (* 1 = 0.980532 loss)
I1015 13:53:31.396312 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0546853 (* 1 = 0.0546853 loss)
I1015 13:53:31.396317 15018 sgd_solver.cpp:138] Iteration 15180, lr = 0.0005
I1015 13:53:43.209847 15018 solver.cpp:243] Iteration 15200, loss = 2.59467
I1015 13:53:43.209882 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.96725 (* 1 = 1.96725 loss)
I1015 13:53:43.209887 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0762467 (* 1 = 0.0762467 loss)
I1015 13:53:43.209893 15018 sgd_solver.cpp:138] Iteration 15200, lr = 0.0005
I1015 13:53:55.154368 15018 solver.cpp:243] Iteration 15220, loss = 2.5774
I1015 13:53:55.154402 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.47174 (* 1 = 3.47174 loss)
I1015 13:53:55.154407 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0587286 (* 1 = 0.0587286 loss)
I1015 13:53:55.154413 15018 sgd_solver.cpp:138] Iteration 15220, lr = 0.0005
I1015 13:54:07.230011 15018 solver.cpp:243] Iteration 15240, loss = 2.5488
I1015 13:54:07.230062 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.75577 (* 1 = 1.75577 loss)
I1015 13:54:07.230068 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0673475 (* 1 = 0.0673475 loss)
I1015 13:54:07.230074 15018 sgd_solver.cpp:138] Iteration 15240, lr = 0.0005
I1015 13:54:19.047206 15018 solver.cpp:243] Iteration 15260, loss = 2.09095
I1015 13:54:19.047255 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.69368 (* 1 = 2.69368 loss)
I1015 13:54:19.047261 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0729478 (* 1 = 0.0729478 loss)
I1015 13:54:19.047267 15018 sgd_solver.cpp:138] Iteration 15260, lr = 0.0005
I1015 13:54:30.948326 15018 solver.cpp:243] Iteration 15280, loss = 2.53472
I1015 13:54:30.948374 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.53544 (* 1 = 2.53544 loss)
I1015 13:54:30.948380 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0853978 (* 1 = 0.0853978 loss)
I1015 13:54:30.948386 15018 sgd_solver.cpp:138] Iteration 15280, lr = 0.0005
I1015 13:54:42.647853 15018 solver.cpp:243] Iteration 15300, loss = 2.21106
I1015 13:54:42.647887 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.16653 (* 1 = 2.16653 loss)
I1015 13:54:42.647893 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0629534 (* 1 = 0.0629534 loss)
I1015 13:54:42.647898 15018 sgd_solver.cpp:138] Iteration 15300, lr = 0.0005
I1015 13:54:54.198848 15018 solver.cpp:243] Iteration 15320, loss = 2.44443
I1015 13:54:54.198896 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.59549 (* 1 = 2.59549 loss)
I1015 13:54:54.198902 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0563269 (* 1 = 0.0563269 loss)
I1015 13:54:54.198909 15018 sgd_solver.cpp:138] Iteration 15320, lr = 0.0005
I1015 13:55:05.779722 15018 solver.cpp:243] Iteration 15340, loss = 1.76325
I1015 13:55:05.779773 15018 solver.cpp:259]     Train net output #0: mbox_loss = 0.950729 (* 1 = 0.950729 loss)
I1015 13:55:05.779779 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0676239 (* 1 = 0.0676239 loss)
I1015 13:55:05.779785 15018 sgd_solver.cpp:138] Iteration 15340, lr = 0.0005
I1015 13:55:17.870893 15018 solver.cpp:243] Iteration 15360, loss = 2.69411
I1015 13:55:17.870944 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.75673 (* 1 = 4.75673 loss)
I1015 13:55:17.870949 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.184758 (* 1 = 0.184758 loss)
I1015 13:55:17.870955 15018 sgd_solver.cpp:138] Iteration 15360, lr = 0.0005
I1015 13:55:29.896651 15018 solver.cpp:243] Iteration 15380, loss = 2.53125
I1015 13:55:29.896685 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.70639 (* 1 = 2.70639 loss)
I1015 13:55:29.896692 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.069869 (* 1 = 0.069869 loss)
I1015 13:55:29.896697 15018 sgd_solver.cpp:138] Iteration 15380, lr = 0.0005
I1015 13:55:42.066866 15018 solver.cpp:243] Iteration 15400, loss = 3.92733
I1015 13:55:42.066916 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.91743 (* 1 = 4.91743 loss)
I1015 13:55:42.066922 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0719953 (* 1 = 0.0719953 loss)
I1015 13:55:42.066927 15018 sgd_solver.cpp:138] Iteration 15400, lr = 0.0005
I1015 13:55:54.149219 15018 solver.cpp:243] Iteration 15420, loss = 3.48407
I1015 13:55:54.149268 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.57665 (* 1 = 3.57665 loss)
I1015 13:55:54.149276 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0799522 (* 1 = 0.0799522 loss)
I1015 13:55:54.149281 15018 sgd_solver.cpp:138] Iteration 15420, lr = 0.0005
I1015 13:56:06.026286 15018 solver.cpp:243] Iteration 15440, loss = 3.28048
I1015 13:56:06.026335 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.07814 (* 1 = 2.07814 loss)
I1015 13:56:06.026341 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0993867 (* 1 = 0.0993867 loss)
I1015 13:56:06.026346 15018 sgd_solver.cpp:138] Iteration 15440, lr = 0.0005
I1015 13:56:17.985875 15018 solver.cpp:243] Iteration 15460, loss = 2.02712
I1015 13:56:17.985926 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.47391 (* 1 = 2.47391 loss)
I1015 13:56:17.985932 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0778928 (* 1 = 0.0778928 loss)
I1015 13:56:17.985939 15018 sgd_solver.cpp:138] Iteration 15460, lr = 0.0005
I1015 13:56:29.847797 15018 solver.cpp:243] Iteration 15480, loss = 2.03215
I1015 13:56:29.847846 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.02396 (* 1 = 1.02396 loss)
I1015 13:56:29.847853 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0842239 (* 1 = 0.0842239 loss)
I1015 13:56:29.847859 15018 sgd_solver.cpp:138] Iteration 15480, lr = 0.0005
I1015 13:56:41.355865 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15500.caffemodel
I1015 13:56:41.661535 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15500.solverstate
I1015 13:56:42.241668 15018 solver.cpp:243] Iteration 15500, loss = 2.15475
I1015 13:56:42.241710 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.09271 (* 1 = 2.09271 loss)
I1015 13:56:42.241717 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0791507 (* 1 = 0.0791507 loss)
I1015 13:56:42.241724 15018 sgd_solver.cpp:138] Iteration 15500, lr = 0.0005
I1015 13:56:53.985334 15018 solver.cpp:243] Iteration 15520, loss = 2.86115
I1015 13:56:53.985368 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.87251 (* 1 = 3.87251 loss)
I1015 13:56:53.985373 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0521561 (* 1 = 0.0521561 loss)
I1015 13:56:53.985379 15018 sgd_solver.cpp:138] Iteration 15520, lr = 0.0005
I1015 13:57:06.426884 15018 solver.cpp:243] Iteration 15540, loss = 2.66547
I1015 13:57:06.426932 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.78038 (* 1 = 2.78038 loss)
I1015 13:57:06.426939 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.172857 (* 1 = 0.172857 loss)
I1015 13:57:06.426944 15018 sgd_solver.cpp:138] Iteration 15540, lr = 0.0005
I1015 13:57:18.709415 15018 solver.cpp:243] Iteration 15560, loss = 2.62433
I1015 13:57:18.709447 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.3457 (* 1 = 3.3457 loss)
I1015 13:57:18.709453 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0707485 (* 1 = 0.0707485 loss)
I1015 13:57:18.709460 15018 sgd_solver.cpp:138] Iteration 15560, lr = 0.0005
I1015 13:57:30.935369 15018 solver.cpp:243] Iteration 15580, loss = 2.714
I1015 13:57:30.935402 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.53967 (* 1 = 2.53967 loss)
I1015 13:57:30.935408 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0668383 (* 1 = 0.0668383 loss)
I1015 13:57:30.935415 15018 sgd_solver.cpp:138] Iteration 15580, lr = 0.0005
I1015 13:57:43.286522 15018 solver.cpp:243] Iteration 15600, loss = 1.85204
I1015 13:57:43.286568 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.58996 (* 1 = 2.58996 loss)
I1015 13:57:43.286574 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.103406 (* 1 = 0.103406 loss)
I1015 13:57:43.286581 15018 sgd_solver.cpp:138] Iteration 15600, lr = 0.0005
I1015 13:57:55.462338 15018 solver.cpp:243] Iteration 15620, loss = 2.2816
I1015 13:57:55.462388 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.11444 (* 1 = 2.11444 loss)
I1015 13:57:55.462393 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0700473 (* 1 = 0.0700473 loss)
I1015 13:57:55.462400 15018 sgd_solver.cpp:138] Iteration 15620, lr = 0.0005
I1015 13:58:07.873651 15018 solver.cpp:243] Iteration 15640, loss = 1.55301
I1015 13:58:07.873713 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.64879 (* 1 = 1.64879 loss)
I1015 13:58:07.873719 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0759641 (* 1 = 0.0759641 loss)
I1015 13:58:07.873726 15018 sgd_solver.cpp:138] Iteration 15640, lr = 0.0005
I1015 13:58:20.347901 15018 solver.cpp:243] Iteration 15660, loss = 2.4333
I1015 13:58:20.347932 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.10142 (* 1 = 2.10142 loss)
I1015 13:58:20.347939 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0484447 (* 1 = 0.0484447 loss)
I1015 13:58:20.347945 15018 sgd_solver.cpp:138] Iteration 15660, lr = 0.0005
I1015 13:58:32.799191 15018 solver.cpp:243] Iteration 15680, loss = 2.1058
I1015 13:58:32.799226 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.33416 (* 1 = 3.33416 loss)
I1015 13:58:32.799232 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0940887 (* 1 = 0.0940887 loss)
I1015 13:58:32.799238 15018 sgd_solver.cpp:138] Iteration 15680, lr = 0.0005
I1015 13:58:45.081590 15018 solver.cpp:243] Iteration 15700, loss = 2.88852
I1015 13:58:45.081624 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.84826 (* 1 = 2.84826 loss)
I1015 13:58:45.081629 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.093348 (* 1 = 0.093348 loss)
I1015 13:58:45.081635 15018 sgd_solver.cpp:138] Iteration 15700, lr = 0.0005
I1015 13:58:56.244051 15018 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 13:58:57.362020 15018 solver.cpp:243] Iteration 15720, loss = 3.18265
I1015 13:58:57.362052 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.13168 (* 1 = 4.13168 loss)
I1015 13:58:57.362058 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0655525 (* 1 = 0.0655525 loss)
I1015 13:58:57.362064 15018 sgd_solver.cpp:138] Iteration 15720, lr = 0.0005
I1015 13:59:09.582970 15018 solver.cpp:243] Iteration 15740, loss = 2.77551
I1015 13:59:09.583004 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.27419 (* 1 = 3.27419 loss)
I1015 13:59:09.583011 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.066647 (* 1 = 0.066647 loss)
I1015 13:59:09.583019 15018 sgd_solver.cpp:138] Iteration 15740, lr = 0.0005
I1015 13:59:22.007486 15018 solver.cpp:243] Iteration 15760, loss = 2.62161
I1015 13:59:22.007536 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.51671 (* 1 = 1.51671 loss)
I1015 13:59:22.007544 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.06124 (* 1 = 0.06124 loss)
I1015 13:59:22.007549 15018 sgd_solver.cpp:138] Iteration 15760, lr = 0.0005
I1015 13:59:34.408751 15018 solver.cpp:243] Iteration 15780, loss = 2.66446
I1015 13:59:34.408783 15018 solver.cpp:259]     Train net output #0: mbox_loss = 4.40628 (* 1 = 4.40628 loss)
I1015 13:59:34.408790 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0674984 (* 1 = 0.0674984 loss)
I1015 13:59:34.408795 15018 sgd_solver.cpp:138] Iteration 15780, lr = 0.0005
I1015 13:59:46.676900 15018 solver.cpp:243] Iteration 15800, loss = 2.09402
I1015 13:59:46.676934 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.11572 (* 1 = 3.11572 loss)
I1015 13:59:46.676940 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0536611 (* 1 = 0.0536611 loss)
I1015 13:59:46.676945 15018 sgd_solver.cpp:138] Iteration 15800, lr = 0.0005
I1015 13:59:59.079382 15018 solver.cpp:243] Iteration 15820, loss = 2.35691
I1015 13:59:59.079416 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.42458 (* 1 = 1.42458 loss)
I1015 13:59:59.079423 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.055921 (* 1 = 0.055921 loss)
I1015 13:59:59.079429 15018 sgd_solver.cpp:138] Iteration 15820, lr = 0.0005
I1015 14:00:11.348592 15018 solver.cpp:243] Iteration 15840, loss = 2.38075
I1015 14:00:11.348644 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.47943 (* 1 = 2.47943 loss)
I1015 14:00:11.348650 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.207594 (* 1 = 0.207594 loss)
I1015 14:00:11.348656 15018 sgd_solver.cpp:138] Iteration 15840, lr = 0.0005
I1015 14:00:23.310636 15018 solver.cpp:243] Iteration 15860, loss = 2.21172
I1015 14:00:23.310683 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.86149 (* 1 = 1.86149 loss)
I1015 14:00:23.310689 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0588601 (* 1 = 0.0588601 loss)
I1015 14:00:23.310694 15018 sgd_solver.cpp:138] Iteration 15860, lr = 0.0005
I1015 14:00:35.252954 15018 solver.cpp:243] Iteration 15880, loss = 2.02992
I1015 14:00:35.252987 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.65177 (* 1 = 1.65177 loss)
I1015 14:00:35.252995 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0551909 (* 1 = 0.0551909 loss)
I1015 14:00:35.253000 15018 sgd_solver.cpp:138] Iteration 15880, lr = 0.0005
I1015 14:00:47.750370 15018 solver.cpp:243] Iteration 15900, loss = 2.46174
I1015 14:00:47.750417 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.27488 (* 1 = 2.27488 loss)
I1015 14:00:47.750423 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.142768 (* 1 = 0.142768 loss)
I1015 14:00:47.750429 15018 sgd_solver.cpp:138] Iteration 15900, lr = 0.0005
I1015 14:01:00.167440 15018 solver.cpp:243] Iteration 15920, loss = 2.53165
I1015 14:01:00.167490 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.20254 (* 1 = 2.20254 loss)
I1015 14:01:00.167496 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0600608 (* 1 = 0.0600608 loss)
I1015 14:01:00.167502 15018 sgd_solver.cpp:138] Iteration 15920, lr = 0.0005
I1015 14:01:12.806835 15018 solver.cpp:243] Iteration 15940, loss = 3.57794
I1015 14:01:12.806867 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.9789 (* 1 = 2.9789 loss)
I1015 14:01:12.806874 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0906512 (* 1 = 0.0906512 loss)
I1015 14:01:12.806880 15018 sgd_solver.cpp:138] Iteration 15940, lr = 0.0005
I1015 14:01:25.369549 15018 solver.cpp:243] Iteration 15960, loss = 3.45732
I1015 14:01:25.369585 15018 solver.cpp:259]     Train net output #0: mbox_loss = 2.40701 (* 1 = 2.40701 loss)
I1015 14:01:25.369590 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.295369 (* 1 = 0.295369 loss)
I1015 14:01:25.369596 15018 sgd_solver.cpp:138] Iteration 15960, lr = 0.0005
I1015 14:01:37.692852 15018 solver.cpp:243] Iteration 15980, loss = 3.31794
I1015 14:01:37.692885 15018 solver.cpp:259]     Train net output #0: mbox_loss = 3.67804 (* 1 = 3.67804 loss)
I1015 14:01:37.692893 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0554806 (* 1 = 0.0554806 loss)
I1015 14:01:37.692898 15018 sgd_solver.cpp:138] Iteration 15980, lr = 0.0005
I1015 14:01:49.463029 15018 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_16000.caffemodel
I1015 14:01:49.698479 15018 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_16000.solverstate
I1015 14:01:49.907995 15018 net.cpp:693] Ignoring source layer mbox_loss
I1015 14:03:30.444619 15018 solver.cpp:243] Iteration 16000, loss = 1.38899
I1015 14:03:30.444653 15018 solver.cpp:259]     Train net output #0: mbox_loss = 1.29807 (* 1 = 1.29807 loss)
I1015 14:03:30.444659 15018 solver.cpp:259]     Train net output #1: seg_loss = 0.0909164 (* 1 = 0.0909164 loss)
I1015 14:03:30.444665 15018 sgd_solver.cpp:138] Iteration 16000, lr = 0.0005
