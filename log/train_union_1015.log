WARNING: Logging before InitGoogleLogging() is written to STDERR
I1015 15:32:51.330018  4233 solver.cpp:63] Initializing solver from parameters: 
train_net: "proto/union/MobileNetSSD_train.prototxt"
test_net: "proto/union/MobileNetSSD_test.prototxt"
test_iter: 673
test_interval: 99999999
base_lr: 0.0005
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 500
snapshot_prefix: "snapshot/union/"
solver_mode: GPU
debug_info: false
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I1015 15:32:51.330634  4233 solver.cpp:96] Creating training net from train_net file: proto/union/MobileNetSSD_train.prototxt
I1015 15:32:51.333998  4233 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_train.prototxt
I1015 15:32:51.334029  4233 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 15:32:51.337074  4233 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_trainval_lmdb/"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_
I1015 15:32:51.338842  4233 layer_factory.hpp:77] Creating layer data
I1015 15:32:51.339093  4233 net.cpp:100] Creating Layer data
I1015 15:32:51.339120  4233 net.cpp:408] data -> data
I1015 15:32:51.339143  4233 net.cpp:408] data -> label
I1015 15:32:51.339159  4233 net.cpp:408] data -> label_seg
I1015 15:32:51.339174  4233 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1015 15:32:51.342962  4264 db_lmdb.cpp:35] Opened lmdb lmdb/seg_trainval_lmdb/
I1015 15:32:51.448809  4233 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 4,3,320,480
I1015 15:32:51.466537  4233 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1015 15:32:51.466601  4233 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1015 15:32:51.466606  4233 net.cpp:150] Setting up data
I1015 15:32:51.466615  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466620  4233 net.cpp:157] Top shape: 1 1 6 8 (48)
I1015 15:32:51.466624  4233 net.cpp:157] Top shape: 4 1 320 480 (614400)
I1015 15:32:51.466626  4233 net.cpp:165] Memory required for data: 9830592
I1015 15:32:51.466632  4233 layer_factory.hpp:77] Creating layer data_data_0_split
I1015 15:32:51.466646  4233 net.cpp:100] Creating Layer data_data_0_split
I1015 15:32:51.466650  4233 net.cpp:434] data_data_0_split <- data
I1015 15:32:51.466657  4233 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1015 15:32:51.466667  4233 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1015 15:32:51.466675  4233 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1015 15:32:51.466679  4233 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1015 15:32:51.466683  4233 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1015 15:32:51.466688  4233 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1015 15:32:51.466694  4233 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1015 15:32:51.466699  4233 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1015 15:32:51.466806  4233 net.cpp:150] Setting up data_data_0_split
I1015 15:32:51.466812  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466816  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466820  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466822  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466825  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466828  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466831  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466835  4233 net.cpp:157] Top shape: 4 3 320 480 (1843200)
I1015 15:32:51.466836  4233 net.cpp:165] Memory required for data: 68812992
I1015 15:32:51.466840  4233 layer_factory.hpp:77] Creating layer conv0
I1015 15:32:51.466856  4233 net.cpp:100] Creating Layer conv0
I1015 15:32:51.466858  4233 net.cpp:434] conv0 <- data_data_0_split_0
I1015 15:32:51.466863  4233 net.cpp:408] conv0 -> conv0
I1015 15:32:51.469179  4265 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1015 15:32:52.000320  4233 net.cpp:150] Setting up conv0
I1015 15:32:52.000344  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.000347  4233 net.cpp:165] Memory required for data: 88473792
I1015 15:32:52.000358  4233 layer_factory.hpp:77] Creating layer conv0/bn
I1015 15:32:52.000367  4233 net.cpp:100] Creating Layer conv0/bn
I1015 15:32:52.000371  4233 net.cpp:434] conv0/bn <- conv0
I1015 15:32:52.000376  4233 net.cpp:395] conv0/bn -> conv0 (in-place)
I1015 15:32:52.001324  4233 net.cpp:150] Setting up conv0/bn
I1015 15:32:52.001336  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.001338  4233 net.cpp:165] Memory required for data: 108134592
I1015 15:32:52.001348  4233 layer_factory.hpp:77] Creating layer conv0/scale
I1015 15:32:52.001358  4233 net.cpp:100] Creating Layer conv0/scale
I1015 15:32:52.001360  4233 net.cpp:434] conv0/scale <- conv0
I1015 15:32:52.001364  4233 net.cpp:395] conv0/scale -> conv0 (in-place)
I1015 15:32:52.001400  4233 layer_factory.hpp:77] Creating layer conv0/scale
I1015 15:32:52.001519  4233 net.cpp:150] Setting up conv0/scale
I1015 15:32:52.001525  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.001528  4233 net.cpp:165] Memory required for data: 127795392
I1015 15:32:52.001533  4233 layer_factory.hpp:77] Creating layer conv0/relu
I1015 15:32:52.001538  4233 net.cpp:100] Creating Layer conv0/relu
I1015 15:32:52.001540  4233 net.cpp:434] conv0/relu <- conv0
I1015 15:32:52.001544  4233 net.cpp:395] conv0/relu -> conv0 (in-place)
I1015 15:32:52.001864  4233 net.cpp:150] Setting up conv0/relu
I1015 15:32:52.001874  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.001876  4233 net.cpp:165] Memory required for data: 147456192
I1015 15:32:52.001879  4233 layer_factory.hpp:77] Creating layer conv1/dw
I1015 15:32:52.001888  4233 net.cpp:100] Creating Layer conv1/dw
I1015 15:32:52.001890  4233 net.cpp:434] conv1/dw <- conv0
I1015 15:32:52.001895  4233 net.cpp:408] conv1/dw -> conv1/dw
I1015 15:32:52.002055  4233 net.cpp:150] Setting up conv1/dw
I1015 15:32:52.002063  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.002065  4233 net.cpp:165] Memory required for data: 167116992
I1015 15:32:52.002069  4233 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1015 15:32:52.002074  4233 net.cpp:100] Creating Layer conv1/dw/bn
I1015 15:32:52.002075  4233 net.cpp:434] conv1/dw/bn <- conv1/dw
I1015 15:32:52.002079  4233 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1015 15:32:52.002238  4233 net.cpp:150] Setting up conv1/dw/bn
I1015 15:32:52.002245  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.002248  4233 net.cpp:165] Memory required for data: 186777792
I1015 15:32:52.002255  4233 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 15:32:52.002261  4233 net.cpp:100] Creating Layer conv1/dw/scale
I1015 15:32:52.002264  4233 net.cpp:434] conv1/dw/scale <- conv1/dw
I1015 15:32:52.002267  4233 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1015 15:32:52.002297  4233 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 15:32:52.002411  4233 net.cpp:150] Setting up conv1/dw/scale
I1015 15:32:52.002418  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.002419  4233 net.cpp:165] Memory required for data: 206438592
I1015 15:32:52.002424  4233 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1015 15:32:52.002427  4233 net.cpp:100] Creating Layer conv1/dw/relu
I1015 15:32:52.002429  4233 net.cpp:434] conv1/dw/relu <- conv1/dw
I1015 15:32:52.002434  4233 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1015 15:32:52.002732  4233 net.cpp:150] Setting up conv1/dw/relu
I1015 15:32:52.002740  4233 net.cpp:157] Top shape: 4 32 160 240 (4915200)
I1015 15:32:52.002743  4233 net.cpp:165] Memory required for data: 226099392
I1015 15:32:52.002745  4233 layer_factory.hpp:77] Creating layer conv1
I1015 15:32:52.002751  4233 net.cpp:100] Creating Layer conv1
I1015 15:32:52.002754  4233 net.cpp:434] conv1 <- conv1/dw
I1015 15:32:52.002758  4233 net.cpp:408] conv1 -> conv1
I1015 15:32:52.004899  4233 net.cpp:150] Setting up conv1
I1015 15:32:52.004914  4233 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 15:32:52.004916  4233 net.cpp:165] Memory required for data: 265420992
I1015 15:32:52.004920  4233 layer_factory.hpp:77] Creating layer conv1/bn
I1015 15:32:52.004926  4233 net.cpp:100] Creating Layer conv1/bn
I1015 15:32:52.004930  4233 net.cpp:434] conv1/bn <- conv1
I1015 15:32:52.004933  4233 net.cpp:395] conv1/bn -> conv1 (in-place)
I1015 15:32:52.005134  4233 net.cpp:150] Setting up conv1/bn
I1015 15:32:52.005143  4233 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 15:32:52.005146  4233 net.cpp:165] Memory required for data: 304742592
I1015 15:32:52.005152  4233 layer_factory.hpp:77] Creating layer conv1/scale
I1015 15:32:52.005157  4233 net.cpp:100] Creating Layer conv1/scale
I1015 15:32:52.005161  4233 net.cpp:434] conv1/scale <- conv1
I1015 15:32:52.005164  4233 net.cpp:395] conv1/scale -> conv1 (in-place)
I1015 15:32:52.005197  4233 layer_factory.hpp:77] Creating layer conv1/scale
I1015 15:32:52.005321  4233 net.cpp:150] Setting up conv1/scale
I1015 15:32:52.005327  4233 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 15:32:52.005331  4233 net.cpp:165] Memory required for data: 344064192
I1015 15:32:52.005337  4233 layer_factory.hpp:77] Creating layer conv1/relu
I1015 15:32:52.005342  4233 net.cpp:100] Creating Layer conv1/relu
I1015 15:32:52.005344  4233 net.cpp:434] conv1/relu <- conv1
I1015 15:32:52.005348  4233 net.cpp:395] conv1/relu -> conv1 (in-place)
I1015 15:32:52.005934  4233 net.cpp:150] Setting up conv1/relu
I1015 15:32:52.005945  4233 net.cpp:157] Top shape: 4 64 160 240 (9830400)
I1015 15:32:52.005947  4233 net.cpp:165] Memory required for data: 383385792
I1015 15:32:52.005951  4233 layer_factory.hpp:77] Creating layer conv2/dw
I1015 15:32:52.005959  4233 net.cpp:100] Creating Layer conv2/dw
I1015 15:32:52.005961  4233 net.cpp:434] conv2/dw <- conv1
I1015 15:32:52.005965  4233 net.cpp:408] conv2/dw -> conv2/dw
I1015 15:32:52.006124  4233 net.cpp:150] Setting up conv2/dw
I1015 15:32:52.006132  4233 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 15:32:52.006135  4233 net.cpp:165] Memory required for data: 393216192
I1015 15:32:52.006139  4233 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1015 15:32:52.006144  4233 net.cpp:100] Creating Layer conv2/dw/bn
I1015 15:32:52.006146  4233 net.cpp:434] conv2/dw/bn <- conv2/dw
I1015 15:32:52.006150  4233 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1015 15:32:52.007045  4233 net.cpp:150] Setting up conv2/dw/bn
I1015 15:32:52.007056  4233 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 15:32:52.007059  4233 net.cpp:165] Memory required for data: 403046592
I1015 15:32:52.007066  4233 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 15:32:52.007073  4233 net.cpp:100] Creating Layer conv2/dw/scale
I1015 15:32:52.007076  4233 net.cpp:434] conv2/dw/scale <- conv2/dw
I1015 15:32:52.007081  4233 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1015 15:32:52.007115  4233 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 15:32:52.007203  4233 net.cpp:150] Setting up conv2/dw/scale
I1015 15:32:52.007210  4233 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 15:32:52.007211  4233 net.cpp:165] Memory required for data: 412876992
I1015 15:32:52.007215  4233 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1015 15:32:52.007220  4233 net.cpp:100] Creating Layer conv2/dw/relu
I1015 15:32:52.007222  4233 net.cpp:434] conv2/dw/relu <- conv2/dw
I1015 15:32:52.007225  4233 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1015 15:32:52.007529  4233 net.cpp:150] Setting up conv2/dw/relu
I1015 15:32:52.007537  4233 net.cpp:157] Top shape: 4 64 80 120 (2457600)
I1015 15:32:52.007541  4233 net.cpp:165] Memory required for data: 422707392
I1015 15:32:52.007544  4233 layer_factory.hpp:77] Creating layer conv2
I1015 15:32:52.007550  4233 net.cpp:100] Creating Layer conv2
I1015 15:32:52.007553  4233 net.cpp:434] conv2 <- conv2/dw
I1015 15:32:52.007557  4233 net.cpp:408] conv2 -> conv2
I1015 15:32:52.009254  4233 net.cpp:150] Setting up conv2
I1015 15:32:52.009266  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.009269  4233 net.cpp:165] Memory required for data: 442368192
I1015 15:32:52.009274  4233 layer_factory.hpp:77] Creating layer conv2/bn
I1015 15:32:52.009279  4233 net.cpp:100] Creating Layer conv2/bn
I1015 15:32:52.009281  4233 net.cpp:434] conv2/bn <- conv2
I1015 15:32:52.009285  4233 net.cpp:395] conv2/bn -> conv2 (in-place)
I1015 15:32:52.009435  4233 net.cpp:150] Setting up conv2/bn
I1015 15:32:52.009443  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.009445  4233 net.cpp:165] Memory required for data: 462028992
I1015 15:32:52.009450  4233 layer_factory.hpp:77] Creating layer conv2/scale
I1015 15:32:52.009456  4233 net.cpp:100] Creating Layer conv2/scale
I1015 15:32:52.009459  4233 net.cpp:434] conv2/scale <- conv2
I1015 15:32:52.009462  4233 net.cpp:395] conv2/scale -> conv2 (in-place)
I1015 15:32:52.009492  4233 layer_factory.hpp:77] Creating layer conv2/scale
I1015 15:32:52.009573  4233 net.cpp:150] Setting up conv2/scale
I1015 15:32:52.009578  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.009582  4233 net.cpp:165] Memory required for data: 481689792
I1015 15:32:52.009585  4233 layer_factory.hpp:77] Creating layer conv2/relu
I1015 15:32:52.009589  4233 net.cpp:100] Creating Layer conv2/relu
I1015 15:32:52.009591  4233 net.cpp:434] conv2/relu <- conv2
I1015 15:32:52.009595  4233 net.cpp:395] conv2/relu -> conv2 (in-place)
I1015 15:32:52.009908  4233 net.cpp:150] Setting up conv2/relu
I1015 15:32:52.009917  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.009920  4233 net.cpp:165] Memory required for data: 501350592
I1015 15:32:52.009922  4233 layer_factory.hpp:77] Creating layer conv3/dw
I1015 15:32:52.009929  4233 net.cpp:100] Creating Layer conv3/dw
I1015 15:32:52.009932  4233 net.cpp:434] conv3/dw <- conv2
I1015 15:32:52.009938  4233 net.cpp:408] conv3/dw -> conv3/dw
I1015 15:32:52.010098  4233 net.cpp:150] Setting up conv3/dw
I1015 15:32:52.010107  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.010109  4233 net.cpp:165] Memory required for data: 521011392
I1015 15:32:52.010113  4233 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1015 15:32:52.010118  4233 net.cpp:100] Creating Layer conv3/dw/bn
I1015 15:32:52.010119  4233 net.cpp:434] conv3/dw/bn <- conv3/dw
I1015 15:32:52.010123  4233 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1015 15:32:52.010260  4233 net.cpp:150] Setting up conv3/dw/bn
I1015 15:32:52.010264  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.010267  4233 net.cpp:165] Memory required for data: 540672192
I1015 15:32:52.010277  4233 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 15:32:52.010282  4233 net.cpp:100] Creating Layer conv3/dw/scale
I1015 15:32:52.010283  4233 net.cpp:434] conv3/dw/scale <- conv3/dw
I1015 15:32:52.010288  4233 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1015 15:32:52.010316  4233 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 15:32:52.010398  4233 net.cpp:150] Setting up conv3/dw/scale
I1015 15:32:52.010404  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.010406  4233 net.cpp:165] Memory required for data: 560332992
I1015 15:32:52.010411  4233 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1015 15:32:52.010414  4233 net.cpp:100] Creating Layer conv3/dw/relu
I1015 15:32:52.010416  4233 net.cpp:434] conv3/dw/relu <- conv3/dw
I1015 15:32:52.010419  4233 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1015 15:32:52.010996  4233 net.cpp:150] Setting up conv3/dw/relu
I1015 15:32:52.011008  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.011010  4233 net.cpp:165] Memory required for data: 579993792
I1015 15:32:52.011013  4233 layer_factory.hpp:77] Creating layer conv3
I1015 15:32:52.011020  4233 net.cpp:100] Creating Layer conv3
I1015 15:32:52.011023  4233 net.cpp:434] conv3 <- conv3/dw
I1015 15:32:52.011027  4233 net.cpp:408] conv3 -> conv3
I1015 15:32:52.012861  4233 net.cpp:150] Setting up conv3
I1015 15:32:52.012877  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.012881  4233 net.cpp:165] Memory required for data: 599654592
I1015 15:32:52.012888  4233 layer_factory.hpp:77] Creating layer conv3/bn
I1015 15:32:52.012897  4233 net.cpp:100] Creating Layer conv3/bn
I1015 15:32:52.012902  4233 net.cpp:434] conv3/bn <- conv3
I1015 15:32:52.012908  4233 net.cpp:395] conv3/bn -> conv3 (in-place)
I1015 15:32:52.013134  4233 net.cpp:150] Setting up conv3/bn
I1015 15:32:52.013144  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.013149  4233 net.cpp:165] Memory required for data: 619315392
I1015 15:32:52.013157  4233 layer_factory.hpp:77] Creating layer conv3/scale
I1015 15:32:52.013165  4233 net.cpp:100] Creating Layer conv3/scale
I1015 15:32:52.013170  4233 net.cpp:434] conv3/scale <- conv3
I1015 15:32:52.013176  4233 net.cpp:395] conv3/scale -> conv3 (in-place)
I1015 15:32:52.013223  4233 layer_factory.hpp:77] Creating layer conv3/scale
I1015 15:32:52.013358  4233 net.cpp:150] Setting up conv3/scale
I1015 15:32:52.013368  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.013373  4233 net.cpp:165] Memory required for data: 638976192
I1015 15:32:52.013381  4233 layer_factory.hpp:77] Creating layer conv3/relu
I1015 15:32:52.013386  4233 net.cpp:100] Creating Layer conv3/relu
I1015 15:32:52.013389  4233 net.cpp:434] conv3/relu <- conv3
I1015 15:32:52.013396  4233 net.cpp:395] conv3/relu -> conv3 (in-place)
I1015 15:32:52.013835  4233 net.cpp:150] Setting up conv3/relu
I1015 15:32:52.013855  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.013859  4233 net.cpp:165] Memory required for data: 658636992
I1015 15:32:52.013864  4233 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1015 15:32:52.013871  4233 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1015 15:32:52.013875  4233 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1015 15:32:52.013882  4233 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1015 15:32:52.013890  4233 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1015 15:32:52.013942  4233 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1015 15:32:52.013949  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.013954  4233 net.cpp:157] Top shape: 4 128 80 120 (4915200)
I1015 15:32:52.013958  4233 net.cpp:165] Memory required for data: 697958592
I1015 15:32:52.013962  4233 layer_factory.hpp:77] Creating layer conv4/dw
I1015 15:32:52.013973  4233 net.cpp:100] Creating Layer conv4/dw
I1015 15:32:52.013978  4233 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1015 15:32:52.013984  4233 net.cpp:408] conv4/dw -> conv4/dw
I1015 15:32:52.014220  4233 net.cpp:150] Setting up conv4/dw
I1015 15:32:52.014230  4233 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 15:32:52.014235  4233 net.cpp:165] Memory required for data: 702873792
I1015 15:32:52.014240  4233 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1015 15:32:52.014251  4233 net.cpp:100] Creating Layer conv4/dw/bn
I1015 15:32:52.014256  4233 net.cpp:434] conv4/dw/bn <- conv4/dw
I1015 15:32:52.014261  4233 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1015 15:32:52.014478  4233 net.cpp:150] Setting up conv4/dw/bn
I1015 15:32:52.014488  4233 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 15:32:52.014492  4233 net.cpp:165] Memory required for data: 707788992
I1015 15:32:52.014500  4233 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 15:32:52.014508  4233 net.cpp:100] Creating Layer conv4/dw/scale
I1015 15:32:52.014513  4233 net.cpp:434] conv4/dw/scale <- conv4/dw
I1015 15:32:52.014518  4233 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1015 15:32:52.014564  4233 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 15:32:52.014696  4233 net.cpp:150] Setting up conv4/dw/scale
I1015 15:32:52.014705  4233 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 15:32:52.014709  4233 net.cpp:165] Memory required for data: 712704192
I1015 15:32:52.014716  4233 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1015 15:32:52.014722  4233 net.cpp:100] Creating Layer conv4/dw/relu
I1015 15:32:52.014726  4233 net.cpp:434] conv4/dw/relu <- conv4/dw
I1015 15:32:52.014732  4233 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1015 15:32:52.015172  4233 net.cpp:150] Setting up conv4/dw/relu
I1015 15:32:52.015183  4233 net.cpp:157] Top shape: 4 128 40 60 (1228800)
I1015 15:32:52.015187  4233 net.cpp:165] Memory required for data: 717619392
I1015 15:32:52.015192  4233 layer_factory.hpp:77] Creating layer conv4
I1015 15:32:52.015202  4233 net.cpp:100] Creating Layer conv4
I1015 15:32:52.015205  4233 net.cpp:434] conv4 <- conv4/dw
I1015 15:32:52.015211  4233 net.cpp:408] conv4 -> conv4
I1015 15:32:52.017330  4233 net.cpp:150] Setting up conv4
I1015 15:32:52.017344  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.017347  4233 net.cpp:165] Memory required for data: 727449792
I1015 15:32:52.017352  4233 layer_factory.hpp:77] Creating layer conv4/bn
I1015 15:32:52.017357  4233 net.cpp:100] Creating Layer conv4/bn
I1015 15:32:52.017360  4233 net.cpp:434] conv4/bn <- conv4
I1015 15:32:52.017364  4233 net.cpp:395] conv4/bn -> conv4 (in-place)
I1015 15:32:52.017518  4233 net.cpp:150] Setting up conv4/bn
I1015 15:32:52.017522  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.017524  4233 net.cpp:165] Memory required for data: 737280192
I1015 15:32:52.017530  4233 layer_factory.hpp:77] Creating layer conv4/scale
I1015 15:32:52.017535  4233 net.cpp:100] Creating Layer conv4/scale
I1015 15:32:52.017539  4233 net.cpp:434] conv4/scale <- conv4
I1015 15:32:52.017541  4233 net.cpp:395] conv4/scale -> conv4 (in-place)
I1015 15:32:52.017573  4233 layer_factory.hpp:77] Creating layer conv4/scale
I1015 15:32:52.017658  4233 net.cpp:150] Setting up conv4/scale
I1015 15:32:52.017663  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.017665  4233 net.cpp:165] Memory required for data: 747110592
I1015 15:32:52.017670  4233 layer_factory.hpp:77] Creating layer conv4/relu
I1015 15:32:52.017674  4233 net.cpp:100] Creating Layer conv4/relu
I1015 15:32:52.017678  4233 net.cpp:434] conv4/relu <- conv4
I1015 15:32:52.017680  4233 net.cpp:395] conv4/relu -> conv4 (in-place)
I1015 15:32:52.017989  4233 net.cpp:150] Setting up conv4/relu
I1015 15:32:52.017998  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.018000  4233 net.cpp:165] Memory required for data: 756940992
I1015 15:32:52.018003  4233 layer_factory.hpp:77] Creating layer conv5/dw
I1015 15:32:52.018010  4233 net.cpp:100] Creating Layer conv5/dw
I1015 15:32:52.018013  4233 net.cpp:434] conv5/dw <- conv4
I1015 15:32:52.018018  4233 net.cpp:408] conv5/dw -> conv5/dw
I1015 15:32:52.018194  4233 net.cpp:150] Setting up conv5/dw
I1015 15:32:52.018203  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.018204  4233 net.cpp:165] Memory required for data: 766771392
I1015 15:32:52.018208  4233 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1015 15:32:52.018213  4233 net.cpp:100] Creating Layer conv5/dw/bn
I1015 15:32:52.018215  4233 net.cpp:434] conv5/dw/bn <- conv5/dw
I1015 15:32:52.018218  4233 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1015 15:32:52.018355  4233 net.cpp:150] Setting up conv5/dw/bn
I1015 15:32:52.018362  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.018363  4233 net.cpp:165] Memory required for data: 776601792
I1015 15:32:52.018368  4233 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 15:32:52.018373  4233 net.cpp:100] Creating Layer conv5/dw/scale
I1015 15:32:52.018375  4233 net.cpp:434] conv5/dw/scale <- conv5/dw
I1015 15:32:52.018379  4233 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1015 15:32:52.018409  4233 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 15:32:52.018489  4233 net.cpp:150] Setting up conv5/dw/scale
I1015 15:32:52.018496  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.018497  4233 net.cpp:165] Memory required for data: 786432192
I1015 15:32:52.018502  4233 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1015 15:32:52.018505  4233 net.cpp:100] Creating Layer conv5/dw/relu
I1015 15:32:52.018508  4233 net.cpp:434] conv5/dw/relu <- conv5/dw
I1015 15:32:52.018512  4233 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1015 15:32:52.019101  4233 net.cpp:150] Setting up conv5/dw/relu
I1015 15:32:52.019114  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.019115  4233 net.cpp:165] Memory required for data: 796262592
I1015 15:32:52.019119  4233 layer_factory.hpp:77] Creating layer conv5
I1015 15:32:52.019125  4233 net.cpp:100] Creating Layer conv5
I1015 15:32:52.019129  4233 net.cpp:434] conv5 <- conv5/dw
I1015 15:32:52.019132  4233 net.cpp:408] conv5 -> conv5
I1015 15:32:52.021028  4233 net.cpp:150] Setting up conv5
I1015 15:32:52.021039  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021042  4233 net.cpp:165] Memory required for data: 806092992
I1015 15:32:52.021046  4233 layer_factory.hpp:77] Creating layer conv5/bn
I1015 15:32:52.021051  4233 net.cpp:100] Creating Layer conv5/bn
I1015 15:32:52.021054  4233 net.cpp:434] conv5/bn <- conv5
I1015 15:32:52.021059  4233 net.cpp:395] conv5/bn -> conv5 (in-place)
I1015 15:32:52.021208  4233 net.cpp:150] Setting up conv5/bn
I1015 15:32:52.021214  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021216  4233 net.cpp:165] Memory required for data: 815923392
I1015 15:32:52.021221  4233 layer_factory.hpp:77] Creating layer conv5/scale
I1015 15:32:52.021227  4233 net.cpp:100] Creating Layer conv5/scale
I1015 15:32:52.021229  4233 net.cpp:434] conv5/scale <- conv5
I1015 15:32:52.021234  4233 net.cpp:395] conv5/scale -> conv5 (in-place)
I1015 15:32:52.021263  4233 layer_factory.hpp:77] Creating layer conv5/scale
I1015 15:32:52.021347  4233 net.cpp:150] Setting up conv5/scale
I1015 15:32:52.021351  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021353  4233 net.cpp:165] Memory required for data: 825753792
I1015 15:32:52.021364  4233 layer_factory.hpp:77] Creating layer conv5/relu
I1015 15:32:52.021368  4233 net.cpp:100] Creating Layer conv5/relu
I1015 15:32:52.021371  4233 net.cpp:434] conv5/relu <- conv5
I1015 15:32:52.021374  4233 net.cpp:395] conv5/relu -> conv5 (in-place)
I1015 15:32:52.021675  4233 net.cpp:150] Setting up conv5/relu
I1015 15:32:52.021687  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021690  4233 net.cpp:165] Memory required for data: 835584192
I1015 15:32:52.021694  4233 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1015 15:32:52.021701  4233 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1015 15:32:52.021705  4233 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1015 15:32:52.021711  4233 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1015 15:32:52.021718  4233 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1015 15:32:52.021765  4233 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1015 15:32:52.021773  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021776  4233 net.cpp:157] Top shape: 4 256 40 60 (2457600)
I1015 15:32:52.021778  4233 net.cpp:165] Memory required for data: 855244992
I1015 15:32:52.021780  4233 layer_factory.hpp:77] Creating layer conv6/dw
I1015 15:32:52.021787  4233 net.cpp:100] Creating Layer conv6/dw
I1015 15:32:52.021790  4233 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1015 15:32:52.021795  4233 net.cpp:408] conv6/dw -> conv6/dw
I1015 15:32:52.021975  4233 net.cpp:150] Setting up conv6/dw
I1015 15:32:52.021982  4233 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 15:32:52.021984  4233 net.cpp:165] Memory required for data: 857702592
I1015 15:32:52.021988  4233 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1015 15:32:52.021992  4233 net.cpp:100] Creating Layer conv6/dw/bn
I1015 15:32:52.021994  4233 net.cpp:434] conv6/dw/bn <- conv6/dw
I1015 15:32:52.021998  4233 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1015 15:32:52.022168  4233 net.cpp:150] Setting up conv6/dw/bn
I1015 15:32:52.022176  4233 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 15:32:52.022178  4233 net.cpp:165] Memory required for data: 860160192
I1015 15:32:52.022184  4233 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 15:32:52.022191  4233 net.cpp:100] Creating Layer conv6/dw/scale
I1015 15:32:52.022192  4233 net.cpp:434] conv6/dw/scale <- conv6/dw
I1015 15:32:52.022197  4233 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1015 15:32:52.022228  4233 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 15:32:52.022315  4233 net.cpp:150] Setting up conv6/dw/scale
I1015 15:32:52.022321  4233 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 15:32:52.022323  4233 net.cpp:165] Memory required for data: 862617792
I1015 15:32:52.022327  4233 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1015 15:32:52.022331  4233 net.cpp:100] Creating Layer conv6/dw/relu
I1015 15:32:52.022334  4233 net.cpp:434] conv6/dw/relu <- conv6/dw
I1015 15:32:52.022337  4233 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1015 15:32:52.022637  4233 net.cpp:150] Setting up conv6/dw/relu
I1015 15:32:52.022645  4233 net.cpp:157] Top shape: 4 256 20 30 (614400)
I1015 15:32:52.022647  4233 net.cpp:165] Memory required for data: 865075392
I1015 15:32:52.022650  4233 layer_factory.hpp:77] Creating layer conv6
I1015 15:32:52.022656  4233 net.cpp:100] Creating Layer conv6
I1015 15:32:52.022660  4233 net.cpp:434] conv6 <- conv6/dw
I1015 15:32:52.022663  4233 net.cpp:408] conv6 -> conv6
I1015 15:32:52.025928  4233 net.cpp:150] Setting up conv6
I1015 15:32:52.025944  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.025948  4233 net.cpp:165] Memory required for data: 869990592
I1015 15:32:52.025952  4233 layer_factory.hpp:77] Creating layer conv6/bn
I1015 15:32:52.025957  4233 net.cpp:100] Creating Layer conv6/bn
I1015 15:32:52.025960  4233 net.cpp:434] conv6/bn <- conv6
I1015 15:32:52.025965  4233 net.cpp:395] conv6/bn -> conv6 (in-place)
I1015 15:32:52.026129  4233 net.cpp:150] Setting up conv6/bn
I1015 15:32:52.026137  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.026140  4233 net.cpp:165] Memory required for data: 874905792
I1015 15:32:52.026145  4233 layer_factory.hpp:77] Creating layer conv6/scale
I1015 15:32:52.026150  4233 net.cpp:100] Creating Layer conv6/scale
I1015 15:32:52.026154  4233 net.cpp:434] conv6/scale <- conv6
I1015 15:32:52.026156  4233 net.cpp:395] conv6/scale -> conv6 (in-place)
I1015 15:32:52.026191  4233 layer_factory.hpp:77] Creating layer conv6/scale
I1015 15:32:52.026283  4233 net.cpp:150] Setting up conv6/scale
I1015 15:32:52.026288  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.026289  4233 net.cpp:165] Memory required for data: 879820992
I1015 15:32:52.026293  4233 layer_factory.hpp:77] Creating layer conv6/relu
I1015 15:32:52.026298  4233 net.cpp:100] Creating Layer conv6/relu
I1015 15:32:52.026300  4233 net.cpp:434] conv6/relu <- conv6
I1015 15:32:52.026304  4233 net.cpp:395] conv6/relu -> conv6 (in-place)
I1015 15:32:52.026976  4233 net.cpp:150] Setting up conv6/relu
I1015 15:32:52.026988  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.026990  4233 net.cpp:165] Memory required for data: 884736192
I1015 15:32:52.026993  4233 layer_factory.hpp:77] Creating layer conv7/dw
I1015 15:32:52.027001  4233 net.cpp:100] Creating Layer conv7/dw
I1015 15:32:52.027004  4233 net.cpp:434] conv7/dw <- conv6
I1015 15:32:52.027010  4233 net.cpp:408] conv7/dw -> conv7/dw
I1015 15:32:52.027218  4233 net.cpp:150] Setting up conv7/dw
I1015 15:32:52.027225  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.027227  4233 net.cpp:165] Memory required for data: 889651392
I1015 15:32:52.027230  4233 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1015 15:32:52.027235  4233 net.cpp:100] Creating Layer conv7/dw/bn
I1015 15:32:52.027237  4233 net.cpp:434] conv7/dw/bn <- conv7/dw
I1015 15:32:52.027242  4233 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1015 15:32:52.027410  4233 net.cpp:150] Setting up conv7/dw/bn
I1015 15:32:52.027416  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.027418  4233 net.cpp:165] Memory required for data: 894566592
I1015 15:32:52.027424  4233 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 15:32:52.027429  4233 net.cpp:100] Creating Layer conv7/dw/scale
I1015 15:32:52.027431  4233 net.cpp:434] conv7/dw/scale <- conv7/dw
I1015 15:32:52.027436  4233 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1015 15:32:52.027469  4233 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 15:32:52.027561  4233 net.cpp:150] Setting up conv7/dw/scale
I1015 15:32:52.027566  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.027568  4233 net.cpp:165] Memory required for data: 899481792
I1015 15:32:52.027573  4233 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1015 15:32:52.027576  4233 net.cpp:100] Creating Layer conv7/dw/relu
I1015 15:32:52.027580  4233 net.cpp:434] conv7/dw/relu <- conv7/dw
I1015 15:32:52.027582  4233 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1015 15:32:52.027959  4233 net.cpp:150] Setting up conv7/dw/relu
I1015 15:32:52.027971  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.027974  4233 net.cpp:165] Memory required for data: 904396992
I1015 15:32:52.027978  4233 layer_factory.hpp:77] Creating layer conv7
I1015 15:32:52.027989  4233 net.cpp:100] Creating Layer conv7
I1015 15:32:52.027993  4233 net.cpp:434] conv7 <- conv7/dw
I1015 15:32:52.028000  4233 net.cpp:408] conv7 -> conv7
I1015 15:32:52.031603  4233 net.cpp:150] Setting up conv7
I1015 15:32:52.031622  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.031626  4233 net.cpp:165] Memory required for data: 909312192
I1015 15:32:52.031633  4233 layer_factory.hpp:77] Creating layer conv7/bn
I1015 15:32:52.031641  4233 net.cpp:100] Creating Layer conv7/bn
I1015 15:32:52.031646  4233 net.cpp:434] conv7/bn <- conv7
I1015 15:32:52.031653  4233 net.cpp:395] conv7/bn -> conv7 (in-place)
I1015 15:32:52.031911  4233 net.cpp:150] Setting up conv7/bn
I1015 15:32:52.031921  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.031925  4233 net.cpp:165] Memory required for data: 914227392
I1015 15:32:52.031934  4233 layer_factory.hpp:77] Creating layer conv7/scale
I1015 15:32:52.031941  4233 net.cpp:100] Creating Layer conv7/scale
I1015 15:32:52.031945  4233 net.cpp:434] conv7/scale <- conv7
I1015 15:32:52.031953  4233 net.cpp:395] conv7/scale -> conv7 (in-place)
I1015 15:32:52.032007  4233 layer_factory.hpp:77] Creating layer conv7/scale
I1015 15:32:52.032160  4233 net.cpp:150] Setting up conv7/scale
I1015 15:32:52.032171  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.032174  4233 net.cpp:165] Memory required for data: 919142592
I1015 15:32:52.032181  4233 layer_factory.hpp:77] Creating layer conv7/relu
I1015 15:32:52.032187  4233 net.cpp:100] Creating Layer conv7/relu
I1015 15:32:52.032191  4233 net.cpp:434] conv7/relu <- conv7
I1015 15:32:52.032198  4233 net.cpp:395] conv7/relu -> conv7 (in-place)
I1015 15:32:52.032774  4233 net.cpp:150] Setting up conv7/relu
I1015 15:32:52.032788  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.032793  4233 net.cpp:165] Memory required for data: 924057792
I1015 15:32:52.032797  4233 layer_factory.hpp:77] Creating layer conv8/dw
I1015 15:32:52.032816  4233 net.cpp:100] Creating Layer conv8/dw
I1015 15:32:52.032821  4233 net.cpp:434] conv8/dw <- conv7
I1015 15:32:52.032829  4233 net.cpp:408] conv8/dw -> conv8/dw
I1015 15:32:52.033143  4233 net.cpp:150] Setting up conv8/dw
I1015 15:32:52.033154  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.033159  4233 net.cpp:165] Memory required for data: 928972992
I1015 15:32:52.033164  4233 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1015 15:32:52.033172  4233 net.cpp:100] Creating Layer conv8/dw/bn
I1015 15:32:52.033177  4233 net.cpp:434] conv8/dw/bn <- conv8/dw
I1015 15:32:52.033185  4233 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1015 15:32:52.033433  4233 net.cpp:150] Setting up conv8/dw/bn
I1015 15:32:52.033444  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.033447  4233 net.cpp:165] Memory required for data: 933888192
I1015 15:32:52.033457  4233 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 15:32:52.033465  4233 net.cpp:100] Creating Layer conv8/dw/scale
I1015 15:32:52.033469  4233 net.cpp:434] conv8/dw/scale <- conv8/dw
I1015 15:32:52.033475  4233 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1015 15:32:52.033527  4233 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 15:32:52.033674  4233 net.cpp:150] Setting up conv8/dw/scale
I1015 15:32:52.033682  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.033686  4233 net.cpp:165] Memory required for data: 938803392
I1015 15:32:52.033694  4233 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1015 15:32:52.033699  4233 net.cpp:100] Creating Layer conv8/dw/relu
I1015 15:32:52.033704  4233 net.cpp:434] conv8/dw/relu <- conv8/dw
I1015 15:32:52.033710  4233 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1015 15:32:52.034687  4233 net.cpp:150] Setting up conv8/dw/relu
I1015 15:32:52.034703  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.034708  4233 net.cpp:165] Memory required for data: 943718592
I1015 15:32:52.034713  4233 layer_factory.hpp:77] Creating layer conv8
I1015 15:32:52.034724  4233 net.cpp:100] Creating Layer conv8
I1015 15:32:52.034729  4233 net.cpp:434] conv8 <- conv8/dw
I1015 15:32:52.034737  4233 net.cpp:408] conv8 -> conv8
I1015 15:32:52.039925  4233 net.cpp:150] Setting up conv8
I1015 15:32:52.039947  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.039949  4233 net.cpp:165] Memory required for data: 948633792
I1015 15:32:52.039955  4233 layer_factory.hpp:77] Creating layer conv8/bn
I1015 15:32:52.039963  4233 net.cpp:100] Creating Layer conv8/bn
I1015 15:32:52.039968  4233 net.cpp:434] conv8/bn <- conv8
I1015 15:32:52.039973  4233 net.cpp:395] conv8/bn -> conv8 (in-place)
I1015 15:32:52.040146  4233 net.cpp:150] Setting up conv8/bn
I1015 15:32:52.040154  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.040158  4233 net.cpp:165] Memory required for data: 953548992
I1015 15:32:52.040163  4233 layer_factory.hpp:77] Creating layer conv8/scale
I1015 15:32:52.040169  4233 net.cpp:100] Creating Layer conv8/scale
I1015 15:32:52.040174  4233 net.cpp:434] conv8/scale <- conv8
I1015 15:32:52.040179  4233 net.cpp:395] conv8/scale -> conv8 (in-place)
I1015 15:32:52.040218  4233 layer_factory.hpp:77] Creating layer conv8/scale
I1015 15:32:52.040323  4233 net.cpp:150] Setting up conv8/scale
I1015 15:32:52.040329  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.040333  4233 net.cpp:165] Memory required for data: 958464192
I1015 15:32:52.040336  4233 layer_factory.hpp:77] Creating layer conv8/relu
I1015 15:32:52.040343  4233 net.cpp:100] Creating Layer conv8/relu
I1015 15:32:52.040345  4233 net.cpp:434] conv8/relu <- conv8
I1015 15:32:52.040350  4233 net.cpp:395] conv8/relu -> conv8 (in-place)
I1015 15:32:52.040715  4233 net.cpp:150] Setting up conv8/relu
I1015 15:32:52.040724  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.040727  4233 net.cpp:165] Memory required for data: 963379392
I1015 15:32:52.040730  4233 layer_factory.hpp:77] Creating layer conv9/dw
I1015 15:32:52.040738  4233 net.cpp:100] Creating Layer conv9/dw
I1015 15:32:52.040741  4233 net.cpp:434] conv9/dw <- conv8
I1015 15:32:52.040746  4233 net.cpp:408] conv9/dw -> conv9/dw
I1015 15:32:52.040969  4233 net.cpp:150] Setting up conv9/dw
I1015 15:32:52.040977  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.040980  4233 net.cpp:165] Memory required for data: 968294592
I1015 15:32:52.040983  4233 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1015 15:32:52.040987  4233 net.cpp:100] Creating Layer conv9/dw/bn
I1015 15:32:52.040990  4233 net.cpp:434] conv9/dw/bn <- conv9/dw
I1015 15:32:52.040993  4233 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1015 15:32:52.041159  4233 net.cpp:150] Setting up conv9/dw/bn
I1015 15:32:52.041167  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.041168  4233 net.cpp:165] Memory required for data: 973209792
I1015 15:32:52.041174  4233 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 15:32:52.041178  4233 net.cpp:100] Creating Layer conv9/dw/scale
I1015 15:32:52.041182  4233 net.cpp:434] conv9/dw/scale <- conv9/dw
I1015 15:32:52.041184  4233 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1015 15:32:52.041220  4233 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 15:32:52.041318  4233 net.cpp:150] Setting up conv9/dw/scale
I1015 15:32:52.041326  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.041328  4233 net.cpp:165] Memory required for data: 978124992
I1015 15:32:52.041332  4233 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1015 15:32:52.041337  4233 net.cpp:100] Creating Layer conv9/dw/relu
I1015 15:32:52.041338  4233 net.cpp:434] conv9/dw/relu <- conv9/dw
I1015 15:32:52.041342  4233 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1015 15:32:52.041697  4233 net.cpp:150] Setting up conv9/dw/relu
I1015 15:32:52.041707  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.041709  4233 net.cpp:165] Memory required for data: 983040192
I1015 15:32:52.041712  4233 layer_factory.hpp:77] Creating layer conv9
I1015 15:32:52.041718  4233 net.cpp:100] Creating Layer conv9
I1015 15:32:52.041721  4233 net.cpp:434] conv9 <- conv9/dw
I1015 15:32:52.041725  4233 net.cpp:408] conv9 -> conv9
I1015 15:32:52.045344  4233 net.cpp:150] Setting up conv9
I1015 15:32:52.045358  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.045361  4233 net.cpp:165] Memory required for data: 987955392
I1015 15:32:52.045367  4233 layer_factory.hpp:77] Creating layer conv9/bn
I1015 15:32:52.045370  4233 net.cpp:100] Creating Layer conv9/bn
I1015 15:32:52.045373  4233 net.cpp:434] conv9/bn <- conv9
I1015 15:32:52.045379  4233 net.cpp:395] conv9/bn -> conv9 (in-place)
I1015 15:32:52.045572  4233 net.cpp:150] Setting up conv9/bn
I1015 15:32:52.045583  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.045586  4233 net.cpp:165] Memory required for data: 992870592
I1015 15:32:52.045593  4233 layer_factory.hpp:77] Creating layer conv9/scale
I1015 15:32:52.045599  4233 net.cpp:100] Creating Layer conv9/scale
I1015 15:32:52.045603  4233 net.cpp:434] conv9/scale <- conv9
I1015 15:32:52.045605  4233 net.cpp:395] conv9/scale -> conv9 (in-place)
I1015 15:32:52.045650  4233 layer_factory.hpp:77] Creating layer conv9/scale
I1015 15:32:52.045768  4233 net.cpp:150] Setting up conv9/scale
I1015 15:32:52.045776  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.045779  4233 net.cpp:165] Memory required for data: 997785792
I1015 15:32:52.045786  4233 layer_factory.hpp:77] Creating layer conv9/relu
I1015 15:32:52.045791  4233 net.cpp:100] Creating Layer conv9/relu
I1015 15:32:52.045795  4233 net.cpp:434] conv9/relu <- conv9
I1015 15:32:52.045800  4233 net.cpp:395] conv9/relu -> conv9 (in-place)
I1015 15:32:52.046255  4233 net.cpp:150] Setting up conv9/relu
I1015 15:32:52.046268  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.046270  4233 net.cpp:165] Memory required for data: 1002700992
I1015 15:32:52.046273  4233 layer_factory.hpp:77] Creating layer conv10/dw
I1015 15:32:52.046280  4233 net.cpp:100] Creating Layer conv10/dw
I1015 15:32:52.046283  4233 net.cpp:434] conv10/dw <- conv9
I1015 15:32:52.046289  4233 net.cpp:408] conv10/dw -> conv10/dw
I1015 15:32:52.046504  4233 net.cpp:150] Setting up conv10/dw
I1015 15:32:52.046511  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.046514  4233 net.cpp:165] Memory required for data: 1007616192
I1015 15:32:52.046517  4233 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1015 15:32:52.046521  4233 net.cpp:100] Creating Layer conv10/dw/bn
I1015 15:32:52.046524  4233 net.cpp:434] conv10/dw/bn <- conv10/dw
I1015 15:32:52.046527  4233 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1015 15:32:52.046684  4233 net.cpp:150] Setting up conv10/dw/bn
I1015 15:32:52.046690  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.046692  4233 net.cpp:165] Memory required for data: 1012531392
I1015 15:32:52.046699  4233 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 15:32:52.046702  4233 net.cpp:100] Creating Layer conv10/dw/scale
I1015 15:32:52.046705  4233 net.cpp:434] conv10/dw/scale <- conv10/dw
I1015 15:32:52.046708  4233 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1015 15:32:52.046744  4233 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 15:32:52.046835  4233 net.cpp:150] Setting up conv10/dw/scale
I1015 15:32:52.046840  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.046842  4233 net.cpp:165] Memory required for data: 1017446592
I1015 15:32:52.046846  4233 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1015 15:32:52.046850  4233 net.cpp:100] Creating Layer conv10/dw/relu
I1015 15:32:52.046852  4233 net.cpp:434] conv10/dw/relu <- conv10/dw
I1015 15:32:52.046856  4233 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1015 15:32:52.047536  4233 net.cpp:150] Setting up conv10/dw/relu
I1015 15:32:52.047549  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.047550  4233 net.cpp:165] Memory required for data: 1022361792
I1015 15:32:52.047554  4233 layer_factory.hpp:77] Creating layer conv10
I1015 15:32:52.047561  4233 net.cpp:100] Creating Layer conv10
I1015 15:32:52.047564  4233 net.cpp:434] conv10 <- conv10/dw
I1015 15:32:52.047569  4233 net.cpp:408] conv10 -> conv10
I1015 15:32:52.052230  4233 net.cpp:150] Setting up conv10
I1015 15:32:52.052256  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.052260  4233 net.cpp:165] Memory required for data: 1027276992
I1015 15:32:52.052270  4233 layer_factory.hpp:77] Creating layer conv10/bn
I1015 15:32:52.052283  4233 net.cpp:100] Creating Layer conv10/bn
I1015 15:32:52.052289  4233 net.cpp:434] conv10/bn <- conv10
I1015 15:32:52.052296  4233 net.cpp:395] conv10/bn -> conv10 (in-place)
I1015 15:32:52.052568  4233 net.cpp:150] Setting up conv10/bn
I1015 15:32:52.052578  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.052583  4233 net.cpp:165] Memory required for data: 1032192192
I1015 15:32:52.052592  4233 layer_factory.hpp:77] Creating layer conv10/scale
I1015 15:32:52.052601  4233 net.cpp:100] Creating Layer conv10/scale
I1015 15:32:52.052606  4233 net.cpp:434] conv10/scale <- conv10
I1015 15:32:52.052613  4233 net.cpp:395] conv10/scale -> conv10 (in-place)
I1015 15:32:52.052672  4233 layer_factory.hpp:77] Creating layer conv10/scale
I1015 15:32:52.052824  4233 net.cpp:150] Setting up conv10/scale
I1015 15:32:52.052835  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.052839  4233 net.cpp:165] Memory required for data: 1037107392
I1015 15:32:52.052846  4233 layer_factory.hpp:77] Creating layer conv10/relu
I1015 15:32:52.052855  4233 net.cpp:100] Creating Layer conv10/relu
I1015 15:32:52.052860  4233 net.cpp:434] conv10/relu <- conv10
I1015 15:32:52.052865  4233 net.cpp:395] conv10/relu -> conv10 (in-place)
I1015 15:32:52.053414  4233 net.cpp:150] Setting up conv10/relu
I1015 15:32:52.053428  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.053432  4233 net.cpp:165] Memory required for data: 1042022592
I1015 15:32:52.053437  4233 layer_factory.hpp:77] Creating layer conv11/dw
I1015 15:32:52.053458  4233 net.cpp:100] Creating Layer conv11/dw
I1015 15:32:52.053463  4233 net.cpp:434] conv11/dw <- conv10
I1015 15:32:52.053472  4233 net.cpp:408] conv11/dw -> conv11/dw
I1015 15:32:52.053805  4233 net.cpp:150] Setting up conv11/dw
I1015 15:32:52.053817  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.053828  4233 net.cpp:165] Memory required for data: 1046937792
I1015 15:32:52.053835  4233 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1015 15:32:52.053843  4233 net.cpp:100] Creating Layer conv11/dw/bn
I1015 15:32:52.053846  4233 net.cpp:434] conv11/dw/bn <- conv11/dw
I1015 15:32:52.053853  4233 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1015 15:32:52.054112  4233 net.cpp:150] Setting up conv11/dw/bn
I1015 15:32:52.054122  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.054126  4233 net.cpp:165] Memory required for data: 1051852992
I1015 15:32:52.054149  4233 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 15:32:52.054157  4233 net.cpp:100] Creating Layer conv11/dw/scale
I1015 15:32:52.054162  4233 net.cpp:434] conv11/dw/scale <- conv11/dw
I1015 15:32:52.054168  4233 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1015 15:32:52.054220  4233 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 15:32:52.054368  4233 net.cpp:150] Setting up conv11/dw/scale
I1015 15:32:52.054378  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.054383  4233 net.cpp:165] Memory required for data: 1056768192
I1015 15:32:52.054389  4233 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1015 15:32:52.054395  4233 net.cpp:100] Creating Layer conv11/dw/relu
I1015 15:32:52.054399  4233 net.cpp:434] conv11/dw/relu <- conv11/dw
I1015 15:32:52.054406  4233 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1015 15:32:52.054934  4233 net.cpp:150] Setting up conv11/dw/relu
I1015 15:32:52.054947  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.054951  4233 net.cpp:165] Memory required for data: 1061683392
I1015 15:32:52.054955  4233 layer_factory.hpp:77] Creating layer conv11
I1015 15:32:52.054965  4233 net.cpp:100] Creating Layer conv11
I1015 15:32:52.054971  4233 net.cpp:434] conv11 <- conv11/dw
I1015 15:32:52.054978  4233 net.cpp:408] conv11 -> conv11
I1015 15:32:52.059720  4233 net.cpp:150] Setting up conv11
I1015 15:32:52.059737  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.059741  4233 net.cpp:165] Memory required for data: 1066598592
I1015 15:32:52.059746  4233 layer_factory.hpp:77] Creating layer conv11/bn
I1015 15:32:52.059751  4233 net.cpp:100] Creating Layer conv11/bn
I1015 15:32:52.059754  4233 net.cpp:434] conv11/bn <- conv11
I1015 15:32:52.059759  4233 net.cpp:395] conv11/bn -> conv11 (in-place)
I1015 15:32:52.059940  4233 net.cpp:150] Setting up conv11/bn
I1015 15:32:52.059947  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.059958  4233 net.cpp:165] Memory required for data: 1071513792
I1015 15:32:52.059964  4233 layer_factory.hpp:77] Creating layer conv11/scale
I1015 15:32:52.059970  4233 net.cpp:100] Creating Layer conv11/scale
I1015 15:32:52.059973  4233 net.cpp:434] conv11/scale <- conv11
I1015 15:32:52.059976  4233 net.cpp:395] conv11/scale -> conv11 (in-place)
I1015 15:32:52.060014  4233 layer_factory.hpp:77] Creating layer conv11/scale
I1015 15:32:52.060111  4233 net.cpp:150] Setting up conv11/scale
I1015 15:32:52.060117  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.060118  4233 net.cpp:165] Memory required for data: 1076428992
I1015 15:32:52.060122  4233 layer_factory.hpp:77] Creating layer conv11/relu
I1015 15:32:52.060127  4233 net.cpp:100] Creating Layer conv11/relu
I1015 15:32:52.060129  4233 net.cpp:434] conv11/relu <- conv11
I1015 15:32:52.060133  4233 net.cpp:395] conv11/relu -> conv11 (in-place)
I1015 15:32:52.060860  4233 net.cpp:150] Setting up conv11/relu
I1015 15:32:52.060873  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.060874  4233 net.cpp:165] Memory required for data: 1081344192
I1015 15:32:52.060878  4233 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1015 15:32:52.060884  4233 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1015 15:32:52.060887  4233 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1015 15:32:52.060894  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1015 15:32:52.060899  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1015 15:32:52.060904  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1015 15:32:52.060909  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1015 15:32:52.060914  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1015 15:32:52.060987  4233 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1015 15:32:52.060992  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.060995  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.060997  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.061000  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.061003  4233 net.cpp:157] Top shape: 4 512 20 30 (1228800)
I1015 15:32:52.061005  4233 net.cpp:165] Memory required for data: 1105920192
I1015 15:32:52.061007  4233 layer_factory.hpp:77] Creating layer conv12/dw
I1015 15:32:52.061015  4233 net.cpp:100] Creating Layer conv12/dw
I1015 15:32:52.061018  4233 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1015 15:32:52.061024  4233 net.cpp:408] conv12/dw -> conv12/dw
I1015 15:32:52.061223  4233 net.cpp:150] Setting up conv12/dw
I1015 15:32:52.061230  4233 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 15:32:52.061233  4233 net.cpp:165] Memory required for data: 1107148992
I1015 15:32:52.061236  4233 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1015 15:32:52.061241  4233 net.cpp:100] Creating Layer conv12/dw/bn
I1015 15:32:52.061244  4233 net.cpp:434] conv12/dw/bn <- conv12/dw
I1015 15:32:52.061247  4233 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1015 15:32:52.061412  4233 net.cpp:150] Setting up conv12/dw/bn
I1015 15:32:52.061419  4233 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 15:32:52.061420  4233 net.cpp:165] Memory required for data: 1108377792
I1015 15:32:52.061425  4233 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 15:32:52.061431  4233 net.cpp:100] Creating Layer conv12/dw/scale
I1015 15:32:52.061434  4233 net.cpp:434] conv12/dw/scale <- conv12/dw
I1015 15:32:52.061437  4233 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1015 15:32:52.061468  4233 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 15:32:52.061566  4233 net.cpp:150] Setting up conv12/dw/scale
I1015 15:32:52.061573  4233 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 15:32:52.061575  4233 net.cpp:165] Memory required for data: 1109606592
I1015 15:32:52.061579  4233 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1015 15:32:52.061583  4233 net.cpp:100] Creating Layer conv12/dw/relu
I1015 15:32:52.061585  4233 net.cpp:434] conv12/dw/relu <- conv12/dw
I1015 15:32:52.061590  4233 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1015 15:32:52.061947  4233 net.cpp:150] Setting up conv12/dw/relu
I1015 15:32:52.061957  4233 net.cpp:157] Top shape: 4 512 10 15 (307200)
I1015 15:32:52.061959  4233 net.cpp:165] Memory required for data: 1110835392
I1015 15:32:52.061962  4233 layer_factory.hpp:77] Creating layer conv12
I1015 15:32:52.061969  4233 net.cpp:100] Creating Layer conv12
I1015 15:32:52.061972  4233 net.cpp:434] conv12 <- conv12/dw
I1015 15:32:52.061977  4233 net.cpp:408] conv12 -> conv12
I1015 15:32:52.068558  4233 net.cpp:150] Setting up conv12
I1015 15:32:52.068575  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.068578  4233 net.cpp:165] Memory required for data: 1113292992
I1015 15:32:52.068583  4233 layer_factory.hpp:77] Creating layer conv12/bn
I1015 15:32:52.068589  4233 net.cpp:100] Creating Layer conv12/bn
I1015 15:32:52.068593  4233 net.cpp:434] conv12/bn <- conv12
I1015 15:32:52.068598  4233 net.cpp:395] conv12/bn -> conv12 (in-place)
I1015 15:32:52.068785  4233 net.cpp:150] Setting up conv12/bn
I1015 15:32:52.068794  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.068796  4233 net.cpp:165] Memory required for data: 1115750592
I1015 15:32:52.068801  4233 layer_factory.hpp:77] Creating layer conv12/scale
I1015 15:32:52.068809  4233 net.cpp:100] Creating Layer conv12/scale
I1015 15:32:52.068811  4233 net.cpp:434] conv12/scale <- conv12
I1015 15:32:52.068814  4233 net.cpp:395] conv12/scale -> conv12 (in-place)
I1015 15:32:52.068850  4233 layer_factory.hpp:77] Creating layer conv12/scale
I1015 15:32:52.068961  4233 net.cpp:150] Setting up conv12/scale
I1015 15:32:52.068969  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.068970  4233 net.cpp:165] Memory required for data: 1118208192
I1015 15:32:52.068975  4233 layer_factory.hpp:77] Creating layer conv12/relu
I1015 15:32:52.068979  4233 net.cpp:100] Creating Layer conv12/relu
I1015 15:32:52.068982  4233 net.cpp:434] conv12/relu <- conv12
I1015 15:32:52.068986  4233 net.cpp:395] conv12/relu -> conv12 (in-place)
I1015 15:32:52.069347  4233 net.cpp:150] Setting up conv12/relu
I1015 15:32:52.069357  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.069360  4233 net.cpp:165] Memory required for data: 1120665792
I1015 15:32:52.069362  4233 layer_factory.hpp:77] Creating layer conv13/dw
I1015 15:32:52.069372  4233 net.cpp:100] Creating Layer conv13/dw
I1015 15:32:52.069375  4233 net.cpp:434] conv13/dw <- conv12
I1015 15:32:52.069381  4233 net.cpp:408] conv13/dw -> conv13/dw
I1015 15:32:52.069638  4233 net.cpp:150] Setting up conv13/dw
I1015 15:32:52.069645  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.069648  4233 net.cpp:165] Memory required for data: 1123123392
I1015 15:32:52.069650  4233 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1015 15:32:52.069656  4233 net.cpp:100] Creating Layer conv13/dw/bn
I1015 15:32:52.069659  4233 net.cpp:434] conv13/dw/bn <- conv13/dw
I1015 15:32:52.069664  4233 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1015 15:32:52.069839  4233 net.cpp:150] Setting up conv13/dw/bn
I1015 15:32:52.069846  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.069849  4233 net.cpp:165] Memory required for data: 1125580992
I1015 15:32:52.069855  4233 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 15:32:52.069862  4233 net.cpp:100] Creating Layer conv13/dw/scale
I1015 15:32:52.069865  4233 net.cpp:434] conv13/dw/scale <- conv13/dw
I1015 15:32:52.069869  4233 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1015 15:32:52.069903  4233 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 15:32:52.070017  4233 net.cpp:150] Setting up conv13/dw/scale
I1015 15:32:52.070024  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.070026  4233 net.cpp:165] Memory required for data: 1128038592
I1015 15:32:52.070030  4233 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1015 15:32:52.070035  4233 net.cpp:100] Creating Layer conv13/dw/relu
I1015 15:32:52.070037  4233 net.cpp:434] conv13/dw/relu <- conv13/dw
I1015 15:32:52.070041  4233 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1015 15:32:52.070705  4233 net.cpp:150] Setting up conv13/dw/relu
I1015 15:32:52.070716  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.070719  4233 net.cpp:165] Memory required for data: 1130496192
I1015 15:32:52.070722  4233 layer_factory.hpp:77] Creating layer conv13
I1015 15:32:52.070729  4233 net.cpp:100] Creating Layer conv13
I1015 15:32:52.070734  4233 net.cpp:434] conv13 <- conv13/dw
I1015 15:32:52.070737  4233 net.cpp:408] conv13 -> conv13
I1015 15:32:52.083568  4233 net.cpp:150] Setting up conv13
I1015 15:32:52.083592  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.083595  4233 net.cpp:165] Memory required for data: 1132953792
I1015 15:32:52.083602  4233 layer_factory.hpp:77] Creating layer conv13/bn
I1015 15:32:52.083612  4233 net.cpp:100] Creating Layer conv13/bn
I1015 15:32:52.083617  4233 net.cpp:434] conv13/bn <- conv13
I1015 15:32:52.083622  4233 net.cpp:395] conv13/bn -> conv13 (in-place)
I1015 15:32:52.083812  4233 net.cpp:150] Setting up conv13/bn
I1015 15:32:52.083820  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.083822  4233 net.cpp:165] Memory required for data: 1135411392
I1015 15:32:52.083829  4233 layer_factory.hpp:77] Creating layer conv13/scale
I1015 15:32:52.083838  4233 net.cpp:100] Creating Layer conv13/scale
I1015 15:32:52.083842  4233 net.cpp:434] conv13/scale <- conv13
I1015 15:32:52.083845  4233 net.cpp:395] conv13/scale -> conv13 (in-place)
I1015 15:32:52.083886  4233 layer_factory.hpp:77] Creating layer conv13/scale
I1015 15:32:52.083989  4233 net.cpp:150] Setting up conv13/scale
I1015 15:32:52.083997  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.083998  4233 net.cpp:165] Memory required for data: 1137868992
I1015 15:32:52.084003  4233 layer_factory.hpp:77] Creating layer conv13/relu
I1015 15:32:52.084009  4233 net.cpp:100] Creating Layer conv13/relu
I1015 15:32:52.084012  4233 net.cpp:434] conv13/relu <- conv13
I1015 15:32:52.084015  4233 net.cpp:395] conv13/relu -> conv13 (in-place)
I1015 15:32:52.084385  4233 net.cpp:150] Setting up conv13/relu
I1015 15:32:52.084395  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084398  4233 net.cpp:165] Memory required for data: 1140326592
I1015 15:32:52.084400  4233 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1015 15:32:52.084408  4233 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1015 15:32:52.084410  4233 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1015 15:32:52.084416  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1015 15:32:52.084424  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1015 15:32:52.084427  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1015 15:32:52.084434  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1015 15:32:52.084437  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1015 15:32:52.084512  4233 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1015 15:32:52.084518  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084522  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084524  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084527  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084529  4233 net.cpp:157] Top shape: 4 1024 10 15 (614400)
I1015 15:32:52.084532  4233 net.cpp:165] Memory required for data: 1152614592
I1015 15:32:52.084534  4233 layer_factory.hpp:77] Creating layer conv14_1
I1015 15:32:52.084542  4233 net.cpp:100] Creating Layer conv14_1
I1015 15:32:52.084545  4233 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1015 15:32:52.084550  4233 net.cpp:408] conv14_1 -> conv14_1
I1015 15:32:52.089252  4233 net.cpp:150] Setting up conv14_1
I1015 15:32:52.089273  4233 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 15:32:52.089277  4233 net.cpp:165] Memory required for data: 1153228992
I1015 15:32:52.089282  4233 layer_factory.hpp:77] Creating layer conv14_1/bn
I1015 15:32:52.089292  4233 net.cpp:100] Creating Layer conv14_1/bn
I1015 15:32:52.089296  4233 net.cpp:434] conv14_1/bn <- conv14_1
I1015 15:32:52.089300  4233 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1015 15:32:52.089483  4233 net.cpp:150] Setting up conv14_1/bn
I1015 15:32:52.089489  4233 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 15:32:52.089493  4233 net.cpp:165] Memory required for data: 1153843392
I1015 15:32:52.089498  4233 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 15:32:52.089507  4233 net.cpp:100] Creating Layer conv14_1/scale
I1015 15:32:52.089510  4233 net.cpp:434] conv14_1/scale <- conv14_1
I1015 15:32:52.089514  4233 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1015 15:32:52.089556  4233 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 15:32:52.089656  4233 net.cpp:150] Setting up conv14_1/scale
I1015 15:32:52.089663  4233 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 15:32:52.089664  4233 net.cpp:165] Memory required for data: 1154457792
I1015 15:32:52.089668  4233 layer_factory.hpp:77] Creating layer conv14_1/relu
I1015 15:32:52.089676  4233 net.cpp:100] Creating Layer conv14_1/relu
I1015 15:32:52.089679  4233 net.cpp:434] conv14_1/relu <- conv14_1
I1015 15:32:52.089684  4233 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1015 15:32:52.090059  4233 net.cpp:150] Setting up conv14_1/relu
I1015 15:32:52.090070  4233 net.cpp:157] Top shape: 4 256 10 15 (153600)
I1015 15:32:52.090072  4233 net.cpp:165] Memory required for data: 1155072192
I1015 15:32:52.090075  4233 layer_factory.hpp:77] Creating layer conv14_2
I1015 15:32:52.090086  4233 net.cpp:100] Creating Layer conv14_2
I1015 15:32:52.090090  4233 net.cpp:434] conv14_2 <- conv14_1
I1015 15:32:52.090095  4233 net.cpp:408] conv14_2 -> conv14_2
I1015 15:32:52.104327  4233 net.cpp:150] Setting up conv14_2
I1015 15:32:52.104351  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.104353  4233 net.cpp:165] Memory required for data: 1155399872
I1015 15:32:52.104362  4233 layer_factory.hpp:77] Creating layer conv14_2/bn
I1015 15:32:52.104372  4233 net.cpp:100] Creating Layer conv14_2/bn
I1015 15:32:52.104375  4233 net.cpp:434] conv14_2/bn <- conv14_2
I1015 15:32:52.104382  4233 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1015 15:32:52.104584  4233 net.cpp:150] Setting up conv14_2/bn
I1015 15:32:52.104593  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.104594  4233 net.cpp:165] Memory required for data: 1155727552
I1015 15:32:52.104600  4233 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 15:32:52.104610  4233 net.cpp:100] Creating Layer conv14_2/scale
I1015 15:32:52.104614  4233 net.cpp:434] conv14_2/scale <- conv14_2
I1015 15:32:52.104617  4233 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1015 15:32:52.104666  4233 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 15:32:52.104777  4233 net.cpp:150] Setting up conv14_2/scale
I1015 15:32:52.104785  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.104787  4233 net.cpp:165] Memory required for data: 1156055232
I1015 15:32:52.104791  4233 layer_factory.hpp:77] Creating layer conv14_2/relu
I1015 15:32:52.104796  4233 net.cpp:100] Creating Layer conv14_2/relu
I1015 15:32:52.104799  4233 net.cpp:434] conv14_2/relu <- conv14_2
I1015 15:32:52.104804  4233 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1015 15:32:52.105204  4233 net.cpp:150] Setting up conv14_2/relu
I1015 15:32:52.105217  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.105221  4233 net.cpp:165] Memory required for data: 1156382912
I1015 15:32:52.105224  4233 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1015 15:32:52.105233  4233 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1015 15:32:52.105242  4233 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1015 15:32:52.105248  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1015 15:32:52.105257  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1015 15:32:52.105265  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1015 15:32:52.105273  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1015 15:32:52.105357  4233 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1015 15:32:52.105365  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.105370  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.105374  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.105378  4233 net.cpp:157] Top shape: 4 512 5 8 (81920)
I1015 15:32:52.105382  4233 net.cpp:165] Memory required for data: 1157693632
I1015 15:32:52.105386  4233 layer_factory.hpp:77] Creating layer conv15_1
I1015 15:32:52.105401  4233 net.cpp:100] Creating Layer conv15_1
I1015 15:32:52.105404  4233 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1015 15:32:52.105412  4233 net.cpp:408] conv15_1 -> conv15_1
I1015 15:32:52.107753  4233 net.cpp:150] Setting up conv15_1
I1015 15:32:52.107775  4233 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 15:32:52.107779  4233 net.cpp:165] Memory required for data: 1157775552
I1015 15:32:52.107789  4233 layer_factory.hpp:77] Creating layer conv15_1/bn
I1015 15:32:52.107800  4233 net.cpp:100] Creating Layer conv15_1/bn
I1015 15:32:52.107806  4233 net.cpp:434] conv15_1/bn <- conv15_1
I1015 15:32:52.107813  4233 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1015 15:32:52.108052  4233 net.cpp:150] Setting up conv15_1/bn
I1015 15:32:52.108060  4233 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 15:32:52.108064  4233 net.cpp:165] Memory required for data: 1157857472
I1015 15:32:52.108072  4233 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 15:32:52.108083  4233 net.cpp:100] Creating Layer conv15_1/scale
I1015 15:32:52.108086  4233 net.cpp:434] conv15_1/scale <- conv15_1
I1015 15:32:52.108091  4233 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1015 15:32:52.108139  4233 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 15:32:52.108268  4233 net.cpp:150] Setting up conv15_1/scale
I1015 15:32:52.108275  4233 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 15:32:52.108278  4233 net.cpp:165] Memory required for data: 1157939392
I1015 15:32:52.108283  4233 layer_factory.hpp:77] Creating layer conv15_1/relu
I1015 15:32:52.108287  4233 net.cpp:100] Creating Layer conv15_1/relu
I1015 15:32:52.108290  4233 net.cpp:434] conv15_1/relu <- conv15_1
I1015 15:32:52.108294  4233 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1015 15:32:52.109012  4233 net.cpp:150] Setting up conv15_1/relu
I1015 15:32:52.109025  4233 net.cpp:157] Top shape: 4 128 5 8 (20480)
I1015 15:32:52.109027  4233 net.cpp:165] Memory required for data: 1158021312
I1015 15:32:52.109030  4233 layer_factory.hpp:77] Creating layer conv15_2
I1015 15:32:52.109040  4233 net.cpp:100] Creating Layer conv15_2
I1015 15:32:52.109043  4233 net.cpp:434] conv15_2 <- conv15_1
I1015 15:32:52.109048  4233 net.cpp:408] conv15_2 -> conv15_2
I1015 15:32:52.114946  4233 net.cpp:150] Setting up conv15_2
I1015 15:32:52.114974  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.114977  4233 net.cpp:165] Memory required for data: 1158070464
I1015 15:32:52.114986  4233 layer_factory.hpp:77] Creating layer conv15_2/bn
I1015 15:32:52.115016  4233 net.cpp:100] Creating Layer conv15_2/bn
I1015 15:32:52.115023  4233 net.cpp:434] conv15_2/bn <- conv15_2
I1015 15:32:52.115032  4233 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1015 15:32:52.115314  4233 net.cpp:150] Setting up conv15_2/bn
I1015 15:32:52.115324  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.115329  4233 net.cpp:165] Memory required for data: 1158119616
I1015 15:32:52.115337  4233 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 15:32:52.115348  4233 net.cpp:100] Creating Layer conv15_2/scale
I1015 15:32:52.115353  4233 net.cpp:434] conv15_2/scale <- conv15_2
I1015 15:32:52.115360  4233 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1015 15:32:52.115414  4233 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 15:32:52.115576  4233 net.cpp:150] Setting up conv15_2/scale
I1015 15:32:52.115589  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.115593  4233 net.cpp:165] Memory required for data: 1158168768
I1015 15:32:52.115600  4233 layer_factory.hpp:77] Creating layer conv15_2/relu
I1015 15:32:52.115607  4233 net.cpp:100] Creating Layer conv15_2/relu
I1015 15:32:52.115612  4233 net.cpp:434] conv15_2/relu <- conv15_2
I1015 15:32:52.115617  4233 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1015 15:32:52.116145  4233 net.cpp:150] Setting up conv15_2/relu
I1015 15:32:52.116158  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.116163  4233 net.cpp:165] Memory required for data: 1158217920
I1015 15:32:52.116168  4233 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1015 15:32:52.116175  4233 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1015 15:32:52.116179  4233 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1015 15:32:52.116189  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1015 15:32:52.116197  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1015 15:32:52.116205  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1015 15:32:52.116214  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1015 15:32:52.116308  4233 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1015 15:32:52.116318  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.116323  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.116328  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.116333  4233 net.cpp:157] Top shape: 4 256 3 4 (12288)
I1015 15:32:52.116336  4233 net.cpp:165] Memory required for data: 1158414528
I1015 15:32:52.116340  4233 layer_factory.hpp:77] Creating layer conv16_1
I1015 15:32:52.116351  4233 net.cpp:100] Creating Layer conv16_1
I1015 15:32:52.116356  4233 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1015 15:32:52.116365  4233 net.cpp:408] conv16_1 -> conv16_1
I1015 15:32:52.119349  4233 net.cpp:150] Setting up conv16_1
I1015 15:32:52.119364  4233 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 15:32:52.119366  4233 net.cpp:165] Memory required for data: 1158439104
I1015 15:32:52.119371  4233 layer_factory.hpp:77] Creating layer conv16_1/bn
I1015 15:32:52.119379  4233 net.cpp:100] Creating Layer conv16_1/bn
I1015 15:32:52.119381  4233 net.cpp:434] conv16_1/bn <- conv16_1
I1015 15:32:52.119387  4233 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1015 15:32:52.119561  4233 net.cpp:150] Setting up conv16_1/bn
I1015 15:32:52.119568  4233 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 15:32:52.119570  4233 net.cpp:165] Memory required for data: 1158463680
I1015 15:32:52.119575  4233 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 15:32:52.119582  4233 net.cpp:100] Creating Layer conv16_1/scale
I1015 15:32:52.119585  4233 net.cpp:434] conv16_1/scale <- conv16_1
I1015 15:32:52.119588  4233 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1015 15:32:52.119624  4233 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 15:32:52.119720  4233 net.cpp:150] Setting up conv16_1/scale
I1015 15:32:52.119726  4233 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 15:32:52.119729  4233 net.cpp:165] Memory required for data: 1158488256
I1015 15:32:52.119734  4233 layer_factory.hpp:77] Creating layer conv16_1/relu
I1015 15:32:52.119737  4233 net.cpp:100] Creating Layer conv16_1/relu
I1015 15:32:52.119740  4233 net.cpp:434] conv16_1/relu <- conv16_1
I1015 15:32:52.119745  4233 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1015 15:32:52.120100  4233 net.cpp:150] Setting up conv16_1/relu
I1015 15:32:52.120110  4233 net.cpp:157] Top shape: 4 128 3 4 (6144)
I1015 15:32:52.120111  4233 net.cpp:165] Memory required for data: 1158512832
I1015 15:32:52.120115  4233 layer_factory.hpp:77] Creating layer conv16_2
I1015 15:32:52.120122  4233 net.cpp:100] Creating Layer conv16_2
I1015 15:32:52.120124  4233 net.cpp:434] conv16_2 <- conv16_1
I1015 15:32:52.120131  4233 net.cpp:408] conv16_2 -> conv16_2
I1015 15:32:52.125294  4233 net.cpp:150] Setting up conv16_2
I1015 15:32:52.125314  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.125317  4233 net.cpp:165] Memory required for data: 1158529216
I1015 15:32:52.125324  4233 layer_factory.hpp:77] Creating layer conv16_2/bn
I1015 15:32:52.125332  4233 net.cpp:100] Creating Layer conv16_2/bn
I1015 15:32:52.125337  4233 net.cpp:434] conv16_2/bn <- conv16_2
I1015 15:32:52.125344  4233 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1015 15:32:52.125524  4233 net.cpp:150] Setting up conv16_2/bn
I1015 15:32:52.125530  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.125532  4233 net.cpp:165] Memory required for data: 1158545600
I1015 15:32:52.125537  4233 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 15:32:52.125545  4233 net.cpp:100] Creating Layer conv16_2/scale
I1015 15:32:52.125548  4233 net.cpp:434] conv16_2/scale <- conv16_2
I1015 15:32:52.125552  4233 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1015 15:32:52.125589  4233 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 15:32:52.125687  4233 net.cpp:150] Setting up conv16_2/scale
I1015 15:32:52.125694  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.125696  4233 net.cpp:165] Memory required for data: 1158561984
I1015 15:32:52.125700  4233 layer_factory.hpp:77] Creating layer conv16_2/relu
I1015 15:32:52.125705  4233 net.cpp:100] Creating Layer conv16_2/relu
I1015 15:32:52.125706  4233 net.cpp:434] conv16_2/relu <- conv16_2
I1015 15:32:52.125712  4233 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1015 15:32:52.126433  4233 net.cpp:150] Setting up conv16_2/relu
I1015 15:32:52.126446  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.126447  4233 net.cpp:165] Memory required for data: 1158578368
I1015 15:32:52.126451  4233 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1015 15:32:52.126456  4233 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1015 15:32:52.126458  4233 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1015 15:32:52.126466  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1015 15:32:52.126472  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1015 15:32:52.126477  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1015 15:32:52.126482  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1015 15:32:52.126546  4233 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1015 15:32:52.126551  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.126554  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.126557  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.126559  4233 net.cpp:157] Top shape: 4 256 2 2 (4096)
I1015 15:32:52.126562  4233 net.cpp:165] Memory required for data: 1158643904
I1015 15:32:52.126564  4233 layer_factory.hpp:77] Creating layer conv17_1
I1015 15:32:52.126572  4233 net.cpp:100] Creating Layer conv17_1
I1015 15:32:52.126574  4233 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1015 15:32:52.126580  4233 net.cpp:408] conv17_1 -> conv17_1
I1015 15:32:52.128361  4233 net.cpp:150] Setting up conv17_1
I1015 15:32:52.128373  4233 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 15:32:52.128376  4233 net.cpp:165] Memory required for data: 1158648000
I1015 15:32:52.128381  4233 layer_factory.hpp:77] Creating layer conv17_1/bn
I1015 15:32:52.128386  4233 net.cpp:100] Creating Layer conv17_1/bn
I1015 15:32:52.128389  4233 net.cpp:434] conv17_1/bn <- conv17_1
I1015 15:32:52.128393  4233 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1015 15:32:52.128582  4233 net.cpp:150] Setting up conv17_1/bn
I1015 15:32:52.128588  4233 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 15:32:52.128590  4233 net.cpp:165] Memory required for data: 1158652096
I1015 15:32:52.128595  4233 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 15:32:52.128600  4233 net.cpp:100] Creating Layer conv17_1/scale
I1015 15:32:52.128603  4233 net.cpp:434] conv17_1/scale <- conv17_1
I1015 15:32:52.128608  4233 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1015 15:32:52.128645  4233 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 15:32:52.128751  4233 net.cpp:150] Setting up conv17_1/scale
I1015 15:32:52.128756  4233 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 15:32:52.128758  4233 net.cpp:165] Memory required for data: 1158656192
I1015 15:32:52.128762  4233 layer_factory.hpp:77] Creating layer conv17_1/relu
I1015 15:32:52.128768  4233 net.cpp:100] Creating Layer conv17_1/relu
I1015 15:32:52.128770  4233 net.cpp:434] conv17_1/relu <- conv17_1
I1015 15:32:52.128773  4233 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1015 15:32:52.129138  4233 net.cpp:150] Setting up conv17_1/relu
I1015 15:32:52.129148  4233 net.cpp:157] Top shape: 4 64 2 2 (1024)
I1015 15:32:52.129149  4233 net.cpp:165] Memory required for data: 1158660288
I1015 15:32:52.129151  4233 layer_factory.hpp:77] Creating layer conv17_2
I1015 15:32:52.129160  4233 net.cpp:100] Creating Layer conv17_2
I1015 15:32:52.129163  4233 net.cpp:434] conv17_2 <- conv17_1
I1015 15:32:52.129168  4233 net.cpp:408] conv17_2 -> conv17_2
I1015 15:32:52.131397  4233 net.cpp:150] Setting up conv17_2
I1015 15:32:52.131409  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.131412  4233 net.cpp:165] Memory required for data: 1158662336
I1015 15:32:52.131417  4233 layer_factory.hpp:77] Creating layer conv17_2/bn
I1015 15:32:52.131420  4233 net.cpp:100] Creating Layer conv17_2/bn
I1015 15:32:52.131423  4233 net.cpp:434] conv17_2/bn <- conv17_2
I1015 15:32:52.131428  4233 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1015 15:32:52.131605  4233 net.cpp:150] Setting up conv17_2/bn
I1015 15:32:52.131613  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.131614  4233 net.cpp:165] Memory required for data: 1158664384
I1015 15:32:52.131619  4233 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 15:32:52.131625  4233 net.cpp:100] Creating Layer conv17_2/scale
I1015 15:32:52.131628  4233 net.cpp:434] conv17_2/scale <- conv17_2
I1015 15:32:52.131633  4233 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1015 15:32:52.131669  4233 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 15:32:52.131764  4233 net.cpp:150] Setting up conv17_2/scale
I1015 15:32:52.131770  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.131772  4233 net.cpp:165] Memory required for data: 1158666432
I1015 15:32:52.131778  4233 layer_factory.hpp:77] Creating layer conv17_2/relu
I1015 15:32:52.131781  4233 net.cpp:100] Creating Layer conv17_2/relu
I1015 15:32:52.131783  4233 net.cpp:434] conv17_2/relu <- conv17_2
I1015 15:32:52.131788  4233 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1015 15:32:52.132213  4233 net.cpp:150] Setting up conv17_2/relu
I1015 15:32:52.132226  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.132230  4233 net.cpp:165] Memory required for data: 1158668480
I1015 15:32:52.132236  4233 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1015 15:32:52.132244  4233 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1015 15:32:52.132249  4233 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1015 15:32:52.132257  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1015 15:32:52.132266  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1015 15:32:52.132274  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1015 15:32:52.132354  4233 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1015 15:32:52.132361  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.132366  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.132371  4233 net.cpp:157] Top shape: 4 128 1 1 (512)
I1015 15:32:52.132375  4233 net.cpp:165] Memory required for data: 1158674624
I1015 15:32:52.132380  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1015 15:32:52.132392  4233 net.cpp:100] Creating Layer conv11_mbox_loc
I1015 15:32:52.132398  4233 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1015 15:32:52.132406  4233 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1015 15:32:52.135836  4233 net.cpp:150] Setting up conv11_mbox_loc
I1015 15:32:52.135855  4233 net.cpp:157] Top shape: 4 12 20 30 (28800)
I1015 15:32:52.135860  4233 net.cpp:165] Memory required for data: 1158789824
I1015 15:32:52.135869  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1015 15:32:52.135881  4233 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1015 15:32:52.135886  4233 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1015 15:32:52.135893  4233 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1015 15:32:52.136044  4233 net.cpp:150] Setting up conv11_mbox_loc_perm
I1015 15:32:52.136054  4233 net.cpp:157] Top shape: 4 20 30 12 (28800)
I1015 15:32:52.136057  4233 net.cpp:165] Memory required for data: 1158905024
I1015 15:32:52.136061  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1015 15:32:52.136070  4233 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1015 15:32:52.136075  4233 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1015 15:32:52.136081  4233 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1015 15:32:52.136116  4233 net.cpp:150] Setting up conv11_mbox_loc_flat
I1015 15:32:52.136122  4233 net.cpp:157] Top shape: 4 7200 (28800)
I1015 15:32:52.136126  4233 net.cpp:165] Memory required for data: 1159020224
I1015 15:32:52.136129  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1015 15:32:52.136142  4233 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1015 15:32:52.136148  4233 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1015 15:32:52.136157  4233 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1015 15:32:52.138268  4233 net.cpp:150] Setting up conv11_mbox_conf_new
I1015 15:32:52.138286  4233 net.cpp:157] Top shape: 4 9 20 30 (21600)
I1015 15:32:52.138289  4233 net.cpp:165] Memory required for data: 1159106624
I1015 15:32:52.138295  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1015 15:32:52.138303  4233 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1015 15:32:52.138306  4233 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1015 15:32:52.138310  4233 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1015 15:32:52.138408  4233 net.cpp:150] Setting up conv11_mbox_conf_perm
I1015 15:32:52.138414  4233 net.cpp:157] Top shape: 4 20 30 9 (21600)
I1015 15:32:52.138417  4233 net.cpp:165] Memory required for data: 1159193024
I1015 15:32:52.138418  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1015 15:32:52.138423  4233 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1015 15:32:52.138427  4233 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1015 15:32:52.138432  4233 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1015 15:32:52.138463  4233 net.cpp:150] Setting up conv11_mbox_conf_flat
I1015 15:32:52.138469  4233 net.cpp:157] Top shape: 4 5400 (21600)
I1015 15:32:52.138473  4233 net.cpp:165] Memory required for data: 1159279424
I1015 15:32:52.138476  4233 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1015 15:32:52.138485  4233 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1015 15:32:52.138489  4233 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1015 15:32:52.138495  4233 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1015 15:32:52.138504  4233 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1015 15:32:52.138540  4233 net.cpp:150] Setting up conv11_mbox_priorbox
I1015 15:32:52.138546  4233 net.cpp:157] Top shape: 1 2 7200 (14400)
I1015 15:32:52.138550  4233 net.cpp:165] Memory required for data: 1159337024
I1015 15:32:52.138553  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1015 15:32:52.138566  4233 net.cpp:100] Creating Layer conv13_mbox_loc
I1015 15:32:52.138569  4233 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1015 15:32:52.138577  4233 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1015 15:32:52.140724  4233 net.cpp:150] Setting up conv13_mbox_loc
I1015 15:32:52.140738  4233 net.cpp:157] Top shape: 4 24 10 15 (14400)
I1015 15:32:52.140739  4233 net.cpp:165] Memory required for data: 1159394624
I1015 15:32:52.140745  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1015 15:32:52.140753  4233 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1015 15:32:52.140755  4233 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1015 15:32:52.140759  4233 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1015 15:32:52.140861  4233 net.cpp:150] Setting up conv13_mbox_loc_perm
I1015 15:32:52.140866  4233 net.cpp:157] Top shape: 4 10 15 24 (14400)
I1015 15:32:52.140868  4233 net.cpp:165] Memory required for data: 1159452224
I1015 15:32:52.140871  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1015 15:32:52.140877  4233 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1015 15:32:52.140879  4233 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1015 15:32:52.140882  4233 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1015 15:32:52.140904  4233 net.cpp:150] Setting up conv13_mbox_loc_flat
I1015 15:32:52.140908  4233 net.cpp:157] Top shape: 4 3600 (14400)
I1015 15:32:52.140911  4233 net.cpp:165] Memory required for data: 1159509824
I1015 15:32:52.140913  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1015 15:32:52.140920  4233 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1015 15:32:52.140923  4233 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1015 15:32:52.140929  4233 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1015 15:32:52.142788  4233 net.cpp:150] Setting up conv13_mbox_conf_new
I1015 15:32:52.142802  4233 net.cpp:157] Top shape: 4 18 10 15 (10800)
I1015 15:32:52.142804  4233 net.cpp:165] Memory required for data: 1159553024
I1015 15:32:52.142810  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1015 15:32:52.142817  4233 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1015 15:32:52.142820  4233 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1015 15:32:52.142827  4233 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1015 15:32:52.142923  4233 net.cpp:150] Setting up conv13_mbox_conf_perm
I1015 15:32:52.142930  4233 net.cpp:157] Top shape: 4 10 15 18 (10800)
I1015 15:32:52.142931  4233 net.cpp:165] Memory required for data: 1159596224
I1015 15:32:52.142933  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1015 15:32:52.142938  4233 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1015 15:32:52.142941  4233 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1015 15:32:52.142946  4233 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1015 15:32:52.142967  4233 net.cpp:150] Setting up conv13_mbox_conf_flat
I1015 15:32:52.142973  4233 net.cpp:157] Top shape: 4 2700 (10800)
I1015 15:32:52.142976  4233 net.cpp:165] Memory required for data: 1159639424
I1015 15:32:52.142977  4233 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1015 15:32:52.142982  4233 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1015 15:32:52.142985  4233 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1015 15:32:52.142989  4233 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1015 15:32:52.142995  4233 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1015 15:32:52.143019  4233 net.cpp:150] Setting up conv13_mbox_priorbox
I1015 15:32:52.143024  4233 net.cpp:157] Top shape: 1 2 3600 (7200)
I1015 15:32:52.143026  4233 net.cpp:165] Memory required for data: 1159668224
I1015 15:32:52.143028  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1015 15:32:52.143036  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1015 15:32:52.143039  4233 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1015 15:32:52.143044  4233 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1015 15:32:52.144853  4233 net.cpp:150] Setting up conv14_2_mbox_loc
I1015 15:32:52.144865  4233 net.cpp:157] Top shape: 4 24 5 8 (3840)
I1015 15:32:52.144867  4233 net.cpp:165] Memory required for data: 1159683584
I1015 15:32:52.144873  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1015 15:32:52.144879  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1015 15:32:52.144882  4233 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1015 15:32:52.144888  4233 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1015 15:32:52.144990  4233 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1015 15:32:52.144994  4233 net.cpp:157] Top shape: 4 5 8 24 (3840)
I1015 15:32:52.144997  4233 net.cpp:165] Memory required for data: 1159698944
I1015 15:32:52.144999  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1015 15:32:52.145004  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1015 15:32:52.145006  4233 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1015 15:32:52.145010  4233 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1015 15:32:52.145033  4233 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1015 15:32:52.145037  4233 net.cpp:157] Top shape: 4 960 (3840)
I1015 15:32:52.145040  4233 net.cpp:165] Memory required for data: 1159714304
I1015 15:32:52.145041  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1015 15:32:52.145050  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1015 15:32:52.145051  4233 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1015 15:32:52.145058  4233 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1015 15:32:52.147155  4233 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1015 15:32:52.147166  4233 net.cpp:157] Top shape: 4 18 5 8 (2880)
I1015 15:32:52.147169  4233 net.cpp:165] Memory required for data: 1159725824
I1015 15:32:52.147174  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1015 15:32:52.147181  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1015 15:32:52.147184  4233 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1015 15:32:52.147188  4233 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1015 15:32:52.147287  4233 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1015 15:32:52.147292  4233 net.cpp:157] Top shape: 4 5 8 18 (2880)
I1015 15:32:52.147294  4233 net.cpp:165] Memory required for data: 1159737344
I1015 15:32:52.147296  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1015 15:32:52.147302  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1015 15:32:52.147305  4233 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1015 15:32:52.147308  4233 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1015 15:32:52.147332  4233 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1015 15:32:52.147336  4233 net.cpp:157] Top shape: 4 720 (2880)
I1015 15:32:52.147337  4233 net.cpp:165] Memory required for data: 1159748864
I1015 15:32:52.147341  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1015 15:32:52.147346  4233 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1015 15:32:52.147348  4233 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1015 15:32:52.147352  4233 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1015 15:32:52.147356  4233 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1015 15:32:52.147382  4233 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1015 15:32:52.147385  4233 net.cpp:157] Top shape: 1 2 960 (1920)
I1015 15:32:52.147387  4233 net.cpp:165] Memory required for data: 1159756544
I1015 15:32:52.147389  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1015 15:32:52.147397  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1015 15:32:52.147399  4233 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1015 15:32:52.147404  4233 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1015 15:32:52.149154  4233 net.cpp:150] Setting up conv15_2_mbox_loc
I1015 15:32:52.149165  4233 net.cpp:157] Top shape: 4 24 3 4 (1152)
I1015 15:32:52.149168  4233 net.cpp:165] Memory required for data: 1159761152
I1015 15:32:52.149173  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1015 15:32:52.149180  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1015 15:32:52.149183  4233 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1015 15:32:52.149188  4233 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1015 15:32:52.149288  4233 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1015 15:32:52.149294  4233 net.cpp:157] Top shape: 4 3 4 24 (1152)
I1015 15:32:52.149296  4233 net.cpp:165] Memory required for data: 1159765760
I1015 15:32:52.149299  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1015 15:32:52.149303  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1015 15:32:52.149307  4233 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1015 15:32:52.149310  4233 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1015 15:32:52.149333  4233 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1015 15:32:52.149338  4233 net.cpp:157] Top shape: 4 288 (1152)
I1015 15:32:52.149339  4233 net.cpp:165] Memory required for data: 1159770368
I1015 15:32:52.149341  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1015 15:32:52.149349  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1015 15:32:52.149351  4233 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1015 15:32:52.149356  4233 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1015 15:32:52.151094  4233 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1015 15:32:52.151105  4233 net.cpp:157] Top shape: 4 18 3 4 (864)
I1015 15:32:52.151108  4233 net.cpp:165] Memory required for data: 1159773824
I1015 15:32:52.151113  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1015 15:32:52.151119  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1015 15:32:52.151123  4233 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1015 15:32:52.151127  4233 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1015 15:32:52.151229  4233 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1015 15:32:52.151234  4233 net.cpp:157] Top shape: 4 3 4 18 (864)
I1015 15:32:52.151237  4233 net.cpp:165] Memory required for data: 1159777280
I1015 15:32:52.151238  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1015 15:32:52.151243  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1015 15:32:52.151245  4233 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1015 15:32:52.151250  4233 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1015 15:32:52.151274  4233 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1015 15:32:52.151278  4233 net.cpp:157] Top shape: 4 216 (864)
I1015 15:32:52.151280  4233 net.cpp:165] Memory required for data: 1159780736
I1015 15:32:52.151283  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1015 15:32:52.151288  4233 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1015 15:32:52.151290  4233 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1015 15:32:52.151293  4233 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1015 15:32:52.151298  4233 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1015 15:32:52.151324  4233 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1015 15:32:52.151327  4233 net.cpp:157] Top shape: 1 2 288 (576)
I1015 15:32:52.151329  4233 net.cpp:165] Memory required for data: 1159783040
I1015 15:32:52.151331  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1015 15:32:52.151340  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1015 15:32:52.151342  4233 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1015 15:32:52.151346  4233 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1015 15:32:52.153817  4233 net.cpp:150] Setting up conv16_2_mbox_loc
I1015 15:32:52.153846  4233 net.cpp:157] Top shape: 4 24 2 2 (384)
I1015 15:32:52.153851  4233 net.cpp:165] Memory required for data: 1159784576
I1015 15:32:52.153858  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1015 15:32:52.153869  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1015 15:32:52.153874  4233 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1015 15:32:52.153882  4233 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1015 15:32:52.154033  4233 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1015 15:32:52.154042  4233 net.cpp:157] Top shape: 4 2 2 24 (384)
I1015 15:32:52.154045  4233 net.cpp:165] Memory required for data: 1159786112
I1015 15:32:52.154050  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1015 15:32:52.154058  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1015 15:32:52.154062  4233 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1015 15:32:52.154069  4233 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1015 15:32:52.154104  4233 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1015 15:32:52.154111  4233 net.cpp:157] Top shape: 4 96 (384)
I1015 15:32:52.154115  4233 net.cpp:165] Memory required for data: 1159787648
I1015 15:32:52.154119  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1015 15:32:52.154131  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1015 15:32:52.154135  4233 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1015 15:32:52.154145  4233 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1015 15:32:52.157204  4233 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1015 15:32:52.157222  4233 net.cpp:157] Top shape: 4 18 2 2 (288)
I1015 15:32:52.157225  4233 net.cpp:165] Memory required for data: 1159788800
I1015 15:32:52.157233  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1015 15:32:52.157243  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1015 15:32:52.157248  4233 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1015 15:32:52.157256  4233 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1015 15:32:52.157395  4233 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1015 15:32:52.157403  4233 net.cpp:157] Top shape: 4 2 2 18 (288)
I1015 15:32:52.157407  4233 net.cpp:165] Memory required for data: 1159789952
I1015 15:32:52.157411  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1015 15:32:52.157418  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1015 15:32:52.157423  4233 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1015 15:32:52.157430  4233 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1015 15:32:52.157459  4233 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1015 15:32:52.157465  4233 net.cpp:157] Top shape: 4 72 (288)
I1015 15:32:52.157469  4233 net.cpp:165] Memory required for data: 1159791104
I1015 15:32:52.157472  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1015 15:32:52.157481  4233 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1015 15:32:52.157485  4233 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1015 15:32:52.157491  4233 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1015 15:32:52.157500  4233 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1015 15:32:52.157532  4233 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1015 15:32:52.157538  4233 net.cpp:157] Top shape: 1 2 96 (192)
I1015 15:32:52.157541  4233 net.cpp:165] Memory required for data: 1159791872
I1015 15:32:52.157544  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1015 15:32:52.157559  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1015 15:32:52.157564  4233 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1015 15:32:52.157572  4233 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1015 15:32:52.159723  4233 net.cpp:150] Setting up conv17_2_mbox_loc
I1015 15:32:52.159735  4233 net.cpp:157] Top shape: 4 24 1 1 (96)
I1015 15:32:52.159739  4233 net.cpp:165] Memory required for data: 1159792256
I1015 15:32:52.159744  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1015 15:32:52.159750  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1015 15:32:52.159754  4233 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1015 15:32:52.159759  4233 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1015 15:32:52.159859  4233 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1015 15:32:52.159865  4233 net.cpp:157] Top shape: 4 1 1 24 (96)
I1015 15:32:52.159868  4233 net.cpp:165] Memory required for data: 1159792640
I1015 15:32:52.159870  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1015 15:32:52.159874  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1015 15:32:52.159878  4233 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1015 15:32:52.159881  4233 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1015 15:32:52.159906  4233 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1015 15:32:52.159911  4233 net.cpp:157] Top shape: 4 24 (96)
I1015 15:32:52.159914  4233 net.cpp:165] Memory required for data: 1159793024
I1015 15:32:52.159915  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1015 15:32:52.159922  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1015 15:32:52.159925  4233 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1015 15:32:52.159931  4233 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1015 15:32:52.161660  4233 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1015 15:32:52.161672  4233 net.cpp:157] Top shape: 4 18 1 1 (72)
I1015 15:32:52.161674  4233 net.cpp:165] Memory required for data: 1159793312
I1015 15:32:52.161680  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1015 15:32:52.161687  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1015 15:32:52.161690  4233 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1015 15:32:52.161696  4233 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1015 15:32:52.161798  4233 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1015 15:32:52.161804  4233 net.cpp:157] Top shape: 4 1 1 18 (72)
I1015 15:32:52.161806  4233 net.cpp:165] Memory required for data: 1159793600
I1015 15:32:52.161808  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1015 15:32:52.161813  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1015 15:32:52.161815  4233 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1015 15:32:52.161825  4233 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1015 15:32:52.161851  4233 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1015 15:32:52.161856  4233 net.cpp:157] Top shape: 4 18 (72)
I1015 15:32:52.161857  4233 net.cpp:165] Memory required for data: 1159793888
I1015 15:32:52.161860  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1015 15:32:52.161865  4233 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1015 15:32:52.161869  4233 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1015 15:32:52.161871  4233 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1015 15:32:52.161877  4233 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1015 15:32:52.161903  4233 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1015 15:32:52.161907  4233 net.cpp:157] Top shape: 1 2 24 (48)
I1015 15:32:52.161909  4233 net.cpp:165] Memory required for data: 1159794080
I1015 15:32:52.161911  4233 layer_factory.hpp:77] Creating layer mbox_loc
I1015 15:32:52.161917  4233 net.cpp:100] Creating Layer mbox_loc
I1015 15:32:52.161921  4233 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1015 15:32:52.161926  4233 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1015 15:32:52.161928  4233 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1015 15:32:52.161932  4233 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1015 15:32:52.161936  4233 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1015 15:32:52.161938  4233 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1015 15:32:52.161942  4233 net.cpp:408] mbox_loc -> mbox_loc
I1015 15:32:52.161967  4233 net.cpp:150] Setting up mbox_loc
I1015 15:32:52.161970  4233 net.cpp:157] Top shape: 4 12168 (48672)
I1015 15:32:52.161972  4233 net.cpp:165] Memory required for data: 1159988768
I1015 15:32:52.161974  4233 layer_factory.hpp:77] Creating layer mbox_conf
I1015 15:32:52.161979  4233 net.cpp:100] Creating Layer mbox_conf
I1015 15:32:52.161983  4233 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1015 15:32:52.161985  4233 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1015 15:32:52.161988  4233 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1015 15:32:52.161991  4233 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1015 15:32:52.161995  4233 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1015 15:32:52.161998  4233 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1015 15:32:52.162003  4233 net.cpp:408] mbox_conf -> mbox_conf
I1015 15:32:52.162024  4233 net.cpp:150] Setting up mbox_conf
I1015 15:32:52.162029  4233 net.cpp:157] Top shape: 4 9126 (36504)
I1015 15:32:52.162030  4233 net.cpp:165] Memory required for data: 1160134784
I1015 15:32:52.162032  4233 layer_factory.hpp:77] Creating layer mbox_priorbox
I1015 15:32:52.162036  4233 net.cpp:100] Creating Layer mbox_priorbox
I1015 15:32:52.162039  4233 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1015 15:32:52.162042  4233 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1015 15:32:52.162045  4233 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1015 15:32:52.162047  4233 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1015 15:32:52.162050  4233 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1015 15:32:52.162053  4233 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1015 15:32:52.162056  4233 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1015 15:32:52.162078  4233 net.cpp:150] Setting up mbox_priorbox
I1015 15:32:52.162082  4233 net.cpp:157] Top shape: 1 2 12168 (24336)
I1015 15:32:52.162084  4233 net.cpp:165] Memory required for data: 1160232128
I1015 15:32:52.162086  4233 layer_factory.hpp:77] Creating layer mbox_loss
I1015 15:32:52.162094  4233 net.cpp:100] Creating Layer mbox_loss
I1015 15:32:52.162097  4233 net.cpp:434] mbox_loss <- mbox_loc
I1015 15:32:52.162101  4233 net.cpp:434] mbox_loss <- mbox_conf
I1015 15:32:52.162103  4233 net.cpp:434] mbox_loss <- mbox_priorbox
I1015 15:32:52.162106  4233 net.cpp:434] mbox_loss <- label
I1015 15:32:52.162109  4233 net.cpp:408] mbox_loss -> mbox_loss
I1015 15:32:52.162161  4233 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I1015 15:32:52.162246  4233 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1015 15:32:52.162252  4233 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I1015 15:32:52.163060  4233 net.cpp:150] Setting up mbox_loss
I1015 15:32:52.163071  4233 net.cpp:157] Top shape: (1)
I1015 15:32:52.163074  4233 net.cpp:160]     with loss weight 1
I1015 15:32:52.163082  4233 net.cpp:165] Memory required for data: 1160232132
I1015 15:32:52.163085  4233 layer_factory.hpp:77] Creating layer score_32
I1015 15:32:52.163094  4233 net.cpp:100] Creating Layer score_32
I1015 15:32:52.163096  4233 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1015 15:32:52.163102  4233 net.cpp:408] score_32 -> score_32
I1015 15:32:52.164826  4233 net.cpp:150] Setting up score_32
I1015 15:32:52.164839  4233 net.cpp:157] Top shape: 4 2 10 15 (1200)
I1015 15:32:52.164841  4233 net.cpp:165] Memory required for data: 1160236932
I1015 15:32:52.164846  4233 layer_factory.hpp:77] Creating layer upscore_16
I1015 15:32:52.164855  4233 net.cpp:100] Creating Layer upscore_16
I1015 15:32:52.164857  4233 net.cpp:434] upscore_16 <- score_32
I1015 15:32:52.164862  4233 net.cpp:408] upscore_16 -> upscore_16
I1015 15:32:52.165060  4233 net.cpp:150] Setting up upscore_16
I1015 15:32:52.165066  4233 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 15:32:52.165068  4233 net.cpp:165] Memory required for data: 1160256132
I1015 15:32:52.165072  4233 layer_factory.hpp:77] Creating layer score_16
I1015 15:32:52.165078  4233 net.cpp:100] Creating Layer score_16
I1015 15:32:52.165081  4233 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1015 15:32:52.165086  4233 net.cpp:408] score_16 -> score_16
I1015 15:32:52.166820  4233 net.cpp:150] Setting up score_16
I1015 15:32:52.166831  4233 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 15:32:52.166834  4233 net.cpp:165] Memory required for data: 1160275332
I1015 15:32:52.166839  4233 layer_factory.hpp:77] Creating layer fuse_16
I1015 15:32:52.166846  4233 net.cpp:100] Creating Layer fuse_16
I1015 15:32:52.166849  4233 net.cpp:434] fuse_16 <- upscore_16
I1015 15:32:52.166852  4233 net.cpp:434] fuse_16 <- score_16
I1015 15:32:52.166857  4233 net.cpp:408] fuse_16 -> fuse_16
I1015 15:32:52.166885  4233 net.cpp:150] Setting up fuse_16
I1015 15:32:52.166890  4233 net.cpp:157] Top shape: 4 2 20 30 (4800)
I1015 15:32:52.166893  4233 net.cpp:165] Memory required for data: 1160294532
I1015 15:32:52.166895  4233 layer_factory.hpp:77] Creating layer upscore_8
I1015 15:32:52.166901  4233 net.cpp:100] Creating Layer upscore_8
I1015 15:32:52.166903  4233 net.cpp:434] upscore_8 <- fuse_16
I1015 15:32:52.166908  4233 net.cpp:408] upscore_8 -> upscore_8
I1015 15:32:52.167090  4233 net.cpp:150] Setting up upscore_8
I1015 15:32:52.167098  4233 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 15:32:52.167099  4233 net.cpp:165] Memory required for data: 1160371332
I1015 15:32:52.167104  4233 layer_factory.hpp:77] Creating layer score_8
I1015 15:32:52.167109  4233 net.cpp:100] Creating Layer score_8
I1015 15:32:52.167111  4233 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1015 15:32:52.167115  4233 net.cpp:408] score_8 -> score_8
I1015 15:32:52.168836  4233 net.cpp:150] Setting up score_8
I1015 15:32:52.168849  4233 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 15:32:52.168853  4233 net.cpp:165] Memory required for data: 1160448132
I1015 15:32:52.168857  4233 layer_factory.hpp:77] Creating layer fuse_8
I1015 15:32:52.168864  4233 net.cpp:100] Creating Layer fuse_8
I1015 15:32:52.168866  4233 net.cpp:434] fuse_8 <- upscore_8
I1015 15:32:52.168869  4233 net.cpp:434] fuse_8 <- score_8
I1015 15:32:52.168874  4233 net.cpp:408] fuse_8 -> fuse_8
I1015 15:32:52.168902  4233 net.cpp:150] Setting up fuse_8
I1015 15:32:52.168907  4233 net.cpp:157] Top shape: 4 2 40 60 (19200)
I1015 15:32:52.168910  4233 net.cpp:165] Memory required for data: 1160524932
I1015 15:32:52.168912  4233 layer_factory.hpp:77] Creating layer upscore_4
I1015 15:32:52.168918  4233 net.cpp:100] Creating Layer upscore_4
I1015 15:32:52.168920  4233 net.cpp:434] upscore_4 <- fuse_8
I1015 15:32:52.168926  4233 net.cpp:408] upscore_4 -> upscore_4
I1015 15:32:52.169128  4233 net.cpp:150] Setting up upscore_4
I1015 15:32:52.169137  4233 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 15:32:52.169139  4233 net.cpp:165] Memory required for data: 1160832132
I1015 15:32:52.169142  4233 layer_factory.hpp:77] Creating layer score_4
I1015 15:32:52.169148  4233 net.cpp:100] Creating Layer score_4
I1015 15:32:52.169152  4233 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1015 15:32:52.169157  4233 net.cpp:408] score_4 -> score_4
I1015 15:32:52.170912  4233 net.cpp:150] Setting up score_4
I1015 15:32:52.170928  4233 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 15:32:52.170930  4233 net.cpp:165] Memory required for data: 1161139332
I1015 15:32:52.170936  4233 layer_factory.hpp:77] Creating layer fuse_4
I1015 15:32:52.170943  4233 net.cpp:100] Creating Layer fuse_4
I1015 15:32:52.170945  4233 net.cpp:434] fuse_4 <- upscore_4
I1015 15:32:52.170949  4233 net.cpp:434] fuse_4 <- score_4
I1015 15:32:52.170954  4233 net.cpp:408] fuse_4 -> fuse_4
I1015 15:32:52.170982  4233 net.cpp:150] Setting up fuse_4
I1015 15:32:52.170986  4233 net.cpp:157] Top shape: 4 2 80 120 (76800)
I1015 15:32:52.170989  4233 net.cpp:165] Memory required for data: 1161446532
I1015 15:32:52.170991  4233 layer_factory.hpp:77] Creating layer upscore
I1015 15:32:52.170998  4233 net.cpp:100] Creating Layer upscore
I1015 15:32:52.171000  4233 net.cpp:434] upscore <- fuse_4
I1015 15:32:52.171005  4233 net.cpp:408] upscore -> upscore
I1015 15:32:52.171192  4233 net.cpp:150] Setting up upscore
I1015 15:32:52.171200  4233 net.cpp:157] Top shape: 4 2 331 491 (1300168)
I1015 15:32:52.171201  4233 net.cpp:165] Memory required for data: 1166647204
I1015 15:32:52.171205  4233 layer_factory.hpp:77] Creating layer score
I1015 15:32:52.171211  4233 net.cpp:100] Creating Layer score
I1015 15:32:52.171212  4233 net.cpp:434] score <- upscore
I1015 15:32:52.171216  4233 net.cpp:434] score <- data_data_0_split_7
I1015 15:32:52.171221  4233 net.cpp:408] score -> score
I1015 15:32:52.171244  4233 net.cpp:150] Setting up score
I1015 15:32:52.171248  4233 net.cpp:157] Top shape: 4 2 320 480 (1228800)
I1015 15:32:52.171250  4233 net.cpp:165] Memory required for data: 1171562404
I1015 15:32:52.171252  4233 layer_factory.hpp:77] Creating layer seg_loss
I1015 15:32:52.171257  4233 net.cpp:100] Creating Layer seg_loss
I1015 15:32:52.171259  4233 net.cpp:434] seg_loss <- score
I1015 15:32:52.171262  4233 net.cpp:434] seg_loss <- label_seg
I1015 15:32:52.171267  4233 net.cpp:408] seg_loss -> seg_loss
I1015 15:32:52.171273  4233 layer_factory.hpp:77] Creating layer seg_loss
I1015 15:32:52.174643  4233 net.cpp:150] Setting up seg_loss
I1015 15:32:52.174666  4233 net.cpp:157] Top shape: (1)
I1015 15:32:52.174670  4233 net.cpp:160]     with loss weight 1
I1015 15:32:52.174684  4233 net.cpp:165] Memory required for data: 1171562408
I1015 15:32:52.174688  4233 net.cpp:226] seg_loss needs backward computation.
I1015 15:32:52.174695  4233 net.cpp:226] score needs backward computation.
I1015 15:32:52.174700  4233 net.cpp:226] upscore needs backward computation.
I1015 15:32:52.174703  4233 net.cpp:226] fuse_4 needs backward computation.
I1015 15:32:52.174708  4233 net.cpp:226] score_4 needs backward computation.
I1015 15:32:52.174712  4233 net.cpp:226] upscore_4 needs backward computation.
I1015 15:32:52.174717  4233 net.cpp:226] fuse_8 needs backward computation.
I1015 15:32:52.174721  4233 net.cpp:226] score_8 needs backward computation.
I1015 15:32:52.174726  4233 net.cpp:226] upscore_8 needs backward computation.
I1015 15:32:52.174731  4233 net.cpp:226] fuse_16 needs backward computation.
I1015 15:32:52.174736  4233 net.cpp:226] score_16 needs backward computation.
I1015 15:32:52.174739  4233 net.cpp:226] upscore_16 needs backward computation.
I1015 15:32:52.174743  4233 net.cpp:226] score_32 needs backward computation.
I1015 15:32:52.174747  4233 net.cpp:226] mbox_loss needs backward computation.
I1015 15:32:52.174757  4233 net.cpp:228] mbox_priorbox does not need backward computation.
I1015 15:32:52.174767  4233 net.cpp:226] mbox_conf needs backward computation.
I1015 15:32:52.174775  4233 net.cpp:226] mbox_loc needs backward computation.
I1015 15:32:52.174782  4233 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.174789  4233 net.cpp:226] conv17_2_mbox_conf_flat needs backward computation.
I1015 15:32:52.174794  4233 net.cpp:226] conv17_2_mbox_conf_perm needs backward computation.
I1015 15:32:52.174798  4233 net.cpp:226] conv17_2_mbox_conf_new needs backward computation.
I1015 15:32:52.174803  4233 net.cpp:226] conv17_2_mbox_loc_flat needs backward computation.
I1015 15:32:52.174809  4233 net.cpp:226] conv17_2_mbox_loc_perm needs backward computation.
I1015 15:32:52.174814  4233 net.cpp:226] conv17_2_mbox_loc needs backward computation.
I1015 15:32:52.174819  4233 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.174824  4233 net.cpp:226] conv16_2_mbox_conf_flat needs backward computation.
I1015 15:32:52.174829  4233 net.cpp:226] conv16_2_mbox_conf_perm needs backward computation.
I1015 15:32:52.174834  4233 net.cpp:226] conv16_2_mbox_conf_new needs backward computation.
I1015 15:32:52.174839  4233 net.cpp:226] conv16_2_mbox_loc_flat needs backward computation.
I1015 15:32:52.174842  4233 net.cpp:226] conv16_2_mbox_loc_perm needs backward computation.
I1015 15:32:52.174847  4233 net.cpp:226] conv16_2_mbox_loc needs backward computation.
I1015 15:32:52.174851  4233 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.174857  4233 net.cpp:226] conv15_2_mbox_conf_flat needs backward computation.
I1015 15:32:52.174861  4233 net.cpp:226] conv15_2_mbox_conf_perm needs backward computation.
I1015 15:32:52.174866  4233 net.cpp:226] conv15_2_mbox_conf_new needs backward computation.
I1015 15:32:52.174870  4233 net.cpp:226] conv15_2_mbox_loc_flat needs backward computation.
I1015 15:32:52.174876  4233 net.cpp:226] conv15_2_mbox_loc_perm needs backward computation.
I1015 15:32:52.174881  4233 net.cpp:226] conv15_2_mbox_loc needs backward computation.
I1015 15:32:52.174886  4233 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.174891  4233 net.cpp:226] conv14_2_mbox_conf_flat needs backward computation.
I1015 15:32:52.174896  4233 net.cpp:226] conv14_2_mbox_conf_perm needs backward computation.
I1015 15:32:52.174901  4233 net.cpp:226] conv14_2_mbox_conf_new needs backward computation.
I1015 15:32:52.174906  4233 net.cpp:226] conv14_2_mbox_loc_flat needs backward computation.
I1015 15:32:52.174909  4233 net.cpp:226] conv14_2_mbox_loc_perm needs backward computation.
I1015 15:32:52.174913  4233 net.cpp:226] conv14_2_mbox_loc needs backward computation.
I1015 15:32:52.174918  4233 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1015 15:32:52.174926  4233 net.cpp:226] conv13_mbox_conf_flat needs backward computation.
I1015 15:32:52.174931  4233 net.cpp:226] conv13_mbox_conf_perm needs backward computation.
I1015 15:32:52.174934  4233 net.cpp:226] conv13_mbox_conf_new needs backward computation.
I1015 15:32:52.174939  4233 net.cpp:226] conv13_mbox_loc_flat needs backward computation.
I1015 15:32:52.174944  4233 net.cpp:226] conv13_mbox_loc_perm needs backward computation.
I1015 15:32:52.174948  4233 net.cpp:226] conv13_mbox_loc needs backward computation.
I1015 15:32:52.174952  4233 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1015 15:32:52.174958  4233 net.cpp:226] conv11_mbox_conf_flat needs backward computation.
I1015 15:32:52.174962  4233 net.cpp:226] conv11_mbox_conf_perm needs backward computation.
I1015 15:32:52.174968  4233 net.cpp:226] conv11_mbox_conf_new needs backward computation.
I1015 15:32:52.174971  4233 net.cpp:226] conv11_mbox_loc_flat needs backward computation.
I1015 15:32:52.174976  4233 net.cpp:226] conv11_mbox_loc_perm needs backward computation.
I1015 15:32:52.174980  4233 net.cpp:226] conv11_mbox_loc needs backward computation.
I1015 15:32:52.174985  4233 net.cpp:226] conv17_2_conv17_2/relu_0_split needs backward computation.
I1015 15:32:52.174989  4233 net.cpp:226] conv17_2/relu needs backward computation.
I1015 15:32:52.174993  4233 net.cpp:226] conv17_2/scale needs backward computation.
I1015 15:32:52.174998  4233 net.cpp:226] conv17_2/bn needs backward computation.
I1015 15:32:52.175001  4233 net.cpp:226] conv17_2 needs backward computation.
I1015 15:32:52.175006  4233 net.cpp:226] conv17_1/relu needs backward computation.
I1015 15:32:52.175010  4233 net.cpp:226] conv17_1/scale needs backward computation.
I1015 15:32:52.175014  4233 net.cpp:226] conv17_1/bn needs backward computation.
I1015 15:32:52.175019  4233 net.cpp:226] conv17_1 needs backward computation.
I1015 15:32:52.175024  4233 net.cpp:226] conv16_2_conv16_2/relu_0_split needs backward computation.
I1015 15:32:52.175029  4233 net.cpp:226] conv16_2/relu needs backward computation.
I1015 15:32:52.175032  4233 net.cpp:226] conv16_2/scale needs backward computation.
I1015 15:32:52.175037  4233 net.cpp:226] conv16_2/bn needs backward computation.
I1015 15:32:52.175040  4233 net.cpp:226] conv16_2 needs backward computation.
I1015 15:32:52.175045  4233 net.cpp:226] conv16_1/relu needs backward computation.
I1015 15:32:52.175050  4233 net.cpp:226] conv16_1/scale needs backward computation.
I1015 15:32:52.175052  4233 net.cpp:226] conv16_1/bn needs backward computation.
I1015 15:32:52.175056  4233 net.cpp:226] conv16_1 needs backward computation.
I1015 15:32:52.175060  4233 net.cpp:226] conv15_2_conv15_2/relu_0_split needs backward computation.
I1015 15:32:52.175065  4233 net.cpp:226] conv15_2/relu needs backward computation.
I1015 15:32:52.175070  4233 net.cpp:226] conv15_2/scale needs backward computation.
I1015 15:32:52.175073  4233 net.cpp:226] conv15_2/bn needs backward computation.
I1015 15:32:52.175077  4233 net.cpp:226] conv15_2 needs backward computation.
I1015 15:32:52.175081  4233 net.cpp:226] conv15_1/relu needs backward computation.
I1015 15:32:52.175086  4233 net.cpp:226] conv15_1/scale needs backward computation.
I1015 15:32:52.175089  4233 net.cpp:226] conv15_1/bn needs backward computation.
I1015 15:32:52.175092  4233 net.cpp:226] conv15_1 needs backward computation.
I1015 15:32:52.175097  4233 net.cpp:226] conv14_2_conv14_2/relu_0_split needs backward computation.
I1015 15:32:52.175102  4233 net.cpp:226] conv14_2/relu needs backward computation.
I1015 15:32:52.175106  4233 net.cpp:226] conv14_2/scale needs backward computation.
I1015 15:32:52.175109  4233 net.cpp:226] conv14_2/bn needs backward computation.
I1015 15:32:52.175114  4233 net.cpp:226] conv14_2 needs backward computation.
I1015 15:32:52.175118  4233 net.cpp:226] conv14_1/relu needs backward computation.
I1015 15:32:52.175122  4233 net.cpp:226] conv14_1/scale needs backward computation.
I1015 15:32:52.175125  4233 net.cpp:226] conv14_1/bn needs backward computation.
I1015 15:32:52.175129  4233 net.cpp:226] conv14_1 needs backward computation.
I1015 15:32:52.175134  4233 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1015 15:32:52.175138  4233 net.cpp:226] conv13/relu needs backward computation.
I1015 15:32:52.175143  4233 net.cpp:226] conv13/scale needs backward computation.
I1015 15:32:52.175148  4233 net.cpp:226] conv13/bn needs backward computation.
I1015 15:32:52.175150  4233 net.cpp:226] conv13 needs backward computation.
I1015 15:32:52.175155  4233 net.cpp:226] conv13/dw/relu needs backward computation.
I1015 15:32:52.175159  4233 net.cpp:226] conv13/dw/scale needs backward computation.
I1015 15:32:52.175164  4233 net.cpp:226] conv13/dw/bn needs backward computation.
I1015 15:32:52.175168  4233 net.cpp:226] conv13/dw needs backward computation.
I1015 15:32:52.175173  4233 net.cpp:226] conv12/relu needs backward computation.
I1015 15:32:52.175176  4233 net.cpp:226] conv12/scale needs backward computation.
I1015 15:32:52.175180  4233 net.cpp:226] conv12/bn needs backward computation.
I1015 15:32:52.175184  4233 net.cpp:226] conv12 needs backward computation.
I1015 15:32:52.175189  4233 net.cpp:226] conv12/dw/relu needs backward computation.
I1015 15:32:52.175192  4233 net.cpp:226] conv12/dw/scale needs backward computation.
I1015 15:32:52.175196  4233 net.cpp:226] conv12/dw/bn needs backward computation.
I1015 15:32:52.175200  4233 net.cpp:226] conv12/dw needs backward computation.
I1015 15:32:52.175205  4233 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1015 15:32:52.175209  4233 net.cpp:226] conv11/relu needs backward computation.
I1015 15:32:52.175213  4233 net.cpp:226] conv11/scale needs backward computation.
I1015 15:32:52.175217  4233 net.cpp:226] conv11/bn needs backward computation.
I1015 15:32:52.175221  4233 net.cpp:226] conv11 needs backward computation.
I1015 15:32:52.175226  4233 net.cpp:226] conv11/dw/relu needs backward computation.
I1015 15:32:52.175230  4233 net.cpp:226] conv11/dw/scale needs backward computation.
I1015 15:32:52.175235  4233 net.cpp:226] conv11/dw/bn needs backward computation.
I1015 15:32:52.175238  4233 net.cpp:226] conv11/dw needs backward computation.
I1015 15:32:52.175242  4233 net.cpp:226] conv10/relu needs backward computation.
I1015 15:32:52.175246  4233 net.cpp:226] conv10/scale needs backward computation.
I1015 15:32:52.175251  4233 net.cpp:226] conv10/bn needs backward computation.
I1015 15:32:52.175254  4233 net.cpp:226] conv10 needs backward computation.
I1015 15:32:52.175258  4233 net.cpp:226] conv10/dw/relu needs backward computation.
I1015 15:32:52.175262  4233 net.cpp:226] conv10/dw/scale needs backward computation.
I1015 15:32:52.175266  4233 net.cpp:226] conv10/dw/bn needs backward computation.
I1015 15:32:52.175271  4233 net.cpp:226] conv10/dw needs backward computation.
I1015 15:32:52.175276  4233 net.cpp:226] conv9/relu needs backward computation.
I1015 15:32:52.175279  4233 net.cpp:226] conv9/scale needs backward computation.
I1015 15:32:52.175283  4233 net.cpp:226] conv9/bn needs backward computation.
I1015 15:32:52.175287  4233 net.cpp:226] conv9 needs backward computation.
I1015 15:32:52.175292  4233 net.cpp:226] conv9/dw/relu needs backward computation.
I1015 15:32:52.175298  4233 net.cpp:226] conv9/dw/scale needs backward computation.
I1015 15:32:52.175302  4233 net.cpp:226] conv9/dw/bn needs backward computation.
I1015 15:32:52.175307  4233 net.cpp:226] conv9/dw needs backward computation.
I1015 15:32:52.175310  4233 net.cpp:226] conv8/relu needs backward computation.
I1015 15:32:52.175315  4233 net.cpp:226] conv8/scale needs backward computation.
I1015 15:32:52.175318  4233 net.cpp:226] conv8/bn needs backward computation.
I1015 15:32:52.175323  4233 net.cpp:226] conv8 needs backward computation.
I1015 15:32:52.175326  4233 net.cpp:226] conv8/dw/relu needs backward computation.
I1015 15:32:52.175330  4233 net.cpp:226] conv8/dw/scale needs backward computation.
I1015 15:32:52.175334  4233 net.cpp:226] conv8/dw/bn needs backward computation.
I1015 15:32:52.175338  4233 net.cpp:226] conv8/dw needs backward computation.
I1015 15:32:52.175343  4233 net.cpp:226] conv7/relu needs backward computation.
I1015 15:32:52.175348  4233 net.cpp:226] conv7/scale needs backward computation.
I1015 15:32:52.175350  4233 net.cpp:226] conv7/bn needs backward computation.
I1015 15:32:52.175354  4233 net.cpp:226] conv7 needs backward computation.
I1015 15:32:52.175359  4233 net.cpp:226] conv7/dw/relu needs backward computation.
I1015 15:32:52.175362  4233 net.cpp:226] conv7/dw/scale needs backward computation.
I1015 15:32:52.175366  4233 net.cpp:226] conv7/dw/bn needs backward computation.
I1015 15:32:52.175370  4233 net.cpp:226] conv7/dw needs backward computation.
I1015 15:32:52.175374  4233 net.cpp:226] conv6/relu needs backward computation.
I1015 15:32:52.175379  4233 net.cpp:226] conv6/scale needs backward computation.
I1015 15:32:52.175382  4233 net.cpp:226] conv6/bn needs backward computation.
I1015 15:32:52.175386  4233 net.cpp:226] conv6 needs backward computation.
I1015 15:32:52.175390  4233 net.cpp:226] conv6/dw/relu needs backward computation.
I1015 15:32:52.175395  4233 net.cpp:226] conv6/dw/scale needs backward computation.
I1015 15:32:52.175398  4233 net.cpp:226] conv6/dw/bn needs backward computation.
I1015 15:32:52.175402  4233 net.cpp:226] conv6/dw needs backward computation.
I1015 15:32:52.175406  4233 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1015 15:32:52.175411  4233 net.cpp:226] conv5/relu needs backward computation.
I1015 15:32:52.175415  4233 net.cpp:226] conv5/scale needs backward computation.
I1015 15:32:52.175420  4233 net.cpp:226] conv5/bn needs backward computation.
I1015 15:32:52.175423  4233 net.cpp:226] conv5 needs backward computation.
I1015 15:32:52.175427  4233 net.cpp:226] conv5/dw/relu needs backward computation.
I1015 15:32:52.175431  4233 net.cpp:226] conv5/dw/scale needs backward computation.
I1015 15:32:52.175436  4233 net.cpp:226] conv5/dw/bn needs backward computation.
I1015 15:32:52.175439  4233 net.cpp:226] conv5/dw needs backward computation.
I1015 15:32:52.175443  4233 net.cpp:226] conv4/relu needs backward computation.
I1015 15:32:52.175447  4233 net.cpp:226] conv4/scale needs backward computation.
I1015 15:32:52.175451  4233 net.cpp:226] conv4/bn needs backward computation.
I1015 15:32:52.175454  4233 net.cpp:226] conv4 needs backward computation.
I1015 15:32:52.175459  4233 net.cpp:226] conv4/dw/relu needs backward computation.
I1015 15:32:52.175463  4233 net.cpp:226] conv4/dw/scale needs backward computation.
I1015 15:32:52.175467  4233 net.cpp:226] conv4/dw/bn needs backward computation.
I1015 15:32:52.175470  4233 net.cpp:226] conv4/dw needs backward computation.
I1015 15:32:52.175475  4233 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1015 15:32:52.175479  4233 net.cpp:226] conv3/relu needs backward computation.
I1015 15:32:52.175483  4233 net.cpp:226] conv3/scale needs backward computation.
I1015 15:32:52.175487  4233 net.cpp:226] conv3/bn needs backward computation.
I1015 15:32:52.175492  4233 net.cpp:226] conv3 needs backward computation.
I1015 15:32:52.175496  4233 net.cpp:226] conv3/dw/relu needs backward computation.
I1015 15:32:52.175499  4233 net.cpp:226] conv3/dw/scale needs backward computation.
I1015 15:32:52.175503  4233 net.cpp:226] conv3/dw/bn needs backward computation.
I1015 15:32:52.175508  4233 net.cpp:226] conv3/dw needs backward computation.
I1015 15:32:52.175511  4233 net.cpp:226] conv2/relu needs backward computation.
I1015 15:32:52.175515  4233 net.cpp:226] conv2/scale needs backward computation.
I1015 15:32:52.175519  4233 net.cpp:226] conv2/bn needs backward computation.
I1015 15:32:52.175523  4233 net.cpp:226] conv2 needs backward computation.
I1015 15:32:52.175528  4233 net.cpp:226] conv2/dw/relu needs backward computation.
I1015 15:32:52.175530  4233 net.cpp:226] conv2/dw/scale needs backward computation.
I1015 15:32:52.175534  4233 net.cpp:226] conv2/dw/bn needs backward computation.
I1015 15:32:52.175539  4233 net.cpp:226] conv2/dw needs backward computation.
I1015 15:32:52.175542  4233 net.cpp:226] conv1/relu needs backward computation.
I1015 15:32:52.175546  4233 net.cpp:226] conv1/scale needs backward computation.
I1015 15:32:52.175550  4233 net.cpp:226] conv1/bn needs backward computation.
I1015 15:32:52.175554  4233 net.cpp:226] conv1 needs backward computation.
I1015 15:32:52.175559  4233 net.cpp:226] conv1/dw/relu needs backward computation.
I1015 15:32:52.175563  4233 net.cpp:226] conv1/dw/scale needs backward computation.
I1015 15:32:52.175566  4233 net.cpp:226] conv1/dw/bn needs backward computation.
I1015 15:32:52.175571  4233 net.cpp:226] conv1/dw needs backward computation.
I1015 15:32:52.175575  4233 net.cpp:226] conv0/relu needs backward computation.
I1015 15:32:52.175580  4233 net.cpp:226] conv0/scale needs backward computation.
I1015 15:32:52.175582  4233 net.cpp:226] conv0/bn needs backward computation.
I1015 15:32:52.175587  4233 net.cpp:226] conv0 needs backward computation.
I1015 15:32:52.175593  4233 net.cpp:228] data_data_0_split does not need backward computation.
I1015 15:32:52.175598  4233 net.cpp:228] data does not need backward computation.
I1015 15:32:52.175602  4233 net.cpp:270] This network produces output mbox_loss
I1015 15:32:52.175608  4233 net.cpp:270] This network produces output seg_loss
I1015 15:32:52.175750  4233 net.cpp:283] Network initialization done.
I1015 15:32:52.177443  4233 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: proto/union/MobileNetSSD_test.prototxt
I1015 15:32:52.177458  4233 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 15:32:52.177461  4233 solver.cpp:196] Creating test net (#0) specified by test_net file: proto/union/MobileNetSSD_test.prototxt
I1015 15:32:52.178369  4233 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedDataWithSeg"
  top: "data"
  top: "label"
  top: "label_seg"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 320
      width: 480
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "lmdb/seg_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_conf_perm"
  type: "Permute"
  bottom: "conv13_mbox_conf"
  top: "conv13_mbox_conf_perm"
  permute_param {
    
I1015 15:32:52.178849  4233 layer_factory.hpp:77] Creating layer data
I1015 15:32:52.178916  4233 net.cpp:100] Creating Layer data
I1015 15:32:52.178925  4233 net.cpp:408] data -> data
I1015 15:32:52.178932  4233 net.cpp:408] data -> label
I1015 15:32:52.178937  4233 net.cpp:408] data -> label_seg
I1015 15:32:52.178944  4233 base_data_with_seg_layer.cpp:32] --------------lin 32 begin datalayersetup-------------------------
I1015 15:32:52.181187  4277 db_lmdb.cpp:35] Opened lmdb lmdb/seg_test_lmdb
I1015 15:32:52.265651  4233 annotated_data_with_seg_layer.cpp:91] ----[top0]output data size: 1,3,320,480
I1015 15:32:52.270932  4233 base_data_with_seg_layer.cpp:75] Initializing prefetch
I1015 15:32:52.270984  4233 base_data_with_seg_layer.cpp:78] Prefetch initialized.
I1015 15:32:52.270989  4233 net.cpp:150] Setting up data
I1015 15:32:52.270997  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271000  4233 net.cpp:157] Top shape: 1 1 2 8 (16)
I1015 15:32:52.271003  4233 net.cpp:157] Top shape: 1 1 320 480 (153600)
I1015 15:32:52.271005  4233 net.cpp:165] Memory required for data: 2457664
I1015 15:32:52.271011  4233 layer_factory.hpp:77] Creating layer data_data_0_split
I1015 15:32:52.271023  4233 net.cpp:100] Creating Layer data_data_0_split
I1015 15:32:52.271026  4233 net.cpp:434] data_data_0_split <- data
I1015 15:32:52.271034  4233 net.cpp:408] data_data_0_split -> data_data_0_split_0
I1015 15:32:52.271044  4233 net.cpp:408] data_data_0_split -> data_data_0_split_1
I1015 15:32:52.271049  4233 net.cpp:408] data_data_0_split -> data_data_0_split_2
I1015 15:32:52.271054  4233 net.cpp:408] data_data_0_split -> data_data_0_split_3
I1015 15:32:52.271059  4233 net.cpp:408] data_data_0_split -> data_data_0_split_4
I1015 15:32:52.271062  4233 net.cpp:408] data_data_0_split -> data_data_0_split_5
I1015 15:32:52.271067  4233 net.cpp:408] data_data_0_split -> data_data_0_split_6
I1015 15:32:52.271071  4233 net.cpp:408] data_data_0_split -> data_data_0_split_7
I1015 15:32:52.271281  4233 net.cpp:150] Setting up data_data_0_split
I1015 15:32:52.271289  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271293  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271296  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271299  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271301  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271304  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271308  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271311  4233 net.cpp:157] Top shape: 1 3 320 480 (460800)
I1015 15:32:52.271313  4233 net.cpp:165] Memory required for data: 17203264
I1015 15:32:52.271317  4233 layer_factory.hpp:77] Creating layer conv0
I1015 15:32:52.271327  4233 net.cpp:100] Creating Layer conv0
I1015 15:32:52.271329  4233 net.cpp:434] conv0 <- data_data_0_split_0
I1015 15:32:52.271337  4233 net.cpp:408] conv0 -> conv0
I1015 15:32:52.272102  4278 base_data_with_seg_layer.cpp:84] --------------InternalThreadEntry---------------------
I1015 15:32:52.273325  4233 net.cpp:150] Setting up conv0
I1015 15:32:52.273339  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.273341  4233 net.cpp:165] Memory required for data: 22118464
I1015 15:32:52.273349  4233 layer_factory.hpp:77] Creating layer conv0/bn
I1015 15:32:52.273355  4233 net.cpp:100] Creating Layer conv0/bn
I1015 15:32:52.273357  4233 net.cpp:434] conv0/bn <- conv0
I1015 15:32:52.273361  4233 net.cpp:395] conv0/bn -> conv0 (in-place)
I1015 15:32:52.273593  4233 net.cpp:150] Setting up conv0/bn
I1015 15:32:52.273602  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.273603  4233 net.cpp:165] Memory required for data: 27033664
I1015 15:32:52.273612  4233 layer_factory.hpp:77] Creating layer conv0/scale
I1015 15:32:52.273619  4233 net.cpp:100] Creating Layer conv0/scale
I1015 15:32:52.273622  4233 net.cpp:434] conv0/scale <- conv0
I1015 15:32:52.273627  4233 net.cpp:395] conv0/scale -> conv0 (in-place)
I1015 15:32:52.273665  4233 layer_factory.hpp:77] Creating layer conv0/scale
I1015 15:32:52.273819  4233 net.cpp:150] Setting up conv0/scale
I1015 15:32:52.273835  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.273838  4233 net.cpp:165] Memory required for data: 31948864
I1015 15:32:52.273844  4233 layer_factory.hpp:77] Creating layer conv0/relu
I1015 15:32:52.273847  4233 net.cpp:100] Creating Layer conv0/relu
I1015 15:32:52.273850  4233 net.cpp:434] conv0/relu <- conv0
I1015 15:32:52.273854  4233 net.cpp:395] conv0/relu -> conv0 (in-place)
I1015 15:32:52.274272  4233 net.cpp:150] Setting up conv0/relu
I1015 15:32:52.274282  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.274284  4233 net.cpp:165] Memory required for data: 36864064
I1015 15:32:52.274287  4233 layer_factory.hpp:77] Creating layer conv1/dw
I1015 15:32:52.274294  4233 net.cpp:100] Creating Layer conv1/dw
I1015 15:32:52.274297  4233 net.cpp:434] conv1/dw <- conv0
I1015 15:32:52.274302  4233 net.cpp:408] conv1/dw -> conv1/dw
I1015 15:32:52.274499  4233 net.cpp:150] Setting up conv1/dw
I1015 15:32:52.274507  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.274508  4233 net.cpp:165] Memory required for data: 41779264
I1015 15:32:52.274513  4233 layer_factory.hpp:77] Creating layer conv1/dw/bn
I1015 15:32:52.274516  4233 net.cpp:100] Creating Layer conv1/dw/bn
I1015 15:32:52.274519  4233 net.cpp:434] conv1/dw/bn <- conv1/dw
I1015 15:32:52.274523  4233 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I1015 15:32:52.274725  4233 net.cpp:150] Setting up conv1/dw/bn
I1015 15:32:52.274732  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.274735  4233 net.cpp:165] Memory required for data: 46694464
I1015 15:32:52.274742  4233 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 15:32:52.274749  4233 net.cpp:100] Creating Layer conv1/dw/scale
I1015 15:32:52.274751  4233 net.cpp:434] conv1/dw/scale <- conv1/dw
I1015 15:32:52.274755  4233 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I1015 15:32:52.274791  4233 layer_factory.hpp:77] Creating layer conv1/dw/scale
I1015 15:32:52.274943  4233 net.cpp:150] Setting up conv1/dw/scale
I1015 15:32:52.274950  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.274952  4233 net.cpp:165] Memory required for data: 51609664
I1015 15:32:52.274956  4233 layer_factory.hpp:77] Creating layer conv1/dw/relu
I1015 15:32:52.274960  4233 net.cpp:100] Creating Layer conv1/dw/relu
I1015 15:32:52.274963  4233 net.cpp:434] conv1/dw/relu <- conv1/dw
I1015 15:32:52.274966  4233 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I1015 15:32:52.275398  4233 net.cpp:150] Setting up conv1/dw/relu
I1015 15:32:52.275408  4233 net.cpp:157] Top shape: 1 32 160 240 (1228800)
I1015 15:32:52.275410  4233 net.cpp:165] Memory required for data: 56524864
I1015 15:32:52.275413  4233 layer_factory.hpp:77] Creating layer conv1
I1015 15:32:52.275419  4233 net.cpp:100] Creating Layer conv1
I1015 15:32:52.275422  4233 net.cpp:434] conv1 <- conv1/dw
I1015 15:32:52.275427  4233 net.cpp:408] conv1 -> conv1
I1015 15:32:52.278278  4233 net.cpp:150] Setting up conv1
I1015 15:32:52.278290  4233 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 15:32:52.278293  4233 net.cpp:165] Memory required for data: 66355264
I1015 15:32:52.278298  4233 layer_factory.hpp:77] Creating layer conv1/bn
I1015 15:32:52.278303  4233 net.cpp:100] Creating Layer conv1/bn
I1015 15:32:52.278306  4233 net.cpp:434] conv1/bn <- conv1
I1015 15:32:52.278309  4233 net.cpp:395] conv1/bn -> conv1 (in-place)
I1015 15:32:52.278527  4233 net.cpp:150] Setting up conv1/bn
I1015 15:32:52.278533  4233 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 15:32:52.278535  4233 net.cpp:165] Memory required for data: 76185664
I1015 15:32:52.278542  4233 layer_factory.hpp:77] Creating layer conv1/scale
I1015 15:32:52.278548  4233 net.cpp:100] Creating Layer conv1/scale
I1015 15:32:52.278550  4233 net.cpp:434] conv1/scale <- conv1
I1015 15:32:52.278553  4233 net.cpp:395] conv1/scale -> conv1 (in-place)
I1015 15:32:52.278590  4233 layer_factory.hpp:77] Creating layer conv1/scale
I1015 15:32:52.278743  4233 net.cpp:150] Setting up conv1/scale
I1015 15:32:52.278749  4233 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 15:32:52.278751  4233 net.cpp:165] Memory required for data: 86016064
I1015 15:32:52.278759  4233 layer_factory.hpp:77] Creating layer conv1/relu
I1015 15:32:52.278764  4233 net.cpp:100] Creating Layer conv1/relu
I1015 15:32:52.278766  4233 net.cpp:434] conv1/relu <- conv1
I1015 15:32:52.278769  4233 net.cpp:395] conv1/relu -> conv1 (in-place)
I1015 15:32:52.279412  4233 net.cpp:150] Setting up conv1/relu
I1015 15:32:52.279424  4233 net.cpp:157] Top shape: 1 64 160 240 (2457600)
I1015 15:32:52.279428  4233 net.cpp:165] Memory required for data: 95846464
I1015 15:32:52.279430  4233 layer_factory.hpp:77] Creating layer conv2/dw
I1015 15:32:52.279438  4233 net.cpp:100] Creating Layer conv2/dw
I1015 15:32:52.279440  4233 net.cpp:434] conv2/dw <- conv1
I1015 15:32:52.279445  4233 net.cpp:408] conv2/dw -> conv2/dw
I1015 15:32:52.279651  4233 net.cpp:150] Setting up conv2/dw
I1015 15:32:52.279659  4233 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 15:32:52.279661  4233 net.cpp:165] Memory required for data: 98304064
I1015 15:32:52.279665  4233 layer_factory.hpp:77] Creating layer conv2/dw/bn
I1015 15:32:52.279670  4233 net.cpp:100] Creating Layer conv2/dw/bn
I1015 15:32:52.279672  4233 net.cpp:434] conv2/dw/bn <- conv2/dw
I1015 15:32:52.279675  4233 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I1015 15:32:52.279868  4233 net.cpp:150] Setting up conv2/dw/bn
I1015 15:32:52.279875  4233 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 15:32:52.279878  4233 net.cpp:165] Memory required for data: 100761664
I1015 15:32:52.279883  4233 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 15:32:52.279891  4233 net.cpp:100] Creating Layer conv2/dw/scale
I1015 15:32:52.279892  4233 net.cpp:434] conv2/dw/scale <- conv2/dw
I1015 15:32:52.279896  4233 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I1015 15:32:52.279933  4233 layer_factory.hpp:77] Creating layer conv2/dw/scale
I1015 15:32:52.280047  4233 net.cpp:150] Setting up conv2/dw/scale
I1015 15:32:52.280055  4233 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 15:32:52.280056  4233 net.cpp:165] Memory required for data: 103219264
I1015 15:32:52.280061  4233 layer_factory.hpp:77] Creating layer conv2/dw/relu
I1015 15:32:52.280066  4233 net.cpp:100] Creating Layer conv2/dw/relu
I1015 15:32:52.280067  4233 net.cpp:434] conv2/dw/relu <- conv2/dw
I1015 15:32:52.280071  4233 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I1015 15:32:52.280388  4233 net.cpp:150] Setting up conv2/dw/relu
I1015 15:32:52.280396  4233 net.cpp:157] Top shape: 1 64 80 120 (614400)
I1015 15:32:52.280400  4233 net.cpp:165] Memory required for data: 105676864
I1015 15:32:52.280401  4233 layer_factory.hpp:77] Creating layer conv2
I1015 15:32:52.280408  4233 net.cpp:100] Creating Layer conv2
I1015 15:32:52.280411  4233 net.cpp:434] conv2 <- conv2/dw
I1015 15:32:52.280414  4233 net.cpp:408] conv2 -> conv2
I1015 15:32:52.282012  4233 net.cpp:150] Setting up conv2
I1015 15:32:52.282024  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.282027  4233 net.cpp:165] Memory required for data: 110592064
I1015 15:32:52.282032  4233 layer_factory.hpp:77] Creating layer conv2/bn
I1015 15:32:52.282037  4233 net.cpp:100] Creating Layer conv2/bn
I1015 15:32:52.282039  4233 net.cpp:434] conv2/bn <- conv2
I1015 15:32:52.282042  4233 net.cpp:395] conv2/bn -> conv2 (in-place)
I1015 15:32:52.282232  4233 net.cpp:150] Setting up conv2/bn
I1015 15:32:52.282238  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.282240  4233 net.cpp:165] Memory required for data: 115507264
I1015 15:32:52.282245  4233 layer_factory.hpp:77] Creating layer conv2/scale
I1015 15:32:52.282250  4233 net.cpp:100] Creating Layer conv2/scale
I1015 15:32:52.282253  4233 net.cpp:434] conv2/scale <- conv2
I1015 15:32:52.282258  4233 net.cpp:395] conv2/scale -> conv2 (in-place)
I1015 15:32:52.282292  4233 layer_factory.hpp:77] Creating layer conv2/scale
I1015 15:32:52.282400  4233 net.cpp:150] Setting up conv2/scale
I1015 15:32:52.282405  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.282408  4233 net.cpp:165] Memory required for data: 120422464
I1015 15:32:52.282413  4233 layer_factory.hpp:77] Creating layer conv2/relu
I1015 15:32:52.282416  4233 net.cpp:100] Creating Layer conv2/relu
I1015 15:32:52.282418  4233 net.cpp:434] conv2/relu <- conv2
I1015 15:32:52.282423  4233 net.cpp:395] conv2/relu -> conv2 (in-place)
I1015 15:32:52.282743  4233 net.cpp:150] Setting up conv2/relu
I1015 15:32:52.282752  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.282754  4233 net.cpp:165] Memory required for data: 125337664
I1015 15:32:52.282757  4233 layer_factory.hpp:77] Creating layer conv3/dw
I1015 15:32:52.282763  4233 net.cpp:100] Creating Layer conv3/dw
I1015 15:32:52.282765  4233 net.cpp:434] conv3/dw <- conv2
I1015 15:32:52.282769  4233 net.cpp:408] conv3/dw -> conv3/dw
I1015 15:32:52.282970  4233 net.cpp:150] Setting up conv3/dw
I1015 15:32:52.282977  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.282979  4233 net.cpp:165] Memory required for data: 130252864
I1015 15:32:52.282984  4233 layer_factory.hpp:77] Creating layer conv3/dw/bn
I1015 15:32:52.282987  4233 net.cpp:100] Creating Layer conv3/dw/bn
I1015 15:32:52.282989  4233 net.cpp:434] conv3/dw/bn <- conv3/dw
I1015 15:32:52.282992  4233 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I1015 15:32:52.283169  4233 net.cpp:150] Setting up conv3/dw/bn
I1015 15:32:52.283175  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.283177  4233 net.cpp:165] Memory required for data: 135168064
I1015 15:32:52.283185  4233 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 15:32:52.283190  4233 net.cpp:100] Creating Layer conv3/dw/scale
I1015 15:32:52.283193  4233 net.cpp:434] conv3/dw/scale <- conv3/dw
I1015 15:32:52.283197  4233 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I1015 15:32:52.283232  4233 layer_factory.hpp:77] Creating layer conv3/dw/scale
I1015 15:32:52.283335  4233 net.cpp:150] Setting up conv3/dw/scale
I1015 15:32:52.283342  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.283344  4233 net.cpp:165] Memory required for data: 140083264
I1015 15:32:52.283349  4233 layer_factory.hpp:77] Creating layer conv3/dw/relu
I1015 15:32:52.283352  4233 net.cpp:100] Creating Layer conv3/dw/relu
I1015 15:32:52.283355  4233 net.cpp:434] conv3/dw/relu <- conv3/dw
I1015 15:32:52.283358  4233 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I1015 15:32:52.284006  4233 net.cpp:150] Setting up conv3/dw/relu
I1015 15:32:52.284018  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.284020  4233 net.cpp:165] Memory required for data: 144998464
I1015 15:32:52.284024  4233 layer_factory.hpp:77] Creating layer conv3
I1015 15:32:52.284029  4233 net.cpp:100] Creating Layer conv3
I1015 15:32:52.284032  4233 net.cpp:434] conv3 <- conv3/dw
I1015 15:32:52.284037  4233 net.cpp:408] conv3 -> conv3
I1015 15:32:52.285676  4233 net.cpp:150] Setting up conv3
I1015 15:32:52.285687  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.285689  4233 net.cpp:165] Memory required for data: 149913664
I1015 15:32:52.285694  4233 layer_factory.hpp:77] Creating layer conv3/bn
I1015 15:32:52.285698  4233 net.cpp:100] Creating Layer conv3/bn
I1015 15:32:52.285701  4233 net.cpp:434] conv3/bn <- conv3
I1015 15:32:52.285706  4233 net.cpp:395] conv3/bn -> conv3 (in-place)
I1015 15:32:52.285899  4233 net.cpp:150] Setting up conv3/bn
I1015 15:32:52.285907  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.285908  4233 net.cpp:165] Memory required for data: 154828864
I1015 15:32:52.285913  4233 layer_factory.hpp:77] Creating layer conv3/scale
I1015 15:32:52.285919  4233 net.cpp:100] Creating Layer conv3/scale
I1015 15:32:52.285923  4233 net.cpp:434] conv3/scale <- conv3
I1015 15:32:52.285925  4233 net.cpp:395] conv3/scale -> conv3 (in-place)
I1015 15:32:52.285961  4233 layer_factory.hpp:77] Creating layer conv3/scale
I1015 15:32:52.286069  4233 net.cpp:150] Setting up conv3/scale
I1015 15:32:52.286075  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.286077  4233 net.cpp:165] Memory required for data: 159744064
I1015 15:32:52.286082  4233 layer_factory.hpp:77] Creating layer conv3/relu
I1015 15:32:52.286085  4233 net.cpp:100] Creating Layer conv3/relu
I1015 15:32:52.286087  4233 net.cpp:434] conv3/relu <- conv3
I1015 15:32:52.286092  4233 net.cpp:395] conv3/relu -> conv3 (in-place)
I1015 15:32:52.286417  4233 net.cpp:150] Setting up conv3/relu
I1015 15:32:52.286427  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.286428  4233 net.cpp:165] Memory required for data: 164659264
I1015 15:32:52.286432  4233 layer_factory.hpp:77] Creating layer conv3_conv3/relu_0_split
I1015 15:32:52.286437  4233 net.cpp:100] Creating Layer conv3_conv3/relu_0_split
I1015 15:32:52.286438  4233 net.cpp:434] conv3_conv3/relu_0_split <- conv3
I1015 15:32:52.286442  4233 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_0
I1015 15:32:52.286448  4233 net.cpp:408] conv3_conv3/relu_0_split -> conv3_conv3/relu_0_split_1
I1015 15:32:52.286489  4233 net.cpp:150] Setting up conv3_conv3/relu_0_split
I1015 15:32:52.286494  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.286496  4233 net.cpp:157] Top shape: 1 128 80 120 (1228800)
I1015 15:32:52.286499  4233 net.cpp:165] Memory required for data: 174489664
I1015 15:32:52.286501  4233 layer_factory.hpp:77] Creating layer conv4/dw
I1015 15:32:52.286509  4233 net.cpp:100] Creating Layer conv4/dw
I1015 15:32:52.286510  4233 net.cpp:434] conv4/dw <- conv3_conv3/relu_0_split_0
I1015 15:32:52.286514  4233 net.cpp:408] conv4/dw -> conv4/dw
I1015 15:32:52.286703  4233 net.cpp:150] Setting up conv4/dw
I1015 15:32:52.286710  4233 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 15:32:52.286712  4233 net.cpp:165] Memory required for data: 175718464
I1015 15:32:52.286715  4233 layer_factory.hpp:77] Creating layer conv4/dw/bn
I1015 15:32:52.286721  4233 net.cpp:100] Creating Layer conv4/dw/bn
I1015 15:32:52.286725  4233 net.cpp:434] conv4/dw/bn <- conv4/dw
I1015 15:32:52.286728  4233 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I1015 15:32:52.286916  4233 net.cpp:150] Setting up conv4/dw/bn
I1015 15:32:52.286922  4233 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 15:32:52.286924  4233 net.cpp:165] Memory required for data: 176947264
I1015 15:32:52.286931  4233 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 15:32:52.286936  4233 net.cpp:100] Creating Layer conv4/dw/scale
I1015 15:32:52.286937  4233 net.cpp:434] conv4/dw/scale <- conv4/dw
I1015 15:32:52.286942  4233 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I1015 15:32:52.286976  4233 layer_factory.hpp:77] Creating layer conv4/dw/scale
I1015 15:32:52.287081  4233 net.cpp:150] Setting up conv4/dw/scale
I1015 15:32:52.287087  4233 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 15:32:52.287091  4233 net.cpp:165] Memory required for data: 178176064
I1015 15:32:52.287094  4233 layer_factory.hpp:77] Creating layer conv4/dw/relu
I1015 15:32:52.287098  4233 net.cpp:100] Creating Layer conv4/dw/relu
I1015 15:32:52.287101  4233 net.cpp:434] conv4/dw/relu <- conv4/dw
I1015 15:32:52.287103  4233 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I1015 15:32:52.287425  4233 net.cpp:150] Setting up conv4/dw/relu
I1015 15:32:52.287434  4233 net.cpp:157] Top shape: 1 128 40 60 (307200)
I1015 15:32:52.287436  4233 net.cpp:165] Memory required for data: 179404864
I1015 15:32:52.287439  4233 layer_factory.hpp:77] Creating layer conv4
I1015 15:32:52.287446  4233 net.cpp:100] Creating Layer conv4
I1015 15:32:52.287448  4233 net.cpp:434] conv4 <- conv4/dw
I1015 15:32:52.287452  4233 net.cpp:408] conv4 -> conv4
I1015 15:32:52.289274  4233 net.cpp:150] Setting up conv4
I1015 15:32:52.289285  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.289288  4233 net.cpp:165] Memory required for data: 181862464
I1015 15:32:52.289292  4233 layer_factory.hpp:77] Creating layer conv4/bn
I1015 15:32:52.289297  4233 net.cpp:100] Creating Layer conv4/bn
I1015 15:32:52.289300  4233 net.cpp:434] conv4/bn <- conv4
I1015 15:32:52.289304  4233 net.cpp:395] conv4/bn -> conv4 (in-place)
I1015 15:32:52.289492  4233 net.cpp:150] Setting up conv4/bn
I1015 15:32:52.289499  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.289500  4233 net.cpp:165] Memory required for data: 184320064
I1015 15:32:52.289505  4233 layer_factory.hpp:77] Creating layer conv4/scale
I1015 15:32:52.289510  4233 net.cpp:100] Creating Layer conv4/scale
I1015 15:32:52.289512  4233 net.cpp:434] conv4/scale <- conv4
I1015 15:32:52.289516  4233 net.cpp:395] conv4/scale -> conv4 (in-place)
I1015 15:32:52.289561  4233 layer_factory.hpp:77] Creating layer conv4/scale
I1015 15:32:52.289687  4233 net.cpp:150] Setting up conv4/scale
I1015 15:32:52.289695  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.289696  4233 net.cpp:165] Memory required for data: 186777664
I1015 15:32:52.289700  4233 layer_factory.hpp:77] Creating layer conv4/relu
I1015 15:32:52.289705  4233 net.cpp:100] Creating Layer conv4/relu
I1015 15:32:52.289707  4233 net.cpp:434] conv4/relu <- conv4
I1015 15:32:52.289711  4233 net.cpp:395] conv4/relu -> conv4 (in-place)
I1015 15:32:52.290697  4233 net.cpp:150] Setting up conv4/relu
I1015 15:32:52.290710  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.290714  4233 net.cpp:165] Memory required for data: 189235264
I1015 15:32:52.290719  4233 layer_factory.hpp:77] Creating layer conv5/dw
I1015 15:32:52.290727  4233 net.cpp:100] Creating Layer conv5/dw
I1015 15:32:52.290730  4233 net.cpp:434] conv5/dw <- conv4
I1015 15:32:52.290736  4233 net.cpp:408] conv5/dw -> conv5/dw
I1015 15:32:52.290982  4233 net.cpp:150] Setting up conv5/dw
I1015 15:32:52.290990  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.290994  4233 net.cpp:165] Memory required for data: 191692864
I1015 15:32:52.291000  4233 layer_factory.hpp:77] Creating layer conv5/dw/bn
I1015 15:32:52.291004  4233 net.cpp:100] Creating Layer conv5/dw/bn
I1015 15:32:52.291007  4233 net.cpp:434] conv5/dw/bn <- conv5/dw
I1015 15:32:52.291010  4233 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I1015 15:32:52.291213  4233 net.cpp:150] Setting up conv5/dw/bn
I1015 15:32:52.291220  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.291224  4233 net.cpp:165] Memory required for data: 194150464
I1015 15:32:52.291230  4233 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 15:32:52.291235  4233 net.cpp:100] Creating Layer conv5/dw/scale
I1015 15:32:52.291239  4233 net.cpp:434] conv5/dw/scale <- conv5/dw
I1015 15:32:52.291241  4233 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I1015 15:32:52.291283  4233 layer_factory.hpp:77] Creating layer conv5/dw/scale
I1015 15:32:52.291406  4233 net.cpp:150] Setting up conv5/dw/scale
I1015 15:32:52.291414  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.291417  4233 net.cpp:165] Memory required for data: 196608064
I1015 15:32:52.291424  4233 layer_factory.hpp:77] Creating layer conv5/dw/relu
I1015 15:32:52.291429  4233 net.cpp:100] Creating Layer conv5/dw/relu
I1015 15:32:52.291430  4233 net.cpp:434] conv5/dw/relu <- conv5/dw
I1015 15:32:52.291435  4233 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I1015 15:32:52.291776  4233 net.cpp:150] Setting up conv5/dw/relu
I1015 15:32:52.291786  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.291790  4233 net.cpp:165] Memory required for data: 199065664
I1015 15:32:52.291793  4233 layer_factory.hpp:77] Creating layer conv5
I1015 15:32:52.291801  4233 net.cpp:100] Creating Layer conv5
I1015 15:32:52.291805  4233 net.cpp:434] conv5 <- conv5/dw
I1015 15:32:52.291808  4233 net.cpp:408] conv5 -> conv5
I1015 15:32:52.294195  4233 net.cpp:150] Setting up conv5
I1015 15:32:52.294209  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.294212  4233 net.cpp:165] Memory required for data: 201523264
I1015 15:32:52.294219  4233 layer_factory.hpp:77] Creating layer conv5/bn
I1015 15:32:52.294225  4233 net.cpp:100] Creating Layer conv5/bn
I1015 15:32:52.294227  4233 net.cpp:434] conv5/bn <- conv5
I1015 15:32:52.294232  4233 net.cpp:395] conv5/bn -> conv5 (in-place)
I1015 15:32:52.294453  4233 net.cpp:150] Setting up conv5/bn
I1015 15:32:52.294459  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.294462  4233 net.cpp:165] Memory required for data: 203980864
I1015 15:32:52.294467  4233 layer_factory.hpp:77] Creating layer conv5/scale
I1015 15:32:52.294472  4233 net.cpp:100] Creating Layer conv5/scale
I1015 15:32:52.294474  4233 net.cpp:434] conv5/scale <- conv5
I1015 15:32:52.294478  4233 net.cpp:395] conv5/scale -> conv5 (in-place)
I1015 15:32:52.294526  4233 layer_factory.hpp:77] Creating layer conv5/scale
I1015 15:32:52.294647  4233 net.cpp:150] Setting up conv5/scale
I1015 15:32:52.294653  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.294656  4233 net.cpp:165] Memory required for data: 206438464
I1015 15:32:52.294665  4233 layer_factory.hpp:77] Creating layer conv5/relu
I1015 15:32:52.294669  4233 net.cpp:100] Creating Layer conv5/relu
I1015 15:32:52.294672  4233 net.cpp:434] conv5/relu <- conv5
I1015 15:32:52.294675  4233 net.cpp:395] conv5/relu -> conv5 (in-place)
I1015 15:32:52.295243  4233 net.cpp:150] Setting up conv5/relu
I1015 15:32:52.295253  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.295256  4233 net.cpp:165] Memory required for data: 208896064
I1015 15:32:52.295260  4233 layer_factory.hpp:77] Creating layer conv5_conv5/relu_0_split
I1015 15:32:52.295266  4233 net.cpp:100] Creating Layer conv5_conv5/relu_0_split
I1015 15:32:52.295269  4233 net.cpp:434] conv5_conv5/relu_0_split <- conv5
I1015 15:32:52.295274  4233 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_0
I1015 15:32:52.295279  4233 net.cpp:408] conv5_conv5/relu_0_split -> conv5_conv5/relu_0_split_1
I1015 15:32:52.295326  4233 net.cpp:150] Setting up conv5_conv5/relu_0_split
I1015 15:32:52.295331  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.295334  4233 net.cpp:157] Top shape: 1 256 40 60 (614400)
I1015 15:32:52.295336  4233 net.cpp:165] Memory required for data: 213811264
I1015 15:32:52.295338  4233 layer_factory.hpp:77] Creating layer conv6/dw
I1015 15:32:52.295346  4233 net.cpp:100] Creating Layer conv6/dw
I1015 15:32:52.295347  4233 net.cpp:434] conv6/dw <- conv5_conv5/relu_0_split_0
I1015 15:32:52.295353  4233 net.cpp:408] conv6/dw -> conv6/dw
I1015 15:32:52.295595  4233 net.cpp:150] Setting up conv6/dw
I1015 15:32:52.295603  4233 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 15:32:52.295608  4233 net.cpp:165] Memory required for data: 214425664
I1015 15:32:52.295612  4233 layer_factory.hpp:77] Creating layer conv6/dw/bn
I1015 15:32:52.295617  4233 net.cpp:100] Creating Layer conv6/dw/bn
I1015 15:32:52.295619  4233 net.cpp:434] conv6/dw/bn <- conv6/dw
I1015 15:32:52.295624  4233 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I1015 15:32:52.295838  4233 net.cpp:150] Setting up conv6/dw/bn
I1015 15:32:52.295846  4233 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 15:32:52.295850  4233 net.cpp:165] Memory required for data: 215040064
I1015 15:32:52.295857  4233 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 15:32:52.295862  4233 net.cpp:100] Creating Layer conv6/dw/scale
I1015 15:32:52.295864  4233 net.cpp:434] conv6/dw/scale <- conv6/dw
I1015 15:32:52.295868  4233 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I1015 15:32:52.295910  4233 layer_factory.hpp:77] Creating layer conv6/dw/scale
I1015 15:32:52.296048  4233 net.cpp:150] Setting up conv6/dw/scale
I1015 15:32:52.296056  4233 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 15:32:52.296059  4233 net.cpp:165] Memory required for data: 215654464
I1015 15:32:52.296066  4233 layer_factory.hpp:77] Creating layer conv6/dw/relu
I1015 15:32:52.296070  4233 net.cpp:100] Creating Layer conv6/dw/relu
I1015 15:32:52.296072  4233 net.cpp:434] conv6/dw/relu <- conv6/dw
I1015 15:32:52.296077  4233 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I1015 15:32:52.296417  4233 net.cpp:150] Setting up conv6/dw/relu
I1015 15:32:52.296427  4233 net.cpp:157] Top shape: 1 256 20 30 (153600)
I1015 15:32:52.296432  4233 net.cpp:165] Memory required for data: 216268864
I1015 15:32:52.296435  4233 layer_factory.hpp:77] Creating layer conv6
I1015 15:32:52.296442  4233 net.cpp:100] Creating Layer conv6
I1015 15:32:52.296445  4233 net.cpp:434] conv6 <- conv6/dw
I1015 15:32:52.296450  4233 net.cpp:408] conv6 -> conv6
I1015 15:32:52.299082  4233 net.cpp:150] Setting up conv6
I1015 15:32:52.299095  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.299099  4233 net.cpp:165] Memory required for data: 217497664
I1015 15:32:52.299106  4233 layer_factory.hpp:77] Creating layer conv6/bn
I1015 15:32:52.299111  4233 net.cpp:100] Creating Layer conv6/bn
I1015 15:32:52.299114  4233 net.cpp:434] conv6/bn <- conv6
I1015 15:32:52.299118  4233 net.cpp:395] conv6/bn -> conv6 (in-place)
I1015 15:32:52.299337  4233 net.cpp:150] Setting up conv6/bn
I1015 15:32:52.299346  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.299350  4233 net.cpp:165] Memory required for data: 218726464
I1015 15:32:52.299356  4233 layer_factory.hpp:77] Creating layer conv6/scale
I1015 15:32:52.299362  4233 net.cpp:100] Creating Layer conv6/scale
I1015 15:32:52.299365  4233 net.cpp:434] conv6/scale <- conv6
I1015 15:32:52.299369  4233 net.cpp:395] conv6/scale -> conv6 (in-place)
I1015 15:32:52.299418  4233 layer_factory.hpp:77] Creating layer conv6/scale
I1015 15:32:52.299542  4233 net.cpp:150] Setting up conv6/scale
I1015 15:32:52.299548  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.299551  4233 net.cpp:165] Memory required for data: 219955264
I1015 15:32:52.299556  4233 layer_factory.hpp:77] Creating layer conv6/relu
I1015 15:32:52.299559  4233 net.cpp:100] Creating Layer conv6/relu
I1015 15:32:52.299561  4233 net.cpp:434] conv6/relu <- conv6
I1015 15:32:52.299566  4233 net.cpp:395] conv6/relu -> conv6 (in-place)
I1015 15:32:52.300245  4233 net.cpp:150] Setting up conv6/relu
I1015 15:32:52.300257  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.300261  4233 net.cpp:165] Memory required for data: 221184064
I1015 15:32:52.300266  4233 layer_factory.hpp:77] Creating layer conv7/dw
I1015 15:32:52.300274  4233 net.cpp:100] Creating Layer conv7/dw
I1015 15:32:52.300277  4233 net.cpp:434] conv7/dw <- conv6
I1015 15:32:52.300282  4233 net.cpp:408] conv7/dw -> conv7/dw
I1015 15:32:52.300544  4233 net.cpp:150] Setting up conv7/dw
I1015 15:32:52.300554  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.300557  4233 net.cpp:165] Memory required for data: 222412864
I1015 15:32:52.300562  4233 layer_factory.hpp:77] Creating layer conv7/dw/bn
I1015 15:32:52.300566  4233 net.cpp:100] Creating Layer conv7/dw/bn
I1015 15:32:52.300570  4233 net.cpp:434] conv7/dw/bn <- conv7/dw
I1015 15:32:52.300572  4233 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I1015 15:32:52.300783  4233 net.cpp:150] Setting up conv7/dw/bn
I1015 15:32:52.300791  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.300796  4233 net.cpp:165] Memory required for data: 223641664
I1015 15:32:52.300802  4233 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 15:32:52.300807  4233 net.cpp:100] Creating Layer conv7/dw/scale
I1015 15:32:52.300809  4233 net.cpp:434] conv7/dw/scale <- conv7/dw
I1015 15:32:52.300812  4233 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I1015 15:32:52.300858  4233 layer_factory.hpp:77] Creating layer conv7/dw/scale
I1015 15:32:52.300987  4233 net.cpp:150] Setting up conv7/dw/scale
I1015 15:32:52.300994  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.300998  4233 net.cpp:165] Memory required for data: 224870464
I1015 15:32:52.301004  4233 layer_factory.hpp:77] Creating layer conv7/dw/relu
I1015 15:32:52.301008  4233 net.cpp:100] Creating Layer conv7/dw/relu
I1015 15:32:52.301012  4233 net.cpp:434] conv7/dw/relu <- conv7/dw
I1015 15:32:52.301014  4233 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I1015 15:32:52.301400  4233 net.cpp:150] Setting up conv7/dw/relu
I1015 15:32:52.301410  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.301414  4233 net.cpp:165] Memory required for data: 226099264
I1015 15:32:52.301419  4233 layer_factory.hpp:77] Creating layer conv7
I1015 15:32:52.301425  4233 net.cpp:100] Creating Layer conv7
I1015 15:32:52.301429  4233 net.cpp:434] conv7 <- conv7/dw
I1015 15:32:52.301432  4233 net.cpp:408] conv7 -> conv7
I1015 15:32:52.305934  4233 net.cpp:150] Setting up conv7
I1015 15:32:52.305950  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.305954  4233 net.cpp:165] Memory required for data: 227328064
I1015 15:32:52.305961  4233 layer_factory.hpp:77] Creating layer conv7/bn
I1015 15:32:52.305966  4233 net.cpp:100] Creating Layer conv7/bn
I1015 15:32:52.305970  4233 net.cpp:434] conv7/bn <- conv7
I1015 15:32:52.305976  4233 net.cpp:395] conv7/bn -> conv7 (in-place)
I1015 15:32:52.306201  4233 net.cpp:150] Setting up conv7/bn
I1015 15:32:52.306210  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.306213  4233 net.cpp:165] Memory required for data: 228556864
I1015 15:32:52.306221  4233 layer_factory.hpp:77] Creating layer conv7/scale
I1015 15:32:52.306227  4233 net.cpp:100] Creating Layer conv7/scale
I1015 15:32:52.306231  4233 net.cpp:434] conv7/scale <- conv7
I1015 15:32:52.306236  4233 net.cpp:395] conv7/scale -> conv7 (in-place)
I1015 15:32:52.306288  4233 layer_factory.hpp:77] Creating layer conv7/scale
I1015 15:32:52.306422  4233 net.cpp:150] Setting up conv7/scale
I1015 15:32:52.306430  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.306434  4233 net.cpp:165] Memory required for data: 229785664
I1015 15:32:52.306440  4233 layer_factory.hpp:77] Creating layer conv7/relu
I1015 15:32:52.306444  4233 net.cpp:100] Creating Layer conv7/relu
I1015 15:32:52.306448  4233 net.cpp:434] conv7/relu <- conv7
I1015 15:32:52.306453  4233 net.cpp:395] conv7/relu -> conv7 (in-place)
I1015 15:32:52.306852  4233 net.cpp:150] Setting up conv7/relu
I1015 15:32:52.306862  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.306866  4233 net.cpp:165] Memory required for data: 231014464
I1015 15:32:52.306870  4233 layer_factory.hpp:77] Creating layer conv8/dw
I1015 15:32:52.306890  4233 net.cpp:100] Creating Layer conv8/dw
I1015 15:32:52.306892  4233 net.cpp:434] conv8/dw <- conv7
I1015 15:32:52.306897  4233 net.cpp:408] conv8/dw -> conv8/dw
I1015 15:32:52.307163  4233 net.cpp:150] Setting up conv8/dw
I1015 15:32:52.307171  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.307175  4233 net.cpp:165] Memory required for data: 232243264
I1015 15:32:52.307181  4233 layer_factory.hpp:77] Creating layer conv8/dw/bn
I1015 15:32:52.307188  4233 net.cpp:100] Creating Layer conv8/dw/bn
I1015 15:32:52.307193  4233 net.cpp:434] conv8/dw/bn <- conv8/dw
I1015 15:32:52.307196  4233 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I1015 15:32:52.307410  4233 net.cpp:150] Setting up conv8/dw/bn
I1015 15:32:52.307422  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.307426  4233 net.cpp:165] Memory required for data: 233472064
I1015 15:32:52.307432  4233 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 15:32:52.307438  4233 net.cpp:100] Creating Layer conv8/dw/scale
I1015 15:32:52.307443  4233 net.cpp:434] conv8/dw/scale <- conv8/dw
I1015 15:32:52.307446  4233 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I1015 15:32:52.307502  4233 layer_factory.hpp:77] Creating layer conv8/dw/scale
I1015 15:32:52.307632  4233 net.cpp:150] Setting up conv8/dw/scale
I1015 15:32:52.307641  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.307644  4233 net.cpp:165] Memory required for data: 234700864
I1015 15:32:52.307651  4233 layer_factory.hpp:77] Creating layer conv8/dw/relu
I1015 15:32:52.307655  4233 net.cpp:100] Creating Layer conv8/dw/relu
I1015 15:32:52.307658  4233 net.cpp:434] conv8/dw/relu <- conv8/dw
I1015 15:32:52.307662  4233 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I1015 15:32:52.308383  4233 net.cpp:150] Setting up conv8/dw/relu
I1015 15:32:52.308396  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.308400  4233 net.cpp:165] Memory required for data: 235929664
I1015 15:32:52.308405  4233 layer_factory.hpp:77] Creating layer conv8
I1015 15:32:52.308414  4233 net.cpp:100] Creating Layer conv8
I1015 15:32:52.308419  4233 net.cpp:434] conv8 <- conv8/dw
I1015 15:32:52.308429  4233 net.cpp:408] conv8 -> conv8
I1015 15:32:52.312093  4233 net.cpp:150] Setting up conv8
I1015 15:32:52.312105  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.312111  4233 net.cpp:165] Memory required for data: 237158464
I1015 15:32:52.312119  4233 layer_factory.hpp:77] Creating layer conv8/bn
I1015 15:32:52.312124  4233 net.cpp:100] Creating Layer conv8/bn
I1015 15:32:52.312127  4233 net.cpp:434] conv8/bn <- conv8
I1015 15:32:52.312134  4233 net.cpp:395] conv8/bn -> conv8 (in-place)
I1015 15:32:52.312364  4233 net.cpp:150] Setting up conv8/bn
I1015 15:32:52.312373  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.312377  4233 net.cpp:165] Memory required for data: 238387264
I1015 15:32:52.312384  4233 layer_factory.hpp:77] Creating layer conv8/scale
I1015 15:32:52.312391  4233 net.cpp:100] Creating Layer conv8/scale
I1015 15:32:52.312397  4233 net.cpp:434] conv8/scale <- conv8
I1015 15:32:52.312400  4233 net.cpp:395] conv8/scale -> conv8 (in-place)
I1015 15:32:52.312455  4233 layer_factory.hpp:77] Creating layer conv8/scale
I1015 15:32:52.312595  4233 net.cpp:150] Setting up conv8/scale
I1015 15:32:52.312603  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.312608  4233 net.cpp:165] Memory required for data: 239616064
I1015 15:32:52.312613  4233 layer_factory.hpp:77] Creating layer conv8/relu
I1015 15:32:52.312618  4233 net.cpp:100] Creating Layer conv8/relu
I1015 15:32:52.312623  4233 net.cpp:434] conv8/relu <- conv8
I1015 15:32:52.312626  4233 net.cpp:395] conv8/relu -> conv8 (in-place)
I1015 15:32:52.313032  4233 net.cpp:150] Setting up conv8/relu
I1015 15:32:52.313043  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.313046  4233 net.cpp:165] Memory required for data: 240844864
I1015 15:32:52.313050  4233 layer_factory.hpp:77] Creating layer conv9/dw
I1015 15:32:52.313060  4233 net.cpp:100] Creating Layer conv9/dw
I1015 15:32:52.313066  4233 net.cpp:434] conv9/dw <- conv8
I1015 15:32:52.313072  4233 net.cpp:408] conv9/dw -> conv9/dw
I1015 15:32:52.313331  4233 net.cpp:150] Setting up conv9/dw
I1015 15:32:52.313340  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.313344  4233 net.cpp:165] Memory required for data: 242073664
I1015 15:32:52.313349  4233 layer_factory.hpp:77] Creating layer conv9/dw/bn
I1015 15:32:52.313356  4233 net.cpp:100] Creating Layer conv9/dw/bn
I1015 15:32:52.313359  4233 net.cpp:434] conv9/dw/bn <- conv9/dw
I1015 15:32:52.313364  4233 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I1015 15:32:52.313573  4233 net.cpp:150] Setting up conv9/dw/bn
I1015 15:32:52.313581  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.313585  4233 net.cpp:165] Memory required for data: 243302464
I1015 15:32:52.313592  4233 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 15:32:52.313601  4233 net.cpp:100] Creating Layer conv9/dw/scale
I1015 15:32:52.313604  4233 net.cpp:434] conv9/dw/scale <- conv9/dw
I1015 15:32:52.313608  4233 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I1015 15:32:52.313661  4233 layer_factory.hpp:77] Creating layer conv9/dw/scale
I1015 15:32:52.313789  4233 net.cpp:150] Setting up conv9/dw/scale
I1015 15:32:52.313797  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.313800  4233 net.cpp:165] Memory required for data: 244531264
I1015 15:32:52.313807  4233 layer_factory.hpp:77] Creating layer conv9/dw/relu
I1015 15:32:52.313814  4233 net.cpp:100] Creating Layer conv9/dw/relu
I1015 15:32:52.313817  4233 net.cpp:434] conv9/dw/relu <- conv9/dw
I1015 15:32:52.313825  4233 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I1015 15:32:52.314215  4233 net.cpp:150] Setting up conv9/dw/relu
I1015 15:32:52.314227  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.314230  4233 net.cpp:165] Memory required for data: 245760064
I1015 15:32:52.314234  4233 layer_factory.hpp:77] Creating layer conv9
I1015 15:32:52.314244  4233 net.cpp:100] Creating Layer conv9
I1015 15:32:52.314247  4233 net.cpp:434] conv9 <- conv9/dw
I1015 15:32:52.314252  4233 net.cpp:408] conv9 -> conv9
I1015 15:32:52.319007  4233 net.cpp:150] Setting up conv9
I1015 15:32:52.319025  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.319030  4233 net.cpp:165] Memory required for data: 246988864
I1015 15:32:52.319036  4233 layer_factory.hpp:77] Creating layer conv9/bn
I1015 15:32:52.319044  4233 net.cpp:100] Creating Layer conv9/bn
I1015 15:32:52.319048  4233 net.cpp:434] conv9/bn <- conv9
I1015 15:32:52.319052  4233 net.cpp:395] conv9/bn -> conv9 (in-place)
I1015 15:32:52.319288  4233 net.cpp:150] Setting up conv9/bn
I1015 15:32:52.319295  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.319299  4233 net.cpp:165] Memory required for data: 248217664
I1015 15:32:52.319305  4233 layer_factory.hpp:77] Creating layer conv9/scale
I1015 15:32:52.319314  4233 net.cpp:100] Creating Layer conv9/scale
I1015 15:32:52.319317  4233 net.cpp:434] conv9/scale <- conv9
I1015 15:32:52.319321  4233 net.cpp:395] conv9/scale -> conv9 (in-place)
I1015 15:32:52.319375  4233 layer_factory.hpp:77] Creating layer conv9/scale
I1015 15:32:52.319509  4233 net.cpp:150] Setting up conv9/scale
I1015 15:32:52.319517  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.319521  4233 net.cpp:165] Memory required for data: 249446464
I1015 15:32:52.319526  4233 layer_factory.hpp:77] Creating layer conv9/relu
I1015 15:32:52.319532  4233 net.cpp:100] Creating Layer conv9/relu
I1015 15:32:52.319536  4233 net.cpp:434] conv9/relu <- conv9
I1015 15:32:52.319540  4233 net.cpp:395] conv9/relu -> conv9 (in-place)
I1015 15:32:52.320300  4233 net.cpp:150] Setting up conv9/relu
I1015 15:32:52.320313  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.320317  4233 net.cpp:165] Memory required for data: 250675264
I1015 15:32:52.320322  4233 layer_factory.hpp:77] Creating layer conv10/dw
I1015 15:32:52.320333  4233 net.cpp:100] Creating Layer conv10/dw
I1015 15:32:52.320338  4233 net.cpp:434] conv10/dw <- conv9
I1015 15:32:52.320343  4233 net.cpp:408] conv10/dw -> conv10/dw
I1015 15:32:52.320619  4233 net.cpp:150] Setting up conv10/dw
I1015 15:32:52.320628  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.320631  4233 net.cpp:165] Memory required for data: 251904064
I1015 15:32:52.320637  4233 layer_factory.hpp:77] Creating layer conv10/dw/bn
I1015 15:32:52.320641  4233 net.cpp:100] Creating Layer conv10/dw/bn
I1015 15:32:52.320644  4233 net.cpp:434] conv10/dw/bn <- conv10/dw
I1015 15:32:52.320650  4233 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I1015 15:32:52.320870  4233 net.cpp:150] Setting up conv10/dw/bn
I1015 15:32:52.320878  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.320881  4233 net.cpp:165] Memory required for data: 253132864
I1015 15:32:52.320888  4233 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 15:32:52.320894  4233 net.cpp:100] Creating Layer conv10/dw/scale
I1015 15:32:52.320895  4233 net.cpp:434] conv10/dw/scale <- conv10/dw
I1015 15:32:52.320899  4233 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I1015 15:32:52.320947  4233 layer_factory.hpp:77] Creating layer conv10/dw/scale
I1015 15:32:52.321086  4233 net.cpp:150] Setting up conv10/dw/scale
I1015 15:32:52.321096  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.321100  4233 net.cpp:165] Memory required for data: 254361664
I1015 15:32:52.321105  4233 layer_factory.hpp:77] Creating layer conv10/dw/relu
I1015 15:32:52.321108  4233 net.cpp:100] Creating Layer conv10/dw/relu
I1015 15:32:52.321111  4233 net.cpp:434] conv10/dw/relu <- conv10/dw
I1015 15:32:52.321115  4233 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I1015 15:32:52.321507  4233 net.cpp:150] Setting up conv10/dw/relu
I1015 15:32:52.321518  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.321522  4233 net.cpp:165] Memory required for data: 255590464
I1015 15:32:52.321527  4233 layer_factory.hpp:77] Creating layer conv10
I1015 15:32:52.321533  4233 net.cpp:100] Creating Layer conv10
I1015 15:32:52.321537  4233 net.cpp:434] conv10 <- conv10/dw
I1015 15:32:52.321540  4233 net.cpp:408] conv10 -> conv10
I1015 15:32:52.325271  4233 net.cpp:150] Setting up conv10
I1015 15:32:52.325286  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.325290  4233 net.cpp:165] Memory required for data: 256819264
I1015 15:32:52.325297  4233 layer_factory.hpp:77] Creating layer conv10/bn
I1015 15:32:52.325304  4233 net.cpp:100] Creating Layer conv10/bn
I1015 15:32:52.325306  4233 net.cpp:434] conv10/bn <- conv10
I1015 15:32:52.325312  4233 net.cpp:395] conv10/bn -> conv10 (in-place)
I1015 15:32:52.325543  4233 net.cpp:150] Setting up conv10/bn
I1015 15:32:52.325553  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.325557  4233 net.cpp:165] Memory required for data: 258048064
I1015 15:32:52.325563  4233 layer_factory.hpp:77] Creating layer conv10/scale
I1015 15:32:52.325569  4233 net.cpp:100] Creating Layer conv10/scale
I1015 15:32:52.325572  4233 net.cpp:434] conv10/scale <- conv10
I1015 15:32:52.325575  4233 net.cpp:395] conv10/scale -> conv10 (in-place)
I1015 15:32:52.325628  4233 layer_factory.hpp:77] Creating layer conv10/scale
I1015 15:32:52.325768  4233 net.cpp:150] Setting up conv10/scale
I1015 15:32:52.325776  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.325780  4233 net.cpp:165] Memory required for data: 259276864
I1015 15:32:52.325786  4233 layer_factory.hpp:77] Creating layer conv10/relu
I1015 15:32:52.325790  4233 net.cpp:100] Creating Layer conv10/relu
I1015 15:32:52.325793  4233 net.cpp:434] conv10/relu <- conv10
I1015 15:32:52.325798  4233 net.cpp:395] conv10/relu -> conv10 (in-place)
I1015 15:32:52.326202  4233 net.cpp:150] Setting up conv10/relu
I1015 15:32:52.326213  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.326217  4233 net.cpp:165] Memory required for data: 260505664
I1015 15:32:52.326221  4233 layer_factory.hpp:77] Creating layer conv11/dw
I1015 15:32:52.326231  4233 net.cpp:100] Creating Layer conv11/dw
I1015 15:32:52.326236  4233 net.cpp:434] conv11/dw <- conv10
I1015 15:32:52.326242  4233 net.cpp:408] conv11/dw -> conv11/dw
I1015 15:32:52.326508  4233 net.cpp:150] Setting up conv11/dw
I1015 15:32:52.326516  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.326520  4233 net.cpp:165] Memory required for data: 261734464
I1015 15:32:52.326525  4233 layer_factory.hpp:77] Creating layer conv11/dw/bn
I1015 15:32:52.326531  4233 net.cpp:100] Creating Layer conv11/dw/bn
I1015 15:32:52.326534  4233 net.cpp:434] conv11/dw/bn <- conv11/dw
I1015 15:32:52.326540  4233 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I1015 15:32:52.326758  4233 net.cpp:150] Setting up conv11/dw/bn
I1015 15:32:52.326766  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.326768  4233 net.cpp:165] Memory required for data: 262963264
I1015 15:32:52.326787  4233 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 15:32:52.326794  4233 net.cpp:100] Creating Layer conv11/dw/scale
I1015 15:32:52.326797  4233 net.cpp:434] conv11/dw/scale <- conv11/dw
I1015 15:32:52.326802  4233 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I1015 15:32:52.326855  4233 layer_factory.hpp:77] Creating layer conv11/dw/scale
I1015 15:32:52.326992  4233 net.cpp:150] Setting up conv11/dw/scale
I1015 15:32:52.326999  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.327003  4233 net.cpp:165] Memory required for data: 264192064
I1015 15:32:52.327009  4233 layer_factory.hpp:77] Creating layer conv11/dw/relu
I1015 15:32:52.327013  4233 net.cpp:100] Creating Layer conv11/dw/relu
I1015 15:32:52.327016  4233 net.cpp:434] conv11/dw/relu <- conv11/dw
I1015 15:32:52.327020  4233 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I1015 15:32:52.327422  4233 net.cpp:150] Setting up conv11/dw/relu
I1015 15:32:52.327432  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.327436  4233 net.cpp:165] Memory required for data: 265420864
I1015 15:32:52.327440  4233 layer_factory.hpp:77] Creating layer conv11
I1015 15:32:52.327448  4233 net.cpp:100] Creating Layer conv11
I1015 15:32:52.327451  4233 net.cpp:434] conv11 <- conv11/dw
I1015 15:32:52.327459  4233 net.cpp:408] conv11 -> conv11
I1015 15:32:52.331980  4233 net.cpp:150] Setting up conv11
I1015 15:32:52.331998  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.332002  4233 net.cpp:165] Memory required for data: 266649664
I1015 15:32:52.332010  4233 layer_factory.hpp:77] Creating layer conv11/bn
I1015 15:32:52.332015  4233 net.cpp:100] Creating Layer conv11/bn
I1015 15:32:52.332017  4233 net.cpp:434] conv11/bn <- conv11
I1015 15:32:52.332023  4233 net.cpp:395] conv11/bn -> conv11 (in-place)
I1015 15:32:52.332254  4233 net.cpp:150] Setting up conv11/bn
I1015 15:32:52.332264  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.332268  4233 net.cpp:165] Memory required for data: 267878464
I1015 15:32:52.332275  4233 layer_factory.hpp:77] Creating layer conv11/scale
I1015 15:32:52.332280  4233 net.cpp:100] Creating Layer conv11/scale
I1015 15:32:52.332283  4233 net.cpp:434] conv11/scale <- conv11
I1015 15:32:52.332286  4233 net.cpp:395] conv11/scale -> conv11 (in-place)
I1015 15:32:52.332340  4233 layer_factory.hpp:77] Creating layer conv11/scale
I1015 15:32:52.332478  4233 net.cpp:150] Setting up conv11/scale
I1015 15:32:52.332485  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.332489  4233 net.cpp:165] Memory required for data: 269107264
I1015 15:32:52.332494  4233 layer_factory.hpp:77] Creating layer conv11/relu
I1015 15:32:52.332499  4233 net.cpp:100] Creating Layer conv11/relu
I1015 15:32:52.332501  4233 net.cpp:434] conv11/relu <- conv11
I1015 15:32:52.332509  4233 net.cpp:395] conv11/relu -> conv11 (in-place)
I1015 15:32:52.333295  4233 net.cpp:150] Setting up conv11/relu
I1015 15:32:52.333308  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333312  4233 net.cpp:165] Memory required for data: 270336064
I1015 15:32:52.333317  4233 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I1015 15:32:52.333326  4233 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I1015 15:32:52.333329  4233 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I1015 15:32:52.333335  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I1015 15:32:52.333343  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I1015 15:32:52.333349  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I1015 15:32:52.333353  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I1015 15:32:52.333358  4233 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_4
I1015 15:32:52.333463  4233 net.cpp:150] Setting up conv11_conv11/relu_0_split
I1015 15:32:52.333470  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333475  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333479  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333482  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333487  4233 net.cpp:157] Top shape: 1 512 20 30 (307200)
I1015 15:32:52.333489  4233 net.cpp:165] Memory required for data: 276480064
I1015 15:32:52.333492  4233 layer_factory.hpp:77] Creating layer conv12/dw
I1015 15:32:52.333500  4233 net.cpp:100] Creating Layer conv12/dw
I1015 15:32:52.333503  4233 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I1015 15:32:52.333513  4233 net.cpp:408] conv12/dw -> conv12/dw
I1015 15:32:52.333773  4233 net.cpp:150] Setting up conv12/dw
I1015 15:32:52.333782  4233 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 15:32:52.333786  4233 net.cpp:165] Memory required for data: 276787264
I1015 15:32:52.333791  4233 layer_factory.hpp:77] Creating layer conv12/dw/bn
I1015 15:32:52.333797  4233 net.cpp:100] Creating Layer conv12/dw/bn
I1015 15:32:52.333801  4233 net.cpp:434] conv12/dw/bn <- conv12/dw
I1015 15:32:52.333806  4233 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I1015 15:32:52.334046  4233 net.cpp:150] Setting up conv12/dw/bn
I1015 15:32:52.334054  4233 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 15:32:52.334059  4233 net.cpp:165] Memory required for data: 277094464
I1015 15:32:52.334065  4233 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 15:32:52.334074  4233 net.cpp:100] Creating Layer conv12/dw/scale
I1015 15:32:52.334076  4233 net.cpp:434] conv12/dw/scale <- conv12/dw
I1015 15:32:52.334080  4233 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I1015 15:32:52.334128  4233 layer_factory.hpp:77] Creating layer conv12/dw/scale
I1015 15:32:52.334272  4233 net.cpp:150] Setting up conv12/dw/scale
I1015 15:32:52.334281  4233 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 15:32:52.334285  4233 net.cpp:165] Memory required for data: 277401664
I1015 15:32:52.334290  4233 layer_factory.hpp:77] Creating layer conv12/dw/relu
I1015 15:32:52.334295  4233 net.cpp:100] Creating Layer conv12/dw/relu
I1015 15:32:52.334300  4233 net.cpp:434] conv12/dw/relu <- conv12/dw
I1015 15:32:52.334305  4233 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I1015 15:32:52.334698  4233 net.cpp:150] Setting up conv12/dw/relu
I1015 15:32:52.334708  4233 net.cpp:157] Top shape: 1 512 10 15 (76800)
I1015 15:32:52.334712  4233 net.cpp:165] Memory required for data: 277708864
I1015 15:32:52.334717  4233 layer_factory.hpp:77] Creating layer conv12
I1015 15:32:52.334724  4233 net.cpp:100] Creating Layer conv12
I1015 15:32:52.334728  4233 net.cpp:434] conv12 <- conv12/dw
I1015 15:32:52.334733  4233 net.cpp:408] conv12 -> conv12
I1015 15:32:52.341372  4233 net.cpp:150] Setting up conv12
I1015 15:32:52.341393  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.341399  4233 net.cpp:165] Memory required for data: 278323264
I1015 15:32:52.341408  4233 layer_factory.hpp:77] Creating layer conv12/bn
I1015 15:32:52.341418  4233 net.cpp:100] Creating Layer conv12/bn
I1015 15:32:52.341421  4233 net.cpp:434] conv12/bn <- conv12
I1015 15:32:52.341426  4233 net.cpp:395] conv12/bn -> conv12 (in-place)
I1015 15:32:52.341778  4233 net.cpp:150] Setting up conv12/bn
I1015 15:32:52.341787  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.341790  4233 net.cpp:165] Memory required for data: 278937664
I1015 15:32:52.341796  4233 layer_factory.hpp:77] Creating layer conv12/scale
I1015 15:32:52.341804  4233 net.cpp:100] Creating Layer conv12/scale
I1015 15:32:52.341806  4233 net.cpp:434] conv12/scale <- conv12
I1015 15:32:52.341811  4233 net.cpp:395] conv12/scale -> conv12 (in-place)
I1015 15:32:52.341874  4233 layer_factory.hpp:77] Creating layer conv12/scale
I1015 15:32:52.342078  4233 net.cpp:150] Setting up conv12/scale
I1015 15:32:52.342088  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.342090  4233 net.cpp:165] Memory required for data: 279552064
I1015 15:32:52.342094  4233 layer_factory.hpp:77] Creating layer conv12/relu
I1015 15:32:52.342099  4233 net.cpp:100] Creating Layer conv12/relu
I1015 15:32:52.342103  4233 net.cpp:434] conv12/relu <- conv12
I1015 15:32:52.342106  4233 net.cpp:395] conv12/relu -> conv12 (in-place)
I1015 15:32:52.342573  4233 net.cpp:150] Setting up conv12/relu
I1015 15:32:52.342583  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.342586  4233 net.cpp:165] Memory required for data: 280166464
I1015 15:32:52.342588  4233 layer_factory.hpp:77] Creating layer conv13/dw
I1015 15:32:52.342598  4233 net.cpp:100] Creating Layer conv13/dw
I1015 15:32:52.342600  4233 net.cpp:434] conv13/dw <- conv12
I1015 15:32:52.342605  4233 net.cpp:408] conv13/dw -> conv13/dw
I1015 15:32:52.343005  4233 net.cpp:150] Setting up conv13/dw
I1015 15:32:52.343014  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.343016  4233 net.cpp:165] Memory required for data: 280780864
I1015 15:32:52.343020  4233 layer_factory.hpp:77] Creating layer conv13/dw/bn
I1015 15:32:52.343024  4233 net.cpp:100] Creating Layer conv13/dw/bn
I1015 15:32:52.343027  4233 net.cpp:434] conv13/dw/bn <- conv13/dw
I1015 15:32:52.343030  4233 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I1015 15:32:52.343343  4233 net.cpp:150] Setting up conv13/dw/bn
I1015 15:32:52.343350  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.343353  4233 net.cpp:165] Memory required for data: 281395264
I1015 15:32:52.343358  4233 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 15:32:52.343364  4233 net.cpp:100] Creating Layer conv13/dw/scale
I1015 15:32:52.343365  4233 net.cpp:434] conv13/dw/scale <- conv13/dw
I1015 15:32:52.343369  4233 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I1015 15:32:52.343423  4233 layer_factory.hpp:77] Creating layer conv13/dw/scale
I1015 15:32:52.343611  4233 net.cpp:150] Setting up conv13/dw/scale
I1015 15:32:52.343623  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.343626  4233 net.cpp:165] Memory required for data: 282009664
I1015 15:32:52.343631  4233 layer_factory.hpp:77] Creating layer conv13/dw/relu
I1015 15:32:52.343636  4233 net.cpp:100] Creating Layer conv13/dw/relu
I1015 15:32:52.343637  4233 net.cpp:434] conv13/dw/relu <- conv13/dw
I1015 15:32:52.343641  4233 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I1015 15:32:52.344483  4233 net.cpp:150] Setting up conv13/dw/relu
I1015 15:32:52.344496  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.344499  4233 net.cpp:165] Memory required for data: 282624064
I1015 15:32:52.344501  4233 layer_factory.hpp:77] Creating layer conv13
I1015 15:32:52.344509  4233 net.cpp:100] Creating Layer conv13
I1015 15:32:52.344513  4233 net.cpp:434] conv13 <- conv13/dw
I1015 15:32:52.344517  4233 net.cpp:408] conv13 -> conv13
I1015 15:32:52.357100  4233 net.cpp:150] Setting up conv13
I1015 15:32:52.357122  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.357125  4233 net.cpp:165] Memory required for data: 283238464
I1015 15:32:52.357132  4233 layer_factory.hpp:77] Creating layer conv13/bn
I1015 15:32:52.357141  4233 net.cpp:100] Creating Layer conv13/bn
I1015 15:32:52.357146  4233 net.cpp:434] conv13/bn <- conv13
I1015 15:32:52.357152  4233 net.cpp:395] conv13/bn -> conv13 (in-place)
I1015 15:32:52.357461  4233 net.cpp:150] Setting up conv13/bn
I1015 15:32:52.357475  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.357480  4233 net.cpp:165] Memory required for data: 283852864
I1015 15:32:52.357487  4233 layer_factory.hpp:77] Creating layer conv13/scale
I1015 15:32:52.357494  4233 net.cpp:100] Creating Layer conv13/scale
I1015 15:32:52.357497  4233 net.cpp:434] conv13/scale <- conv13
I1015 15:32:52.357501  4233 net.cpp:395] conv13/scale -> conv13 (in-place)
I1015 15:32:52.357560  4233 layer_factory.hpp:77] Creating layer conv13/scale
I1015 15:32:52.357758  4233 net.cpp:150] Setting up conv13/scale
I1015 15:32:52.357770  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.357774  4233 net.cpp:165] Memory required for data: 284467264
I1015 15:32:52.357779  4233 layer_factory.hpp:77] Creating layer conv13/relu
I1015 15:32:52.357784  4233 net.cpp:100] Creating Layer conv13/relu
I1015 15:32:52.357787  4233 net.cpp:434] conv13/relu <- conv13
I1015 15:32:52.357792  4233 net.cpp:395] conv13/relu -> conv13 (in-place)
I1015 15:32:52.358274  4233 net.cpp:150] Setting up conv13/relu
I1015 15:32:52.358285  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358287  4233 net.cpp:165] Memory required for data: 285081664
I1015 15:32:52.358290  4233 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I1015 15:32:52.358297  4233 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I1015 15:32:52.358300  4233 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I1015 15:32:52.358304  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I1015 15:32:52.358311  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I1015 15:32:52.358316  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I1015 15:32:52.358322  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I1015 15:32:52.358328  4233 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_4
I1015 15:32:52.358453  4233 net.cpp:150] Setting up conv13_conv13/relu_0_split
I1015 15:32:52.358466  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358470  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358474  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358475  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358479  4233 net.cpp:157] Top shape: 1 1024 10 15 (153600)
I1015 15:32:52.358480  4233 net.cpp:165] Memory required for data: 288153664
I1015 15:32:52.358484  4233 layer_factory.hpp:77] Creating layer conv14_1
I1015 15:32:52.358492  4233 net.cpp:100] Creating Layer conv14_1
I1015 15:32:52.358495  4233 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I1015 15:32:52.358500  4233 net.cpp:408] conv14_1 -> conv14_1
I1015 15:32:52.362753  4233 net.cpp:150] Setting up conv14_1
I1015 15:32:52.362767  4233 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 15:32:52.362771  4233 net.cpp:165] Memory required for data: 288307264
I1015 15:32:52.362776  4233 layer_factory.hpp:77] Creating layer conv14_1/bn
I1015 15:32:52.362782  4233 net.cpp:100] Creating Layer conv14_1/bn
I1015 15:32:52.362784  4233 net.cpp:434] conv14_1/bn <- conv14_1
I1015 15:32:52.362788  4233 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I1015 15:32:52.363059  4233 net.cpp:150] Setting up conv14_1/bn
I1015 15:32:52.363070  4233 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 15:32:52.363072  4233 net.cpp:165] Memory required for data: 288460864
I1015 15:32:52.363082  4233 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 15:32:52.363091  4233 net.cpp:100] Creating Layer conv14_1/scale
I1015 15:32:52.363095  4233 net.cpp:434] conv14_1/scale <- conv14_1
I1015 15:32:52.363098  4233 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I1015 15:32:52.363159  4233 layer_factory.hpp:77] Creating layer conv14_1/scale
I1015 15:32:52.363332  4233 net.cpp:150] Setting up conv14_1/scale
I1015 15:32:52.363340  4233 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 15:32:52.363343  4233 net.cpp:165] Memory required for data: 288614464
I1015 15:32:52.363351  4233 layer_factory.hpp:77] Creating layer conv14_1/relu
I1015 15:32:52.363359  4233 net.cpp:100] Creating Layer conv14_1/relu
I1015 15:32:52.363364  4233 net.cpp:434] conv14_1/relu <- conv14_1
I1015 15:32:52.363368  4233 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I1015 15:32:52.363844  4233 net.cpp:150] Setting up conv14_1/relu
I1015 15:32:52.363855  4233 net.cpp:157] Top shape: 1 256 10 15 (38400)
I1015 15:32:52.363857  4233 net.cpp:165] Memory required for data: 288768064
I1015 15:32:52.363860  4233 layer_factory.hpp:77] Creating layer conv14_2
I1015 15:32:52.363870  4233 net.cpp:100] Creating Layer conv14_2
I1015 15:32:52.363874  4233 net.cpp:434] conv14_2 <- conv14_1
I1015 15:32:52.363883  4233 net.cpp:408] conv14_2 -> conv14_2
I1015 15:32:52.378243  4233 net.cpp:150] Setting up conv14_2
I1015 15:32:52.378269  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.378273  4233 net.cpp:165] Memory required for data: 288849984
I1015 15:32:52.378279  4233 layer_factory.hpp:77] Creating layer conv14_2/bn
I1015 15:32:52.378288  4233 net.cpp:100] Creating Layer conv14_2/bn
I1015 15:32:52.378293  4233 net.cpp:434] conv14_2/bn <- conv14_2
I1015 15:32:52.378298  4233 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I1015 15:32:52.378588  4233 net.cpp:150] Setting up conv14_2/bn
I1015 15:32:52.378597  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.378600  4233 net.cpp:165] Memory required for data: 288931904
I1015 15:32:52.378607  4233 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 15:32:52.378614  4233 net.cpp:100] Creating Layer conv14_2/scale
I1015 15:32:52.378618  4233 net.cpp:434] conv14_2/scale <- conv14_2
I1015 15:32:52.378621  4233 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I1015 15:32:52.378680  4233 layer_factory.hpp:77] Creating layer conv14_2/scale
I1015 15:32:52.378852  4233 net.cpp:150] Setting up conv14_2/scale
I1015 15:32:52.378862  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.378865  4233 net.cpp:165] Memory required for data: 289013824
I1015 15:32:52.378870  4233 layer_factory.hpp:77] Creating layer conv14_2/relu
I1015 15:32:52.378878  4233 net.cpp:100] Creating Layer conv14_2/relu
I1015 15:32:52.378882  4233 net.cpp:434] conv14_2/relu <- conv14_2
I1015 15:32:52.378890  4233 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I1015 15:32:52.379743  4233 net.cpp:150] Setting up conv14_2/relu
I1015 15:32:52.379762  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.379766  4233 net.cpp:165] Memory required for data: 289095744
I1015 15:32:52.379770  4233 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I1015 15:32:52.379777  4233 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I1015 15:32:52.379781  4233 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I1015 15:32:52.379789  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I1015 15:32:52.379798  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I1015 15:32:52.379804  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I1015 15:32:52.379812  4233 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I1015 15:32:52.379920  4233 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I1015 15:32:52.379928  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.379932  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.379937  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.379941  4233 net.cpp:157] Top shape: 1 512 5 8 (20480)
I1015 15:32:52.379945  4233 net.cpp:165] Memory required for data: 289423424
I1015 15:32:52.379947  4233 layer_factory.hpp:77] Creating layer conv15_1
I1015 15:32:52.379959  4233 net.cpp:100] Creating Layer conv15_1
I1015 15:32:52.379963  4233 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I1015 15:32:52.379972  4233 net.cpp:408] conv15_1 -> conv15_1
I1015 15:32:52.384296  4233 net.cpp:150] Setting up conv15_1
I1015 15:32:52.384316  4233 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 15:32:52.384320  4233 net.cpp:165] Memory required for data: 289443904
I1015 15:32:52.384326  4233 layer_factory.hpp:77] Creating layer conv15_1/bn
I1015 15:32:52.384332  4233 net.cpp:100] Creating Layer conv15_1/bn
I1015 15:32:52.384336  4233 net.cpp:434] conv15_1/bn <- conv15_1
I1015 15:32:52.384342  4233 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I1015 15:32:52.384658  4233 net.cpp:150] Setting up conv15_1/bn
I1015 15:32:52.384670  4233 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 15:32:52.384672  4233 net.cpp:165] Memory required for data: 289464384
I1015 15:32:52.384678  4233 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 15:32:52.384686  4233 net.cpp:100] Creating Layer conv15_1/scale
I1015 15:32:52.384690  4233 net.cpp:434] conv15_1/scale <- conv15_1
I1015 15:32:52.384699  4233 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I1015 15:32:52.384765  4233 layer_factory.hpp:77] Creating layer conv15_1/scale
I1015 15:32:52.384930  4233 net.cpp:150] Setting up conv15_1/scale
I1015 15:32:52.384939  4233 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 15:32:52.384941  4233 net.cpp:165] Memory required for data: 289484864
I1015 15:32:52.384945  4233 layer_factory.hpp:77] Creating layer conv15_1/relu
I1015 15:32:52.384951  4233 net.cpp:100] Creating Layer conv15_1/relu
I1015 15:32:52.384955  4233 net.cpp:434] conv15_1/relu <- conv15_1
I1015 15:32:52.384963  4233 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I1015 15:32:52.385372  4233 net.cpp:150] Setting up conv15_1/relu
I1015 15:32:52.385382  4233 net.cpp:157] Top shape: 1 128 5 8 (5120)
I1015 15:32:52.385385  4233 net.cpp:165] Memory required for data: 289505344
I1015 15:32:52.385388  4233 layer_factory.hpp:77] Creating layer conv15_2
I1015 15:32:52.385401  4233 net.cpp:100] Creating Layer conv15_2
I1015 15:32:52.385406  4233 net.cpp:434] conv15_2 <- conv15_1
I1015 15:32:52.385413  4233 net.cpp:408] conv15_2 -> conv15_2
I1015 15:32:52.390614  4233 net.cpp:150] Setting up conv15_2
I1015 15:32:52.390630  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.390632  4233 net.cpp:165] Memory required for data: 289517632
I1015 15:32:52.390637  4233 layer_factory.hpp:77] Creating layer conv15_2/bn
I1015 15:32:52.390661  4233 net.cpp:100] Creating Layer conv15_2/bn
I1015 15:32:52.390666  4233 net.cpp:434] conv15_2/bn <- conv15_2
I1015 15:32:52.390673  4233 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I1015 15:32:52.390935  4233 net.cpp:150] Setting up conv15_2/bn
I1015 15:32:52.390944  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.390945  4233 net.cpp:165] Memory required for data: 289529920
I1015 15:32:52.390954  4233 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 15:32:52.390964  4233 net.cpp:100] Creating Layer conv15_2/scale
I1015 15:32:52.390969  4233 net.cpp:434] conv15_2/scale <- conv15_2
I1015 15:32:52.390976  4233 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I1015 15:32:52.391041  4233 layer_factory.hpp:77] Creating layer conv15_2/scale
I1015 15:32:52.391183  4233 net.cpp:150] Setting up conv15_2/scale
I1015 15:32:52.391191  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391193  4233 net.cpp:165] Memory required for data: 289542208
I1015 15:32:52.391199  4233 layer_factory.hpp:77] Creating layer conv15_2/relu
I1015 15:32:52.391206  4233 net.cpp:100] Creating Layer conv15_2/relu
I1015 15:32:52.391211  4233 net.cpp:434] conv15_2/relu <- conv15_2
I1015 15:32:52.391216  4233 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I1015 15:32:52.391626  4233 net.cpp:150] Setting up conv15_2/relu
I1015 15:32:52.391635  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391638  4233 net.cpp:165] Memory required for data: 289554496
I1015 15:32:52.391641  4233 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I1015 15:32:52.391649  4233 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I1015 15:32:52.391654  4233 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I1015 15:32:52.391664  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I1015 15:32:52.391674  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I1015 15:32:52.391683  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I1015 15:32:52.391688  4233 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I1015 15:32:52.391795  4233 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I1015 15:32:52.391803  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391806  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391810  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391815  4233 net.cpp:157] Top shape: 1 256 3 4 (3072)
I1015 15:32:52.391819  4233 net.cpp:165] Memory required for data: 289603648
I1015 15:32:52.391822  4233 layer_factory.hpp:77] Creating layer conv16_1
I1015 15:32:52.391834  4233 net.cpp:100] Creating Layer conv16_1
I1015 15:32:52.391839  4233 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I1015 15:32:52.391846  4233 net.cpp:408] conv16_1 -> conv16_1
I1015 15:32:52.393916  4233 net.cpp:150] Setting up conv16_1
I1015 15:32:52.393929  4233 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 15:32:52.393932  4233 net.cpp:165] Memory required for data: 289609792
I1015 15:32:52.393936  4233 layer_factory.hpp:77] Creating layer conv16_1/bn
I1015 15:32:52.393945  4233 net.cpp:100] Creating Layer conv16_1/bn
I1015 15:32:52.393950  4233 net.cpp:434] conv16_1/bn <- conv16_1
I1015 15:32:52.393959  4233 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I1015 15:32:52.394199  4233 net.cpp:150] Setting up conv16_1/bn
I1015 15:32:52.394208  4233 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 15:32:52.394210  4233 net.cpp:165] Memory required for data: 289615936
I1015 15:32:52.394217  4233 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 15:32:52.394227  4233 net.cpp:100] Creating Layer conv16_1/scale
I1015 15:32:52.394232  4233 net.cpp:434] conv16_1/scale <- conv16_1
I1015 15:32:52.394238  4233 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I1015 15:32:52.394304  4233 layer_factory.hpp:77] Creating layer conv16_1/scale
I1015 15:32:52.394461  4233 net.cpp:150] Setting up conv16_1/scale
I1015 15:32:52.394469  4233 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 15:32:52.394471  4233 net.cpp:165] Memory required for data: 289622080
I1015 15:32:52.394477  4233 layer_factory.hpp:77] Creating layer conv16_1/relu
I1015 15:32:52.394484  4233 net.cpp:100] Creating Layer conv16_1/relu
I1015 15:32:52.394487  4233 net.cpp:434] conv16_1/relu <- conv16_1
I1015 15:32:52.394495  4233 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I1015 15:32:52.394893  4233 net.cpp:150] Setting up conv16_1/relu
I1015 15:32:52.394903  4233 net.cpp:157] Top shape: 1 128 3 4 (1536)
I1015 15:32:52.394906  4233 net.cpp:165] Memory required for data: 289628224
I1015 15:32:52.394908  4233 layer_factory.hpp:77] Creating layer conv16_2
I1015 15:32:52.394918  4233 net.cpp:100] Creating Layer conv16_2
I1015 15:32:52.394922  4233 net.cpp:434] conv16_2 <- conv16_1
I1015 15:32:52.394932  4233 net.cpp:408] conv16_2 -> conv16_2
I1015 15:32:52.399754  4233 net.cpp:150] Setting up conv16_2
I1015 15:32:52.399770  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.399773  4233 net.cpp:165] Memory required for data: 289632320
I1015 15:32:52.399778  4233 layer_factory.hpp:77] Creating layer conv16_2/bn
I1015 15:32:52.399785  4233 net.cpp:100] Creating Layer conv16_2/bn
I1015 15:32:52.399788  4233 net.cpp:434] conv16_2/bn <- conv16_2
I1015 15:32:52.399796  4233 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I1015 15:32:52.400053  4233 net.cpp:150] Setting up conv16_2/bn
I1015 15:32:52.400060  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.400063  4233 net.cpp:165] Memory required for data: 289636416
I1015 15:32:52.400068  4233 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 15:32:52.400075  4233 net.cpp:100] Creating Layer conv16_2/scale
I1015 15:32:52.400080  4233 net.cpp:434] conv16_2/scale <- conv16_2
I1015 15:32:52.400089  4233 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I1015 15:32:52.400147  4233 layer_factory.hpp:77] Creating layer conv16_2/scale
I1015 15:32:52.400298  4233 net.cpp:150] Setting up conv16_2/scale
I1015 15:32:52.400306  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.400308  4233 net.cpp:165] Memory required for data: 289640512
I1015 15:32:52.400313  4233 layer_factory.hpp:77] Creating layer conv16_2/relu
I1015 15:32:52.400318  4233 net.cpp:100] Creating Layer conv16_2/relu
I1015 15:32:52.400322  4233 net.cpp:434] conv16_2/relu <- conv16_2
I1015 15:32:52.400331  4233 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I1015 15:32:52.401100  4233 net.cpp:150] Setting up conv16_2/relu
I1015 15:32:52.401113  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.401115  4233 net.cpp:165] Memory required for data: 289644608
I1015 15:32:52.401118  4233 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I1015 15:32:52.401127  4233 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I1015 15:32:52.401132  4233 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I1015 15:32:52.401140  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I1015 15:32:52.401150  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I1015 15:32:52.401160  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I1015 15:32:52.401168  4233 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I1015 15:32:52.401284  4233 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I1015 15:32:52.401293  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.401295  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.401298  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.401301  4233 net.cpp:157] Top shape: 1 256 2 2 (1024)
I1015 15:32:52.401304  4233 net.cpp:165] Memory required for data: 289660992
I1015 15:32:52.401309  4233 layer_factory.hpp:77] Creating layer conv17_1
I1015 15:32:52.401320  4233 net.cpp:100] Creating Layer conv17_1
I1015 15:32:52.401325  4233 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I1015 15:32:52.401334  4233 net.cpp:408] conv17_1 -> conv17_1
I1015 15:32:52.403301  4233 net.cpp:150] Setting up conv17_1
I1015 15:32:52.403313  4233 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 15:32:52.403316  4233 net.cpp:165] Memory required for data: 289662016
I1015 15:32:52.403321  4233 layer_factory.hpp:77] Creating layer conv17_1/bn
I1015 15:32:52.403329  4233 net.cpp:100] Creating Layer conv17_1/bn
I1015 15:32:52.403334  4233 net.cpp:434] conv17_1/bn <- conv17_1
I1015 15:32:52.403340  4233 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I1015 15:32:52.403597  4233 net.cpp:150] Setting up conv17_1/bn
I1015 15:32:52.403605  4233 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 15:32:52.403607  4233 net.cpp:165] Memory required for data: 289663040
I1015 15:32:52.403614  4233 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 15:32:52.403623  4233 net.cpp:100] Creating Layer conv17_1/scale
I1015 15:32:52.403627  4233 net.cpp:434] conv17_1/scale <- conv17_1
I1015 15:32:52.403635  4233 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I1015 15:32:52.403697  4233 layer_factory.hpp:77] Creating layer conv17_1/scale
I1015 15:32:52.403851  4233 net.cpp:150] Setting up conv17_1/scale
I1015 15:32:52.403859  4233 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 15:32:52.403861  4233 net.cpp:165] Memory required for data: 289664064
I1015 15:32:52.403867  4233 layer_factory.hpp:77] Creating layer conv17_1/relu
I1015 15:32:52.403872  4233 net.cpp:100] Creating Layer conv17_1/relu
I1015 15:32:52.403875  4233 net.cpp:434] conv17_1/relu <- conv17_1
I1015 15:32:52.403882  4233 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I1015 15:32:52.404294  4233 net.cpp:150] Setting up conv17_1/relu
I1015 15:32:52.404304  4233 net.cpp:157] Top shape: 1 64 2 2 (256)
I1015 15:32:52.404307  4233 net.cpp:165] Memory required for data: 289665088
I1015 15:32:52.404309  4233 layer_factory.hpp:77] Creating layer conv17_2
I1015 15:32:52.404321  4233 net.cpp:100] Creating Layer conv17_2
I1015 15:32:52.404326  4233 net.cpp:434] conv17_2 <- conv17_1
I1015 15:32:52.404332  4233 net.cpp:408] conv17_2 -> conv17_2
I1015 15:32:52.406711  4233 net.cpp:150] Setting up conv17_2
I1015 15:32:52.406724  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.406726  4233 net.cpp:165] Memory required for data: 289665600
I1015 15:32:52.406731  4233 layer_factory.hpp:77] Creating layer conv17_2/bn
I1015 15:32:52.406739  4233 net.cpp:100] Creating Layer conv17_2/bn
I1015 15:32:52.406744  4233 net.cpp:434] conv17_2/bn <- conv17_2
I1015 15:32:52.406750  4233 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I1015 15:32:52.407001  4233 net.cpp:150] Setting up conv17_2/bn
I1015 15:32:52.407008  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407011  4233 net.cpp:165] Memory required for data: 289666112
I1015 15:32:52.407017  4233 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 15:32:52.407025  4233 net.cpp:100] Creating Layer conv17_2/scale
I1015 15:32:52.407029  4233 net.cpp:434] conv17_2/scale <- conv17_2
I1015 15:32:52.407037  4233 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I1015 15:32:52.407095  4233 layer_factory.hpp:77] Creating layer conv17_2/scale
I1015 15:32:52.407246  4233 net.cpp:150] Setting up conv17_2/scale
I1015 15:32:52.407254  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407258  4233 net.cpp:165] Memory required for data: 289666624
I1015 15:32:52.407261  4233 layer_factory.hpp:77] Creating layer conv17_2/relu
I1015 15:32:52.407268  4233 net.cpp:100] Creating Layer conv17_2/relu
I1015 15:32:52.407271  4233 net.cpp:434] conv17_2/relu <- conv17_2
I1015 15:32:52.407277  4233 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I1015 15:32:52.407702  4233 net.cpp:150] Setting up conv17_2/relu
I1015 15:32:52.407712  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407714  4233 net.cpp:165] Memory required for data: 289667136
I1015 15:32:52.407718  4233 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I1015 15:32:52.407726  4233 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I1015 15:32:52.407729  4233 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I1015 15:32:52.407739  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I1015 15:32:52.407748  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I1015 15:32:52.407757  4233 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I1015 15:32:52.407847  4233 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I1015 15:32:52.407855  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407857  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407860  4233 net.cpp:157] Top shape: 1 128 1 1 (128)
I1015 15:32:52.407861  4233 net.cpp:165] Memory required for data: 289668672
I1015 15:32:52.407865  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I1015 15:32:52.407876  4233 net.cpp:100] Creating Layer conv11_mbox_loc
I1015 15:32:52.407881  4233 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I1015 15:32:52.407891  4233 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I1015 15:32:52.409832  4233 net.cpp:150] Setting up conv11_mbox_loc
I1015 15:32:52.409843  4233 net.cpp:157] Top shape: 1 12 20 30 (7200)
I1015 15:32:52.409847  4233 net.cpp:165] Memory required for data: 289697472
I1015 15:32:52.409852  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I1015 15:32:52.409862  4233 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I1015 15:32:52.409868  4233 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I1015 15:32:52.409876  4233 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I1015 15:32:52.410029  4233 net.cpp:150] Setting up conv11_mbox_loc_perm
I1015 15:32:52.410038  4233 net.cpp:157] Top shape: 1 20 30 12 (7200)
I1015 15:32:52.410040  4233 net.cpp:165] Memory required for data: 289726272
I1015 15:32:52.410043  4233 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I1015 15:32:52.410049  4233 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I1015 15:32:52.410054  4233 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I1015 15:32:52.410063  4233 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I1015 15:32:52.410101  4233 net.cpp:150] Setting up conv11_mbox_loc_flat
I1015 15:32:52.410109  4233 net.cpp:157] Top shape: 1 7200 (7200)
I1015 15:32:52.410112  4233 net.cpp:165] Memory required for data: 289755072
I1015 15:32:52.410116  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I1015 15:32:52.410128  4233 net.cpp:100] Creating Layer conv11_mbox_conf_new
I1015 15:32:52.410133  4233 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I1015 15:32:52.410140  4233 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I1015 15:32:52.412047  4233 net.cpp:150] Setting up conv11_mbox_conf_new
I1015 15:32:52.412061  4233 net.cpp:157] Top shape: 1 9 20 30 (5400)
I1015 15:32:52.412063  4233 net.cpp:165] Memory required for data: 289776672
I1015 15:32:52.412070  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I1015 15:32:52.412078  4233 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I1015 15:32:52.412083  4233 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I1015 15:32:52.412091  4233 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I1015 15:32:52.412245  4233 net.cpp:150] Setting up conv11_mbox_conf_perm
I1015 15:32:52.412252  4233 net.cpp:157] Top shape: 1 20 30 9 (5400)
I1015 15:32:52.412255  4233 net.cpp:165] Memory required for data: 289798272
I1015 15:32:52.412256  4233 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I1015 15:32:52.412261  4233 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I1015 15:32:52.412266  4233 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I1015 15:32:52.412274  4233 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I1015 15:32:52.412314  4233 net.cpp:150] Setting up conv11_mbox_conf_flat
I1015 15:32:52.412320  4233 net.cpp:157] Top shape: 1 5400 (5400)
I1015 15:32:52.412323  4233 net.cpp:165] Memory required for data: 289819872
I1015 15:32:52.412325  4233 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I1015 15:32:52.412333  4233 net.cpp:100] Creating Layer conv11_mbox_priorbox
I1015 15:32:52.412338  4233 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I1015 15:32:52.412343  4233 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I1015 15:32:52.412353  4233 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I1015 15:32:52.412400  4233 net.cpp:150] Setting up conv11_mbox_priorbox
I1015 15:32:52.412407  4233 net.cpp:157] Top shape: 1 2 7200 (14400)
I1015 15:32:52.412410  4233 net.cpp:165] Memory required for data: 289877472
I1015 15:32:52.412412  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I1015 15:32:52.412420  4233 net.cpp:100] Creating Layer conv13_mbox_loc
I1015 15:32:52.412423  4233 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I1015 15:32:52.412430  4233 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I1015 15:32:52.415961  4233 net.cpp:150] Setting up conv13_mbox_loc
I1015 15:32:52.415977  4233 net.cpp:157] Top shape: 1 24 10 15 (3600)
I1015 15:32:52.415979  4233 net.cpp:165] Memory required for data: 289891872
I1015 15:32:52.415985  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I1015 15:32:52.415993  4233 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I1015 15:32:52.415998  4233 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I1015 15:32:52.416005  4233 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I1015 15:32:52.416164  4233 net.cpp:150] Setting up conv13_mbox_loc_perm
I1015 15:32:52.416173  4233 net.cpp:157] Top shape: 1 10 15 24 (3600)
I1015 15:32:52.416175  4233 net.cpp:165] Memory required for data: 289906272
I1015 15:32:52.416178  4233 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I1015 15:32:52.416184  4233 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I1015 15:32:52.416188  4233 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I1015 15:32:52.416194  4233 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I1015 15:32:52.416235  4233 net.cpp:150] Setting up conv13_mbox_loc_flat
I1015 15:32:52.416241  4233 net.cpp:157] Top shape: 1 3600 (3600)
I1015 15:32:52.416244  4233 net.cpp:165] Memory required for data: 289920672
I1015 15:32:52.416246  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I1015 15:32:52.416258  4233 net.cpp:100] Creating Layer conv13_mbox_conf_new
I1015 15:32:52.416263  4233 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I1015 15:32:52.416275  4233 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I1015 15:32:52.419028  4233 net.cpp:150] Setting up conv13_mbox_conf_new
I1015 15:32:52.419042  4233 net.cpp:157] Top shape: 1 18 10 15 (2700)
I1015 15:32:52.419045  4233 net.cpp:165] Memory required for data: 289931472
I1015 15:32:52.419051  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I1015 15:32:52.419059  4233 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I1015 15:32:52.419062  4233 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I1015 15:32:52.419070  4233 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I1015 15:32:52.419230  4233 net.cpp:150] Setting up conv13_mbox_conf_perm
I1015 15:32:52.419239  4233 net.cpp:157] Top shape: 1 10 15 18 (2700)
I1015 15:32:52.419240  4233 net.cpp:165] Memory required for data: 289942272
I1015 15:32:52.419243  4233 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I1015 15:32:52.419250  4233 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I1015 15:32:52.419255  4233 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I1015 15:32:52.419263  4233 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I1015 15:32:52.419301  4233 net.cpp:150] Setting up conv13_mbox_conf_flat
I1015 15:32:52.419306  4233 net.cpp:157] Top shape: 1 2700 (2700)
I1015 15:32:52.419309  4233 net.cpp:165] Memory required for data: 289953072
I1015 15:32:52.419312  4233 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I1015 15:32:52.419323  4233 net.cpp:100] Creating Layer conv13_mbox_priorbox
I1015 15:32:52.419327  4233 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I1015 15:32:52.419334  4233 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I1015 15:32:52.419343  4233 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I1015 15:32:52.419386  4233 net.cpp:150] Setting up conv13_mbox_priorbox
I1015 15:32:52.419394  4233 net.cpp:157] Top shape: 1 2 3600 (7200)
I1015 15:32:52.419396  4233 net.cpp:165] Memory required for data: 289981872
I1015 15:32:52.419399  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I1015 15:32:52.419409  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc
I1015 15:32:52.419412  4233 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I1015 15:32:52.419417  4233 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I1015 15:32:52.421429  4233 net.cpp:150] Setting up conv14_2_mbox_loc
I1015 15:32:52.421442  4233 net.cpp:157] Top shape: 1 24 5 8 (960)
I1015 15:32:52.421443  4233 net.cpp:165] Memory required for data: 289985712
I1015 15:32:52.421449  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I1015 15:32:52.421456  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I1015 15:32:52.421461  4233 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I1015 15:32:52.421470  4233 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I1015 15:32:52.421629  4233 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I1015 15:32:52.421638  4233 net.cpp:157] Top shape: 1 5 8 24 (960)
I1015 15:32:52.421639  4233 net.cpp:165] Memory required for data: 289989552
I1015 15:32:52.421643  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I1015 15:32:52.421646  4233 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I1015 15:32:52.421650  4233 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I1015 15:32:52.421658  4233 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I1015 15:32:52.421696  4233 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I1015 15:32:52.421702  4233 net.cpp:157] Top shape: 1 960 (960)
I1015 15:32:52.421705  4233 net.cpp:165] Memory required for data: 289993392
I1015 15:32:52.421706  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I1015 15:32:52.421720  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I1015 15:32:52.421725  4233 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I1015 15:32:52.421741  4233 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I1015 15:32:52.423772  4233 net.cpp:150] Setting up conv14_2_mbox_conf_new
I1015 15:32:52.423784  4233 net.cpp:157] Top shape: 1 18 5 8 (720)
I1015 15:32:52.423787  4233 net.cpp:165] Memory required for data: 289996272
I1015 15:32:52.423792  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I1015 15:32:52.423800  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I1015 15:32:52.423805  4233 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I1015 15:32:52.423815  4233 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I1015 15:32:52.423970  4233 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I1015 15:32:52.423979  4233 net.cpp:157] Top shape: 1 5 8 18 (720)
I1015 15:32:52.423980  4233 net.cpp:165] Memory required for data: 289999152
I1015 15:32:52.423983  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I1015 15:32:52.423990  4233 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I1015 15:32:52.423993  4233 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I1015 15:32:52.424000  4233 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I1015 15:32:52.424038  4233 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I1015 15:32:52.424044  4233 net.cpp:157] Top shape: 1 720 (720)
I1015 15:32:52.424047  4233 net.cpp:165] Memory required for data: 290002032
I1015 15:32:52.424052  4233 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I1015 15:32:52.424059  4233 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I1015 15:32:52.424064  4233 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I1015 15:32:52.424072  4233 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I1015 15:32:52.424078  4233 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I1015 15:32:52.424121  4233 net.cpp:150] Setting up conv14_2_mbox_priorbox
I1015 15:32:52.424129  4233 net.cpp:157] Top shape: 1 2 960 (1920)
I1015 15:32:52.424131  4233 net.cpp:165] Memory required for data: 290009712
I1015 15:32:52.424134  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I1015 15:32:52.424142  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc
I1015 15:32:52.424145  4233 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I1015 15:32:52.424152  4233 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I1015 15:32:52.426110  4233 net.cpp:150] Setting up conv15_2_mbox_loc
I1015 15:32:52.426122  4233 net.cpp:157] Top shape: 1 24 3 4 (288)
I1015 15:32:52.426126  4233 net.cpp:165] Memory required for data: 290010864
I1015 15:32:52.426131  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I1015 15:32:52.426141  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I1015 15:32:52.426146  4233 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I1015 15:32:52.426153  4233 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I1015 15:32:52.426306  4233 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I1015 15:32:52.426313  4233 net.cpp:157] Top shape: 1 3 4 24 (288)
I1015 15:32:52.426316  4233 net.cpp:165] Memory required for data: 290012016
I1015 15:32:52.426318  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I1015 15:32:52.426326  4233 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I1015 15:32:52.426329  4233 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I1015 15:32:52.426337  4233 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I1015 15:32:52.426375  4233 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I1015 15:32:52.426383  4233 net.cpp:157] Top shape: 1 288 (288)
I1015 15:32:52.426386  4233 net.cpp:165] Memory required for data: 290013168
I1015 15:32:52.426390  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I1015 15:32:52.426401  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I1015 15:32:52.426406  4233 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I1015 15:32:52.426415  4233 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I1015 15:32:52.428401  4233 net.cpp:150] Setting up conv15_2_mbox_conf_new
I1015 15:32:52.428413  4233 net.cpp:157] Top shape: 1 18 3 4 (216)
I1015 15:32:52.428416  4233 net.cpp:165] Memory required for data: 290014032
I1015 15:32:52.428421  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I1015 15:32:52.428431  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I1015 15:32:52.428436  4233 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I1015 15:32:52.428444  4233 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I1015 15:32:52.428596  4233 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I1015 15:32:52.428604  4233 net.cpp:157] Top shape: 1 3 4 18 (216)
I1015 15:32:52.428606  4233 net.cpp:165] Memory required for data: 290014896
I1015 15:32:52.428609  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I1015 15:32:52.428614  4233 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I1015 15:32:52.428618  4233 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I1015 15:32:52.428627  4233 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I1015 15:32:52.428664  4233 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I1015 15:32:52.428671  4233 net.cpp:157] Top shape: 1 216 (216)
I1015 15:32:52.428673  4233 net.cpp:165] Memory required for data: 290015760
I1015 15:32:52.428676  4233 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I1015 15:32:52.428684  4233 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I1015 15:32:52.428689  4233 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I1015 15:32:52.428694  4233 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I1015 15:32:52.428702  4233 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I1015 15:32:52.428747  4233 net.cpp:150] Setting up conv15_2_mbox_priorbox
I1015 15:32:52.428755  4233 net.cpp:157] Top shape: 1 2 288 (576)
I1015 15:32:52.428758  4233 net.cpp:165] Memory required for data: 290018064
I1015 15:32:52.428762  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I1015 15:32:52.428772  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc
I1015 15:32:52.428776  4233 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I1015 15:32:52.428781  4233 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I1015 15:32:52.430707  4233 net.cpp:150] Setting up conv16_2_mbox_loc
I1015 15:32:52.430719  4233 net.cpp:157] Top shape: 1 24 2 2 (96)
I1015 15:32:52.430722  4233 net.cpp:165] Memory required for data: 290018448
I1015 15:32:52.430727  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I1015 15:32:52.430737  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I1015 15:32:52.430742  4233 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I1015 15:32:52.430748  4233 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I1015 15:32:52.430902  4233 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I1015 15:32:52.430909  4233 net.cpp:157] Top shape: 1 2 2 24 (96)
I1015 15:32:52.430912  4233 net.cpp:165] Memory required for data: 290018832
I1015 15:32:52.430914  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I1015 15:32:52.430918  4233 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I1015 15:32:52.430922  4233 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I1015 15:32:52.430929  4233 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I1015 15:32:52.430970  4233 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I1015 15:32:52.430976  4233 net.cpp:157] Top shape: 1 96 (96)
I1015 15:32:52.430979  4233 net.cpp:165] Memory required for data: 290019216
I1015 15:32:52.430981  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I1015 15:32:52.430989  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I1015 15:32:52.430994  4233 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I1015 15:32:52.431002  4233 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I1015 15:32:52.432914  4233 net.cpp:150] Setting up conv16_2_mbox_conf_new
I1015 15:32:52.432926  4233 net.cpp:157] Top shape: 1 18 2 2 (72)
I1015 15:32:52.432929  4233 net.cpp:165] Memory required for data: 290019504
I1015 15:32:52.432934  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I1015 15:32:52.432943  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I1015 15:32:52.432948  4233 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I1015 15:32:52.432955  4233 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I1015 15:32:52.433109  4233 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I1015 15:32:52.433116  4233 net.cpp:157] Top shape: 1 2 2 18 (72)
I1015 15:32:52.433118  4233 net.cpp:165] Memory required for data: 290019792
I1015 15:32:52.433121  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I1015 15:32:52.433127  4233 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I1015 15:32:52.433131  4233 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I1015 15:32:52.433137  4233 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I1015 15:32:52.433178  4233 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I1015 15:32:52.433184  4233 net.cpp:157] Top shape: 1 72 (72)
I1015 15:32:52.433187  4233 net.cpp:165] Memory required for data: 290020080
I1015 15:32:52.433188  4233 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I1015 15:32:52.433195  4233 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I1015 15:32:52.433199  4233 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I1015 15:32:52.433205  4233 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I1015 15:32:52.433212  4233 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I1015 15:32:52.433255  4233 net.cpp:150] Setting up conv16_2_mbox_priorbox
I1015 15:32:52.433264  4233 net.cpp:157] Top shape: 1 2 96 (192)
I1015 15:32:52.433267  4233 net.cpp:165] Memory required for data: 290020848
I1015 15:32:52.433271  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I1015 15:32:52.433284  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc
I1015 15:32:52.433287  4233 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I1015 15:32:52.433292  4233 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I1015 15:32:52.436522  4233 net.cpp:150] Setting up conv17_2_mbox_loc
I1015 15:32:52.436537  4233 net.cpp:157] Top shape: 1 24 1 1 (24)
I1015 15:32:52.436538  4233 net.cpp:165] Memory required for data: 290020944
I1015 15:32:52.436545  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I1015 15:32:52.436553  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I1015 15:32:52.436556  4233 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I1015 15:32:52.436565  4233 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I1015 15:32:52.436730  4233 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I1015 15:32:52.436738  4233 net.cpp:157] Top shape: 1 1 1 24 (24)
I1015 15:32:52.436740  4233 net.cpp:165] Memory required for data: 290021040
I1015 15:32:52.436743  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I1015 15:32:52.436748  4233 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I1015 15:32:52.436751  4233 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I1015 15:32:52.436758  4233 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I1015 15:32:52.436799  4233 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I1015 15:32:52.436805  4233 net.cpp:157] Top shape: 1 24 (24)
I1015 15:32:52.436806  4233 net.cpp:165] Memory required for data: 290021136
I1015 15:32:52.436810  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I1015 15:32:52.436822  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I1015 15:32:52.436827  4233 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I1015 15:32:52.436836  4233 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I1015 15:32:52.439618  4233 net.cpp:150] Setting up conv17_2_mbox_conf_new
I1015 15:32:52.439630  4233 net.cpp:157] Top shape: 1 18 1 1 (18)
I1015 15:32:52.439633  4233 net.cpp:165] Memory required for data: 290021208
I1015 15:32:52.439640  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I1015 15:32:52.439647  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I1015 15:32:52.439652  4233 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I1015 15:32:52.439661  4233 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I1015 15:32:52.439816  4233 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I1015 15:32:52.439824  4233 net.cpp:157] Top shape: 1 1 1 18 (18)
I1015 15:32:52.439826  4233 net.cpp:165] Memory required for data: 290021280
I1015 15:32:52.439829  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I1015 15:32:52.439836  4233 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I1015 15:32:52.439839  4233 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I1015 15:32:52.439844  4233 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I1015 15:32:52.439877  4233 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I1015 15:32:52.439880  4233 net.cpp:157] Top shape: 1 18 (18)
I1015 15:32:52.439882  4233 net.cpp:165] Memory required for data: 290021352
I1015 15:32:52.439884  4233 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I1015 15:32:52.439890  4233 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I1015 15:32:52.439893  4233 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I1015 15:32:52.439898  4233 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I1015 15:32:52.439905  4233 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I1015 15:32:52.439940  4233 net.cpp:150] Setting up conv17_2_mbox_priorbox
I1015 15:32:52.439944  4233 net.cpp:157] Top shape: 1 2 24 (48)
I1015 15:32:52.439946  4233 net.cpp:165] Memory required for data: 290021544
I1015 15:32:52.439949  4233 layer_factory.hpp:77] Creating layer mbox_loc
I1015 15:32:52.439954  4233 net.cpp:100] Creating Layer mbox_loc
I1015 15:32:52.439959  4233 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I1015 15:32:52.439961  4233 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I1015 15:32:52.439965  4233 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I1015 15:32:52.439970  4233 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I1015 15:32:52.439972  4233 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I1015 15:32:52.439975  4233 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I1015 15:32:52.439980  4233 net.cpp:408] mbox_loc -> mbox_loc
I1015 15:32:52.440014  4233 net.cpp:150] Setting up mbox_loc
I1015 15:32:52.440021  4233 net.cpp:157] Top shape: 1 12168 (12168)
I1015 15:32:52.440024  4233 net.cpp:165] Memory required for data: 290070216
I1015 15:32:52.440027  4233 layer_factory.hpp:77] Creating layer mbox_conf
I1015 15:32:52.440034  4233 net.cpp:100] Creating Layer mbox_conf
I1015 15:32:52.440039  4233 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I1015 15:32:52.440045  4233 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I1015 15:32:52.440049  4233 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I1015 15:32:52.440053  4233 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I1015 15:32:52.440057  4233 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I1015 15:32:52.440062  4233 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I1015 15:32:52.440069  4233 net.cpp:408] mbox_conf -> mbox_conf
I1015 15:32:52.440101  4233 net.cpp:150] Setting up mbox_conf
I1015 15:32:52.440106  4233 net.cpp:157] Top shape: 1 9126 (9126)
I1015 15:32:52.440109  4233 net.cpp:165] Memory required for data: 290106720
I1015 15:32:52.440112  4233 layer_factory.hpp:77] Creating layer mbox_priorbox
I1015 15:32:52.440119  4233 net.cpp:100] Creating Layer mbox_priorbox
I1015 15:32:52.440121  4233 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I1015 15:32:52.440124  4233 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I1015 15:32:52.440127  4233 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I1015 15:32:52.440130  4233 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I1015 15:32:52.440134  4233 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I1015 15:32:52.440136  4233 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I1015 15:32:52.440140  4233 net.cpp:408] mbox_priorbox -> mbox_priorbox
I1015 15:32:52.440172  4233 net.cpp:150] Setting up mbox_priorbox
I1015 15:32:52.440177  4233 net.cpp:157] Top shape: 1 2 12168 (24336)
I1015 15:32:52.440179  4233 net.cpp:165] Memory required for data: 290204064
I1015 15:32:52.440181  4233 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I1015 15:32:52.440188  4233 net.cpp:100] Creating Layer mbox_conf_reshape
I1015 15:32:52.440191  4233 net.cpp:434] mbox_conf_reshape <- mbox_conf
I1015 15:32:52.440197  4233 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I1015 15:32:52.440228  4233 net.cpp:150] Setting up mbox_conf_reshape
I1015 15:32:52.440233  4233 net.cpp:157] Top shape: 1 3042 3 (9126)
I1015 15:32:52.440235  4233 net.cpp:165] Memory required for data: 290240568
I1015 15:32:52.440237  4233 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I1015 15:32:52.440243  4233 net.cpp:100] Creating Layer mbox_conf_softmax
I1015 15:32:52.440245  4233 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I1015 15:32:52.440250  4233 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I1015 15:32:52.441107  4233 net.cpp:150] Setting up mbox_conf_softmax
I1015 15:32:52.441118  4233 net.cpp:157] Top shape: 1 3042 3 (9126)
I1015 15:32:52.441120  4233 net.cpp:165] Memory required for data: 290277072
I1015 15:32:52.441123  4233 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I1015 15:32:52.441130  4233 net.cpp:100] Creating Layer mbox_conf_flatten
I1015 15:32:52.441134  4233 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I1015 15:32:52.441140  4233 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I1015 15:32:52.441175  4233 net.cpp:150] Setting up mbox_conf_flatten
I1015 15:32:52.441179  4233 net.cpp:157] Top shape: 1 9126 (9126)
I1015 15:32:52.441181  4233 net.cpp:165] Memory required for data: 290313576
I1015 15:32:52.441184  4233 layer_factory.hpp:77] Creating layer detection_out
I1015 15:32:52.441195  4233 net.cpp:100] Creating Layer detection_out
I1015 15:32:52.441196  4233 net.cpp:434] detection_out <- mbox_loc
I1015 15:32:52.441200  4233 net.cpp:434] detection_out <- mbox_conf_flatten
I1015 15:32:52.441203  4233 net.cpp:434] detection_out <- mbox_priorbox
I1015 15:32:52.441206  4233 net.cpp:408] detection_out -> detection_out
I1015 15:32:52.441274  4233 net.cpp:150] Setting up detection_out
I1015 15:32:52.441280  4233 net.cpp:157] Top shape: 1 1 1 7 (7)
I1015 15:32:52.441283  4233 net.cpp:165] Memory required for data: 290313604
I1015 15:32:52.441285  4233 layer_factory.hpp:77] Creating layer detection_eval
I1015 15:32:52.441290  4233 net.cpp:100] Creating Layer detection_eval
I1015 15:32:52.441293  4233 net.cpp:434] detection_eval <- detection_out
I1015 15:32:52.441295  4233 net.cpp:434] detection_eval <- label
I1015 15:32:52.441300  4233 net.cpp:408] detection_eval -> detection_eval
I1015 15:32:52.441354  4233 net.cpp:150] Setting up detection_eval
I1015 15:32:52.441359  4233 net.cpp:157] Top shape: 1 1 3 5 (15)
I1015 15:32:52.441360  4233 net.cpp:165] Memory required for data: 290313664
I1015 15:32:52.441362  4233 layer_factory.hpp:77] Creating layer score_32
I1015 15:32:52.441368  4233 net.cpp:100] Creating Layer score_32
I1015 15:32:52.441371  4233 net.cpp:434] score_32 <- conv13_conv13/relu_0_split_4
I1015 15:32:52.441378  4233 net.cpp:408] score_32 -> score_32
I1015 15:32:52.443253  4233 net.cpp:150] Setting up score_32
I1015 15:32:52.443264  4233 net.cpp:157] Top shape: 1 2 10 15 (300)
I1015 15:32:52.443267  4233 net.cpp:165] Memory required for data: 290314864
I1015 15:32:52.443274  4233 layer_factory.hpp:77] Creating layer upscore_16
I1015 15:32:52.443292  4233 net.cpp:100] Creating Layer upscore_16
I1015 15:32:52.443295  4233 net.cpp:434] upscore_16 <- score_32
I1015 15:32:52.443300  4233 net.cpp:408] upscore_16 -> upscore_16
I1015 15:32:52.443539  4233 net.cpp:150] Setting up upscore_16
I1015 15:32:52.443547  4233 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 15:32:52.443549  4233 net.cpp:165] Memory required for data: 290319664
I1015 15:32:52.443553  4233 layer_factory.hpp:77] Creating layer score_16
I1015 15:32:52.443559  4233 net.cpp:100] Creating Layer score_16
I1015 15:32:52.443562  4233 net.cpp:434] score_16 <- conv11_conv11/relu_0_split_4
I1015 15:32:52.443567  4233 net.cpp:408] score_16 -> score_16
I1015 15:32:52.445767  4233 net.cpp:150] Setting up score_16
I1015 15:32:52.445780  4233 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 15:32:52.445782  4233 net.cpp:165] Memory required for data: 290324464
I1015 15:32:52.445791  4233 layer_factory.hpp:77] Creating layer fuse_16
I1015 15:32:52.445799  4233 net.cpp:100] Creating Layer fuse_16
I1015 15:32:52.445802  4233 net.cpp:434] fuse_16 <- upscore_16
I1015 15:32:52.445806  4233 net.cpp:434] fuse_16 <- score_16
I1015 15:32:52.445809  4233 net.cpp:408] fuse_16 -> fuse_16
I1015 15:32:52.445873  4233 net.cpp:150] Setting up fuse_16
I1015 15:32:52.445881  4233 net.cpp:157] Top shape: 1 2 20 30 (1200)
I1015 15:32:52.445883  4233 net.cpp:165] Memory required for data: 290329264
I1015 15:32:52.445885  4233 layer_factory.hpp:77] Creating layer upscore_8
I1015 15:32:52.445890  4233 net.cpp:100] Creating Layer upscore_8
I1015 15:32:52.445894  4233 net.cpp:434] upscore_8 <- fuse_16
I1015 15:32:52.445897  4233 net.cpp:408] upscore_8 -> upscore_8
I1015 15:32:52.446120  4233 net.cpp:150] Setting up upscore_8
I1015 15:32:52.446127  4233 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 15:32:52.446130  4233 net.cpp:165] Memory required for data: 290348464
I1015 15:32:52.446135  4233 layer_factory.hpp:77] Creating layer score_8
I1015 15:32:52.446143  4233 net.cpp:100] Creating Layer score_8
I1015 15:32:52.446146  4233 net.cpp:434] score_8 <- conv5_conv5/relu_0_split_1
I1015 15:32:52.446151  4233 net.cpp:408] score_8 -> score_8
I1015 15:32:52.448429  4233 net.cpp:150] Setting up score_8
I1015 15:32:52.448441  4233 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 15:32:52.448444  4233 net.cpp:165] Memory required for data: 290367664
I1015 15:32:52.448451  4233 layer_factory.hpp:77] Creating layer fuse_8
I1015 15:32:52.448457  4233 net.cpp:100] Creating Layer fuse_8
I1015 15:32:52.448459  4233 net.cpp:434] fuse_8 <- upscore_8
I1015 15:32:52.448463  4233 net.cpp:434] fuse_8 <- score_8
I1015 15:32:52.448467  4233 net.cpp:408] fuse_8 -> fuse_8
I1015 15:32:52.448501  4233 net.cpp:150] Setting up fuse_8
I1015 15:32:52.448508  4233 net.cpp:157] Top shape: 1 2 40 60 (4800)
I1015 15:32:52.448509  4233 net.cpp:165] Memory required for data: 290386864
I1015 15:32:52.448511  4233 layer_factory.hpp:77] Creating layer upscore_4
I1015 15:32:52.448518  4233 net.cpp:100] Creating Layer upscore_4
I1015 15:32:52.448520  4233 net.cpp:434] upscore_4 <- fuse_8
I1015 15:32:52.448525  4233 net.cpp:408] upscore_4 -> upscore_4
I1015 15:32:52.448750  4233 net.cpp:150] Setting up upscore_4
I1015 15:32:52.448756  4233 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 15:32:52.448758  4233 net.cpp:165] Memory required for data: 290463664
I1015 15:32:52.448763  4233 layer_factory.hpp:77] Creating layer score_4
I1015 15:32:52.448770  4233 net.cpp:100] Creating Layer score_4
I1015 15:32:52.448773  4233 net.cpp:434] score_4 <- conv3_conv3/relu_0_split_1
I1015 15:32:52.448778  4233 net.cpp:408] score_4 -> score_4
I1015 15:32:52.450693  4233 net.cpp:150] Setting up score_4
I1015 15:32:52.450706  4233 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 15:32:52.450709  4233 net.cpp:165] Memory required for data: 290540464
I1015 15:32:52.450717  4233 layer_factory.hpp:77] Creating layer fuse_4
I1015 15:32:52.450726  4233 net.cpp:100] Creating Layer fuse_4
I1015 15:32:52.450729  4233 net.cpp:434] fuse_4 <- upscore_4
I1015 15:32:52.450732  4233 net.cpp:434] fuse_4 <- score_4
I1015 15:32:52.450736  4233 net.cpp:408] fuse_4 -> fuse_4
I1015 15:32:52.450773  4233 net.cpp:150] Setting up fuse_4
I1015 15:32:52.450778  4233 net.cpp:157] Top shape: 1 2 80 120 (19200)
I1015 15:32:52.450780  4233 net.cpp:165] Memory required for data: 290617264
I1015 15:32:52.450783  4233 layer_factory.hpp:77] Creating layer upscore
I1015 15:32:52.450788  4233 net.cpp:100] Creating Layer upscore
I1015 15:32:52.450791  4233 net.cpp:434] upscore <- fuse_4
I1015 15:32:52.450796  4233 net.cpp:408] upscore -> upscore
I1015 15:32:52.451026  4233 net.cpp:150] Setting up upscore
I1015 15:32:52.451033  4233 net.cpp:157] Top shape: 1 2 331 491 (325042)
I1015 15:32:52.451036  4233 net.cpp:165] Memory required for data: 291917432
I1015 15:32:52.451040  4233 layer_factory.hpp:77] Creating layer score
I1015 15:32:52.451046  4233 net.cpp:100] Creating Layer score
I1015 15:32:52.451050  4233 net.cpp:434] score <- upscore
I1015 15:32:52.451052  4233 net.cpp:434] score <- data_data_0_split_7
I1015 15:32:52.451056  4233 net.cpp:408] score -> score
I1015 15:32:52.451089  4233 net.cpp:150] Setting up score
I1015 15:32:52.451095  4233 net.cpp:157] Top shape: 1 2 320 480 (307200)
I1015 15:32:52.451098  4233 net.cpp:165] Memory required for data: 293146232
I1015 15:32:52.451100  4233 layer_factory.hpp:77] Creating layer seg_loss
I1015 15:32:52.451105  4233 net.cpp:100] Creating Layer seg_loss
I1015 15:32:52.451107  4233 net.cpp:434] seg_loss <- score
I1015 15:32:52.451112  4233 net.cpp:434] seg_loss <- label_seg
I1015 15:32:52.451114  4233 net.cpp:408] seg_loss -> seg_loss
I1015 15:32:52.451122  4233 layer_factory.hpp:77] Creating layer seg_loss
I1015 15:32:52.452620  4233 net.cpp:150] Setting up seg_loss
I1015 15:32:52.452631  4233 net.cpp:157] Top shape: (1)
I1015 15:32:52.452633  4233 net.cpp:160]     with loss weight 1
I1015 15:32:52.452644  4233 net.cpp:165] Memory required for data: 293146236
I1015 15:32:52.452648  4233 net.cpp:226] seg_loss needs backward computation.
I1015 15:32:52.452653  4233 net.cpp:226] score needs backward computation.
I1015 15:32:52.452656  4233 net.cpp:226] upscore needs backward computation.
I1015 15:32:52.452659  4233 net.cpp:226] fuse_4 needs backward computation.
I1015 15:32:52.452661  4233 net.cpp:226] score_4 needs backward computation.
I1015 15:32:52.452664  4233 net.cpp:226] upscore_4 needs backward computation.
I1015 15:32:52.452666  4233 net.cpp:226] fuse_8 needs backward computation.
I1015 15:32:52.452669  4233 net.cpp:226] score_8 needs backward computation.
I1015 15:32:52.452672  4233 net.cpp:226] upscore_8 needs backward computation.
I1015 15:32:52.452674  4233 net.cpp:226] fuse_16 needs backward computation.
I1015 15:32:52.452677  4233 net.cpp:226] score_16 needs backward computation.
I1015 15:32:52.452680  4233 net.cpp:226] upscore_16 needs backward computation.
I1015 15:32:52.452682  4233 net.cpp:226] score_32 needs backward computation.
I1015 15:32:52.452687  4233 net.cpp:228] detection_eval does not need backward computation.
I1015 15:32:52.452692  4233 net.cpp:228] detection_out does not need backward computation.
I1015 15:32:52.452698  4233 net.cpp:228] mbox_conf_flatten does not need backward computation.
I1015 15:32:52.452702  4233 net.cpp:228] mbox_conf_softmax does not need backward computation.
I1015 15:32:52.452704  4233 net.cpp:228] mbox_conf_reshape does not need backward computation.
I1015 15:32:52.452708  4233 net.cpp:228] mbox_priorbox does not need backward computation.
I1015 15:32:52.452711  4233 net.cpp:228] mbox_conf does not need backward computation.
I1015 15:32:52.452715  4233 net.cpp:228] mbox_loc does not need backward computation.
I1015 15:32:52.452720  4233 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.452724  4233 net.cpp:228] conv17_2_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452726  4233 net.cpp:228] conv17_2_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452730  4233 net.cpp:228] conv17_2_mbox_conf_new does not need backward computation.
I1015 15:32:52.452733  4233 net.cpp:228] conv17_2_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452736  4233 net.cpp:228] conv17_2_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452739  4233 net.cpp:228] conv17_2_mbox_loc does not need backward computation.
I1015 15:32:52.452744  4233 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.452749  4233 net.cpp:228] conv16_2_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452752  4233 net.cpp:228] conv16_2_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452757  4233 net.cpp:228] conv16_2_mbox_conf_new does not need backward computation.
I1015 15:32:52.452760  4233 net.cpp:228] conv16_2_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452764  4233 net.cpp:228] conv16_2_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452767  4233 net.cpp:228] conv16_2_mbox_loc does not need backward computation.
I1015 15:32:52.452770  4233 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.452774  4233 net.cpp:228] conv15_2_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452776  4233 net.cpp:228] conv15_2_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452780  4233 net.cpp:228] conv15_2_mbox_conf_new does not need backward computation.
I1015 15:32:52.452782  4233 net.cpp:228] conv15_2_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452785  4233 net.cpp:228] conv15_2_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452787  4233 net.cpp:228] conv15_2_mbox_loc does not need backward computation.
I1015 15:32:52.452790  4233 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I1015 15:32:52.452793  4233 net.cpp:228] conv14_2_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452796  4233 net.cpp:228] conv14_2_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452801  4233 net.cpp:228] conv14_2_mbox_conf_new does not need backward computation.
I1015 15:32:52.452805  4233 net.cpp:228] conv14_2_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452807  4233 net.cpp:228] conv14_2_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452811  4233 net.cpp:228] conv14_2_mbox_loc does not need backward computation.
I1015 15:32:52.452816  4233 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I1015 15:32:52.452821  4233 net.cpp:228] conv13_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452826  4233 net.cpp:228] conv13_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452831  4233 net.cpp:228] conv13_mbox_conf_new does not need backward computation.
I1015 15:32:52.452834  4233 net.cpp:228] conv13_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452836  4233 net.cpp:228] conv13_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452839  4233 net.cpp:228] conv13_mbox_loc does not need backward computation.
I1015 15:32:52.452842  4233 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I1015 15:32:52.452845  4233 net.cpp:228] conv11_mbox_conf_flat does not need backward computation.
I1015 15:32:52.452848  4233 net.cpp:228] conv11_mbox_conf_perm does not need backward computation.
I1015 15:32:52.452852  4233 net.cpp:228] conv11_mbox_conf_new does not need backward computation.
I1015 15:32:52.452853  4233 net.cpp:228] conv11_mbox_loc_flat does not need backward computation.
I1015 15:32:52.452857  4233 net.cpp:228] conv11_mbox_loc_perm does not need backward computation.
I1015 15:32:52.452859  4233 net.cpp:228] conv11_mbox_loc does not need backward computation.
I1015 15:32:52.452862  4233 net.cpp:228] conv17_2_conv17_2/relu_0_split does not need backward computation.
I1015 15:32:52.452867  4233 net.cpp:228] conv17_2/relu does not need backward computation.
I1015 15:32:52.452869  4233 net.cpp:228] conv17_2/scale does not need backward computation.
I1015 15:32:52.452872  4233 net.cpp:228] conv17_2/bn does not need backward computation.
I1015 15:32:52.452873  4233 net.cpp:228] conv17_2 does not need backward computation.
I1015 15:32:52.452877  4233 net.cpp:228] conv17_1/relu does not need backward computation.
I1015 15:32:52.452879  4233 net.cpp:228] conv17_1/scale does not need backward computation.
I1015 15:32:52.452881  4233 net.cpp:228] conv17_1/bn does not need backward computation.
I1015 15:32:52.452883  4233 net.cpp:228] conv17_1 does not need backward computation.
I1015 15:32:52.452888  4233 net.cpp:228] conv16_2_conv16_2/relu_0_split does not need backward computation.
I1015 15:32:52.452889  4233 net.cpp:228] conv16_2/relu does not need backward computation.
I1015 15:32:52.452893  4233 net.cpp:228] conv16_2/scale does not need backward computation.
I1015 15:32:52.452894  4233 net.cpp:228] conv16_2/bn does not need backward computation.
I1015 15:32:52.452896  4233 net.cpp:228] conv16_2 does not need backward computation.
I1015 15:32:52.452899  4233 net.cpp:228] conv16_1/relu does not need backward computation.
I1015 15:32:52.452901  4233 net.cpp:228] conv16_1/scale does not need backward computation.
I1015 15:32:52.452904  4233 net.cpp:228] conv16_1/bn does not need backward computation.
I1015 15:32:52.452906  4233 net.cpp:228] conv16_1 does not need backward computation.
I1015 15:32:52.452910  4233 net.cpp:228] conv15_2_conv15_2/relu_0_split does not need backward computation.
I1015 15:32:52.452914  4233 net.cpp:228] conv15_2/relu does not need backward computation.
I1015 15:32:52.452917  4233 net.cpp:228] conv15_2/scale does not need backward computation.
I1015 15:32:52.452921  4233 net.cpp:228] conv15_2/bn does not need backward computation.
I1015 15:32:52.452925  4233 net.cpp:228] conv15_2 does not need backward computation.
I1015 15:32:52.452929  4233 net.cpp:228] conv15_1/relu does not need backward computation.
I1015 15:32:52.452931  4233 net.cpp:228] conv15_1/scale does not need backward computation.
I1015 15:32:52.452935  4233 net.cpp:228] conv15_1/bn does not need backward computation.
I1015 15:32:52.452939  4233 net.cpp:228] conv15_1 does not need backward computation.
I1015 15:32:52.452944  4233 net.cpp:228] conv14_2_conv14_2/relu_0_split does not need backward computation.
I1015 15:32:52.452949  4233 net.cpp:228] conv14_2/relu does not need backward computation.
I1015 15:32:52.452951  4233 net.cpp:228] conv14_2/scale does not need backward computation.
I1015 15:32:52.452955  4233 net.cpp:228] conv14_2/bn does not need backward computation.
I1015 15:32:52.452960  4233 net.cpp:228] conv14_2 does not need backward computation.
I1015 15:32:52.452962  4233 net.cpp:228] conv14_1/relu does not need backward computation.
I1015 15:32:52.452965  4233 net.cpp:228] conv14_1/scale does not need backward computation.
I1015 15:32:52.452967  4233 net.cpp:228] conv14_1/bn does not need backward computation.
I1015 15:32:52.452970  4233 net.cpp:228] conv14_1 does not need backward computation.
I1015 15:32:52.452973  4233 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I1015 15:32:52.452976  4233 net.cpp:226] conv13/relu needs backward computation.
I1015 15:32:52.452978  4233 net.cpp:226] conv13/scale needs backward computation.
I1015 15:32:52.452981  4233 net.cpp:226] conv13/bn needs backward computation.
I1015 15:32:52.452983  4233 net.cpp:226] conv13 needs backward computation.
I1015 15:32:52.452986  4233 net.cpp:226] conv13/dw/relu needs backward computation.
I1015 15:32:52.452988  4233 net.cpp:226] conv13/dw/scale needs backward computation.
I1015 15:32:52.452991  4233 net.cpp:226] conv13/dw/bn needs backward computation.
I1015 15:32:52.452993  4233 net.cpp:226] conv13/dw needs backward computation.
I1015 15:32:52.452996  4233 net.cpp:226] conv12/relu needs backward computation.
I1015 15:32:52.452998  4233 net.cpp:226] conv12/scale needs backward computation.
I1015 15:32:52.453001  4233 net.cpp:226] conv12/bn needs backward computation.
I1015 15:32:52.453002  4233 net.cpp:226] conv12 needs backward computation.
I1015 15:32:52.453004  4233 net.cpp:226] conv12/dw/relu needs backward computation.
I1015 15:32:52.453007  4233 net.cpp:226] conv12/dw/scale needs backward computation.
I1015 15:32:52.453009  4233 net.cpp:226] conv12/dw/bn needs backward computation.
I1015 15:32:52.453011  4233 net.cpp:226] conv12/dw needs backward computation.
I1015 15:32:52.453014  4233 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I1015 15:32:52.453017  4233 net.cpp:226] conv11/relu needs backward computation.
I1015 15:32:52.453019  4233 net.cpp:226] conv11/scale needs backward computation.
I1015 15:32:52.453022  4233 net.cpp:226] conv11/bn needs backward computation.
I1015 15:32:52.453024  4233 net.cpp:226] conv11 needs backward computation.
I1015 15:32:52.453027  4233 net.cpp:226] conv11/dw/relu needs backward computation.
I1015 15:32:52.453028  4233 net.cpp:226] conv11/dw/scale needs backward computation.
I1015 15:32:52.453032  4233 net.cpp:226] conv11/dw/bn needs backward computation.
I1015 15:32:52.453033  4233 net.cpp:226] conv11/dw needs backward computation.
I1015 15:32:52.453037  4233 net.cpp:226] conv10/relu needs backward computation.
I1015 15:32:52.453039  4233 net.cpp:226] conv10/scale needs backward computation.
I1015 15:32:52.453042  4233 net.cpp:226] conv10/bn needs backward computation.
I1015 15:32:52.453047  4233 net.cpp:226] conv10 needs backward computation.
I1015 15:32:52.453050  4233 net.cpp:226] conv10/dw/relu needs backward computation.
I1015 15:32:52.453054  4233 net.cpp:226] conv10/dw/scale needs backward computation.
I1015 15:32:52.453058  4233 net.cpp:226] conv10/dw/bn needs backward computation.
I1015 15:32:52.453061  4233 net.cpp:226] conv10/dw needs backward computation.
I1015 15:32:52.453065  4233 net.cpp:226] conv9/relu needs backward computation.
I1015 15:32:52.453069  4233 net.cpp:226] conv9/scale needs backward computation.
I1015 15:32:52.453073  4233 net.cpp:226] conv9/bn needs backward computation.
I1015 15:32:52.453076  4233 net.cpp:226] conv9 needs backward computation.
I1015 15:32:52.453080  4233 net.cpp:226] conv9/dw/relu needs backward computation.
I1015 15:32:52.453084  4233 net.cpp:226] conv9/dw/scale needs backward computation.
I1015 15:32:52.453088  4233 net.cpp:226] conv9/dw/bn needs backward computation.
I1015 15:32:52.453091  4233 net.cpp:226] conv9/dw needs backward computation.
I1015 15:32:52.453094  4233 net.cpp:226] conv8/relu needs backward computation.
I1015 15:32:52.453096  4233 net.cpp:226] conv8/scale needs backward computation.
I1015 15:32:52.453099  4233 net.cpp:226] conv8/bn needs backward computation.
I1015 15:32:52.453104  4233 net.cpp:226] conv8 needs backward computation.
I1015 15:32:52.453106  4233 net.cpp:226] conv8/dw/relu needs backward computation.
I1015 15:32:52.453109  4233 net.cpp:226] conv8/dw/scale needs backward computation.
I1015 15:32:52.453111  4233 net.cpp:226] conv8/dw/bn needs backward computation.
I1015 15:32:52.453114  4233 net.cpp:226] conv8/dw needs backward computation.
I1015 15:32:52.453116  4233 net.cpp:226] conv7/relu needs backward computation.
I1015 15:32:52.453119  4233 net.cpp:226] conv7/scale needs backward computation.
I1015 15:32:52.453120  4233 net.cpp:226] conv7/bn needs backward computation.
I1015 15:32:52.453124  4233 net.cpp:226] conv7 needs backward computation.
I1015 15:32:52.453127  4233 net.cpp:226] conv7/dw/relu needs backward computation.
I1015 15:32:52.453130  4233 net.cpp:226] conv7/dw/scale needs backward computation.
I1015 15:32:52.453131  4233 net.cpp:226] conv7/dw/bn needs backward computation.
I1015 15:32:52.453135  4233 net.cpp:226] conv7/dw needs backward computation.
I1015 15:32:52.453136  4233 net.cpp:226] conv6/relu needs backward computation.
I1015 15:32:52.453138  4233 net.cpp:226] conv6/scale needs backward computation.
I1015 15:32:52.453141  4233 net.cpp:226] conv6/bn needs backward computation.
I1015 15:32:52.453143  4233 net.cpp:226] conv6 needs backward computation.
I1015 15:32:52.453145  4233 net.cpp:226] conv6/dw/relu needs backward computation.
I1015 15:32:52.453147  4233 net.cpp:226] conv6/dw/scale needs backward computation.
I1015 15:32:52.453150  4233 net.cpp:226] conv6/dw/bn needs backward computation.
I1015 15:32:52.453152  4233 net.cpp:226] conv6/dw needs backward computation.
I1015 15:32:52.453155  4233 net.cpp:226] conv5_conv5/relu_0_split needs backward computation.
I1015 15:32:52.453158  4233 net.cpp:226] conv5/relu needs backward computation.
I1015 15:32:52.453161  4233 net.cpp:226] conv5/scale needs backward computation.
I1015 15:32:52.453166  4233 net.cpp:226] conv5/bn needs backward computation.
I1015 15:32:52.453169  4233 net.cpp:226] conv5 needs backward computation.
I1015 15:32:52.453173  4233 net.cpp:226] conv5/dw/relu needs backward computation.
I1015 15:32:52.453176  4233 net.cpp:226] conv5/dw/scale needs backward computation.
I1015 15:32:52.453178  4233 net.cpp:226] conv5/dw/bn needs backward computation.
I1015 15:32:52.453182  4233 net.cpp:226] conv5/dw needs backward computation.
I1015 15:32:52.453186  4233 net.cpp:226] conv4/relu needs backward computation.
I1015 15:32:52.453191  4233 net.cpp:226] conv4/scale needs backward computation.
I1015 15:32:52.453192  4233 net.cpp:226] conv4/bn needs backward computation.
I1015 15:32:52.453196  4233 net.cpp:226] conv4 needs backward computation.
I1015 15:32:52.453198  4233 net.cpp:226] conv4/dw/relu needs backward computation.
I1015 15:32:52.453202  4233 net.cpp:226] conv4/dw/scale needs backward computation.
I1015 15:32:52.453204  4233 net.cpp:226] conv4/dw/bn needs backward computation.
I1015 15:32:52.453207  4233 net.cpp:226] conv4/dw needs backward computation.
I1015 15:32:52.453209  4233 net.cpp:226] conv3_conv3/relu_0_split needs backward computation.
I1015 15:32:52.453212  4233 net.cpp:226] conv3/relu needs backward computation.
I1015 15:32:52.453214  4233 net.cpp:226] conv3/scale needs backward computation.
I1015 15:32:52.453217  4233 net.cpp:226] conv3/bn needs backward computation.
I1015 15:32:52.453222  4233 net.cpp:226] conv3 needs backward computation.
I1015 15:32:52.453225  4233 net.cpp:226] conv3/dw/relu needs backward computation.
I1015 15:32:52.453228  4233 net.cpp:226] conv3/dw/scale needs backward computation.
I1015 15:32:52.453233  4233 net.cpp:226] conv3/dw/bn needs backward computation.
I1015 15:32:52.453236  4233 net.cpp:226] conv3/dw needs backward computation.
I1015 15:32:52.453240  4233 net.cpp:226] conv2/relu needs backward computation.
I1015 15:32:52.453244  4233 net.cpp:226] conv2/scale needs backward computation.
I1015 15:32:52.453248  4233 net.cpp:226] conv2/bn needs backward computation.
I1015 15:32:52.453251  4233 net.cpp:226] conv2 needs backward computation.
I1015 15:32:52.453255  4233 net.cpp:226] conv2/dw/relu needs backward computation.
I1015 15:32:52.453259  4233 net.cpp:226] conv2/dw/scale needs backward computation.
I1015 15:32:52.453263  4233 net.cpp:226] conv2/dw/bn needs backward computation.
I1015 15:32:52.453265  4233 net.cpp:226] conv2/dw needs backward computation.
I1015 15:32:52.453269  4233 net.cpp:226] conv1/relu needs backward computation.
I1015 15:32:52.453270  4233 net.cpp:226] conv1/scale needs backward computation.
I1015 15:32:52.453272  4233 net.cpp:226] conv1/bn needs backward computation.
I1015 15:32:52.453274  4233 net.cpp:226] conv1 needs backward computation.
I1015 15:32:52.453277  4233 net.cpp:226] conv1/dw/relu needs backward computation.
I1015 15:32:52.453279  4233 net.cpp:226] conv1/dw/scale needs backward computation.
I1015 15:32:52.453282  4233 net.cpp:226] conv1/dw/bn needs backward computation.
I1015 15:32:52.453284  4233 net.cpp:226] conv1/dw needs backward computation.
I1015 15:32:52.453287  4233 net.cpp:226] conv0/relu needs backward computation.
I1015 15:32:52.453289  4233 net.cpp:226] conv0/scale needs backward computation.
I1015 15:32:52.453291  4233 net.cpp:226] conv0/bn needs backward computation.
I1015 15:32:52.453294  4233 net.cpp:226] conv0 needs backward computation.
I1015 15:32:52.453299  4233 net.cpp:228] data_data_0_split does not need backward computation.
I1015 15:32:52.453301  4233 net.cpp:228] data does not need backward computation.
I1015 15:32:52.453303  4233 net.cpp:270] This network produces output detection_eval
I1015 15:32:52.453307  4233 net.cpp:270] This network produces output seg_loss
I1015 15:32:52.453418  4233 net.cpp:283] Network initialization done.
I1015 15:32:52.453847  4233 solver.cpp:75] Solver scaffolding done.
I1015 15:32:52.479965  4233 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: pretrained/mobilenet_iter_73000.caffemodel
I1015 15:32:52.480000  4233 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1015 15:32:52.483745  4233 net.cpp:761] Ignoring source layer conv11_mbox_conf
I1015 15:32:52.483789  4233 net.cpp:761] Ignoring source layer conv13_mbox_conf
I1015 15:32:52.483806  4233 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I1015 15:32:52.483819  4233 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I1015 15:32:52.483830  4233 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I1015 15:32:52.483839  4233 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I1015 15:32:52.976436  4233 solver.cpp:243] Iteration 0, loss = 25.0222
I1015 15:32:52.976464  4233 solver.cpp:259]     Train net output #0: mbox_loss = 24.3291 (* 1 = 24.3291 loss)
I1015 15:32:52.976470  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.693147 (* 1 = 0.693147 loss)
I1015 15:32:52.976475  4233 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I1015 15:32:53.855619  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 15:33:51.298048  4233 solver.cpp:243] Iteration 100, loss = 8.08277
I1015 15:33:51.298080  4233 solver.cpp:259]     Train net output #0: mbox_loss = 7.33723 (* 1 = 7.33723 loss)
I1015 15:33:51.298086  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.199225 (* 1 = 0.199225 loss)
I1015 15:33:51.298092  4233 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I1015 15:34:51.500005  4233 solver.cpp:243] Iteration 200, loss = 8.8588
I1015 15:34:51.500036  4233 solver.cpp:259]     Train net output #0: mbox_loss = 10.7309 (* 1 = 10.7309 loss)
I1015 15:34:51.500042  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.142669 (* 1 = 0.142669 loss)
I1015 15:34:51.500063  4233 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I1015 15:35:52.875962  4233 solver.cpp:243] Iteration 300, loss = 6.53154
I1015 15:35:52.876008  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.27499 (* 1 = 3.27499 loss)
I1015 15:35:52.876013  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.217284 (* 1 = 0.217284 loss)
I1015 15:35:52.876019  4233 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I1015 15:36:53.873105  4233 solver.cpp:243] Iteration 400, loss = 6.72017
I1015 15:36:53.873132  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.25208 (* 1 = 4.25208 loss)
I1015 15:36:53.873139  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.225149 (* 1 = 0.225149 loss)
I1015 15:36:53.873144  4233 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I1015 15:37:54.091823  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_500.caffemodel
I1015 15:37:54.380564  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_500.solverstate
I1015 15:37:55.002346  4233 solver.cpp:243] Iteration 500, loss = 5.39493
I1015 15:37:55.002387  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.34395 (* 1 = 6.34395 loss)
I1015 15:37:55.002393  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.176755 (* 1 = 0.176755 loss)
I1015 15:37:55.002398  4233 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I1015 15:38:54.659047  4233 solver.cpp:243] Iteration 600, loss = 5.37496
I1015 15:38:54.659090  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.69145 (* 1 = 6.69145 loss)
I1015 15:38:54.659096  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.113612 (* 1 = 0.113612 loss)
I1015 15:38:54.659102  4233 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I1015 15:39:54.117272  4233 solver.cpp:243] Iteration 700, loss = 5.99957
I1015 15:39:54.117318  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.81825 (* 1 = 5.81825 loss)
I1015 15:39:54.117324  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.106211 (* 1 = 0.106211 loss)
I1015 15:39:54.117331  4233 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I1015 15:40:54.047216  4233 solver.cpp:243] Iteration 800, loss = 7.30845
I1015 15:40:54.047261  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.68856 (* 1 = 5.68856 loss)
I1015 15:40:54.047267  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.107765 (* 1 = 0.107765 loss)
I1015 15:40:54.047273  4233 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I1015 15:41:54.055842  4233 solver.cpp:243] Iteration 900, loss = 5.61657
I1015 15:41:54.055877  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.52969 (* 1 = 5.52969 loss)
I1015 15:41:54.055887  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.201138 (* 1 = 0.201138 loss)
I1015 15:41:54.055894  4233 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I1015 15:42:54.273667  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1000.caffemodel
I1015 15:42:54.489058  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1000.solverstate
I1015 15:42:55.056371  4233 solver.cpp:243] Iteration 1000, loss = 5.72075
I1015 15:42:55.056406  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.61134 (* 1 = 5.61134 loss)
I1015 15:42:55.056416  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.20803 (* 1 = 0.20803 loss)
I1015 15:42:55.056439  4233 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I1015 15:42:58.559243  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 15:43:54.265856  4233 solver.cpp:243] Iteration 1100, loss = 6.20542
I1015 15:43:54.265884  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.39795 (* 1 = 3.39795 loss)
I1015 15:43:54.265892  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0978331 (* 1 = 0.0978331 loss)
I1015 15:43:54.265897  4233 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I1015 15:44:55.076573  4233 solver.cpp:243] Iteration 1200, loss = 5.71456
I1015 15:44:55.076604  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.99014 (* 1 = 5.99014 loss)
I1015 15:44:55.076611  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.118007 (* 1 = 0.118007 loss)
I1015 15:44:55.076617  4233 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I1015 15:45:53.882140  4233 solver.cpp:243] Iteration 1300, loss = 6.7755
I1015 15:45:53.882174  4233 solver.cpp:259]     Train net output #0: mbox_loss = 8.77128 (* 1 = 8.77128 loss)
I1015 15:45:53.882180  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.202243 (* 1 = 0.202243 loss)
I1015 15:45:53.882185  4233 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I1015 15:46:54.263931  4233 solver.cpp:243] Iteration 1400, loss = 4.99385
I1015 15:46:54.263978  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.07327 (* 1 = 3.07327 loss)
I1015 15:46:54.263984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.151542 (* 1 = 0.151542 loss)
I1015 15:46:54.263990  4233 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I1015 15:47:54.500062  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_1500.caffemodel
I1015 15:47:55.291481  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_1500.solverstate
I1015 15:47:55.854640  4233 solver.cpp:243] Iteration 1500, loss = 6.03805
I1015 15:47:55.854672  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.27035 (* 1 = 3.27035 loss)
I1015 15:47:55.854679  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.149723 (* 1 = 0.149723 loss)
I1015 15:47:55.854684  4233 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I1015 15:48:55.441224  4233 solver.cpp:243] Iteration 1600, loss = 5.46798
I1015 15:48:55.441272  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.40575 (* 1 = 2.40575 loss)
I1015 15:48:55.441278  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0834936 (* 1 = 0.0834936 loss)
I1015 15:48:55.441284  4233 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I1015 15:49:54.675168  4233 solver.cpp:243] Iteration 1700, loss = 5.37316
I1015 15:49:54.675213  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.91197 (* 1 = 4.91197 loss)
I1015 15:49:54.675220  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0926937 (* 1 = 0.0926937 loss)
I1015 15:49:54.675225  4233 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I1015 15:50:53.099987  4233 solver.cpp:243] Iteration 1800, loss = 4.73594
I1015 15:50:53.100030  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.72491 (* 1 = 5.72491 loss)
I1015 15:50:53.100036  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.186876 (* 1 = 0.186876 loss)
I1015 15:50:53.100042  4233 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I1015 15:51:53.038537  4233 solver.cpp:243] Iteration 1900, loss = 6.1052
I1015 15:51:53.038581  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.39213 (* 1 = 4.39213 loss)
I1015 15:51:53.038588  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.21525 (* 1 = 0.21525 loss)
I1015 15:51:53.038594  4233 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I1015 15:52:52.045756  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2000.caffemodel
I1015 15:52:52.281391  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2000.solverstate
I1015 15:52:53.273218  4233 solver.cpp:243] Iteration 2000, loss = 5.24424
I1015 15:52:53.273264  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.06202 (* 1 = 4.06202 loss)
I1015 15:52:53.273272  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.161866 (* 1 = 0.161866 loss)
I1015 15:52:53.273277  4233 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I1015 15:53:01.801879  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 15:53:53.364735  4233 solver.cpp:243] Iteration 2100, loss = 3.94204
I1015 15:53:53.364766  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.61784 (* 1 = 3.61784 loss)
I1015 15:53:53.364773  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.124523 (* 1 = 0.124523 loss)
I1015 15:53:53.364779  4233 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I1015 15:54:53.113428  4233 solver.cpp:243] Iteration 2200, loss = 4.96137
I1015 15:54:53.113457  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.57172 (* 1 = 3.57172 loss)
I1015 15:54:53.113464  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.132883 (* 1 = 0.132883 loss)
I1015 15:54:53.113471  4233 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I1015 15:55:52.989565  4233 solver.cpp:243] Iteration 2300, loss = 4.6388
I1015 15:55:52.989599  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.43413 (* 1 = 4.43413 loss)
I1015 15:55:52.989605  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0950125 (* 1 = 0.0950125 loss)
I1015 15:55:52.989611  4233 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I1015 15:56:53.049317  4233 solver.cpp:243] Iteration 2400, loss = 6.9052
I1015 15:56:53.049348  4233 solver.cpp:259]     Train net output #0: mbox_loss = 7.43894 (* 1 = 7.43894 loss)
I1015 15:56:53.049355  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0970467 (* 1 = 0.0970467 loss)
I1015 15:56:53.049376  4233 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I1015 15:57:52.333317  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_2500.caffemodel
I1015 15:57:52.561856  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_2500.solverstate
I1015 15:57:53.669427  4233 solver.cpp:243] Iteration 2500, loss = 5.34559
I1015 15:57:53.669458  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.73917 (* 1 = 6.73917 loss)
I1015 15:57:53.669464  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0994129 (* 1 = 0.0994129 loss)
I1015 15:57:53.669471  4233 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I1015 15:58:52.886507  4233 solver.cpp:243] Iteration 2600, loss = 4.07774
I1015 15:58:52.886538  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.19586 (* 1 = 4.19586 loss)
I1015 15:58:52.886544  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.11386 (* 1 = 0.11386 loss)
I1015 15:58:52.886551  4233 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I1015 15:59:53.063463  4233 solver.cpp:243] Iteration 2700, loss = 5.5163
I1015 15:59:53.063491  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.07501 (* 1 = 4.07501 loss)
I1015 15:59:53.063498  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.110505 (* 1 = 0.110505 loss)
I1015 15:59:53.063503  4233 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I1015 16:00:52.163671  4233 solver.cpp:243] Iteration 2800, loss = 4.21067
I1015 16:00:52.163699  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.25495 (* 1 = 4.25495 loss)
I1015 16:00:52.163707  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.111108 (* 1 = 0.111108 loss)
I1015 16:00:52.163712  4233 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I1015 16:01:51.558532  4233 solver.cpp:243] Iteration 2900, loss = 5.1073
I1015 16:01:51.558563  4233 solver.cpp:259]     Train net output #0: mbox_loss = 7.91268 (* 1 = 7.91268 loss)
I1015 16:01:51.558570  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.126987 (* 1 = 0.126987 loss)
I1015 16:01:51.558576  4233 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I1015 16:02:51.346015  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3000.caffemodel
I1015 16:02:51.604143  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3000.solverstate
I1015 16:02:52.203500  4233 solver.cpp:243] Iteration 3000, loss = 4.6133
I1015 16:02:52.203528  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.75149 (* 1 = 4.75149 loss)
I1015 16:02:52.203534  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.15742 (* 1 = 0.15742 loss)
I1015 16:02:52.203541  4233 sgd_solver.cpp:138] Iteration 3000, lr = 0.0005
I1015 16:03:05.141492  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:03:52.375154  4233 solver.cpp:243] Iteration 3100, loss = 4.95672
I1015 16:03:52.375200  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.01656 (* 1 = 6.01656 loss)
I1015 16:03:52.375205  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.150196 (* 1 = 0.150196 loss)
I1015 16:03:52.375211  4233 sgd_solver.cpp:138] Iteration 3100, lr = 0.0005
I1015 16:04:53.770948  4233 solver.cpp:243] Iteration 3200, loss = 5.02806
I1015 16:04:53.770977  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.54672 (* 1 = 4.54672 loss)
I1015 16:04:53.770984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0944664 (* 1 = 0.0944664 loss)
I1015 16:04:53.770989  4233 sgd_solver.cpp:138] Iteration 3200, lr = 0.0005
I1015 16:05:53.691287  4233 solver.cpp:243] Iteration 3300, loss = 4.97978
I1015 16:05:53.691330  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.71749 (* 1 = 3.71749 loss)
I1015 16:05:53.691337  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.075402 (* 1 = 0.075402 loss)
I1015 16:05:53.691342  4233 sgd_solver.cpp:138] Iteration 3300, lr = 0.0005
I1015 16:06:53.088649  4233 solver.cpp:243] Iteration 3400, loss = 4.49939
I1015 16:06:53.088680  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.59755 (* 1 = 5.59755 loss)
I1015 16:06:53.088688  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0911004 (* 1 = 0.0911004 loss)
I1015 16:06:53.088711  4233 sgd_solver.cpp:138] Iteration 3400, lr = 0.0005
I1015 16:07:52.343518  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_3500.caffemodel
I1015 16:07:52.576349  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_3500.solverstate
I1015 16:07:53.514873  4233 solver.cpp:243] Iteration 3500, loss = 6.43458
I1015 16:07:53.514914  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.90385 (* 1 = 6.90385 loss)
I1015 16:07:53.514921  4233 solver.cpp:259]     Train net output #1: seg_loss = 1.32608 (* 1 = 1.32608 loss)
I1015 16:07:53.514926  4233 sgd_solver.cpp:138] Iteration 3500, lr = 0.0005
I1015 16:08:52.127980  4233 solver.cpp:243] Iteration 3600, loss = 5.21378
I1015 16:08:52.128027  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.73305 (* 1 = 3.73305 loss)
I1015 16:08:52.128034  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0874866 (* 1 = 0.0874866 loss)
I1015 16:08:52.128039  4233 sgd_solver.cpp:138] Iteration 3600, lr = 0.0005
I1015 16:09:52.915925  4233 solver.cpp:243] Iteration 3700, loss = 3.92286
I1015 16:09:52.915956  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.20593 (* 1 = 5.20593 loss)
I1015 16:09:52.915962  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.121131 (* 1 = 0.121131 loss)
I1015 16:09:52.915968  4233 sgd_solver.cpp:138] Iteration 3700, lr = 0.0005
I1015 16:10:53.120309  4233 solver.cpp:243] Iteration 3800, loss = 5.9044
I1015 16:10:53.120354  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.93871 (* 1 = 6.93871 loss)
I1015 16:10:53.120362  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.104413 (* 1 = 0.104413 loss)
I1015 16:10:53.120366  4233 sgd_solver.cpp:138] Iteration 3800, lr = 0.0005
I1015 16:11:52.200618  4233 solver.cpp:243] Iteration 3900, loss = 4.55839
I1015 16:11:52.200662  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.78685 (* 1 = 2.78685 loss)
I1015 16:11:52.200670  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0955236 (* 1 = 0.0955236 loss)
I1015 16:11:52.200675  4233 sgd_solver.cpp:138] Iteration 3900, lr = 0.0005
I1015 16:12:50.647579  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4000.caffemodel
I1015 16:12:50.889789  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4000.solverstate
I1015 16:12:51.078233  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 16:12:56.608395  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:14:30.494555  4233 solver.cpp:243] Iteration 4000, loss = 6.08951
I1015 16:14:30.494587  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.90149 (* 1 = 5.90149 loss)
I1015 16:14:30.494594  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.188015 (* 1 = 0.188015 loss)
I1015 16:14:30.494601  4233 sgd_solver.cpp:138] Iteration 4000, lr = 0.0005
I1015 16:15:29.557576  4233 solver.cpp:243] Iteration 4100, loss = 3.77177
I1015 16:15:29.557621  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.3581 (* 1 = 3.3581 loss)
I1015 16:15:29.557626  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0806856 (* 1 = 0.0806856 loss)
I1015 16:15:29.557641  4233 sgd_solver.cpp:138] Iteration 4100, lr = 0.0005
I1015 16:16:29.510922  4233 solver.cpp:243] Iteration 4200, loss = 5.06303
I1015 16:16:29.510968  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.86777 (* 1 = 3.86777 loss)
I1015 16:16:29.510975  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.112158 (* 1 = 0.112158 loss)
I1015 16:16:29.510982  4233 sgd_solver.cpp:138] Iteration 4200, lr = 0.0005
I1015 16:17:29.636716  4233 solver.cpp:243] Iteration 4300, loss = 3.45831
I1015 16:17:29.636759  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.74336 (* 1 = 2.74336 loss)
I1015 16:17:29.636766  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.110251 (* 1 = 0.110251 loss)
I1015 16:17:29.636771  4233 sgd_solver.cpp:138] Iteration 4300, lr = 0.0005
I1015 16:18:28.621428  4233 solver.cpp:243] Iteration 4400, loss = 4.48701
I1015 16:18:28.621479  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.87623 (* 1 = 2.87623 loss)
I1015 16:18:28.621486  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.093635 (* 1 = 0.093635 loss)
I1015 16:18:28.621492  4233 sgd_solver.cpp:138] Iteration 4400, lr = 0.0005
I1015 16:19:26.330693  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_4500.caffemodel
I1015 16:19:26.585908  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_4500.solverstate
I1015 16:19:27.169860  4233 solver.cpp:243] Iteration 4500, loss = 3.84725
I1015 16:19:27.169890  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.73265 (* 1 = 4.73265 loss)
I1015 16:19:27.169896  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0968019 (* 1 = 0.0968019 loss)
I1015 16:19:27.169903  4233 sgd_solver.cpp:138] Iteration 4500, lr = 0.0005
I1015 16:19:50.589826  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:20:27.286725  4233 solver.cpp:243] Iteration 4600, loss = 5.48605
I1015 16:20:27.286767  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.02554 (* 1 = 5.02554 loss)
I1015 16:20:27.286773  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.127731 (* 1 = 0.127731 loss)
I1015 16:20:27.286779  4233 sgd_solver.cpp:138] Iteration 4600, lr = 0.0005
I1015 16:21:26.760999  4233 solver.cpp:243] Iteration 4700, loss = 4.63828
I1015 16:21:26.761029  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.76798 (* 1 = 4.76798 loss)
I1015 16:21:26.761036  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0966657 (* 1 = 0.0966657 loss)
I1015 16:21:26.761042  4233 sgd_solver.cpp:138] Iteration 4700, lr = 0.0005
I1015 16:22:26.999109  4233 solver.cpp:243] Iteration 4800, loss = 4.23248
I1015 16:22:26.999155  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.20628 (* 1 = 2.20628 loss)
I1015 16:22:26.999161  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.292593 (* 1 = 0.292593 loss)
I1015 16:22:26.999166  4233 sgd_solver.cpp:138] Iteration 4800, lr = 0.0005
I1015 16:23:26.124189  4233 solver.cpp:243] Iteration 4900, loss = 4.53911
I1015 16:23:26.124233  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.68915 (* 1 = 4.68915 loss)
I1015 16:23:26.124239  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.169649 (* 1 = 0.169649 loss)
I1015 16:23:26.124245  4233 sgd_solver.cpp:138] Iteration 4900, lr = 0.0005
I1015 16:24:24.622305  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5000.caffemodel
I1015 16:24:24.861640  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5000.solverstate
I1015 16:24:25.430603  4233 solver.cpp:243] Iteration 5000, loss = 4.28621
I1015 16:24:25.430642  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.4911 (* 1 = 2.4911 loss)
I1015 16:24:25.430649  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.126955 (* 1 = 0.126955 loss)
I1015 16:24:25.430655  4233 sgd_solver.cpp:138] Iteration 5000, lr = 0.0005
I1015 16:25:24.082612  4233 solver.cpp:243] Iteration 5100, loss = 5.39973
I1015 16:25:24.082659  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.26176 (* 1 = 5.26176 loss)
I1015 16:25:24.082664  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.1341 (* 1 = 0.1341 loss)
I1015 16:25:24.082669  4233 sgd_solver.cpp:138] Iteration 5100, lr = 0.0005
I1015 16:26:24.571897  4233 solver.cpp:243] Iteration 5200, loss = 3.49327
I1015 16:26:24.571941  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.70095 (* 1 = 2.70095 loss)
I1015 16:26:24.571947  4233 solver.cpp:259]     Train net output #1: seg_loss = 2.93853 (* 1 = 2.93853 loss)
I1015 16:26:24.571954  4233 sgd_solver.cpp:138] Iteration 5200, lr = 0.0005
I1015 16:27:24.826937  4233 solver.cpp:243] Iteration 5300, loss = 3.78921
I1015 16:27:24.826982  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.36689 (* 1 = 4.36689 loss)
I1015 16:27:24.826989  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.075473 (* 1 = 0.075473 loss)
I1015 16:27:24.826995  4233 sgd_solver.cpp:138] Iteration 5300, lr = 0.0005
I1015 16:28:25.162276  4233 solver.cpp:243] Iteration 5400, loss = 2.95883
I1015 16:28:25.162318  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.7579 (* 1 = 2.7579 loss)
I1015 16:28:25.162324  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.124333 (* 1 = 0.124333 loss)
I1015 16:28:25.162329  4233 sgd_solver.cpp:138] Iteration 5400, lr = 0.0005
I1015 16:29:24.388324  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_5500.caffemodel
I1015 16:29:24.620841  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_5500.solverstate
I1015 16:29:25.207391  4233 solver.cpp:243] Iteration 5500, loss = 4.25236
I1015 16:29:25.207432  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.67693 (* 1 = 3.67693 loss)
I1015 16:29:25.207437  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0663044 (* 1 = 0.0663044 loss)
I1015 16:29:25.207443  4233 sgd_solver.cpp:138] Iteration 5500, lr = 0.0005
I1015 16:29:50.760617  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:30:23.424969  4233 solver.cpp:243] Iteration 5600, loss = 4.48469
I1015 16:30:23.425014  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.71779 (* 1 = 4.71779 loss)
I1015 16:30:23.425020  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.117519 (* 1 = 0.117519 loss)
I1015 16:30:23.425025  4233 sgd_solver.cpp:138] Iteration 5600, lr = 0.0005
I1015 16:31:23.498764  4233 solver.cpp:243] Iteration 5700, loss = 4.54045
I1015 16:31:23.498809  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.32718 (* 1 = 3.32718 loss)
I1015 16:31:23.498816  4233 solver.cpp:259]     Train net output #1: seg_loss = 1.89769 (* 1 = 1.89769 loss)
I1015 16:31:23.498821  4233 sgd_solver.cpp:138] Iteration 5700, lr = 0.0005
I1015 16:32:24.250105  4233 solver.cpp:243] Iteration 5800, loss = 3.14824
I1015 16:32:24.250136  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.39667 (* 1 = 2.39667 loss)
I1015 16:32:24.250142  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.114751 (* 1 = 0.114751 loss)
I1015 16:32:24.250149  4233 sgd_solver.cpp:138] Iteration 5800, lr = 0.0005
I1015 16:33:25.721875  4233 solver.cpp:243] Iteration 5900, loss = 3.88402
I1015 16:33:25.721905  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.99868 (* 1 = 2.99868 loss)
I1015 16:33:25.721911  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.217261 (* 1 = 0.217261 loss)
I1015 16:33:25.721917  4233 sgd_solver.cpp:138] Iteration 5900, lr = 0.0005
I1015 16:34:25.400240  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6000.caffemodel
I1015 16:34:25.623298  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6000.solverstate
I1015 16:34:26.214342  4233 solver.cpp:243] Iteration 6000, loss = 4.20441
I1015 16:34:26.214385  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.72222 (* 1 = 4.72222 loss)
I1015 16:34:26.214391  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.137139 (* 1 = 0.137139 loss)
I1015 16:34:26.214397  4233 sgd_solver.cpp:138] Iteration 6000, lr = 0.0005
I1015 16:35:25.651351  4233 solver.cpp:243] Iteration 6100, loss = 3.85762
I1015 16:35:25.651381  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.67253 (* 1 = 3.67253 loss)
I1015 16:35:25.651387  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.126875 (* 1 = 0.126875 loss)
I1015 16:35:25.651392  4233 sgd_solver.cpp:138] Iteration 6100, lr = 0.0005
I1015 16:36:25.186830  4233 solver.cpp:243] Iteration 6200, loss = 5.69664
I1015 16:36:25.186874  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.49421 (* 1 = 5.49421 loss)
I1015 16:36:25.186880  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0860229 (* 1 = 0.0860229 loss)
I1015 16:36:25.186887  4233 sgd_solver.cpp:138] Iteration 6200, lr = 0.0005
I1015 16:37:25.016604  4233 solver.cpp:243] Iteration 6300, loss = 3.96986
I1015 16:37:25.016649  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.74911 (* 1 = 4.74911 loss)
I1015 16:37:25.016656  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0711946 (* 1 = 0.0711946 loss)
I1015 16:37:25.016661  4233 sgd_solver.cpp:138] Iteration 6300, lr = 0.0005
I1015 16:38:25.821883  4233 solver.cpp:243] Iteration 6400, loss = 2.4879
I1015 16:38:25.821911  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.81618 (* 1 = 4.81618 loss)
I1015 16:38:25.821918  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0794679 (* 1 = 0.0794679 loss)
I1015 16:38:25.821923  4233 sgd_solver.cpp:138] Iteration 6400, lr = 0.0005
I1015 16:39:25.827730  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_6500.caffemodel
I1015 16:39:26.056794  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_6500.solverstate
I1015 16:39:26.625499  4233 solver.cpp:243] Iteration 6500, loss = 4.58924
I1015 16:39:26.625527  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.03633 (* 1 = 6.03633 loss)
I1015 16:39:26.625535  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.114518 (* 1 = 0.114518 loss)
I1015 16:39:26.625540  4233 sgd_solver.cpp:138] Iteration 6500, lr = 0.0005
I1015 16:39:55.486616  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:40:26.560063  4233 solver.cpp:243] Iteration 6600, loss = 4.24907
I1015 16:40:26.560111  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.0309 (* 1 = 5.0309 loss)
I1015 16:40:26.560117  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0994005 (* 1 = 0.0994005 loss)
I1015 16:40:26.560123  4233 sgd_solver.cpp:138] Iteration 6600, lr = 0.0005
I1015 16:41:26.003312  4233 solver.cpp:243] Iteration 6700, loss = 5.20087
I1015 16:41:26.003345  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.64261 (* 1 = 6.64261 loss)
I1015 16:41:26.003351  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0734827 (* 1 = 0.0734827 loss)
I1015 16:41:26.003357  4233 sgd_solver.cpp:138] Iteration 6700, lr = 0.0005
I1015 16:42:26.750305  4233 solver.cpp:243] Iteration 6800, loss = 3.69496
I1015 16:42:26.750339  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.70497 (* 1 = 3.70497 loss)
I1015 16:42:26.750347  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.142327 (* 1 = 0.142327 loss)
I1015 16:42:26.750370  4233 sgd_solver.cpp:138] Iteration 6800, lr = 0.0005
I1015 16:43:26.932442  4233 solver.cpp:243] Iteration 6900, loss = 4.10582
I1015 16:43:26.932487  4233 solver.cpp:259]     Train net output #0: mbox_loss = 6.1865 (* 1 = 6.1865 loss)
I1015 16:43:26.932493  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.101296 (* 1 = 0.101296 loss)
I1015 16:43:26.932499  4233 sgd_solver.cpp:138] Iteration 6900, lr = 0.0005
I1015 16:44:26.748493  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7000.caffemodel
I1015 16:44:26.978299  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7000.solverstate
I1015 16:44:27.542527  4233 solver.cpp:243] Iteration 7000, loss = 2.99627
I1015 16:44:27.542557  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.83608 (* 1 = 1.83608 loss)
I1015 16:44:27.542563  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0672201 (* 1 = 0.0672201 loss)
I1015 16:44:27.542569  4233 sgd_solver.cpp:138] Iteration 7000, lr = 0.0005
I1015 16:45:27.896307  4233 solver.cpp:243] Iteration 7100, loss = 2.83499
I1015 16:45:27.896338  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.41374 (* 1 = 2.41374 loss)
I1015 16:45:27.896344  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0768105 (* 1 = 0.0768105 loss)
I1015 16:45:27.896350  4233 sgd_solver.cpp:138] Iteration 7100, lr = 0.0005
I1015 16:46:27.107847  4233 solver.cpp:243] Iteration 7200, loss = 3.49469
I1015 16:46:27.107893  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.16952 (* 1 = 2.16952 loss)
I1015 16:46:27.107899  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0566108 (* 1 = 0.0566108 loss)
I1015 16:46:27.107906  4233 sgd_solver.cpp:138] Iteration 7200, lr = 0.0005
I1015 16:47:26.876374  4233 solver.cpp:243] Iteration 7300, loss = 4.84029
I1015 16:47:26.876418  4233 solver.cpp:259]     Train net output #0: mbox_loss = 7.29941 (* 1 = 7.29941 loss)
I1015 16:47:26.876425  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.12719 (* 1 = 0.12719 loss)
I1015 16:47:26.876430  4233 sgd_solver.cpp:138] Iteration 7300, lr = 0.0005
I1015 16:48:26.205487  4233 solver.cpp:243] Iteration 7400, loss = 3.41206
I1015 16:48:26.205533  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.3535 (* 1 = 4.3535 loss)
I1015 16:48:26.205539  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.71465 (* 1 = 0.71465 loss)
I1015 16:48:26.205545  4233 sgd_solver.cpp:138] Iteration 7400, lr = 0.0005
I1015 16:49:26.079275  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_7500.caffemodel
I1015 16:49:26.325156  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_7500.solverstate
I1015 16:49:26.901872  4233 solver.cpp:243] Iteration 7500, loss = 3.73481
I1015 16:49:26.901906  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.57274 (* 1 = 4.57274 loss)
I1015 16:49:26.901916  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.103938 (* 1 = 0.103938 loss)
I1015 16:49:26.901922  4233 sgd_solver.cpp:138] Iteration 7500, lr = 0.0005
I1015 16:49:57.891315  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:50:25.956948  4233 solver.cpp:243] Iteration 7600, loss = 4.40095
I1015 16:50:25.956980  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.02662 (* 1 = 5.02662 loss)
I1015 16:50:25.956990  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0585029 (* 1 = 0.0585029 loss)
I1015 16:50:25.956997  4233 sgd_solver.cpp:138] Iteration 7600, lr = 0.0005
I1015 16:51:25.473615  4233 solver.cpp:243] Iteration 7700, loss = 3.62811
I1015 16:51:25.473649  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.42779 (* 1 = 4.42779 loss)
I1015 16:51:25.473659  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.117647 (* 1 = 0.117647 loss)
I1015 16:51:25.473681  4233 sgd_solver.cpp:138] Iteration 7700, lr = 0.0005
I1015 16:52:25.129371  4233 solver.cpp:243] Iteration 7800, loss = 4.14546
I1015 16:52:25.129403  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.80355 (* 1 = 3.80355 loss)
I1015 16:52:25.129410  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0731217 (* 1 = 0.0731217 loss)
I1015 16:52:25.129415  4233 sgd_solver.cpp:138] Iteration 7800, lr = 0.0005
I1015 16:53:25.820452  4233 solver.cpp:243] Iteration 7900, loss = 3.22282
I1015 16:53:25.820483  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.97368 (* 1 = 4.97368 loss)
I1015 16:53:25.820489  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.176084 (* 1 = 0.176084 loss)
I1015 16:53:25.820494  4233 sgd_solver.cpp:138] Iteration 7900, lr = 0.0005
I1015 16:54:26.417601  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8000.caffemodel
I1015 16:54:26.672718  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8000.solverstate
I1015 16:54:26.917176  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 16:56:06.040220  4233 solver.cpp:243] Iteration 8000, loss = 4.46907
I1015 16:56:06.040252  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.34372 (* 1 = 4.34372 loss)
I1015 16:56:06.040258  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.125356 (* 1 = 0.125356 loss)
I1015 16:56:06.040264  4233 sgd_solver.cpp:138] Iteration 8000, lr = 0.0005
I1015 16:56:42.492799  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 16:57:05.565721  4233 solver.cpp:243] Iteration 8100, loss = 3.48363
I1015 16:57:05.565763  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.08833 (* 1 = 2.08833 loss)
I1015 16:57:05.565770  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.072986 (* 1 = 0.072986 loss)
I1015 16:57:05.565775  4233 sgd_solver.cpp:138] Iteration 8100, lr = 0.0005
I1015 16:58:04.500587  4233 solver.cpp:243] Iteration 8200, loss = 3.49706
I1015 16:58:04.500632  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.18374 (* 1 = 3.18374 loss)
I1015 16:58:04.500638  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0806531 (* 1 = 0.0806531 loss)
I1015 16:58:04.500643  4233 sgd_solver.cpp:138] Iteration 8200, lr = 0.0005
I1015 16:59:03.212322  4233 solver.cpp:243] Iteration 8300, loss = 2.83301
I1015 16:59:03.212374  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.11377 (* 1 = 3.11377 loss)
I1015 16:59:03.212381  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0767131 (* 1 = 0.0767131 loss)
I1015 16:59:03.212388  4233 sgd_solver.cpp:138] Iteration 8300, lr = 0.0005
I1015 17:00:04.528892  4233 solver.cpp:243] Iteration 8400, loss = 4.4293
I1015 17:00:04.528925  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.81089 (* 1 = 2.81089 loss)
I1015 17:00:04.528931  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0881187 (* 1 = 0.0881187 loss)
I1015 17:00:04.528937  4233 sgd_solver.cpp:138] Iteration 8400, lr = 0.0005
I1015 17:01:04.612725  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_8500.caffemodel
I1015 17:01:05.432787  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_8500.solverstate
I1015 17:01:06.059142  4233 solver.cpp:243] Iteration 8500, loss = 3.27591
I1015 17:01:06.059171  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.43185 (* 1 = 1.43185 loss)
I1015 17:01:06.059178  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0930116 (* 1 = 0.0930116 loss)
I1015 17:01:06.059185  4233 sgd_solver.cpp:138] Iteration 8500, lr = 0.0005
I1015 17:02:05.948689  4233 solver.cpp:243] Iteration 8600, loss = 2.57543
I1015 17:02:05.948736  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.09606 (* 1 = 5.09606 loss)
I1015 17:02:05.948743  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.137083 (* 1 = 0.137083 loss)
I1015 17:02:05.948750  4233 sgd_solver.cpp:138] Iteration 8600, lr = 0.0005
I1015 17:03:04.979832  4233 solver.cpp:243] Iteration 8700, loss = 3.38915
I1015 17:03:04.979876  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.61578 (* 1 = 3.61578 loss)
I1015 17:03:04.979883  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0904228 (* 1 = 0.0904228 loss)
I1015 17:03:04.979888  4233 sgd_solver.cpp:138] Iteration 8700, lr = 0.0005
I1015 17:04:04.547245  4233 solver.cpp:243] Iteration 8800, loss = 3.01954
I1015 17:04:04.547276  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.44937 (* 1 = 3.44937 loss)
I1015 17:04:04.547283  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0714007 (* 1 = 0.0714007 loss)
I1015 17:04:04.547288  4233 sgd_solver.cpp:138] Iteration 8800, lr = 0.0005
I1015 17:05:04.967253  4233 solver.cpp:243] Iteration 8900, loss = 5.03254
I1015 17:05:04.967296  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.94866 (* 1 = 3.94866 loss)
I1015 17:05:04.967303  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.137208 (* 1 = 0.137208 loss)
I1015 17:05:04.967308  4233 sgd_solver.cpp:138] Iteration 8900, lr = 0.0005
I1015 17:06:04.135390  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9000.caffemodel
I1015 17:06:04.868423  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9000.solverstate
I1015 17:06:05.430671  4233 solver.cpp:243] Iteration 9000, loss = 3.32815
I1015 17:06:05.430702  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.5496 (* 1 = 2.5496 loss)
I1015 17:06:05.430711  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.126152 (* 1 = 0.126152 loss)
I1015 17:06:05.430732  4233 sgd_solver.cpp:138] Iteration 9000, lr = 0.0005
I1015 17:06:48.140940  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:07:04.803725  4233 solver.cpp:243] Iteration 9100, loss = 2.46003
I1015 17:07:04.803769  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.67263 (* 1 = 1.67263 loss)
I1015 17:07:04.803776  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0758464 (* 1 = 0.0758464 loss)
I1015 17:07:04.803781  4233 sgd_solver.cpp:138] Iteration 9100, lr = 0.0005
I1015 17:08:04.686345  4233 solver.cpp:243] Iteration 9200, loss = 3.74156
I1015 17:08:04.686377  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.18261 (* 1 = 4.18261 loss)
I1015 17:08:04.686383  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.150095 (* 1 = 0.150095 loss)
I1015 17:08:04.686388  4233 sgd_solver.cpp:138] Iteration 9200, lr = 0.0005
I1015 17:09:03.690165  4233 solver.cpp:243] Iteration 9300, loss = 2.73462
I1015 17:09:03.690196  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.61826 (* 1 = 3.61826 loss)
I1015 17:09:03.690204  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0798479 (* 1 = 0.0798479 loss)
I1015 17:09:03.690227  4233 sgd_solver.cpp:138] Iteration 9300, lr = 0.0005
I1015 17:10:02.178658  4233 solver.cpp:243] Iteration 9400, loss = 3.26507
I1015 17:10:02.178689  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.69132 (* 1 = 4.69132 loss)
I1015 17:10:02.178699  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0976885 (* 1 = 0.0976885 loss)
I1015 17:10:02.178721  4233 sgd_solver.cpp:138] Iteration 9400, lr = 0.0005
I1015 17:11:01.828608  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_9500.caffemodel
I1015 17:11:02.079455  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_9500.solverstate
I1015 17:11:02.724506  4233 solver.cpp:243] Iteration 9500, loss = 2.7667
I1015 17:11:02.724539  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.89686 (* 1 = 2.89686 loss)
I1015 17:11:02.724545  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0719765 (* 1 = 0.0719765 loss)
I1015 17:11:02.724551  4233 sgd_solver.cpp:138] Iteration 9500, lr = 0.0005
I1015 17:12:02.542201  4233 solver.cpp:243] Iteration 9600, loss = 3.36487
I1015 17:12:02.542232  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.20108 (* 1 = 4.20108 loss)
I1015 17:12:02.542241  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.197458 (* 1 = 0.197458 loss)
I1015 17:12:02.542264  4233 sgd_solver.cpp:138] Iteration 9600, lr = 0.0005
I1015 17:13:02.899919  4233 solver.cpp:243] Iteration 9700, loss = 3.19839
I1015 17:13:02.899951  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.94121 (* 1 = 2.94121 loss)
I1015 17:13:02.899957  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0778063 (* 1 = 0.0778063 loss)
I1015 17:13:02.899962  4233 sgd_solver.cpp:138] Iteration 9700, lr = 0.0005
I1015 17:14:02.671314  4233 solver.cpp:243] Iteration 9800, loss = 3.50631
I1015 17:14:02.671357  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.45481 (* 1 = 2.45481 loss)
I1015 17:14:02.671363  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0853431 (* 1 = 0.0853431 loss)
I1015 17:14:02.671370  4233 sgd_solver.cpp:138] Iteration 9800, lr = 0.0005
I1015 17:15:02.350061  4233 solver.cpp:243] Iteration 9900, loss = 2.93374
I1015 17:15:02.350093  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.36059 (* 1 = 2.36059 loss)
I1015 17:15:02.350100  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0660399 (* 1 = 0.0660399 loss)
I1015 17:15:02.350105  4233 sgd_solver.cpp:138] Iteration 9900, lr = 0.0005
I1015 17:16:02.939235  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10000.caffemodel
I1015 17:16:03.186695  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10000.solverstate
I1015 17:16:03.768671  4233 solver.cpp:243] Iteration 10000, loss = 4.45299
I1015 17:16:03.768700  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.94912 (* 1 = 2.94912 loss)
I1015 17:16:03.768707  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0918243 (* 1 = 0.0918243 loss)
I1015 17:16:03.768713  4233 sgd_solver.cpp:138] Iteration 10000, lr = 0.0005
I1015 17:16:50.147385  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:17:04.841622  4233 solver.cpp:243] Iteration 10100, loss = 3.72881
I1015 17:17:04.841666  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.84625 (* 1 = 1.84625 loss)
I1015 17:17:04.841672  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0712012 (* 1 = 0.0712012 loss)
I1015 17:17:04.841678  4233 sgd_solver.cpp:138] Iteration 10100, lr = 0.0005
I1015 17:18:06.156410  4233 solver.cpp:243] Iteration 10200, loss = 2.56533
I1015 17:18:06.156455  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.48804 (* 1 = 3.48804 loss)
I1015 17:18:06.156462  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.318427 (* 1 = 0.318427 loss)
I1015 17:18:06.156467  4233 sgd_solver.cpp:138] Iteration 10200, lr = 0.0005
I1015 17:19:06.374406  4233 solver.cpp:243] Iteration 10300, loss = 3.81773
I1015 17:19:06.374450  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.99554 (* 1 = 5.99554 loss)
I1015 17:19:06.374457  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.103121 (* 1 = 0.103121 loss)
I1015 17:19:06.374464  4233 sgd_solver.cpp:138] Iteration 10300, lr = 0.0005
I1015 17:20:05.007287  4233 solver.cpp:243] Iteration 10400, loss = 3.19166
I1015 17:20:05.007333  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.41331 (* 1 = 3.41331 loss)
I1015 17:20:05.007340  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.075953 (* 1 = 0.075953 loss)
I1015 17:20:05.007346  4233 sgd_solver.cpp:138] Iteration 10400, lr = 0.0005
I1015 17:21:04.936076  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_10500.caffemodel
I1015 17:21:05.168815  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_10500.solverstate
I1015 17:21:05.741641  4233 solver.cpp:243] Iteration 10500, loss = 3.33591
I1015 17:21:05.741677  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.87236 (* 1 = 2.87236 loss)
I1015 17:21:05.741686  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0920097 (* 1 = 0.0920097 loss)
I1015 17:21:05.741693  4233 sgd_solver.cpp:138] Iteration 10500, lr = 0.0005
I1015 17:22:06.221911  4233 solver.cpp:243] Iteration 10600, loss = 2.59379
I1015 17:22:06.221940  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.31802 (* 1 = 2.31802 loss)
I1015 17:22:06.221947  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0812612 (* 1 = 0.0812612 loss)
I1015 17:22:06.221953  4233 sgd_solver.cpp:138] Iteration 10600, lr = 0.0005
I1015 17:23:07.879956  4233 solver.cpp:243] Iteration 10700, loss = 3.45444
I1015 17:23:07.879998  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.01254 (* 1 = 4.01254 loss)
I1015 17:23:07.880004  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.104776 (* 1 = 0.104776 loss)
I1015 17:23:07.880010  4233 sgd_solver.cpp:138] Iteration 10700, lr = 0.0005
I1015 17:24:08.878433  4233 solver.cpp:243] Iteration 10800, loss = 2.37031
I1015 17:24:08.878479  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.37959 (* 1 = 2.37959 loss)
I1015 17:24:08.878485  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0915934 (* 1 = 0.0915934 loss)
I1015 17:24:08.878491  4233 sgd_solver.cpp:138] Iteration 10800, lr = 0.0005
I1015 17:25:10.357012  4233 solver.cpp:243] Iteration 10900, loss = 3.29691
I1015 17:25:10.357060  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.52307 (* 1 = 4.52307 loss)
I1015 17:25:10.357066  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0583049 (* 1 = 0.0583049 loss)
I1015 17:25:10.357072  4233 sgd_solver.cpp:138] Iteration 10900, lr = 0.0005
I1015 17:26:07.763428  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11000.caffemodel
I1015 17:26:07.988191  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11000.solverstate
I1015 17:26:08.545019  4233 solver.cpp:243] Iteration 11000, loss = 2.36005
I1015 17:26:08.545051  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.12478 (* 1 = 3.12478 loss)
I1015 17:26:08.545061  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0568079 (* 1 = 0.0568079 loss)
I1015 17:26:08.545083  4233 sgd_solver.cpp:138] Iteration 11000, lr = 0.0005
I1015 17:26:55.976198  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:27:07.707933  4233 solver.cpp:243] Iteration 11100, loss = 4.02449
I1015 17:27:07.707965  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.79187 (* 1 = 4.79187 loss)
I1015 17:27:07.707971  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0905775 (* 1 = 0.0905775 loss)
I1015 17:27:07.707978  4233 sgd_solver.cpp:138] Iteration 11100, lr = 0.0005
I1015 17:28:07.918174  4233 solver.cpp:243] Iteration 11200, loss = 3.01665
I1015 17:28:07.918203  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.81344 (* 1 = 3.81344 loss)
I1015 17:28:07.918212  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.105928 (* 1 = 0.105928 loss)
I1015 17:28:07.918220  4233 sgd_solver.cpp:138] Iteration 11200, lr = 0.0005
I1015 17:29:07.750839  4233 solver.cpp:243] Iteration 11300, loss = 2.72733
I1015 17:29:07.750872  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.54257 (* 1 = 2.54257 loss)
I1015 17:29:07.750881  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0984311 (* 1 = 0.0984311 loss)
I1015 17:29:07.750905  4233 sgd_solver.cpp:138] Iteration 11300, lr = 0.0005
I1015 17:30:06.645999  4233 solver.cpp:243] Iteration 11400, loss = 3.14753
I1015 17:30:06.646033  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.1105 (* 1 = 3.1105 loss)
I1015 17:30:06.646042  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.102854 (* 1 = 0.102854 loss)
I1015 17:30:06.646049  4233 sgd_solver.cpp:138] Iteration 11400, lr = 0.0005
I1015 17:31:05.032359  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_11500.caffemodel
I1015 17:31:05.256938  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_11500.solverstate
I1015 17:31:05.817848  4233 solver.cpp:243] Iteration 11500, loss = 3.31712
I1015 17:31:05.817880  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.66801 (* 1 = 2.66801 loss)
I1015 17:31:05.817889  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0683351 (* 1 = 0.0683351 loss)
I1015 17:31:05.817898  4233 sgd_solver.cpp:138] Iteration 11500, lr = 0.0005
I1015 17:32:03.947492  4233 solver.cpp:243] Iteration 11600, loss = 3.89199
I1015 17:32:03.947526  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.60944 (* 1 = 5.60944 loss)
I1015 17:32:03.947535  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0941413 (* 1 = 0.0941413 loss)
I1015 17:32:03.947558  4233 sgd_solver.cpp:138] Iteration 11600, lr = 0.0005
I1015 17:33:03.534346  4233 solver.cpp:243] Iteration 11700, loss = 1.81074
I1015 17:33:03.534409  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.19789 (* 1 = 1.19789 loss)
I1015 17:33:03.534420  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0654303 (* 1 = 0.0654303 loss)
I1015 17:33:03.534427  4233 sgd_solver.cpp:138] Iteration 11700, lr = 0.0005
I1015 17:34:03.203795  4233 solver.cpp:243] Iteration 11800, loss = 2.67295
I1015 17:34:03.203842  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.43096 (* 1 = 1.43096 loss)
I1015 17:34:03.203850  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0687905 (* 1 = 0.0687905 loss)
I1015 17:34:03.203855  4233 sgd_solver.cpp:138] Iteration 11800, lr = 0.0005
I1015 17:35:03.406193  4233 solver.cpp:243] Iteration 11900, loss = 2.12279
I1015 17:35:03.406237  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.05662 (* 1 = 2.05662 loss)
I1015 17:35:03.406244  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.116295 (* 1 = 0.116295 loss)
I1015 17:35:03.406250  4233 sgd_solver.cpp:138] Iteration 11900, lr = 0.0005
I1015 17:36:01.855573  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12000.caffemodel
I1015 17:36:02.674257  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12000.solverstate
I1015 17:36:02.876046  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 17:36:19.239643  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:37:42.176292  4233 solver.cpp:243] Iteration 12000, loss = 1.85717
I1015 17:37:42.176326  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.76991 (* 1 = 1.76991 loss)
I1015 17:37:42.176331  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0872571 (* 1 = 0.0872571 loss)
I1015 17:37:42.176337  4233 sgd_solver.cpp:138] Iteration 12000, lr = 0.0005
I1015 17:38:39.420784  4233 solver.cpp:243] Iteration 12100, loss = 3.17779
I1015 17:38:39.420812  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.5974 (* 1 = 4.5974 loss)
I1015 17:38:39.420819  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.121528 (* 1 = 0.121528 loss)
I1015 17:38:39.420825  4233 sgd_solver.cpp:138] Iteration 12100, lr = 0.0005
I1015 17:39:38.860311  4233 solver.cpp:243] Iteration 12200, loss = 2.99292
I1015 17:39:38.860355  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.67391 (* 1 = 2.67391 loss)
I1015 17:39:38.860361  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.596015 (* 1 = 0.596015 loss)
I1015 17:39:38.860368  4233 sgd_solver.cpp:138] Iteration 12200, lr = 0.0005
I1015 17:40:38.746516  4233 solver.cpp:243] Iteration 12300, loss = 2.12108
I1015 17:40:38.746559  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.60511 (* 1 = 1.60511 loss)
I1015 17:40:38.746567  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0774815 (* 1 = 0.0774815 loss)
I1015 17:40:38.746572  4233 sgd_solver.cpp:138] Iteration 12300, lr = 0.0005
I1015 17:41:38.774909  4233 solver.cpp:243] Iteration 12400, loss = 2.70389
I1015 17:41:38.774951  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.85098 (* 1 = 1.85098 loss)
I1015 17:41:38.774957  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.115892 (* 1 = 0.115892 loss)
I1015 17:41:38.774963  4233 sgd_solver.cpp:138] Iteration 12400, lr = 0.0005
I1015 17:42:36.865928  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_12500.caffemodel
I1015 17:42:37.085690  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_12500.solverstate
I1015 17:42:38.260676  4233 solver.cpp:243] Iteration 12500, loss = 2.99496
I1015 17:42:38.260723  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.3265 (* 1 = 3.3265 loss)
I1015 17:42:38.260730  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0979454 (* 1 = 0.0979454 loss)
I1015 17:42:38.260735  4233 sgd_solver.cpp:138] Iteration 12500, lr = 0.0005
I1015 17:43:36.752007  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:43:37.840615  4233 solver.cpp:243] Iteration 12600, loss = 2.62678
I1015 17:43:37.840662  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.9785 (* 1 = 1.9785 loss)
I1015 17:43:37.840669  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0744048 (* 1 = 0.0744048 loss)
I1015 17:43:37.840675  4233 sgd_solver.cpp:138] Iteration 12600, lr = 0.0005
I1015 17:44:37.751091  4233 solver.cpp:243] Iteration 12700, loss = 4.28334
I1015 17:44:37.751119  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.48885 (* 1 = 4.48885 loss)
I1015 17:44:37.751125  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0921208 (* 1 = 0.0921208 loss)
I1015 17:44:37.751132  4233 sgd_solver.cpp:138] Iteration 12700, lr = 0.0005
I1015 17:45:36.903689  4233 solver.cpp:243] Iteration 12800, loss = 2.78214
I1015 17:45:36.903738  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.19423 (* 1 = 4.19423 loss)
I1015 17:45:36.903744  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.12435 (* 1 = 0.12435 loss)
I1015 17:45:36.903750  4233 sgd_solver.cpp:138] Iteration 12800, lr = 0.0005
I1015 17:46:36.785336  4233 solver.cpp:243] Iteration 12900, loss = 1.53894
I1015 17:46:36.785368  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.52958 (* 1 = 2.52958 loss)
I1015 17:46:36.785392  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0655905 (* 1 = 0.0655905 loss)
I1015 17:46:36.785400  4233 sgd_solver.cpp:138] Iteration 12900, lr = 0.0005
I1015 17:47:35.923782  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13000.caffemodel
I1015 17:47:36.152112  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13000.solverstate
I1015 17:47:36.715806  4233 solver.cpp:243] Iteration 13000, loss = 3.141
I1015 17:47:36.715852  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.29958 (* 1 = 3.29958 loss)
I1015 17:47:36.715858  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0623014 (* 1 = 0.0623014 loss)
I1015 17:47:36.715864  4233 sgd_solver.cpp:138] Iteration 13000, lr = 0.0005
I1015 17:48:35.265411  4233 solver.cpp:243] Iteration 13100, loss = 3.1044
I1015 17:48:35.265457  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.59077 (* 1 = 2.59077 loss)
I1015 17:48:35.265465  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0809716 (* 1 = 0.0809716 loss)
I1015 17:48:35.265470  4233 sgd_solver.cpp:138] Iteration 13100, lr = 0.0005
I1015 17:49:33.448732  4233 solver.cpp:243] Iteration 13200, loss = 3.72777
I1015 17:49:33.448792  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.78777 (* 1 = 1.78777 loss)
I1015 17:49:33.448799  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0690061 (* 1 = 0.0690061 loss)
I1015 17:49:33.448806  4233 sgd_solver.cpp:138] Iteration 13200, lr = 0.0005
I1015 17:50:32.789508  4233 solver.cpp:243] Iteration 13300, loss = 2.50364
I1015 17:50:32.789553  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.77795 (* 1 = 2.77795 loss)
I1015 17:50:32.789561  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.123525 (* 1 = 0.123525 loss)
I1015 17:50:32.789566  4233 sgd_solver.cpp:138] Iteration 13300, lr = 0.0005
I1015 17:51:32.162281  4233 solver.cpp:243] Iteration 13400, loss = 2.7325
I1015 17:51:32.162326  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.37466 (* 1 = 3.37466 loss)
I1015 17:51:32.162333  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.154713 (* 1 = 0.154713 loss)
I1015 17:51:32.162338  4233 sgd_solver.cpp:138] Iteration 13400, lr = 0.0005
I1015 17:52:31.283537  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_13500.caffemodel
I1015 17:52:32.088801  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_13500.solverstate
I1015 17:52:32.666824  4233 solver.cpp:243] Iteration 13500, loss = 2.20864
I1015 17:52:32.666869  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.32042 (* 1 = 2.32042 loss)
I1015 17:52:32.666877  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0713766 (* 1 = 0.0713766 loss)
I1015 17:52:32.666882  4233 sgd_solver.cpp:138] Iteration 13500, lr = 0.0005
I1015 17:53:30.759881  4233 solver.cpp:243] Iteration 13600, loss = 2.03654
I1015 17:53:30.759928  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.89268 (* 1 = 1.89268 loss)
I1015 17:53:30.759934  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0561749 (* 1 = 0.0561749 loss)
I1015 17:53:30.759940  4233 sgd_solver.cpp:138] Iteration 13600, lr = 0.0005
I1015 17:53:33.800809  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 17:54:28.866508  4233 solver.cpp:243] Iteration 13700, loss = 2.60624
I1015 17:54:28.866554  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.99695 (* 1 = 1.99695 loss)
I1015 17:54:28.866559  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0554309 (* 1 = 0.0554309 loss)
I1015 17:54:28.866566  4233 sgd_solver.cpp:138] Iteration 13700, lr = 0.0005
I1015 17:55:28.188421  4233 solver.cpp:243] Iteration 13800, loss = 3.47751
I1015 17:55:28.188465  4233 solver.cpp:259]     Train net output #0: mbox_loss = 5.16454 (* 1 = 5.16454 loss)
I1015 17:55:28.188472  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0885667 (* 1 = 0.0885667 loss)
I1015 17:55:28.188477  4233 sgd_solver.cpp:138] Iteration 13800, lr = 0.0005
I1015 17:56:27.011281  4233 solver.cpp:243] Iteration 13900, loss = 2.21754
I1015 17:56:27.011328  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.420898 (* 1 = 0.420898 loss)
I1015 17:56:27.011334  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0805179 (* 1 = 0.0805179 loss)
I1015 17:56:27.011340  4233 sgd_solver.cpp:138] Iteration 13900, lr = 0.0005
I1015 17:57:26.551383  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14000.caffemodel
I1015 17:57:26.772588  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14000.solverstate
I1015 17:57:27.325672  4233 solver.cpp:243] Iteration 14000, loss = 2.60527
I1015 17:57:27.325716  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.02974 (* 1 = 2.02974 loss)
I1015 17:57:27.325723  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0593768 (* 1 = 0.0593768 loss)
I1015 17:57:27.325729  4233 sgd_solver.cpp:138] Iteration 14000, lr = 0.0005
I1015 17:58:26.205188  4233 solver.cpp:243] Iteration 14100, loss = 3.136
I1015 17:58:26.205233  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.73151 (* 1 = 2.73151 loss)
I1015 17:58:26.205240  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0662663 (* 1 = 0.0662663 loss)
I1015 17:58:26.205245  4233 sgd_solver.cpp:138] Iteration 14100, lr = 0.0005
I1015 17:59:24.983350  4233 solver.cpp:243] Iteration 14200, loss = 2.67285
I1015 17:59:24.983395  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.46241 (* 1 = 3.46241 loss)
I1015 17:59:24.983402  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.09425 (* 1 = 0.09425 loss)
I1015 17:59:24.983407  4233 sgd_solver.cpp:138] Iteration 14200, lr = 0.0005
I1015 18:00:23.178833  4233 solver.cpp:243] Iteration 14300, loss = 2.994
I1015 18:00:23.178882  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.67545 (* 1 = 3.67545 loss)
I1015 18:00:23.178889  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0677746 (* 1 = 0.0677746 loss)
I1015 18:00:23.178894  4233 sgd_solver.cpp:138] Iteration 14300, lr = 0.0005
I1015 18:01:22.351330  4233 solver.cpp:243] Iteration 14400, loss = 2.1421
I1015 18:01:22.351378  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.37281 (* 1 = 2.37281 loss)
I1015 18:01:22.351384  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0791769 (* 1 = 0.0791769 loss)
I1015 18:01:22.351390  4233 sgd_solver.cpp:138] Iteration 14400, lr = 0.0005
I1015 18:02:21.447535  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_14500.caffemodel
I1015 18:02:21.672549  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_14500.solverstate
I1015 18:02:22.249215  4233 solver.cpp:243] Iteration 14500, loss = 3.00194
I1015 18:02:22.249258  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.33655 (* 1 = 3.33655 loss)
I1015 18:02:22.249265  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.104718 (* 1 = 0.104718 loss)
I1015 18:02:22.249271  4233 sgd_solver.cpp:138] Iteration 14500, lr = 0.0005
I1015 18:03:21.663276  4233 solver.cpp:243] Iteration 14600, loss = 2.83279
I1015 18:03:21.663323  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.9224 (* 1 = 2.9224 loss)
I1015 18:03:21.663329  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0517194 (* 1 = 0.0517194 loss)
I1015 18:03:21.663336  4233 sgd_solver.cpp:138] Iteration 14600, lr = 0.0005
I1015 18:03:27.065502  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:04:20.459564  4233 solver.cpp:243] Iteration 14700, loss = 2.579
I1015 18:04:20.459610  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.86139 (* 1 = 1.86139 loss)
I1015 18:04:20.459617  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0959799 (* 1 = 0.0959799 loss)
I1015 18:04:20.459623  4233 sgd_solver.cpp:138] Iteration 14700, lr = 0.0005
I1015 18:05:18.339045  4233 solver.cpp:243] Iteration 14800, loss = 1.94574
I1015 18:05:18.339090  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.5094 (* 1 = 2.5094 loss)
I1015 18:05:18.339097  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0470369 (* 1 = 0.0470369 loss)
I1015 18:05:18.339103  4233 sgd_solver.cpp:138] Iteration 14800, lr = 0.0005
I1015 18:06:17.967242  4233 solver.cpp:243] Iteration 14900, loss = 3.40337
I1015 18:06:17.967288  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.19029 (* 1 = 2.19029 loss)
I1015 18:06:17.967295  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.100403 (* 1 = 0.100403 loss)
I1015 18:06:17.967300  4233 sgd_solver.cpp:138] Iteration 14900, lr = 0.0005
I1015 18:07:16.813220  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15000.caffemodel
I1015 18:07:17.036590  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15000.solverstate
I1015 18:07:17.598345  4233 solver.cpp:243] Iteration 15000, loss = 2.53421
I1015 18:07:17.598381  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.78701 (* 1 = 1.78701 loss)
I1015 18:07:17.598387  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0703159 (* 1 = 0.0703159 loss)
I1015 18:07:17.598393  4233 sgd_solver.cpp:138] Iteration 15000, lr = 0.0005
I1015 18:08:17.275604  4233 solver.cpp:243] Iteration 15100, loss = 1.62292
I1015 18:08:17.275650  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.0711 (* 1 = 1.0711 loss)
I1015 18:08:17.275656  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0501112 (* 1 = 0.0501112 loss)
I1015 18:08:17.275661  4233 sgd_solver.cpp:138] Iteration 15100, lr = 0.0005
I1015 18:09:16.093272  4233 solver.cpp:243] Iteration 15200, loss = 2.62383
I1015 18:09:16.093318  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.97578 (* 1 = 1.97578 loss)
I1015 18:09:16.093325  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0771855 (* 1 = 0.0771855 loss)
I1015 18:09:16.093331  4233 sgd_solver.cpp:138] Iteration 15200, lr = 0.0005
I1015 18:10:14.742566  4233 solver.cpp:243] Iteration 15300, loss = 2.22653
I1015 18:10:14.742614  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.17623 (* 1 = 2.17623 loss)
I1015 18:10:14.742619  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0617624 (* 1 = 0.0617624 loss)
I1015 18:10:14.742624  4233 sgd_solver.cpp:138] Iteration 15300, lr = 0.0005
I1015 18:11:13.338798  4233 solver.cpp:243] Iteration 15400, loss = 3.95988
I1015 18:11:13.338846  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.94796 (* 1 = 4.94796 loss)
I1015 18:11:13.338852  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0853615 (* 1 = 0.0853615 loss)
I1015 18:11:13.338857  4233 sgd_solver.cpp:138] Iteration 15400, lr = 0.0005
I1015 18:12:11.934271  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_15500.caffemodel
I1015 18:12:12.173537  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_15500.solverstate
I1015 18:12:12.752594  4233 solver.cpp:243] Iteration 15500, loss = 2.1197
I1015 18:12:12.752640  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.11478 (* 1 = 2.11478 loss)
I1015 18:12:12.752645  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0800937 (* 1 = 0.0800937 loss)
I1015 18:12:12.752651  4233 sgd_solver.cpp:138] Iteration 15500, lr = 0.0005
I1015 18:13:12.015262  4233 solver.cpp:243] Iteration 15600, loss = 1.86285
I1015 18:13:12.015295  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.62973 (* 1 = 2.62973 loss)
I1015 18:13:12.015300  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.070743 (* 1 = 0.070743 loss)
I1015 18:13:12.015306  4233 sgd_solver.cpp:138] Iteration 15600, lr = 0.0005
I1015 18:13:19.775106  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:14:11.444948  4233 solver.cpp:243] Iteration 15700, loss = 2.92242
I1015 18:14:11.444995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.89398 (* 1 = 2.89398 loss)
I1015 18:14:11.445003  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0880675 (* 1 = 0.0880675 loss)
I1015 18:14:11.445008  4233 sgd_solver.cpp:138] Iteration 15700, lr = 0.0005
I1015 18:15:10.085455  4233 solver.cpp:243] Iteration 15800, loss = 2.09748
I1015 18:15:10.085500  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.1172 (* 1 = 3.1172 loss)
I1015 18:15:10.085506  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0613708 (* 1 = 0.0613708 loss)
I1015 18:15:10.085511  4233 sgd_solver.cpp:138] Iteration 15800, lr = 0.0005
I1015 18:16:08.162600  4233 solver.cpp:243] Iteration 15900, loss = 2.48806
I1015 18:16:08.162647  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.19249 (* 1 = 2.19249 loss)
I1015 18:16:08.162653  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.204003 (* 1 = 0.204003 loss)
I1015 18:16:08.162659  4233 sgd_solver.cpp:138] Iteration 15900, lr = 0.0005
I1015 18:17:06.989264  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_16000.caffemodel
I1015 18:17:07.214077  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_16000.solverstate
I1015 18:17:07.403354  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 18:18:44.834208  4233 solver.cpp:243] Iteration 16000, loss = 1.37537
I1015 18:18:44.834244  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.28534 (* 1 = 1.28534 loss)
I1015 18:18:44.834250  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0900345 (* 1 = 0.0900345 loss)
I1015 18:18:44.834256  4233 sgd_solver.cpp:138] Iteration 16000, lr = 0.0005
I1015 18:19:43.002341  4233 solver.cpp:243] Iteration 16100, loss = 2.2977
I1015 18:19:43.002372  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.44499 (* 1 = 1.44499 loss)
I1015 18:19:43.002378  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0546254 (* 1 = 0.0546254 loss)
I1015 18:19:43.002384  4233 sgd_solver.cpp:138] Iteration 16100, lr = 0.0005
I1015 18:19:56.833678  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:20:42.829351  4233 solver.cpp:243] Iteration 16200, loss = 2.26922
I1015 18:20:42.829399  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.43171 (* 1 = 2.43171 loss)
I1015 18:20:42.829406  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0503961 (* 1 = 0.0503961 loss)
I1015 18:20:42.829411  4233 sgd_solver.cpp:138] Iteration 16200, lr = 0.0005
I1015 18:21:41.574172  4233 solver.cpp:243] Iteration 16300, loss = 2.67489
I1015 18:21:41.574219  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.98622 (* 1 = 1.98622 loss)
I1015 18:21:41.574225  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0883996 (* 1 = 0.0883996 loss)
I1015 18:21:41.574230  4233 sgd_solver.cpp:138] Iteration 16300, lr = 0.0005
I1015 18:22:39.921720  4233 solver.cpp:243] Iteration 16400, loss = 2.14534
I1015 18:22:39.921766  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.75982 (* 1 = 2.75982 loss)
I1015 18:22:39.921772  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.060972 (* 1 = 0.060972 loss)
I1015 18:22:39.921777  4233 sgd_solver.cpp:138] Iteration 16400, lr = 0.0005
I1015 18:23:38.418400  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_16500.caffemodel
I1015 18:23:39.224618  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_16500.solverstate
I1015 18:23:39.789515  4233 solver.cpp:243] Iteration 16500, loss = 3.44939
I1015 18:23:39.789561  4233 solver.cpp:259]     Train net output #0: mbox_loss = 4.1921 (* 1 = 4.1921 loss)
I1015 18:23:39.789566  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0702129 (* 1 = 0.0702129 loss)
I1015 18:23:39.789572  4233 sgd_solver.cpp:138] Iteration 16500, lr = 0.0005
I1015 18:24:37.945020  4233 solver.cpp:243] Iteration 16600, loss = 2.81134
I1015 18:24:37.945067  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.5014 (* 1 = 1.5014 loss)
I1015 18:24:37.945075  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0458095 (* 1 = 0.0458095 loss)
I1015 18:24:37.945080  4233 sgd_solver.cpp:138] Iteration 16600, lr = 0.0005
I1015 18:25:37.557766  4233 solver.cpp:243] Iteration 16700, loss = 1.71834
I1015 18:25:37.557816  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.78867 (* 1 = 1.78867 loss)
I1015 18:25:37.557826  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0966676 (* 1 = 0.0966676 loss)
I1015 18:25:37.557832  4233 sgd_solver.cpp:138] Iteration 16700, lr = 0.0005
I1015 18:26:36.927578  4233 solver.cpp:243] Iteration 16800, loss = 2.72015
I1015 18:26:36.927611  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.88031 (* 1 = 1.88031 loss)
I1015 18:26:36.927620  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0571796 (* 1 = 0.0571796 loss)
I1015 18:26:36.927628  4233 sgd_solver.cpp:138] Iteration 16800, lr = 0.0005
I1015 18:27:35.802580  4233 solver.cpp:243] Iteration 16900, loss = 2.4214
I1015 18:27:35.802613  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.03175 (* 1 = 3.03175 loss)
I1015 18:27:35.802623  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0576877 (* 1 = 0.0576877 loss)
I1015 18:27:35.802629  4233 sgd_solver.cpp:138] Iteration 16900, lr = 0.0005
I1015 18:28:33.425557  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_17000.caffemodel
I1015 18:28:33.649652  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_17000.solverstate
I1015 18:28:34.208654  4233 solver.cpp:243] Iteration 17000, loss = 2.64323
I1015 18:28:34.208688  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.67698 (* 1 = 1.67698 loss)
I1015 18:28:34.208698  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0772338 (* 1 = 0.0772338 loss)
I1015 18:28:34.208705  4233 sgd_solver.cpp:138] Iteration 17000, lr = 0.0005
I1015 18:29:33.292671  4233 solver.cpp:243] Iteration 17100, loss = 1.94972
I1015 18:29:33.292706  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13734 (* 1 = 1.13734 loss)
I1015 18:29:33.292714  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0580175 (* 1 = 0.0580175 loss)
I1015 18:29:33.292721  4233 sgd_solver.cpp:138] Iteration 17100, lr = 0.0005
I1015 18:29:51.057083  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:30:32.753304  4233 solver.cpp:243] Iteration 17200, loss = 2.58525
I1015 18:30:32.753336  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.27628 (* 1 = 3.27628 loss)
I1015 18:30:32.753345  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0597517 (* 1 = 0.0597517 loss)
I1015 18:30:32.753353  4233 sgd_solver.cpp:138] Iteration 17200, lr = 0.0005
I1015 18:31:32.367105  4233 solver.cpp:243] Iteration 17300, loss = 1.77623
I1015 18:31:32.367137  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.19449 (* 1 = 3.19449 loss)
I1015 18:31:32.367147  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0590509 (* 1 = 0.0590509 loss)
I1015 18:31:32.367154  4233 sgd_solver.cpp:138] Iteration 17300, lr = 0.0005
I1015 18:32:31.067876  4233 solver.cpp:243] Iteration 17400, loss = 2.18767
I1015 18:32:31.067912  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.47836 (* 1 = 1.47836 loss)
I1015 18:32:31.067921  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.062724 (* 1 = 0.062724 loss)
I1015 18:32:31.067945  4233 sgd_solver.cpp:138] Iteration 17400, lr = 0.0005
I1015 18:33:28.515125  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_17500.caffemodel
I1015 18:33:28.740000  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_17500.solverstate
I1015 18:33:29.282580  4233 solver.cpp:243] Iteration 17500, loss = 1.69403
I1015 18:33:29.282626  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.45525 (* 1 = 1.45525 loss)
I1015 18:33:29.282634  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.042587 (* 1 = 0.042587 loss)
I1015 18:33:29.282639  4233 sgd_solver.cpp:138] Iteration 17500, lr = 0.0005
I1015 18:34:28.350122  4233 solver.cpp:243] Iteration 17600, loss = 3.06954
I1015 18:34:28.350183  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.49846 (* 1 = 2.49846 loss)
I1015 18:34:28.350190  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0766809 (* 1 = 0.0766809 loss)
I1015 18:34:28.350195  4233 sgd_solver.cpp:138] Iteration 17600, lr = 0.0005
I1015 18:35:27.304400  4233 solver.cpp:243] Iteration 17700, loss = 2.16786
I1015 18:35:27.304447  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.10214 (* 1 = 2.10214 loss)
I1015 18:35:27.304455  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0951845 (* 1 = 0.0951845 loss)
I1015 18:35:27.304460  4233 sgd_solver.cpp:138] Iteration 17700, lr = 0.0005
I1015 18:36:27.133757  4233 solver.cpp:243] Iteration 17800, loss = 1.97221
I1015 18:36:27.133801  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.65451 (* 1 = 1.65451 loss)
I1015 18:36:27.133808  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.240832 (* 1 = 0.240832 loss)
I1015 18:36:27.133813  4233 sgd_solver.cpp:138] Iteration 17800, lr = 0.0005
I1015 18:37:25.988356  4233 solver.cpp:243] Iteration 17900, loss = 2.14012
I1015 18:37:25.988400  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.29189 (* 1 = 3.29189 loss)
I1015 18:37:25.988406  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0669884 (* 1 = 0.0669884 loss)
I1015 18:37:25.988412  4233 sgd_solver.cpp:138] Iteration 17900, lr = 0.0005
I1015 18:38:24.442415  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_18000.caffemodel
I1015 18:38:24.670406  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_18000.solverstate
I1015 18:38:25.234025  4233 solver.cpp:243] Iteration 18000, loss = 2.53344
I1015 18:38:25.234055  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.34612 (* 1 = 1.34612 loss)
I1015 18:38:25.234061  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0928169 (* 1 = 0.0928169 loss)
I1015 18:38:25.234067  4233 sgd_solver.cpp:138] Iteration 18000, lr = 0.0005
I1015 18:39:23.424850  4233 solver.cpp:243] Iteration 18100, loss = 2.87027
I1015 18:39:23.424896  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.85509 (* 1 = 1.85509 loss)
I1015 18:39:23.424901  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0847684 (* 1 = 0.0847684 loss)
I1015 18:39:23.424907  4233 sgd_solver.cpp:138] Iteration 18100, lr = 0.0005
I1015 18:39:43.814232  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:40:22.479590  4233 solver.cpp:243] Iteration 18200, loss = 1.31403
I1015 18:40:22.479636  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.290477 (* 1 = 0.290477 loss)
I1015 18:40:22.479642  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.420734 (* 1 = 0.420734 loss)
I1015 18:40:22.479648  4233 sgd_solver.cpp:138] Iteration 18200, lr = 0.0005
I1015 18:41:22.089946  4233 solver.cpp:243] Iteration 18300, loss = 2.21311
I1015 18:41:22.089979  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.52537 (* 1 = 1.52537 loss)
I1015 18:41:22.089985  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0631608 (* 1 = 0.0631608 loss)
I1015 18:41:22.089993  4233 sgd_solver.cpp:138] Iteration 18300, lr = 0.0005
I1015 18:42:21.554510  4233 solver.cpp:243] Iteration 18400, loss = 1.79963
I1015 18:42:21.554555  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.64732 (* 1 = 3.64732 loss)
I1015 18:42:21.554563  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0878406 (* 1 = 0.0878406 loss)
I1015 18:42:21.554569  4233 sgd_solver.cpp:138] Iteration 18400, lr = 0.0005
I1015 18:43:19.808818  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_18500.caffemodel
I1015 18:43:20.023939  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_18500.solverstate
I1015 18:43:20.600103  4233 solver.cpp:243] Iteration 18500, loss = 2.26347
I1015 18:43:20.600150  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.82449 (* 1 = 2.82449 loss)
I1015 18:43:20.600157  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0484032 (* 1 = 0.0484032 loss)
I1015 18:43:20.600162  4233 sgd_solver.cpp:138] Iteration 18500, lr = 0.0005
I1015 18:44:18.355931  4233 solver.cpp:243] Iteration 18600, loss = 2.17748
I1015 18:44:18.355978  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.17373 (* 1 = 3.17373 loss)
I1015 18:44:18.355983  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0794787 (* 1 = 0.0794787 loss)
I1015 18:44:18.355989  4233 sgd_solver.cpp:138] Iteration 18600, lr = 0.0005
I1015 18:45:17.817862  4233 solver.cpp:243] Iteration 18700, loss = 2.3572
I1015 18:45:17.817895  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.67752 (* 1 = 3.67752 loss)
I1015 18:45:17.817901  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.235923 (* 1 = 0.235923 loss)
I1015 18:45:17.817908  4233 sgd_solver.cpp:138] Iteration 18700, lr = 0.0005
I1015 18:46:17.023614  4233 solver.cpp:243] Iteration 18800, loss = 1.59508
I1015 18:46:17.023646  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.21478 (* 1 = 1.21478 loss)
I1015 18:46:17.023656  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0570308 (* 1 = 0.0570308 loss)
I1015 18:46:17.023679  4233 sgd_solver.cpp:138] Iteration 18800, lr = 0.0005
I1015 18:47:16.999946  4233 solver.cpp:243] Iteration 18900, loss = 2.21522
I1015 18:47:16.999976  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.07623 (* 1 = 1.07623 loss)
I1015 18:47:16.999984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.27552 (* 1 = 0.27552 loss)
I1015 18:47:17.000006  4233 sgd_solver.cpp:138] Iteration 18900, lr = 0.0005
I1015 18:48:15.173120  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_19000.caffemodel
I1015 18:48:15.409135  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_19000.solverstate
I1015 18:48:16.560442  4233 solver.cpp:243] Iteration 19000, loss = 2.25358
I1015 18:48:16.560510  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.92051 (* 1 = 1.92051 loss)
I1015 18:48:16.560520  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0607487 (* 1 = 0.0607487 loss)
I1015 18:48:16.560529  4233 sgd_solver.cpp:138] Iteration 19000, lr = 0.0005
I1015 18:49:14.424660  4233 solver.cpp:243] Iteration 19100, loss = 1.91494
I1015 18:49:14.424706  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.57632 (* 1 = 1.57632 loss)
I1015 18:49:14.424713  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0586228 (* 1 = 0.0586228 loss)
I1015 18:49:14.424720  4233 sgd_solver.cpp:138] Iteration 19100, lr = 0.0005
I1015 18:49:37.965184  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:50:13.147338  4233 solver.cpp:243] Iteration 19200, loss = 3.39156
I1015 18:50:13.147385  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.91418 (* 1 = 2.91418 loss)
I1015 18:50:13.147392  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0909103 (* 1 = 0.0909103 loss)
I1015 18:50:13.147398  4233 sgd_solver.cpp:138] Iteration 19200, lr = 0.0005
I1015 18:51:12.090097  4233 solver.cpp:243] Iteration 19300, loss = 1.912
I1015 18:51:12.090128  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.54934 (* 1 = 1.54934 loss)
I1015 18:51:12.090135  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0823997 (* 1 = 0.0823997 loss)
I1015 18:51:12.090140  4233 sgd_solver.cpp:138] Iteration 19300, lr = 0.0005
I1015 18:52:11.655326  4233 solver.cpp:243] Iteration 19400, loss = 1.07405
I1015 18:52:11.655373  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.887383 (* 1 = 0.887383 loss)
I1015 18:52:11.655380  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0605854 (* 1 = 0.0605854 loss)
I1015 18:52:11.655386  4233 sgd_solver.cpp:138] Iteration 19400, lr = 0.0005
I1015 18:53:10.563277  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_19500.caffemodel
I1015 18:53:10.813527  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_19500.solverstate
I1015 18:53:11.380259  4233 solver.cpp:243] Iteration 19500, loss = 2.35616
I1015 18:53:11.380303  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.74251 (* 1 = 2.74251 loss)
I1015 18:53:11.380311  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0749146 (* 1 = 0.0749146 loss)
I1015 18:53:11.380316  4233 sgd_solver.cpp:138] Iteration 19500, lr = 0.0005
I1015 18:54:09.773147  4233 solver.cpp:243] Iteration 19600, loss = 2.41515
I1015 18:54:09.773193  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.26523 (* 1 = 1.26523 loss)
I1015 18:54:09.773200  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0699351 (* 1 = 0.0699351 loss)
I1015 18:54:09.773205  4233 sgd_solver.cpp:138] Iteration 19600, lr = 0.0005
I1015 18:55:07.847287  4233 solver.cpp:243] Iteration 19700, loss = 2.88937
I1015 18:55:07.847334  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.19455 (* 1 = 2.19455 loss)
I1015 18:55:07.847342  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0717241 (* 1 = 0.0717241 loss)
I1015 18:55:07.847347  4233 sgd_solver.cpp:138] Iteration 19700, lr = 0.0005
I1015 18:56:07.269394  4233 solver.cpp:243] Iteration 19800, loss = 1.68512
I1015 18:56:07.269438  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.33859 (* 1 = 1.33859 loss)
I1015 18:56:07.269444  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0703823 (* 1 = 0.0703823 loss)
I1015 18:56:07.269450  4233 sgd_solver.cpp:138] Iteration 19800, lr = 0.0005
I1015 18:57:06.805289  4233 solver.cpp:243] Iteration 19900, loss = 1.97716
I1015 18:57:06.805335  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.80763 (* 1 = 1.80763 loss)
I1015 18:57:06.805341  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0884588 (* 1 = 0.0884588 loss)
I1015 18:57:06.805347  4233 sgd_solver.cpp:138] Iteration 19900, lr = 0.0005
I1015 18:58:05.918426  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_20000.caffemodel
I1015 18:58:06.726682  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_20000.solverstate
I1015 18:58:06.928321  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 18:58:34.890980  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 18:59:45.015990  4233 solver.cpp:243] Iteration 20000, loss = 1.87582
I1015 18:59:45.016033  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.81718 (* 1 = 1.81718 loss)
I1015 18:59:45.016041  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0586327 (* 1 = 0.0586327 loss)
I1015 18:59:45.016046  4233 sgd_solver.cpp:47] MultiStep Status: Iteration 20000, step = 1
I1015 18:59:45.016049  4233 sgd_solver.cpp:138] Iteration 20000, lr = 0.00025
I1015 19:00:44.714447  4233 solver.cpp:243] Iteration 20100, loss = 1.60638
I1015 19:00:44.714493  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.463104 (* 1 = 0.463104 loss)
I1015 19:00:44.714498  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0620672 (* 1 = 0.0620672 loss)
I1015 19:00:44.714504  4233 sgd_solver.cpp:138] Iteration 20100, lr = 0.00025
I1015 19:01:42.993083  4233 solver.cpp:243] Iteration 20200, loss = 1.91305
I1015 19:01:42.993129  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.58802 (* 1 = 1.58802 loss)
I1015 19:01:42.993135  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.043727 (* 1 = 0.043727 loss)
I1015 19:01:42.993141  4233 sgd_solver.cpp:138] Iteration 20200, lr = 0.00025
I1015 19:02:42.277290  4233 solver.cpp:243] Iteration 20300, loss = 2.36961
I1015 19:02:42.277338  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.51956 (* 1 = 2.51956 loss)
I1015 19:02:42.277344  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0460447 (* 1 = 0.0460447 loss)
I1015 19:02:42.277350  4233 sgd_solver.cpp:138] Iteration 20300, lr = 0.00025
I1015 19:03:41.139869  4233 solver.cpp:243] Iteration 20400, loss = 1.76815
I1015 19:03:41.139915  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.39588 (* 1 = 1.39588 loss)
I1015 19:03:41.139922  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0696447 (* 1 = 0.0696447 loss)
I1015 19:03:41.139928  4233 sgd_solver.cpp:138] Iteration 20400, lr = 0.00025
I1015 19:04:41.321717  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_20500.caffemodel
I1015 19:04:42.080564  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_20500.solverstate
I1015 19:04:42.641005  4233 solver.cpp:243] Iteration 20500, loss = 1.91337
I1015 19:04:42.641047  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.56124 (* 1 = 0.56124 loss)
I1015 19:04:42.641052  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0486459 (* 1 = 0.0486459 loss)
I1015 19:04:42.641058  4233 sgd_solver.cpp:138] Iteration 20500, lr = 0.00025
I1015 19:05:42.127336  4233 solver.cpp:243] Iteration 20600, loss = 2.4631
I1015 19:05:42.127380  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.1765 (* 1 = 1.1765 loss)
I1015 19:05:42.127388  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0506716 (* 1 = 0.0506716 loss)
I1015 19:05:42.127393  4233 sgd_solver.cpp:138] Iteration 20600, lr = 0.00025
I1015 19:06:16.899302  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:06:42.401845  4233 solver.cpp:243] Iteration 20700, loss = 1.91788
I1015 19:06:42.401881  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.14924 (* 1 = 1.14924 loss)
I1015 19:06:42.401890  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0757436 (* 1 = 0.0757436 loss)
I1015 19:06:42.401895  4233 sgd_solver.cpp:138] Iteration 20700, lr = 0.00025
I1015 19:07:43.106127  4233 solver.cpp:243] Iteration 20800, loss = 2.14286
I1015 19:07:43.106190  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.72531 (* 1 = 2.72531 loss)
I1015 19:07:43.106197  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0516169 (* 1 = 0.0516169 loss)
I1015 19:07:43.106204  4233 sgd_solver.cpp:138] Iteration 20800, lr = 0.00025
I1015 19:08:43.945765  4233 solver.cpp:243] Iteration 20900, loss = 1.52745
I1015 19:08:43.945809  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.17965 (* 1 = 1.17965 loss)
I1015 19:08:43.945816  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0532494 (* 1 = 0.0532494 loss)
I1015 19:08:43.945825  4233 sgd_solver.cpp:138] Iteration 20900, lr = 0.00025
I1015 19:09:43.214939  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_21000.caffemodel
I1015 19:09:43.441388  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_21000.solverstate
I1015 19:09:44.012930  4233 solver.cpp:243] Iteration 21000, loss = 2.03655
I1015 19:09:44.012979  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.34899 (* 1 = 2.34899 loss)
I1015 19:09:44.012984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0626591 (* 1 = 0.0626591 loss)
I1015 19:09:44.012990  4233 sgd_solver.cpp:138] Iteration 21000, lr = 0.00025
I1015 19:10:43.642433  4233 solver.cpp:243] Iteration 21100, loss = 1.9595
I1015 19:10:43.642480  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.85617 (* 1 = 2.85617 loss)
I1015 19:10:43.642488  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0471449 (* 1 = 0.0471449 loss)
I1015 19:10:43.642493  4233 sgd_solver.cpp:138] Iteration 21100, lr = 0.00025
I1015 19:11:42.545444  4233 solver.cpp:243] Iteration 21200, loss = 1.92199
I1015 19:11:42.545475  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.25743 (* 1 = 1.25743 loss)
I1015 19:11:42.545480  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0548308 (* 1 = 0.0548308 loss)
I1015 19:11:42.545486  4233 sgd_solver.cpp:138] Iteration 21200, lr = 0.00025
I1015 19:12:40.602722  4233 solver.cpp:243] Iteration 21300, loss = 1.24894
I1015 19:12:40.602754  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.962483 (* 1 = 0.962483 loss)
I1015 19:12:40.602761  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0510147 (* 1 = 0.0510147 loss)
I1015 19:12:40.602767  4233 sgd_solver.cpp:138] Iteration 21300, lr = 0.00025
I1015 19:13:40.229264  4233 solver.cpp:243] Iteration 21400, loss = 2.58656
I1015 19:13:40.229310  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.80902 (* 1 = 2.80902 loss)
I1015 19:13:40.229316  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0619393 (* 1 = 0.0619393 loss)
I1015 19:13:40.229322  4233 sgd_solver.cpp:138] Iteration 21400, lr = 0.00025
I1015 19:14:38.988757  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_21500.caffemodel
I1015 19:14:39.225706  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_21500.solverstate
I1015 19:14:39.805966  4233 solver.cpp:243] Iteration 21500, loss = 1.93384
I1015 19:14:39.805995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.75403 (* 1 = 1.75403 loss)
I1015 19:14:39.806002  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0722076 (* 1 = 0.0722076 loss)
I1015 19:14:39.806007  4233 sgd_solver.cpp:138] Iteration 21500, lr = 0.00025
I1015 19:15:39.577505  4233 solver.cpp:243] Iteration 21600, loss = 1.14841
I1015 19:15:39.577551  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.83062 (* 1 = 1.83062 loss)
I1015 19:15:39.577558  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0517536 (* 1 = 0.0517536 loss)
I1015 19:15:39.577564  4233 sgd_solver.cpp:138] Iteration 21600, lr = 0.00025
I1015 19:16:16.389953  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:16:38.594530  4233 solver.cpp:243] Iteration 21700, loss = 1.97713
I1015 19:16:38.594578  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.58535 (* 1 = 1.58535 loss)
I1015 19:16:38.594583  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0731555 (* 1 = 0.0731555 loss)
I1015 19:16:38.594589  4233 sgd_solver.cpp:138] Iteration 21700, lr = 0.00025
I1015 19:17:37.512360  4233 solver.cpp:243] Iteration 21800, loss = 1.71829
I1015 19:17:37.512408  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.45703 (* 1 = 1.45703 loss)
I1015 19:17:37.512414  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0409121 (* 1 = 0.0409121 loss)
I1015 19:17:37.512420  4233 sgd_solver.cpp:138] Iteration 21800, lr = 0.00025
I1015 19:18:36.357199  4233 solver.cpp:243] Iteration 21900, loss = 2.89706
I1015 19:18:36.357244  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.05685 (* 1 = 3.05685 loss)
I1015 19:18:36.357250  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0816637 (* 1 = 0.0816637 loss)
I1015 19:18:36.357257  4233 sgd_solver.cpp:138] Iteration 21900, lr = 0.00025
I1015 19:19:36.485363  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_22000.caffemodel
I1015 19:19:36.729427  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_22000.solverstate
I1015 19:19:37.314998  4233 solver.cpp:243] Iteration 22000, loss = 1.32173
I1015 19:19:37.315030  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.63204 (* 1 = 1.63204 loss)
I1015 19:19:37.315037  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0493116 (* 1 = 0.0493116 loss)
I1015 19:19:37.315042  4233 sgd_solver.cpp:138] Iteration 22000, lr = 0.00025
I1015 19:20:37.487692  4233 solver.cpp:243] Iteration 22100, loss = 1.3135
I1015 19:20:37.487740  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.673637 (* 1 = 0.673637 loss)
I1015 19:20:37.487746  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0592206 (* 1 = 0.0592206 loss)
I1015 19:20:37.487752  4233 sgd_solver.cpp:138] Iteration 22100, lr = 0.00025
I1015 19:21:36.864070  4233 solver.cpp:243] Iteration 22200, loss = 2.12604
I1015 19:21:36.864115  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.05467 (* 1 = 2.05467 loss)
I1015 19:21:36.864122  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0685635 (* 1 = 0.0685635 loss)
I1015 19:21:36.864127  4233 sgd_solver.cpp:138] Iteration 22200, lr = 0.00025
I1015 19:22:35.443965  4233 solver.cpp:243] Iteration 22300, loss = 1.58045
I1015 19:22:35.444011  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.48784 (* 1 = 2.48784 loss)
I1015 19:22:35.444018  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0637109 (* 1 = 0.0637109 loss)
I1015 19:22:35.444025  4233 sgd_solver.cpp:138] Iteration 22300, lr = 0.00025
I1015 19:23:33.433138  4233 solver.cpp:243] Iteration 22400, loss = 1.90704
I1015 19:23:33.433184  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.90227 (* 1 = 1.90227 loss)
I1015 19:23:33.433190  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0496364 (* 1 = 0.0496364 loss)
I1015 19:23:33.433197  4233 sgd_solver.cpp:138] Iteration 22400, lr = 0.00025
I1015 19:24:32.186223  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_22500.caffemodel
I1015 19:24:32.411008  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_22500.solverstate
I1015 19:24:32.981560  4233 solver.cpp:243] Iteration 22500, loss = 1.82983
I1015 19:24:32.981606  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.07883 (* 1 = 1.07883 loss)
I1015 19:24:32.981611  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0532547 (* 1 = 0.0532547 loss)
I1015 19:24:32.981617  4233 sgd_solver.cpp:138] Iteration 22500, lr = 0.00025
I1015 19:25:31.900251  4233 solver.cpp:243] Iteration 22600, loss = 1.68252
I1015 19:25:31.900296  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.09888 (* 1 = 1.09888 loss)
I1015 19:25:31.900303  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0736059 (* 1 = 0.0736059 loss)
I1015 19:25:31.900310  4233 sgd_solver.cpp:138] Iteration 22600, lr = 0.00025
I1015 19:26:11.248978  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:26:31.585554  4233 solver.cpp:243] Iteration 22700, loss = 1.44919
I1015 19:26:31.585615  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.2411 (* 1 = 1.2411 loss)
I1015 19:26:31.585623  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0508483 (* 1 = 0.0508483 loss)
I1015 19:26:31.585628  4233 sgd_solver.cpp:138] Iteration 22700, lr = 0.00025
I1015 19:27:30.248884  4233 solver.cpp:243] Iteration 22800, loss = 1.98991
I1015 19:27:30.248929  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.5184 (* 1 = 1.5184 loss)
I1015 19:27:30.248935  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0621979 (* 1 = 0.0621979 loss)
I1015 19:27:30.248941  4233 sgd_solver.cpp:138] Iteration 22800, lr = 0.00025
I1015 19:28:28.449105  4233 solver.cpp:243] Iteration 22900, loss = 1.58807
I1015 19:28:28.449151  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13622 (* 1 = 1.13622 loss)
I1015 19:28:28.449158  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0544445 (* 1 = 0.0544445 loss)
I1015 19:28:28.449163  4233 sgd_solver.cpp:138] Iteration 22900, lr = 0.00025
I1015 19:29:27.309636  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_23000.caffemodel
I1015 19:29:27.518878  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_23000.solverstate
I1015 19:29:28.084780  4233 solver.cpp:243] Iteration 23000, loss = 2.81934
I1015 19:29:28.084811  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.07952 (* 1 = 2.07952 loss)
I1015 19:29:28.084818  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0537456 (* 1 = 0.0537456 loss)
I1015 19:29:28.084823  4233 sgd_solver.cpp:138] Iteration 23000, lr = 0.00025
I1015 19:30:28.443236  4233 solver.cpp:243] Iteration 23100, loss = 2.188
I1015 19:30:28.443269  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.940817 (* 1 = 0.940817 loss)
I1015 19:30:28.443274  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0393458 (* 1 = 0.0393458 loss)
I1015 19:30:28.443279  4233 sgd_solver.cpp:138] Iteration 23100, lr = 0.00025
I1015 19:31:28.928117  4233 solver.cpp:243] Iteration 23200, loss = 1.27033
I1015 19:31:28.928164  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.68218 (* 1 = 1.68218 loss)
I1015 19:31:28.928169  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0558982 (* 1 = 0.0558982 loss)
I1015 19:31:28.928175  4233 sgd_solver.cpp:138] Iteration 23200, lr = 0.00025
I1015 19:32:28.915830  4233 solver.cpp:243] Iteration 23300, loss = 2.05903
I1015 19:32:28.915879  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.10614 (* 1 = 3.10614 loss)
I1015 19:32:28.915884  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0510611 (* 1 = 0.0510611 loss)
I1015 19:32:28.915890  4233 sgd_solver.cpp:138] Iteration 23300, lr = 0.00025
I1015 19:33:28.011762  4233 solver.cpp:243] Iteration 23400, loss = 1.86456
I1015 19:33:28.011795  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.59575 (* 1 = 1.59575 loss)
I1015 19:33:28.011802  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0454977 (* 1 = 0.0454977 loss)
I1015 19:33:28.011826  4233 sgd_solver.cpp:138] Iteration 23400, lr = 0.00025
I1015 19:34:27.498479  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_23500.caffemodel
I1015 19:34:27.740751  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_23500.solverstate
I1015 19:34:28.298630  4233 solver.cpp:243] Iteration 23500, loss = 2.19218
I1015 19:34:28.298665  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.94526 (* 1 = 2.94526 loss)
I1015 19:34:28.298689  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445528 (* 1 = 0.0445528 loss)
I1015 19:34:28.298698  4233 sgd_solver.cpp:138] Iteration 23500, lr = 0.00025
I1015 19:35:27.690291  4233 solver.cpp:243] Iteration 23600, loss = 1.36686
I1015 19:35:27.690337  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.937348 (* 1 = 0.937348 loss)
I1015 19:35:27.690343  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0514451 (* 1 = 0.0514451 loss)
I1015 19:35:27.690349  4233 sgd_solver.cpp:138] Iteration 23600, lr = 0.00025
I1015 19:36:10.032446  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:36:28.580977  4233 solver.cpp:243] Iteration 23700, loss = 1.81593
I1015 19:36:28.581022  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.59098 (* 1 = 1.59098 loss)
I1015 19:36:28.581027  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0629891 (* 1 = 0.0629891 loss)
I1015 19:36:28.581032  4233 sgd_solver.cpp:138] Iteration 23700, lr = 0.00025
I1015 19:37:28.812175  4233 solver.cpp:243] Iteration 23800, loss = 1.12005
I1015 19:37:28.812222  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.19923 (* 1 = 1.19923 loss)
I1015 19:37:28.812229  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0473996 (* 1 = 0.0473996 loss)
I1015 19:37:28.812235  4233 sgd_solver.cpp:138] Iteration 23800, lr = 0.00025
I1015 19:38:28.969141  4233 solver.cpp:243] Iteration 23900, loss = 1.58979
I1015 19:38:28.969172  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.61037 (* 1 = 2.61037 loss)
I1015 19:38:28.969178  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0629313 (* 1 = 0.0629313 loss)
I1015 19:38:28.969184  4233 sgd_solver.cpp:138] Iteration 23900, lr = 0.00025
I1015 19:39:27.530611  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_24000.caffemodel
I1015 19:39:28.317679  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_24000.solverstate
I1015 19:39:28.509342  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 19:41:08.095059  4233 solver.cpp:243] Iteration 24000, loss = 0.445019
I1015 19:41:08.095096  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.394488 (* 1 = 0.394488 loss)
I1015 19:41:08.095103  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.050531 (* 1 = 0.050531 loss)
I1015 19:41:08.095109  4233 sgd_solver.cpp:138] Iteration 24000, lr = 0.00025
I1015 19:42:07.826447  4233 solver.cpp:243] Iteration 24100, loss = 2.44843
I1015 19:42:07.826495  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.35801 (* 1 = 2.35801 loss)
I1015 19:42:07.826519  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0707546 (* 1 = 0.0707546 loss)
I1015 19:42:07.826526  4233 sgd_solver.cpp:138] Iteration 24100, lr = 0.00025
I1015 19:42:56.610657  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:43:08.100986  4233 solver.cpp:243] Iteration 24200, loss = 1.69424
I1015 19:43:08.101030  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.63446 (* 1 = 1.63446 loss)
I1015 19:43:08.101037  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0688989 (* 1 = 0.0688989 loss)
I1015 19:43:08.101042  4233 sgd_solver.cpp:138] Iteration 24200, lr = 0.00025
I1015 19:44:10.135293  4233 solver.cpp:243] Iteration 24300, loss = 1.4492
I1015 19:44:10.135326  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.38882 (* 1 = 1.38882 loss)
I1015 19:44:10.135332  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0566895 (* 1 = 0.0566895 loss)
I1015 19:44:10.135339  4233 sgd_solver.cpp:138] Iteration 24300, lr = 0.00025
I1015 19:45:11.412212  4233 solver.cpp:243] Iteration 24400, loss = 1.39695
I1015 19:45:11.412259  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.01011 (* 1 = 2.01011 loss)
I1015 19:45:11.412266  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.047387 (* 1 = 0.047387 loss)
I1015 19:45:11.412271  4233 sgd_solver.cpp:138] Iteration 24400, lr = 0.00025
I1015 19:46:12.357003  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_24500.caffemodel
I1015 19:46:13.144793  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_24500.solverstate
I1015 19:46:13.767148  4233 solver.cpp:243] Iteration 24500, loss = 2.03103
I1015 19:46:13.767172  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.20093 (* 1 = 3.20093 loss)
I1015 19:46:13.767179  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0561919 (* 1 = 0.0561919 loss)
I1015 19:46:13.767184  4233 sgd_solver.cpp:138] Iteration 24500, lr = 0.00025
I1015 19:47:12.311831  4233 solver.cpp:243] Iteration 24600, loss = 2.25247
I1015 19:47:12.311875  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.24174 (* 1 = 2.24174 loss)
I1015 19:47:12.311882  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0568414 (* 1 = 0.0568414 loss)
I1015 19:47:12.311887  4233 sgd_solver.cpp:138] Iteration 24600, lr = 0.00025
I1015 19:48:13.464399  4233 solver.cpp:243] Iteration 24700, loss = 0.911459
I1015 19:48:13.464432  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.483426 (* 1 = 0.483426 loss)
I1015 19:48:13.464438  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0640988 (* 1 = 0.0640988 loss)
I1015 19:48:13.464444  4233 sgd_solver.cpp:138] Iteration 24700, lr = 0.00025
I1015 19:49:14.332674  4233 solver.cpp:243] Iteration 24800, loss = 1.67481
I1015 19:49:14.332708  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.871077 (* 1 = 0.871077 loss)
I1015 19:49:14.332716  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0679108 (* 1 = 0.0679108 loss)
I1015 19:49:14.332725  4233 sgd_solver.cpp:138] Iteration 24800, lr = 0.00025
I1015 19:50:14.559125  4233 solver.cpp:243] Iteration 24900, loss = 1.11435
I1015 19:50:14.559159  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13962 (* 1 = 1.13962 loss)
I1015 19:50:14.559185  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.043443 (* 1 = 0.043443 loss)
I1015 19:50:14.559192  4233 sgd_solver.cpp:138] Iteration 24900, lr = 0.00025
I1015 19:51:14.429119  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_25000.caffemodel
I1015 19:51:14.695955  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_25000.solverstate
I1015 19:51:15.350677  4233 solver.cpp:243] Iteration 25000, loss = 1.63154
I1015 19:51:15.350711  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.20728 (* 1 = 3.20728 loss)
I1015 19:51:15.350718  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0439939 (* 1 = 0.0439939 loss)
I1015 19:51:15.350723  4233 sgd_solver.cpp:138] Iteration 25000, lr = 0.00025
I1015 19:52:13.530983  4233 solver.cpp:243] Iteration 25100, loss = 1.47272
I1015 19:52:13.531031  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.01076 (* 1 = 2.01076 loss)
I1015 19:52:13.531038  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0540169 (* 1 = 0.0540169 loss)
I1015 19:52:13.531044  4233 sgd_solver.cpp:138] Iteration 25100, lr = 0.00025
I1015 19:53:08.436273  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 19:53:13.684186  4233 solver.cpp:243] Iteration 25200, loss = 1.68508
I1015 19:53:13.684232  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.64009 (* 1 = 2.64009 loss)
I1015 19:53:13.684238  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0544393 (* 1 = 0.0544393 loss)
I1015 19:53:13.684243  4233 sgd_solver.cpp:138] Iteration 25200, lr = 0.00025
I1015 19:54:13.950707  4233 solver.cpp:243] Iteration 25300, loss = 1.32052
I1015 19:54:13.950753  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.09676 (* 1 = 1.09676 loss)
I1015 19:54:13.950760  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0568253 (* 1 = 0.0568253 loss)
I1015 19:54:13.950765  4233 sgd_solver.cpp:138] Iteration 25300, lr = 0.00025
I1015 19:55:15.476517  4233 solver.cpp:243] Iteration 25400, loss = 1.49502
I1015 19:55:15.476562  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.17587 (* 1 = 1.17587 loss)
I1015 19:55:15.476568  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.072889 (* 1 = 0.072889 loss)
I1015 19:55:15.476574  4233 sgd_solver.cpp:138] Iteration 25400, lr = 0.00025
I1015 19:56:14.202878  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_25500.caffemodel
I1015 19:56:14.435811  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_25500.solverstate
I1015 19:56:15.008929  4233 solver.cpp:243] Iteration 25500, loss = 1.64545
I1015 19:56:15.008960  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.61618 (* 1 = 1.61618 loss)
I1015 19:56:15.008966  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0661046 (* 1 = 0.0661046 loss)
I1015 19:56:15.008972  4233 sgd_solver.cpp:138] Iteration 25500, lr = 0.00025
I1015 19:57:14.377799  4233 solver.cpp:243] Iteration 25600, loss = 1.50731
I1015 19:57:14.377848  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.96635 (* 1 = 1.96635 loss)
I1015 19:57:14.377856  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0440562 (* 1 = 0.0440562 loss)
I1015 19:57:14.377861  4233 sgd_solver.cpp:138] Iteration 25600, lr = 0.00025
I1015 19:58:15.311049  4233 solver.cpp:243] Iteration 25700, loss = 2.82289
I1015 19:58:15.311095  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.25417 (* 1 = 3.25417 loss)
I1015 19:58:15.311102  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0997007 (* 1 = 0.0997007 loss)
I1015 19:58:15.311107  4233 sgd_solver.cpp:138] Iteration 25700, lr = 0.00025
I1015 19:59:14.909276  4233 solver.cpp:243] Iteration 25800, loss = 1.56945
I1015 19:59:14.909308  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.16174 (* 1 = 1.16174 loss)
I1015 19:59:14.909317  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0440121 (* 1 = 0.0440121 loss)
I1015 19:59:14.909340  4233 sgd_solver.cpp:138] Iteration 25800, lr = 0.00025
I1015 20:00:15.865869  4233 solver.cpp:243] Iteration 25900, loss = 0.860176
I1015 20:00:15.865898  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.752439 (* 1 = 0.752439 loss)
I1015 20:00:15.865905  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0562605 (* 1 = 0.0562605 loss)
I1015 20:00:15.865909  4233 sgd_solver.cpp:138] Iteration 25900, lr = 0.00025
I1015 20:01:14.722810  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_26000.caffemodel
I1015 20:01:14.949708  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_26000.solverstate
I1015 20:01:15.513615  4233 solver.cpp:243] Iteration 26000, loss = 1.89655
I1015 20:01:15.513659  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.38337 (* 1 = 1.38337 loss)
I1015 20:01:15.513664  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0562468 (* 1 = 0.0562468 loss)
I1015 20:01:15.513670  4233 sgd_solver.cpp:138] Iteration 26000, lr = 0.00025
I1015 20:02:14.002141  4233 solver.cpp:243] Iteration 26100, loss = 1.84718
I1015 20:02:14.002200  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.3139 (* 1 = 2.3139 loss)
I1015 20:02:14.002207  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0415758 (* 1 = 0.0415758 loss)
I1015 20:02:14.002212  4233 sgd_solver.cpp:138] Iteration 26100, lr = 0.00025
I1015 20:03:09.236137  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:03:12.095132  4233 solver.cpp:243] Iteration 26200, loss = 2.35064
I1015 20:03:12.095180  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.56147 (* 1 = 2.56147 loss)
I1015 20:03:12.095186  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0808472 (* 1 = 0.0808472 loss)
I1015 20:03:12.095192  4233 sgd_solver.cpp:138] Iteration 26200, lr = 0.00025
I1015 20:04:11.464948  4233 solver.cpp:243] Iteration 26300, loss = 1.18064
I1015 20:04:11.464995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.590988 (* 1 = 0.590988 loss)
I1015 20:04:11.465001  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0550132 (* 1 = 0.0550132 loss)
I1015 20:04:11.465008  4233 sgd_solver.cpp:138] Iteration 26300, lr = 0.00025
I1015 20:05:11.119575  4233 solver.cpp:243] Iteration 26400, loss = 1.45593
I1015 20:05:11.119621  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.48983 (* 1 = 1.48983 loss)
I1015 20:05:11.119627  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445606 (* 1 = 0.0445606 loss)
I1015 20:05:11.119634  4233 sgd_solver.cpp:138] Iteration 26400, lr = 0.00025
I1015 20:06:11.355027  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_26500.caffemodel
I1015 20:06:11.594702  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_26500.solverstate
I1015 20:06:12.155897  4233 solver.cpp:243] Iteration 26500, loss = 1.13584
I1015 20:06:12.155936  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.814331 (* 1 = 0.814331 loss)
I1015 20:06:12.155946  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0536378 (* 1 = 0.0536378 loss)
I1015 20:06:12.155964  4233 sgd_solver.cpp:138] Iteration 26500, lr = 0.00025
I1015 20:07:11.253211  4233 solver.cpp:243] Iteration 26600, loss = 1.51421
I1015 20:07:11.253258  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.389875 (* 1 = 0.389875 loss)
I1015 20:07:11.253264  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418506 (* 1 = 0.0418506 loss)
I1015 20:07:11.253270  4233 sgd_solver.cpp:138] Iteration 26600, lr = 0.00025
I1015 20:08:09.841429  4233 solver.cpp:243] Iteration 26700, loss = 1.50732
I1015 20:08:09.841475  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.52431 (* 1 = 1.52431 loss)
I1015 20:08:09.841481  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0470243 (* 1 = 0.0470243 loss)
I1015 20:08:09.841487  4233 sgd_solver.cpp:138] Iteration 26700, lr = 0.00025
I1015 20:09:10.012471  4233 solver.cpp:243] Iteration 26800, loss = 1.77199
I1015 20:09:10.012518  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.0136 (* 1 = 1.0136 loss)
I1015 20:09:10.012524  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0587266 (* 1 = 0.0587266 loss)
I1015 20:09:10.012531  4233 sgd_solver.cpp:138] Iteration 26800, lr = 0.00025
I1015 20:10:09.823962  4233 solver.cpp:243] Iteration 26900, loss = 1.46506
I1015 20:10:09.824009  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.24608 (* 1 = 2.24608 loss)
I1015 20:10:09.824015  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0687914 (* 1 = 0.0687914 loss)
I1015 20:10:09.824021  4233 sgd_solver.cpp:138] Iteration 26900, lr = 0.00025
I1015 20:11:10.577029  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_27000.caffemodel
I1015 20:11:10.791529  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_27000.solverstate
I1015 20:11:11.347189  4233 solver.cpp:243] Iteration 27000, loss = 1.54627
I1015 20:11:11.347223  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.724428 (* 1 = 0.724428 loss)
I1015 20:11:11.347229  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0523963 (* 1 = 0.0523963 loss)
I1015 20:11:11.347234  4233 sgd_solver.cpp:138] Iteration 27000, lr = 0.00025
I1015 20:12:10.226717  4233 solver.cpp:243] Iteration 27100, loss = 2.02391
I1015 20:12:10.226763  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.06051 (* 1 = 1.06051 loss)
I1015 20:12:10.226770  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0608185 (* 1 = 0.0608185 loss)
I1015 20:12:10.226775  4233 sgd_solver.cpp:138] Iteration 27100, lr = 0.00025
I1015 20:13:08.287685  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:13:09.389037  4233 solver.cpp:243] Iteration 27200, loss = 1.58114
I1015 20:13:09.389072  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.42734 (* 1 = 1.42734 loss)
I1015 20:13:09.389097  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0694343 (* 1 = 0.0694343 loss)
I1015 20:13:09.389106  4233 sgd_solver.cpp:138] Iteration 27200, lr = 0.00025
I1015 20:14:08.320030  4233 solver.cpp:243] Iteration 27300, loss = 1.58237
I1015 20:14:08.320076  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.52943 (* 1 = 1.52943 loss)
I1015 20:14:08.320083  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0569606 (* 1 = 0.0569606 loss)
I1015 20:14:08.320089  4233 sgd_solver.cpp:138] Iteration 27300, lr = 0.00025
I1015 20:15:08.259068  4233 solver.cpp:243] Iteration 27400, loss = 1.2312
I1015 20:15:08.259102  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.908996 (* 1 = 0.908996 loss)
I1015 20:15:08.259127  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0566919 (* 1 = 0.0566919 loss)
I1015 20:15:08.259135  4233 sgd_solver.cpp:138] Iteration 27400, lr = 0.00025
I1015 20:16:07.941097  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_27500.caffemodel
I1015 20:16:08.774936  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_27500.solverstate
I1015 20:16:09.332080  4233 solver.cpp:243] Iteration 27500, loss = 1.4325
I1015 20:16:09.332126  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.68502 (* 1 = 1.68502 loss)
I1015 20:16:09.332134  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0636524 (* 1 = 0.0636524 loss)
I1015 20:16:09.332139  4233 sgd_solver.cpp:138] Iteration 27500, lr = 0.00025
I1015 20:17:08.307880  4233 solver.cpp:243] Iteration 27600, loss = 1.38584
I1015 20:17:08.307929  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.00067 (* 1 = 1.00067 loss)
I1015 20:17:08.307934  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0633706 (* 1 = 0.0633706 loss)
I1015 20:17:08.307940  4233 sgd_solver.cpp:138] Iteration 27600, lr = 0.00025
I1015 20:18:07.634193  4233 solver.cpp:243] Iteration 27700, loss = 1.58887
I1015 20:18:07.634240  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.50396 (* 1 = 1.50396 loss)
I1015 20:18:07.634246  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490843 (* 1 = 0.0490843 loss)
I1015 20:18:07.634251  4233 sgd_solver.cpp:138] Iteration 27700, lr = 0.00025
I1015 20:19:08.439446  4233 solver.cpp:243] Iteration 27800, loss = 0.971544
I1015 20:19:08.439479  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.567792 (* 1 = 0.567792 loss)
I1015 20:19:08.439486  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0468838 (* 1 = 0.0468838 loss)
I1015 20:19:08.439491  4233 sgd_solver.cpp:138] Iteration 27800, lr = 0.00025
I1015 20:20:09.562726  4233 solver.cpp:243] Iteration 27900, loss = 2.10119
I1015 20:20:09.562757  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.24225 (* 1 = 1.24225 loss)
I1015 20:20:09.562763  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0509876 (* 1 = 0.0509876 loss)
I1015 20:20:09.562769  4233 sgd_solver.cpp:138] Iteration 27900, lr = 0.00025
I1015 20:21:09.372929  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_28000.caffemodel
I1015 20:21:10.163156  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_28000.solverstate
I1015 20:21:10.352429  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 20:21:51.443518  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:22:49.317049  4233 solver.cpp:243] Iteration 28000, loss = 1.71815
I1015 20:22:49.317085  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.66443 (* 1 = 1.66443 loss)
I1015 20:22:49.317095  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0537218 (* 1 = 0.0537218 loss)
I1015 20:22:49.317102  4233 sgd_solver.cpp:138] Iteration 28000, lr = 0.00025
I1015 20:23:49.304747  4233 solver.cpp:243] Iteration 28100, loss = 0.908348
I1015 20:23:49.304781  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.04631 (* 1 = 1.04631 loss)
I1015 20:23:49.304787  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0495242 (* 1 = 0.0495242 loss)
I1015 20:23:49.304793  4233 sgd_solver.cpp:138] Iteration 28100, lr = 0.00025
I1015 20:24:49.021771  4233 solver.cpp:243] Iteration 28200, loss = 1.56333
I1015 20:24:49.021806  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.58644 (* 1 = 1.58644 loss)
I1015 20:24:49.021816  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0525671 (* 1 = 0.0525671 loss)
I1015 20:24:49.021842  4233 sgd_solver.cpp:138] Iteration 28200, lr = 0.00025
I1015 20:25:48.326519  4233 solver.cpp:243] Iteration 28300, loss = 1.39613
I1015 20:25:48.326550  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.80196 (* 1 = 1.80196 loss)
I1015 20:25:48.326555  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0778067 (* 1 = 0.0778067 loss)
I1015 20:25:48.326561  4233 sgd_solver.cpp:138] Iteration 28300, lr = 0.00025
I1015 20:26:47.365427  4233 solver.cpp:243] Iteration 28400, loss = 2.27185
I1015 20:26:47.365468  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.84862 (* 1 = 1.84862 loss)
I1015 20:26:47.365478  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0652615 (* 1 = 0.0652615 loss)
I1015 20:26:47.365485  4233 sgd_solver.cpp:138] Iteration 28400, lr = 0.00025
I1015 20:27:46.425071  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_28500.caffemodel
I1015 20:27:47.252194  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_28500.solverstate
I1015 20:27:47.885329  4233 solver.cpp:243] Iteration 28500, loss = 0.880945
I1015 20:27:47.885361  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.75497 (* 1 = 1.75497 loss)
I1015 20:27:47.885368  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0511665 (* 1 = 0.0511665 loss)
I1015 20:27:47.885375  4233 sgd_solver.cpp:138] Iteration 28500, lr = 0.00025
I1015 20:28:47.849681  4233 solver.cpp:243] Iteration 28600, loss = 1.15874
I1015 20:28:47.849727  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.11084 (* 1 = 1.11084 loss)
I1015 20:28:47.849735  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0540282 (* 1 = 0.0540282 loss)
I1015 20:28:47.849740  4233 sgd_solver.cpp:138] Iteration 28600, lr = 0.00025
I1015 20:29:48.704509  4233 solver.cpp:243] Iteration 28700, loss = 1.63545
I1015 20:29:48.704541  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.00656 (* 1 = 1.00656 loss)
I1015 20:29:48.704548  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0713688 (* 1 = 0.0713688 loss)
I1015 20:29:48.704553  4233 sgd_solver.cpp:138] Iteration 28700, lr = 0.00025
I1015 20:30:00.184068  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:30:48.926995  4233 solver.cpp:243] Iteration 28800, loss = 1.14974
I1015 20:30:48.927042  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.26698 (* 1 = 1.26698 loss)
I1015 20:30:48.927047  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0429119 (* 1 = 0.0429119 loss)
I1015 20:30:48.927053  4233 sgd_solver.cpp:138] Iteration 28800, lr = 0.00025
I1015 20:31:48.793196  4233 solver.cpp:243] Iteration 28900, loss = 1.47859
I1015 20:31:48.793228  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.978977 (* 1 = 0.978977 loss)
I1015 20:31:48.793234  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0457281 (* 1 = 0.0457281 loss)
I1015 20:31:48.793241  4233 sgd_solver.cpp:138] Iteration 28900, lr = 0.00025
I1015 20:32:50.280277  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_29000.caffemodel
I1015 20:32:51.046567  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_29000.solverstate
I1015 20:32:51.705554  4233 solver.cpp:243] Iteration 29000, loss = 1.53334
I1015 20:32:51.705586  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.84385 (* 1 = 0.84385 loss)
I1015 20:32:51.705592  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0436128 (* 1 = 0.0436128 loss)
I1015 20:32:51.705598  4233 sgd_solver.cpp:138] Iteration 29000, lr = 0.00025
I1015 20:33:52.385962  4233 solver.cpp:243] Iteration 29100, loss = 1.33852
I1015 20:33:52.385995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.46353 (* 1 = 1.46353 loss)
I1015 20:33:52.386001  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0525314 (* 1 = 0.0525314 loss)
I1015 20:33:52.386008  4233 sgd_solver.cpp:138] Iteration 29100, lr = 0.00025
I1015 20:34:54.254518  4233 solver.cpp:243] Iteration 29200, loss = 1.2484
I1015 20:34:54.254549  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.54771 (* 1 = 1.54771 loss)
I1015 20:34:54.254555  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0552744 (* 1 = 0.0552744 loss)
I1015 20:34:54.254561  4233 sgd_solver.cpp:138] Iteration 29200, lr = 0.00025
I1015 20:35:55.728533  4233 solver.cpp:243] Iteration 29300, loss = 1.6208
I1015 20:35:55.728579  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.05982 (* 1 = 2.05982 loss)
I1015 20:35:55.728585  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0682303 (* 1 = 0.0682303 loss)
I1015 20:35:55.728591  4233 sgd_solver.cpp:138] Iteration 29300, lr = 0.00025
I1015 20:36:56.482230  4233 solver.cpp:243] Iteration 29400, loss = 1.2174
I1015 20:36:56.482260  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.68256 (* 1 = 1.68256 loss)
I1015 20:36:56.482267  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.064897 (* 1 = 0.064897 loss)
I1015 20:36:56.482273  4233 sgd_solver.cpp:138] Iteration 29400, lr = 0.00025
I1015 20:37:55.947541  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_29500.caffemodel
I1015 20:37:56.782173  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_29500.solverstate
I1015 20:37:57.347143  4233 solver.cpp:243] Iteration 29500, loss = 2.51042
I1015 20:37:57.347192  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.635632 (* 1 = 0.635632 loss)
I1015 20:37:57.347201  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0552131 (* 1 = 0.0552131 loss)
I1015 20:37:57.347210  4233 sgd_solver.cpp:138] Iteration 29500, lr = 0.00025
I1015 20:38:57.373633  4233 solver.cpp:243] Iteration 29600, loss = 1.76906
I1015 20:38:57.373664  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.86837 (* 1 = 1.86837 loss)
I1015 20:38:57.373673  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0432718 (* 1 = 0.0432718 loss)
I1015 20:38:57.373695  4233 sgd_solver.cpp:138] Iteration 29600, lr = 0.00025
I1015 20:39:58.364256  4233 solver.cpp:243] Iteration 29700, loss = 0.929182
I1015 20:39:58.364289  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.15594 (* 1 = 1.15594 loss)
I1015 20:39:58.364297  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0726589 (* 1 = 0.0726589 loss)
I1015 20:39:58.364320  4233 sgd_solver.cpp:138] Iteration 29700, lr = 0.00025
I1015 20:40:16.826026  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:40:59.214653  4233 solver.cpp:243] Iteration 29800, loss = 1.60987
I1015 20:40:59.214699  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.01975 (* 1 = 1.01975 loss)
I1015 20:40:59.214704  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0511163 (* 1 = 0.0511163 loss)
I1015 20:40:59.214710  4233 sgd_solver.cpp:138] Iteration 29800, lr = 0.00025
I1015 20:41:59.655660  4233 solver.cpp:243] Iteration 29900, loss = 1.5415
I1015 20:41:59.655702  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.00716 (* 1 = 1.00716 loss)
I1015 20:41:59.655711  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0391539 (* 1 = 0.0391539 loss)
I1015 20:41:59.655719  4233 sgd_solver.cpp:138] Iteration 29900, lr = 0.00025
I1015 20:42:58.559288  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_30000.caffemodel
I1015 20:42:58.810923  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_30000.solverstate
I1015 20:42:59.419886  4233 solver.cpp:243] Iteration 30000, loss = 1.88926
I1015 20:42:59.419916  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.57739 (* 1 = 1.57739 loss)
I1015 20:42:59.419922  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0460827 (* 1 = 0.0460827 loss)
I1015 20:42:59.419929  4233 sgd_solver.cpp:138] Iteration 30000, lr = 0.00025
I1015 20:44:01.330476  4233 solver.cpp:243] Iteration 30100, loss = 1.06254
I1015 20:44:01.330507  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.972589 (* 1 = 0.972589 loss)
I1015 20:44:01.330513  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0408402 (* 1 = 0.0408402 loss)
I1015 20:44:01.330518  4233 sgd_solver.cpp:138] Iteration 30100, lr = 0.00025
I1015 20:45:02.378943  4233 solver.cpp:243] Iteration 30200, loss = 1.31747
I1015 20:45:02.378973  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.776019 (* 1 = 0.776019 loss)
I1015 20:45:02.378980  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0454017 (* 1 = 0.0454017 loss)
I1015 20:45:02.378986  4233 sgd_solver.cpp:138] Iteration 30200, lr = 0.00025
I1015 20:46:03.143357  4233 solver.cpp:243] Iteration 30300, loss = 0.789289
I1015 20:46:03.143386  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.745846 (* 1 = 0.745846 loss)
I1015 20:46:03.143393  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0397223 (* 1 = 0.0397223 loss)
I1015 20:46:03.143399  4233 sgd_solver.cpp:138] Iteration 30300, lr = 0.00025
I1015 20:47:04.480430  4233 solver.cpp:243] Iteration 30400, loss = 1.07487
I1015 20:47:04.480460  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.844051 (* 1 = 0.844051 loss)
I1015 20:47:04.480466  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0612233 (* 1 = 0.0612233 loss)
I1015 20:47:04.480473  4233 sgd_solver.cpp:138] Iteration 30400, lr = 0.00025
I1015 20:48:04.542332  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_30500.caffemodel
I1015 20:48:04.786707  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_30500.solverstate
I1015 20:48:05.414466  4233 solver.cpp:243] Iteration 30500, loss = 1.18652
I1015 20:48:05.414499  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.417139 (* 1 = 0.417139 loss)
I1015 20:48:05.414505  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0458954 (* 1 = 0.0458954 loss)
I1015 20:48:05.414510  4233 sgd_solver.cpp:138] Iteration 30500, lr = 0.00025
I1015 20:49:07.007807  4233 solver.cpp:243] Iteration 30600, loss = 1.99294
I1015 20:49:07.007839  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.80145 (* 1 = 1.80145 loss)
I1015 20:49:07.007845  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0379031 (* 1 = 0.0379031 loss)
I1015 20:49:07.007851  4233 sgd_solver.cpp:138] Iteration 30600, lr = 0.00025
I1015 20:50:08.557432  4233 solver.cpp:243] Iteration 30700, loss = 1.22428
I1015 20:50:08.557466  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.16363 (* 1 = 2.16363 loss)
I1015 20:50:08.557472  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0505935 (* 1 = 0.0505935 loss)
I1015 20:50:08.557478  4233 sgd_solver.cpp:138] Iteration 30700, lr = 0.00025
I1015 20:50:30.501768  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 20:51:10.884876  4233 solver.cpp:243] Iteration 30800, loss = 1.08424
I1015 20:51:10.884908  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.14917 (* 1 = 1.14917 loss)
I1015 20:51:10.884914  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0547682 (* 1 = 0.0547682 loss)
I1015 20:51:10.884920  4233 sgd_solver.cpp:138] Iteration 30800, lr = 0.00025
I1015 20:52:12.235188  4233 solver.cpp:243] Iteration 30900, loss = 0.983061
I1015 20:52:12.235219  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.58278 (* 1 = 1.58278 loss)
I1015 20:52:12.235225  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0411184 (* 1 = 0.0411184 loss)
I1015 20:52:12.235231  4233 sgd_solver.cpp:138] Iteration 30900, lr = 0.00025
I1015 20:53:13.652938  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_31000.caffemodel
I1015 20:53:14.454825  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_31000.solverstate
I1015 20:53:15.090219  4233 solver.cpp:243] Iteration 31000, loss = 1.6787
I1015 20:53:15.090246  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.37575 (* 1 = 1.37575 loss)
I1015 20:53:15.090253  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0640488 (* 1 = 0.0640488 loss)
I1015 20:53:15.090258  4233 sgd_solver.cpp:138] Iteration 31000, lr = 0.00025
I1015 20:54:15.585671  4233 solver.cpp:243] Iteration 31100, loss = 1.77098
I1015 20:54:15.585702  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.17569 (* 1 = 1.17569 loss)
I1015 20:54:15.585708  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0478535 (* 1 = 0.0478535 loss)
I1015 20:54:15.585714  4233 sgd_solver.cpp:138] Iteration 31100, lr = 0.00025
I1015 20:55:17.046437  4233 solver.cpp:243] Iteration 31200, loss = 0.675027
I1015 20:55:17.046469  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.381082 (* 1 = 0.381082 loss)
I1015 20:55:17.046475  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0694682 (* 1 = 0.0694682 loss)
I1015 20:55:17.046483  4233 sgd_solver.cpp:138] Iteration 31200, lr = 0.00025
I1015 20:56:19.238757  4233 solver.cpp:243] Iteration 31300, loss = 1.26594
I1015 20:56:19.238787  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.895737 (* 1 = 0.895737 loss)
I1015 20:56:19.238793  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0555001 (* 1 = 0.0555001 loss)
I1015 20:56:19.238798  4233 sgd_solver.cpp:138] Iteration 31300, lr = 0.00025
I1015 20:57:21.554242  4233 solver.cpp:243] Iteration 31400, loss = 0.910018
I1015 20:57:21.554275  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.648262 (* 1 = 0.648262 loss)
I1015 20:57:21.554280  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.045911 (* 1 = 0.045911 loss)
I1015 20:57:21.554286  4233 sgd_solver.cpp:138] Iteration 31400, lr = 0.00025
I1015 20:58:21.180399  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_31500.caffemodel
I1015 20:58:21.441872  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_31500.solverstate
I1015 20:58:22.040194  4233 solver.cpp:243] Iteration 31500, loss = 1.14284
I1015 20:58:22.040236  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.549989 (* 1 = 0.549989 loss)
I1015 20:58:22.040242  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0535648 (* 1 = 0.0535648 loss)
I1015 20:58:22.040248  4233 sgd_solver.cpp:138] Iteration 31500, lr = 0.00025
I1015 20:59:21.211812  4233 solver.cpp:243] Iteration 31600, loss = 1.0172
I1015 20:59:21.211855  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.14482 (* 1 = 2.14482 loss)
I1015 20:59:21.211863  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0544116 (* 1 = 0.0544116 loss)
I1015 20:59:21.211869  4233 sgd_solver.cpp:138] Iteration 31600, lr = 0.00025
I1015 21:00:21.911152  4233 solver.cpp:243] Iteration 31700, loss = 1.2714
I1015 21:00:21.911197  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.28099 (* 1 = 2.28099 loss)
I1015 21:00:21.911203  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0555249 (* 1 = 0.0555249 loss)
I1015 21:00:21.911209  4233 sgd_solver.cpp:138] Iteration 31700, lr = 0.00025
I1015 21:00:48.604972  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:01:22.842604  4233 solver.cpp:243] Iteration 31800, loss = 1.01702
I1015 21:01:22.842650  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.457711 (* 1 = 0.457711 loss)
I1015 21:01:22.842658  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0635918 (* 1 = 0.0635918 loss)
I1015 21:01:22.842662  4233 sgd_solver.cpp:138] Iteration 31800, lr = 0.00025
I1015 21:02:24.686960  4233 solver.cpp:243] Iteration 31900, loss = 1.04548
I1015 21:02:24.687003  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.13749 (* 1 = 2.13749 loss)
I1015 21:02:24.687009  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0820276 (* 1 = 0.0820276 loss)
I1015 21:02:24.687016  4233 sgd_solver.cpp:138] Iteration 31900, lr = 0.00025
I1015 21:03:25.071218  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_32000.caffemodel
I1015 21:03:25.313467  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_32000.solverstate
I1015 21:03:25.522965  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 21:05:05.524019  4233 solver.cpp:243] Iteration 32000, loss = 3.17723
I1015 21:05:05.524050  4233 solver.cpp:259]     Train net output #0: mbox_loss = 3.08248 (* 1 = 3.08248 loss)
I1015 21:05:05.524057  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0947529 (* 1 = 0.0947529 loss)
I1015 21:05:05.524063  4233 sgd_solver.cpp:138] Iteration 32000, lr = 0.00025
I1015 21:06:04.620419  4233 solver.cpp:243] Iteration 32100, loss = 1.09501
I1015 21:06:04.620446  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.02487 (* 1 = 1.02487 loss)
I1015 21:06:04.620453  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413447 (* 1 = 0.0413447 loss)
I1015 21:06:04.620460  4233 sgd_solver.cpp:138] Iteration 32100, lr = 0.00025
I1015 21:07:05.360623  4233 solver.cpp:243] Iteration 32200, loss = 2.3416
I1015 21:07:05.360671  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.99695 (* 1 = 2.99695 loss)
I1015 21:07:05.360677  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0864142 (* 1 = 0.0864142 loss)
I1015 21:07:05.360684  4233 sgd_solver.cpp:138] Iteration 32200, lr = 0.00025
I1015 21:07:38.201947  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:08:06.179811  4233 solver.cpp:243] Iteration 32300, loss = 1.1065
I1015 21:08:06.179847  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.538467 (* 1 = 0.538467 loss)
I1015 21:08:06.179857  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0429451 (* 1 = 0.0429451 loss)
I1015 21:08:06.179865  4233 sgd_solver.cpp:138] Iteration 32300, lr = 0.00025
I1015 21:09:07.902592  4233 solver.cpp:243] Iteration 32400, loss = 0.703358
I1015 21:09:07.902639  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.278518 (* 1 = 0.278518 loss)
I1015 21:09:07.902647  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0414655 (* 1 = 0.0414655 loss)
I1015 21:09:07.902652  4233 sgd_solver.cpp:138] Iteration 32400, lr = 0.00025
I1015 21:10:09.187700  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_32500.caffemodel
I1015 21:10:09.518697  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_32500.solverstate
I1015 21:10:10.119343  4233 solver.cpp:243] Iteration 32500, loss = 1.60019
I1015 21:10:10.119388  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.07966 (* 1 = 2.07966 loss)
I1015 21:10:10.119395  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0651543 (* 1 = 0.0651543 loss)
I1015 21:10:10.119400  4233 sgd_solver.cpp:138] Iteration 32500, lr = 0.00025
I1015 21:11:11.082587  4233 solver.cpp:243] Iteration 32600, loss = 1.31472
I1015 21:11:11.082634  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.70093 (* 1 = 1.70093 loss)
I1015 21:11:11.082640  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490365 (* 1 = 0.0490365 loss)
I1015 21:11:11.082646  4233 sgd_solver.cpp:138] Iteration 32600, lr = 0.00025
I1015 21:12:11.038976  4233 solver.cpp:243] Iteration 32700, loss = 1.78331
I1015 21:12:11.039008  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.92112 (* 1 = 2.92112 loss)
I1015 21:12:11.039014  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0626428 (* 1 = 0.0626428 loss)
I1015 21:12:11.039021  4233 sgd_solver.cpp:138] Iteration 32700, lr = 0.00025
I1015 21:13:11.913754  4233 solver.cpp:243] Iteration 32800, loss = 0.906242
I1015 21:13:11.913806  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.900584 (* 1 = 0.900584 loss)
I1015 21:13:11.913813  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0470464 (* 1 = 0.0470464 loss)
I1015 21:13:11.913818  4233 sgd_solver.cpp:138] Iteration 32800, lr = 0.00025
I1015 21:14:12.324508  4233 solver.cpp:243] Iteration 32900, loss = 1.05831
I1015 21:14:12.324555  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.54381 (* 1 = 1.54381 loss)
I1015 21:14:12.324563  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0476953 (* 1 = 0.0476953 loss)
I1015 21:14:12.324568  4233 sgd_solver.cpp:138] Iteration 32900, lr = 0.00025
I1015 21:15:12.695143  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_33000.caffemodel
I1015 21:15:13.550163  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_33000.solverstate
I1015 21:15:14.125702  4233 solver.cpp:243] Iteration 33000, loss = 0.875181
I1015 21:15:14.125744  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.370279 (* 1 = 0.370279 loss)
I1015 21:15:14.125751  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0422097 (* 1 = 0.0422097 loss)
I1015 21:15:14.125756  4233 sgd_solver.cpp:138] Iteration 33000, lr = 0.00025
I1015 21:16:13.765086  4233 solver.cpp:243] Iteration 33100, loss = 1.2009
I1015 21:16:13.765131  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.955602 (* 1 = 0.955602 loss)
I1015 21:16:13.765138  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0482515 (* 1 = 0.0482515 loss)
I1015 21:16:13.765143  4233 sgd_solver.cpp:138] Iteration 33100, lr = 0.00025
I1015 21:17:13.021210  4233 solver.cpp:243] Iteration 33200, loss = 1.09896
I1015 21:17:13.021256  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.02029 (* 1 = 1.02029 loss)
I1015 21:17:13.021263  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0381425 (* 1 = 0.0381425 loss)
I1015 21:17:13.021270  4233 sgd_solver.cpp:138] Iteration 33200, lr = 0.00025
I1015 21:17:50.108500  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:18:13.114668  4233 solver.cpp:243] Iteration 33300, loss = 1.50118
I1015 21:18:13.114713  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.50437 (* 1 = 1.50437 loss)
I1015 21:18:13.114719  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0584773 (* 1 = 0.0584773 loss)
I1015 21:18:13.114725  4233 sgd_solver.cpp:138] Iteration 33300, lr = 0.00025
I1015 21:19:12.768743  4233 solver.cpp:243] Iteration 33400, loss = 1.14505
I1015 21:19:12.768774  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.796507 (* 1 = 0.796507 loss)
I1015 21:19:12.768782  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445684 (* 1 = 0.0445684 loss)
I1015 21:19:12.768805  4233 sgd_solver.cpp:138] Iteration 33400, lr = 0.00025
I1015 21:20:12.774675  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_33500.caffemodel
I1015 21:20:13.003393  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_33500.solverstate
I1015 21:20:13.571254  4233 solver.cpp:243] Iteration 33500, loss = 1.22999
I1015 21:20:13.571287  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.906536 (* 1 = 0.906536 loss)
I1015 21:20:13.571295  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0499394 (* 1 = 0.0499394 loss)
I1015 21:20:13.571303  4233 sgd_solver.cpp:138] Iteration 33500, lr = 0.00025
I1015 21:21:13.528389  4233 solver.cpp:243] Iteration 33600, loss = 1.60549
I1015 21:21:13.528434  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.45784 (* 1 = 1.45784 loss)
I1015 21:21:13.528441  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0343366 (* 1 = 0.0343366 loss)
I1015 21:21:13.528447  4233 sgd_solver.cpp:138] Iteration 33600, lr = 0.00025
I1015 21:22:13.185703  4233 solver.cpp:243] Iteration 33700, loss = 1.22738
I1015 21:22:13.185750  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.61894 (* 1 = 1.61894 loss)
I1015 21:22:13.185755  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0605808 (* 1 = 0.0605808 loss)
I1015 21:22:13.185761  4233 sgd_solver.cpp:138] Iteration 33700, lr = 0.00025
I1015 21:23:12.128970  4233 solver.cpp:243] Iteration 33800, loss = 1.16302
I1015 21:23:12.129017  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.97075 (* 1 = 0.97075 loss)
I1015 21:23:12.129024  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0479028 (* 1 = 0.0479028 loss)
I1015 21:23:12.129029  4233 sgd_solver.cpp:138] Iteration 33800, lr = 0.00025
I1015 21:24:12.081553  4233 solver.cpp:243] Iteration 33900, loss = 0.985923
I1015 21:24:12.081598  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.16862 (* 1 = 1.16862 loss)
I1015 21:24:12.081604  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0385509 (* 1 = 0.0385509 loss)
I1015 21:24:12.081610  4233 sgd_solver.cpp:138] Iteration 33900, lr = 0.00025
I1015 21:25:11.866997  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_34000.caffemodel
I1015 21:25:12.720603  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_34000.solverstate
I1015 21:25:13.286058  4233 solver.cpp:243] Iteration 34000, loss = 0.996092
I1015 21:25:13.286089  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.579333 (* 1 = 0.579333 loss)
I1015 21:25:13.286095  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.044 (* 1 = 0.044 loss)
I1015 21:25:13.286101  4233 sgd_solver.cpp:138] Iteration 34000, lr = 0.00025
I1015 21:26:13.036365  4233 solver.cpp:243] Iteration 34100, loss = 0.98236
I1015 21:26:13.036413  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.48858 (* 1 = 1.48858 loss)
I1015 21:26:13.036420  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0464541 (* 1 = 0.0464541 loss)
I1015 21:26:13.036425  4233 sgd_solver.cpp:138] Iteration 34100, lr = 0.00025
I1015 21:27:12.641283  4233 solver.cpp:243] Iteration 34200, loss = 1.24954
I1015 21:27:12.641312  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.5573 (* 1 = 1.5573 loss)
I1015 21:27:12.641319  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0433434 (* 1 = 0.0433434 loss)
I1015 21:27:12.641324  4233 sgd_solver.cpp:138] Iteration 34200, lr = 0.00025
I1015 21:27:53.423245  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:28:11.138587  4233 solver.cpp:243] Iteration 34300, loss = 0.834955
I1015 21:28:11.138620  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.354505 (* 1 = 0.354505 loss)
I1015 21:28:11.138626  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0381195 (* 1 = 0.0381195 loss)
I1015 21:28:11.138631  4233 sgd_solver.cpp:138] Iteration 34300, lr = 0.00025
I1015 21:29:11.452605  4233 solver.cpp:243] Iteration 34400, loss = 1.62796
I1015 21:29:11.452651  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13218 (* 1 = 1.13218 loss)
I1015 21:29:11.452657  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0509734 (* 1 = 0.0509734 loss)
I1015 21:29:11.452662  4233 sgd_solver.cpp:138] Iteration 34400, lr = 0.00025
I1015 21:30:11.045289  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_34500.caffemodel
I1015 21:30:11.280097  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_34500.solverstate
I1015 21:30:11.846598  4233 solver.cpp:243] Iteration 34500, loss = 1.25879
I1015 21:30:11.846644  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.867432 (* 1 = 0.867432 loss)
I1015 21:30:11.846650  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.049235 (* 1 = 0.049235 loss)
I1015 21:30:11.846655  4233 sgd_solver.cpp:138] Iteration 34500, lr = 0.00025
I1015 21:31:12.353871  4233 solver.cpp:243] Iteration 34600, loss = 0.603222
I1015 21:31:12.353904  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.199822 (* 1 = 0.199822 loss)
I1015 21:31:12.353912  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0415095 (* 1 = 0.0415095 loss)
I1015 21:31:12.353919  4233 sgd_solver.cpp:138] Iteration 34600, lr = 0.00025
I1015 21:32:12.523819  4233 solver.cpp:243] Iteration 34700, loss = 1.07155
I1015 21:32:12.523865  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.08303 (* 1 = 1.08303 loss)
I1015 21:32:12.523872  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0584376 (* 1 = 0.0584376 loss)
I1015 21:32:12.523878  4233 sgd_solver.cpp:138] Iteration 34700, lr = 0.00025
I1015 21:33:12.012953  4233 solver.cpp:243] Iteration 34800, loss = 1.07977
I1015 21:33:12.013003  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.20685 (* 1 = 1.20685 loss)
I1015 21:33:12.013010  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0644915 (* 1 = 0.0644915 loss)
I1015 21:33:12.013015  4233 sgd_solver.cpp:138] Iteration 34800, lr = 0.00025
I1015 21:34:11.475281  4233 solver.cpp:243] Iteration 34900, loss = 1.68554
I1015 21:34:11.475329  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.58515 (* 1 = 2.58515 loss)
I1015 21:34:11.475337  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0696101 (* 1 = 0.0696101 loss)
I1015 21:34:11.475342  4233 sgd_solver.cpp:138] Iteration 34900, lr = 0.00025
I1015 21:35:10.820029  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_35000.caffemodel
I1015 21:35:11.638926  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_35000.solverstate
I1015 21:35:12.214473  4233 solver.cpp:243] Iteration 35000, loss = 0.491037
I1015 21:35:12.214506  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.429787 (* 1 = 0.429787 loss)
I1015 21:35:12.214515  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398574 (* 1 = 0.0398574 loss)
I1015 21:35:12.214524  4233 sgd_solver.cpp:138] Iteration 35000, lr = 0.00025
I1015 21:36:11.750733  4233 solver.cpp:243] Iteration 35100, loss = 0.876016
I1015 21:36:11.750771  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13887 (* 1 = 1.13887 loss)
I1015 21:36:11.750779  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0564623 (* 1 = 0.0564623 loss)
I1015 21:36:11.750787  4233 sgd_solver.cpp:138] Iteration 35100, lr = 0.00025
I1015 21:37:12.079146  4233 solver.cpp:243] Iteration 35200, loss = 1.23106
I1015 21:37:12.079188  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.32043 (* 1 = 2.32043 loss)
I1015 21:37:12.079200  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0416123 (* 1 = 0.0416123 loss)
I1015 21:37:12.079208  4233 sgd_solver.cpp:138] Iteration 35200, lr = 0.00025
I1015 21:37:57.399212  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:38:11.492040  4233 solver.cpp:243] Iteration 35300, loss = 0.902389
I1015 21:38:11.492072  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.757246 (* 1 = 0.757246 loss)
I1015 21:38:11.492079  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413866 (* 1 = 0.0413866 loss)
I1015 21:38:11.492085  4233 sgd_solver.cpp:138] Iteration 35300, lr = 0.00025
I1015 21:39:10.350729  4233 solver.cpp:243] Iteration 35400, loss = 1.14033
I1015 21:39:10.350777  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.711042 (* 1 = 0.711042 loss)
I1015 21:39:10.350783  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0502832 (* 1 = 0.0502832 loss)
I1015 21:39:10.350790  4233 sgd_solver.cpp:138] Iteration 35400, lr = 0.00025
I1015 21:40:10.200337  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_35500.caffemodel
I1015 21:40:10.439368  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_35500.solverstate
I1015 21:40:11.018615  4233 solver.cpp:243] Iteration 35500, loss = 1.16093
I1015 21:40:11.018646  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.726119 (* 1 = 0.726119 loss)
I1015 21:40:11.018651  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0599487 (* 1 = 0.0599487 loss)
I1015 21:40:11.018656  4233 sgd_solver.cpp:138] Iteration 35500, lr = 0.00025
I1015 21:41:10.650271  4233 solver.cpp:243] Iteration 35600, loss = 0.960572
I1015 21:41:10.650305  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.00637 (* 1 = 1.00637 loss)
I1015 21:41:10.650310  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0675092 (* 1 = 0.0675092 loss)
I1015 21:41:10.650316  4233 sgd_solver.cpp:138] Iteration 35600, lr = 0.00025
I1015 21:42:11.309376  4233 solver.cpp:243] Iteration 35700, loss = 0.944866
I1015 21:42:11.309423  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.12056 (* 1 = 1.12056 loss)
I1015 21:42:11.309429  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490858 (* 1 = 0.0490858 loss)
I1015 21:42:11.309435  4233 sgd_solver.cpp:138] Iteration 35700, lr = 0.00025
I1015 21:43:10.745040  4233 solver.cpp:243] Iteration 35800, loss = 1.08102
I1015 21:43:10.745087  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.699894 (* 1 = 0.699894 loss)
I1015 21:43:10.745093  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0511899 (* 1 = 0.0511899 loss)
I1015 21:43:10.745100  4233 sgd_solver.cpp:138] Iteration 35800, lr = 0.00025
I1015 21:44:09.939508  4233 solver.cpp:243] Iteration 35900, loss = 0.800222
I1015 21:44:09.939540  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.708346 (* 1 = 0.708346 loss)
I1015 21:44:09.939546  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0394612 (* 1 = 0.0394612 loss)
I1015 21:44:09.939553  4233 sgd_solver.cpp:138] Iteration 35900, lr = 0.00025
I1015 21:45:09.294479  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_36000.caffemodel
I1015 21:45:10.124004  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_36000.solverstate
I1015 21:45:10.308250  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 21:46:05.048772  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:46:48.570760  4233 solver.cpp:243] Iteration 36000, loss = 1.86956
I1015 21:46:48.570792  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.80602 (* 1 = 1.80602 loss)
I1015 21:46:48.570798  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0635362 (* 1 = 0.0635362 loss)
I1015 21:46:48.570804  4233 sgd_solver.cpp:138] Iteration 36000, lr = 0.00025
I1015 21:47:48.053270  4233 solver.cpp:243] Iteration 36100, loss = 1.29355
I1015 21:47:48.053316  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.30521 (* 1 = 1.30521 loss)
I1015 21:47:48.053323  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0447438 (* 1 = 0.0447438 loss)
I1015 21:47:48.053328  4233 sgd_solver.cpp:138] Iteration 36100, lr = 0.00025
I1015 21:48:48.455482  4233 solver.cpp:243] Iteration 36200, loss = 0.619527
I1015 21:48:48.455513  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.64378 (* 1 = 0.64378 loss)
I1015 21:48:48.455519  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0472035 (* 1 = 0.0472035 loss)
I1015 21:48:48.455524  4233 sgd_solver.cpp:138] Iteration 36200, lr = 0.00025
I1015 21:49:48.814602  4233 solver.cpp:243] Iteration 36300, loss = 1.21231
I1015 21:49:48.814649  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13334 (* 1 = 1.13334 loss)
I1015 21:49:48.814656  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0403982 (* 1 = 0.0403982 loss)
I1015 21:49:48.814661  4233 sgd_solver.cpp:138] Iteration 36300, lr = 0.00025
I1015 21:50:48.255359  4233 solver.cpp:243] Iteration 36400, loss = 1.13378
I1015 21:50:48.255406  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.869934 (* 1 = 0.869934 loss)
I1015 21:50:48.255412  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0396244 (* 1 = 0.0396244 loss)
I1015 21:50:48.255419  4233 sgd_solver.cpp:138] Iteration 36400, lr = 0.00025
I1015 21:51:46.723297  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_36500.caffemodel
I1015 21:51:47.550961  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_36500.solverstate
I1015 21:51:48.126963  4233 solver.cpp:243] Iteration 36500, loss = 1.59146
I1015 21:51:48.126996  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.2833 (* 1 = 1.2833 loss)
I1015 21:51:48.127002  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0865811 (* 1 = 0.0865811 loss)
I1015 21:51:48.127008  4233 sgd_solver.cpp:138] Iteration 36500, lr = 0.00025
I1015 21:52:47.623507  4233 solver.cpp:243] Iteration 36600, loss = 0.814397
I1015 21:52:47.623554  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.02844 (* 1 = 1.02844 loss)
I1015 21:52:47.623560  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.041252 (* 1 = 0.041252 loss)
I1015 21:52:47.623565  4233 sgd_solver.cpp:138] Iteration 36600, lr = 0.00025
I1015 21:53:47.818033  4233 solver.cpp:243] Iteration 36700, loss = 0.907539
I1015 21:53:47.818066  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.516697 (* 1 = 0.516697 loss)
I1015 21:53:47.818073  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0571804 (* 1 = 0.0571804 loss)
I1015 21:53:47.818078  4233 sgd_solver.cpp:138] Iteration 36700, lr = 0.00025
I1015 21:54:45.483309  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 21:54:49.048102  4233 solver.cpp:243] Iteration 36800, loss = 0.519335
I1015 21:54:49.048166  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.481323 (* 1 = 0.481323 loss)
I1015 21:54:49.048171  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0406873 (* 1 = 0.0406873 loss)
I1015 21:54:49.048177  4233 sgd_solver.cpp:138] Iteration 36800, lr = 0.00025
I1015 21:55:49.012167  4233 solver.cpp:243] Iteration 36900, loss = 0.907348
I1015 21:55:49.012199  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.33768 (* 1 = 1.33768 loss)
I1015 21:55:49.012207  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490605 (* 1 = 0.0490605 loss)
I1015 21:55:49.012212  4233 sgd_solver.cpp:138] Iteration 36900, lr = 0.00025
I1015 21:56:47.719367  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_37000.caffemodel
I1015 21:56:47.951719  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_37000.solverstate
I1015 21:56:48.553452  4233 solver.cpp:243] Iteration 37000, loss = 0.934097
I1015 21:56:48.553491  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.14372 (* 1 = 1.14372 loss)
I1015 21:56:48.553498  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0432663 (* 1 = 0.0432663 loss)
I1015 21:56:48.553503  4233 sgd_solver.cpp:138] Iteration 37000, lr = 0.00025
I1015 21:57:48.896025  4233 solver.cpp:243] Iteration 37100, loss = 1.4803
I1015 21:57:48.896070  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.31151 (* 1 = 1.31151 loss)
I1015 21:57:48.896077  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0449568 (* 1 = 0.0449568 loss)
I1015 21:57:48.896082  4233 sgd_solver.cpp:138] Iteration 37100, lr = 0.00025
I1015 21:58:49.603963  4233 solver.cpp:243] Iteration 37200, loss = 0.779827
I1015 21:58:49.603996  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.573037 (* 1 = 0.573037 loss)
I1015 21:58:49.604003  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.058049 (* 1 = 0.058049 loss)
I1015 21:58:49.604027  4233 sgd_solver.cpp:138] Iteration 37200, lr = 0.00025
I1015 21:59:50.377491  4233 solver.cpp:243] Iteration 37300, loss = 0.774789
I1015 21:59:50.377524  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.532367 (* 1 = 0.532367 loss)
I1015 21:59:50.377530  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0548384 (* 1 = 0.0548384 loss)
I1015 21:59:50.377537  4233 sgd_solver.cpp:138] Iteration 37300, lr = 0.00025
I1015 22:00:51.125006  4233 solver.cpp:243] Iteration 37400, loss = 0.648849
I1015 22:00:51.125053  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.650926 (* 1 = 0.650926 loss)
I1015 22:00:51.125059  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314971 (* 1 = 0.0314971 loss)
I1015 22:00:51.125064  4233 sgd_solver.cpp:138] Iteration 37400, lr = 0.00025
I1015 22:01:52.148377  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_37500.caffemodel
I1015 22:01:52.384835  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_37500.solverstate
I1015 22:01:52.936405  4233 solver.cpp:243] Iteration 37500, loss = 1.35573
I1015 22:01:52.936448  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.716391 (* 1 = 0.716391 loss)
I1015 22:01:52.936455  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0858427 (* 1 = 0.0858427 loss)
I1015 22:01:52.936460  4233 sgd_solver.cpp:138] Iteration 37500, lr = 0.00025
I1015 22:02:52.358139  4233 solver.cpp:243] Iteration 37600, loss = 1.30428
I1015 22:02:52.358173  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.437521 (* 1 = 0.437521 loss)
I1015 22:02:52.358182  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0486673 (* 1 = 0.0486673 loss)
I1015 22:02:52.358191  4233 sgd_solver.cpp:138] Iteration 37600, lr = 0.00025
I1015 22:03:52.365954  4233 solver.cpp:243] Iteration 37700, loss = 0.493356
I1015 22:03:52.365985  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.122306 (* 1 = 0.122306 loss)
I1015 22:03:52.365993  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0388585 (* 1 = 0.0388585 loss)
I1015 22:03:52.365998  4233 sgd_solver.cpp:138] Iteration 37700, lr = 0.00025
I1015 22:04:51.253806  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:04:52.416123  4233 solver.cpp:243] Iteration 37800, loss = 0.888257
I1015 22:04:52.416169  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.756245 (* 1 = 0.756245 loss)
I1015 22:04:52.416175  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0493438 (* 1 = 0.0493438 loss)
I1015 22:04:52.416180  4233 sgd_solver.cpp:138] Iteration 37800, lr = 0.00025
I1015 22:05:53.495555  4233 solver.cpp:243] Iteration 37900, loss = 0.682919
I1015 22:05:53.495590  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.451406 (* 1 = 0.451406 loss)
I1015 22:05:53.495596  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0387025 (* 1 = 0.0387025 loss)
I1015 22:05:53.495602  4233 sgd_solver.cpp:138] Iteration 37900, lr = 0.00025
I1015 22:06:52.825930  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_38000.caffemodel
I1015 22:06:53.062196  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_38000.solverstate
I1015 22:06:53.646244  4233 solver.cpp:243] Iteration 38000, loss = 0.896728
I1015 22:06:53.646293  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.893861 (* 1 = 0.893861 loss)
I1015 22:06:53.646299  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0391396 (* 1 = 0.0391396 loss)
I1015 22:06:53.646306  4233 sgd_solver.cpp:138] Iteration 38000, lr = 0.00025
I1015 22:07:52.503065  4233 solver.cpp:243] Iteration 38100, loss = 0.611351
I1015 22:07:52.503098  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.383453 (* 1 = 0.383453 loss)
I1015 22:07:52.503103  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.053034 (* 1 = 0.053034 loss)
I1015 22:07:52.503108  4233 sgd_solver.cpp:138] Iteration 38100, lr = 0.00025
I1015 22:08:53.783197  4233 solver.cpp:243] Iteration 38200, loss = 0.912499
I1015 22:08:53.783242  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.593233 (* 1 = 0.593233 loss)
I1015 22:08:53.783249  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0406889 (* 1 = 0.0406889 loss)
I1015 22:08:53.783254  4233 sgd_solver.cpp:138] Iteration 38200, lr = 0.00025
I1015 22:09:55.465099  4233 solver.cpp:243] Iteration 38300, loss = 0.786627
I1015 22:09:55.465153  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.943023 (* 1 = 0.943023 loss)
I1015 22:09:55.465159  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0113094 (* 1 = 0.0113094 loss)
I1015 22:09:55.465167  4233 sgd_solver.cpp:138] Iteration 38300, lr = 0.00025
I1015 22:10:57.657060  4233 solver.cpp:243] Iteration 38400, loss = 0.588559
I1015 22:10:57.657091  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.62195 (* 1 = 1.62195 loss)
I1015 22:10:57.657115  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0807228 (* 1 = 0.0807228 loss)
I1015 22:10:57.657124  4233 sgd_solver.cpp:138] Iteration 38400, lr = 0.00025
I1015 22:11:57.611600  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_38500.caffemodel
I1015 22:11:57.836935  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_38500.solverstate
I1015 22:11:58.399636  4233 solver.cpp:243] Iteration 38500, loss = 0.748018
I1015 22:11:58.399684  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.304478 (* 1 = 0.304478 loss)
I1015 22:11:58.399690  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0876837 (* 1 = 0.0876837 loss)
I1015 22:11:58.399696  4233 sgd_solver.cpp:138] Iteration 38500, lr = 0.00025
I1015 22:12:58.601853  4233 solver.cpp:243] Iteration 38600, loss = 0.871122
I1015 22:12:58.601884  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.26178 (* 1 = 0.26178 loss)
I1015 22:12:58.601891  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0473881 (* 1 = 0.0473881 loss)
I1015 22:12:58.601896  4233 sgd_solver.cpp:138] Iteration 38600, lr = 0.00025
I1015 22:13:59.983779  4233 solver.cpp:243] Iteration 38700, loss = 1.80758
I1015 22:13:59.983826  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.00351 (* 1 = 2.00351 loss)
I1015 22:13:59.983832  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.073705 (* 1 = 0.073705 loss)
I1015 22:13:59.983839  4233 sgd_solver.cpp:138] Iteration 38700, lr = 0.00025
I1015 22:15:00.700733  4233 solver.cpp:243] Iteration 38800, loss = 0.771886
I1015 22:15:00.700783  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.123845 (* 1 = 0.123845 loss)
I1015 22:15:00.700789  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0444278 (* 1 = 0.0444278 loss)
I1015 22:15:00.700795  4233 sgd_solver.cpp:138] Iteration 38800, lr = 0.00025
I1015 22:15:02.037571  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:16:02.741731  4233 solver.cpp:243] Iteration 38900, loss = 0.498121
I1015 22:16:02.741775  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.131305 (* 1 = 0.131305 loss)
I1015 22:16:02.741782  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0379649 (* 1 = 0.0379649 loss)
I1015 22:16:02.741787  4233 sgd_solver.cpp:138] Iteration 38900, lr = 0.00025
I1015 22:17:03.748632  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_39000.caffemodel
I1015 22:17:04.006453  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_39000.solverstate
I1015 22:17:04.603199  4233 solver.cpp:243] Iteration 39000, loss = 1.21294
I1015 22:17:04.603229  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.666045 (* 1 = 0.666045 loss)
I1015 22:17:04.603235  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0525024 (* 1 = 0.0525024 loss)
I1015 22:17:04.603241  4233 sgd_solver.cpp:138] Iteration 39000, lr = 0.00025
I1015 22:18:03.962210  4233 solver.cpp:243] Iteration 39100, loss = 0.861575
I1015 22:18:03.962258  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.940924 (* 1 = 0.940924 loss)
I1015 22:18:03.962265  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0592755 (* 1 = 0.0592755 loss)
I1015 22:18:03.962271  4233 sgd_solver.cpp:138] Iteration 39100, lr = 0.00025
I1015 22:19:02.738080  4233 solver.cpp:243] Iteration 39200, loss = 1.17336
I1015 22:19:02.738112  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.49948 (* 1 = 2.49948 loss)
I1015 22:19:02.738119  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0599182 (* 1 = 0.0599182 loss)
I1015 22:19:02.738124  4233 sgd_solver.cpp:138] Iteration 39200, lr = 0.00025
I1015 22:20:02.727318  4233 solver.cpp:243] Iteration 39300, loss = 0.622167
I1015 22:20:02.727365  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.32246 (* 1 = 1.32246 loss)
I1015 22:20:02.727372  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0474503 (* 1 = 0.0474503 loss)
I1015 22:20:02.727378  4233 sgd_solver.cpp:138] Iteration 39300, lr = 0.00025
I1015 22:21:02.789326  4233 solver.cpp:243] Iteration 39400, loss = 0.779359
I1015 22:21:02.789388  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.219255 (* 1 = 0.219255 loss)
I1015 22:21:02.789394  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0375211 (* 1 = 0.0375211 loss)
I1015 22:21:02.789400  4233 sgd_solver.cpp:138] Iteration 39400, lr = 0.00025
I1015 22:22:02.622887  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_39500.caffemodel
I1015 22:22:02.862524  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_39500.solverstate
I1015 22:22:03.432245  4233 solver.cpp:243] Iteration 39500, loss = 0.633826
I1015 22:22:03.432292  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.807591 (* 1 = 0.807591 loss)
I1015 22:22:03.432298  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0360646 (* 1 = 0.0360646 loss)
I1015 22:22:03.432304  4233 sgd_solver.cpp:138] Iteration 39500, lr = 0.00025
I1015 22:23:02.677310  4233 solver.cpp:243] Iteration 39600, loss = 0.93034
I1015 22:23:02.677356  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.22218 (* 1 = 1.22218 loss)
I1015 22:23:02.677362  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0448039 (* 1 = 0.0448039 loss)
I1015 22:23:02.677367  4233 sgd_solver.cpp:138] Iteration 39600, lr = 0.00025
I1015 22:24:01.539116  4233 solver.cpp:243] Iteration 39700, loss = 0.771756
I1015 22:24:01.539163  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.563224 (* 1 = 0.563224 loss)
I1015 22:24:01.539170  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0455067 (* 1 = 0.0455067 loss)
I1015 22:24:01.539175  4233 sgd_solver.cpp:138] Iteration 39700, lr = 0.00025
I1015 22:25:01.332767  4233 solver.cpp:243] Iteration 39800, loss = 1.17572
I1015 22:25:01.332814  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.10299 (* 1 = 1.10299 loss)
I1015 22:25:01.332820  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0393911 (* 1 = 0.0393911 loss)
I1015 22:25:01.332826  4233 sgd_solver.cpp:138] Iteration 39800, lr = 0.00025
I1015 22:25:04.989713  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:26:00.858316  4233 solver.cpp:243] Iteration 39900, loss = 1.01082
I1015 22:26:00.858351  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.514656 (* 1 = 0.514656 loss)
I1015 22:26:00.858359  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0359847 (* 1 = 0.0359847 loss)
I1015 22:26:00.858368  4233 sgd_solver.cpp:138] Iteration 39900, lr = 0.00025
I1015 22:27:00.902576  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_40000.caffemodel
I1015 22:27:01.148347  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_40000.solverstate
I1015 22:27:01.353606  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 22:28:40.073217  4233 solver.cpp:243] Iteration 40000, loss = 0.524078
I1015 22:28:40.073251  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.486631 (* 1 = 0.486631 loss)
I1015 22:28:40.073256  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0374472 (* 1 = 0.0374472 loss)
I1015 22:28:40.073261  4233 sgd_solver.cpp:47] MultiStep Status: Iteration 40000, step = 2
I1015 22:28:40.073264  4233 sgd_solver.cpp:138] Iteration 40000, lr = 0.000125
I1015 22:29:38.901124  4233 solver.cpp:243] Iteration 40100, loss = 1.18206
I1015 22:29:38.901170  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.303342 (* 1 = 0.303342 loss)
I1015 22:29:38.901177  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0379288 (* 1 = 0.0379288 loss)
I1015 22:29:38.901182  4233 sgd_solver.cpp:138] Iteration 40100, lr = 0.000125
I1015 22:30:38.243432  4233 solver.cpp:243] Iteration 40200, loss = 0.837567
I1015 22:30:38.243479  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.632552 (* 1 = 0.632552 loss)
I1015 22:30:38.243484  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.047256 (* 1 = 0.047256 loss)
I1015 22:30:38.243490  4233 sgd_solver.cpp:138] Iteration 40200, lr = 0.000125
I1015 22:31:37.089412  4233 solver.cpp:243] Iteration 40300, loss = 0.794064
I1015 22:31:37.089459  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.615109 (* 1 = 0.615109 loss)
I1015 22:31:37.089465  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.044628 (* 1 = 0.044628 loss)
I1015 22:31:37.089470  4233 sgd_solver.cpp:138] Iteration 40300, lr = 0.000125
I1015 22:31:46.891439  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:32:36.828500  4233 solver.cpp:243] Iteration 40400, loss = 0.644817
I1015 22:32:36.828548  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.505005 (* 1 = 0.505005 loss)
I1015 22:32:36.828554  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0593373 (* 1 = 0.0593373 loss)
I1015 22:32:36.828559  4233 sgd_solver.cpp:138] Iteration 40400, lr = 0.000125
I1015 22:33:36.555490  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_40500.caffemodel
I1015 22:33:37.394984  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_40500.solverstate
I1015 22:33:37.966902  4233 solver.cpp:243] Iteration 40500, loss = 0.663367
I1015 22:33:37.966945  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.445939 (* 1 = 0.445939 loss)
I1015 22:33:37.966951  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0509173 (* 1 = 0.0509173 loss)
I1015 22:33:37.966958  4233 sgd_solver.cpp:138] Iteration 40500, lr = 0.000125
I1015 22:34:37.655987  4233 solver.cpp:243] Iteration 40600, loss = 0.612795
I1015 22:34:37.656035  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.998788 (* 1 = 0.998788 loss)
I1015 22:34:37.656041  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0463883 (* 1 = 0.0463883 loss)
I1015 22:34:37.656047  4233 sgd_solver.cpp:138] Iteration 40600, lr = 0.000125
I1015 22:35:37.075367  4233 solver.cpp:243] Iteration 40700, loss = 0.883356
I1015 22:35:37.075415  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.21677 (* 1 = 1.21677 loss)
I1015 22:35:37.075422  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0414625 (* 1 = 0.0414625 loss)
I1015 22:35:37.075428  4233 sgd_solver.cpp:138] Iteration 40700, lr = 0.000125
I1015 22:36:35.599406  4233 solver.cpp:243] Iteration 40800, loss = 0.629919
I1015 22:36:35.599437  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.683506 (* 1 = 0.683506 loss)
I1015 22:36:35.599443  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0357835 (* 1 = 0.0357835 loss)
I1015 22:36:35.599449  4233 sgd_solver.cpp:138] Iteration 40800, lr = 0.000125
I1015 22:37:35.946964  4233 solver.cpp:243] Iteration 40900, loss = 1.15488
I1015 22:37:35.946995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.76445 (* 1 = 1.76445 loss)
I1015 22:37:35.947000  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398427 (* 1 = 0.0398427 loss)
I1015 22:37:35.947006  4233 sgd_solver.cpp:138] Iteration 40900, lr = 0.000125
I1015 22:38:35.083303  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_41000.caffemodel
I1015 22:38:35.317154  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_41000.solverstate
I1015 22:38:35.902611  4233 solver.cpp:243] Iteration 41000, loss = 0.933347
I1015 22:38:35.902642  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.646133 (* 1 = 0.646133 loss)
I1015 22:38:35.902648  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0556389 (* 1 = 0.0556389 loss)
I1015 22:38:35.902654  4233 sgd_solver.cpp:138] Iteration 41000, lr = 0.000125
I1015 22:39:36.253268  4233 solver.cpp:243] Iteration 41100, loss = 0.431864
I1015 22:39:36.253301  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.172906 (* 1 = 0.172906 loss)
I1015 22:39:36.253307  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0366275 (* 1 = 0.0366275 loss)
I1015 22:39:36.253314  4233 sgd_solver.cpp:138] Iteration 41100, lr = 0.000125
I1015 22:40:35.769250  4233 solver.cpp:243] Iteration 41200, loss = 0.679552
I1015 22:40:35.769282  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.809138 (* 1 = 0.809138 loss)
I1015 22:40:35.769289  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0618954 (* 1 = 0.0618954 loss)
I1015 22:40:35.769306  4233 sgd_solver.cpp:138] Iteration 41200, lr = 0.000125
I1015 22:41:35.259809  4233 solver.cpp:243] Iteration 41300, loss = 0.774349
I1015 22:41:35.259843  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.12351 (* 1 = 1.12351 loss)
I1015 22:41:35.259850  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0715407 (* 1 = 0.0715407 loss)
I1015 22:41:35.259855  4233 sgd_solver.cpp:138] Iteration 41300, lr = 0.000125
I1015 22:41:48.618825  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:42:34.371320  4233 solver.cpp:243] Iteration 41400, loss = 1.19283
I1015 22:42:34.371349  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.7106 (* 1 = 1.7106 loss)
I1015 22:42:34.371356  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.05634 (* 1 = 0.05634 loss)
I1015 22:42:34.371361  4233 sgd_solver.cpp:138] Iteration 41400, lr = 0.000125
I1015 22:43:33.566583  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_41500.caffemodel
I1015 22:43:33.797945  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_41500.solverstate
I1015 22:43:34.389919  4233 solver.cpp:243] Iteration 41500, loss = 0.334152
I1015 22:43:34.389948  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.638499 (* 1 = 0.638499 loss)
I1015 22:43:34.389955  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0617504 (* 1 = 0.0617504 loss)
I1015 22:43:34.389961  4233 sgd_solver.cpp:138] Iteration 41500, lr = 0.000125
I1015 22:44:34.369930  4233 solver.cpp:243] Iteration 41600, loss = 0.576121
I1015 22:44:34.369961  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.192466 (* 1 = 0.192466 loss)
I1015 22:44:34.369966  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418462 (* 1 = 0.0418462 loss)
I1015 22:44:34.369972  4233 sgd_solver.cpp:138] Iteration 41600, lr = 0.000125
I1015 22:45:34.578500  4233 solver.cpp:243] Iteration 41700, loss = 0.764068
I1015 22:45:34.578531  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.87213 (* 1 = 1.87213 loss)
I1015 22:45:34.578536  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0475336 (* 1 = 0.0475336 loss)
I1015 22:45:34.578541  4233 sgd_solver.cpp:138] Iteration 41700, lr = 0.000125
I1015 22:46:34.030493  4233 solver.cpp:243] Iteration 41800, loss = 0.707136
I1015 22:46:34.030524  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.282725 (* 1 = 0.282725 loss)
I1015 22:46:34.030529  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0384894 (* 1 = 0.0384894 loss)
I1015 22:46:34.030535  4233 sgd_solver.cpp:138] Iteration 41800, lr = 0.000125
I1015 22:47:32.838919  4233 solver.cpp:243] Iteration 41900, loss = 0.803834
I1015 22:47:32.838953  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.282633 (* 1 = 0.282633 loss)
I1015 22:47:32.838958  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445923 (* 1 = 0.0445923 loss)
I1015 22:47:32.838963  4233 sgd_solver.cpp:138] Iteration 41900, lr = 0.000125
I1015 22:48:32.474704  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_42000.caffemodel
I1015 22:48:33.143405  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_42000.solverstate
I1015 22:48:33.729300  4233 solver.cpp:243] Iteration 42000, loss = 0.789159
I1015 22:48:33.729332  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.447097 (* 1 = 0.447097 loss)
I1015 22:48:33.729338  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.051922 (* 1 = 0.051922 loss)
I1015 22:48:33.729344  4233 sgd_solver.cpp:138] Iteration 42000, lr = 0.000125
I1015 22:49:32.954474  4233 solver.cpp:243] Iteration 42100, loss = 0.693223
I1015 22:49:32.954510  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.00266 (* 1 = 1.00266 loss)
I1015 22:49:32.954516  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0464829 (* 1 = 0.0464829 loss)
I1015 22:49:32.954521  4233 sgd_solver.cpp:138] Iteration 42100, lr = 0.000125
I1015 22:50:33.617898  4233 solver.cpp:243] Iteration 42200, loss = 0.592341
I1015 22:50:33.617933  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.423232 (* 1 = 0.423232 loss)
I1015 22:50:33.617938  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0474251 (* 1 = 0.0474251 loss)
I1015 22:50:33.617944  4233 sgd_solver.cpp:138] Iteration 42200, lr = 0.000125
I1015 22:51:32.916137  4233 solver.cpp:243] Iteration 42300, loss = 0.84011
I1015 22:51:32.916170  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.31534 (* 1 = 1.31534 loss)
I1015 22:51:32.916177  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0512939 (* 1 = 0.0512939 loss)
I1015 22:51:32.916182  4233 sgd_solver.cpp:138] Iteration 42300, lr = 0.000125
I1015 22:51:50.944265  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 22:52:32.006028  4233 solver.cpp:243] Iteration 42400, loss = 0.625709
I1015 22:52:32.006062  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.413023 (* 1 = 0.413023 loss)
I1015 22:52:32.006067  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0376697 (* 1 = 0.0376697 loss)
I1015 22:52:32.006073  4233 sgd_solver.cpp:138] Iteration 42400, lr = 0.000125
I1015 22:53:31.193950  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_42500.caffemodel
I1015 22:53:31.434881  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_42500.solverstate
I1015 22:53:32.025403  4233 solver.cpp:243] Iteration 42500, loss = 1.64377
I1015 22:53:32.025434  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.62236 (* 1 = 1.62236 loss)
I1015 22:53:32.025441  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.051398 (* 1 = 0.051398 loss)
I1015 22:53:32.025447  4233 sgd_solver.cpp:138] Iteration 42500, lr = 0.000125
I1015 22:54:31.378083  4233 solver.cpp:243] Iteration 42600, loss = 0.989766
I1015 22:54:31.378114  4233 solver.cpp:259]     Train net output #0: mbox_loss = 2.2065 (* 1 = 2.2065 loss)
I1015 22:54:31.378120  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0498492 (* 1 = 0.0498492 loss)
I1015 22:54:31.378126  4233 sgd_solver.cpp:138] Iteration 42600, lr = 0.000125
I1015 22:55:31.684406  4233 solver.cpp:243] Iteration 42700, loss = 0.415106
I1015 22:55:31.684438  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.495878 (* 1 = 0.495878 loss)
I1015 22:55:31.684445  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0642258 (* 1 = 0.0642258 loss)
I1015 22:55:31.684451  4233 sgd_solver.cpp:138] Iteration 42700, lr = 0.000125
I1015 22:56:31.914201  4233 solver.cpp:243] Iteration 42800, loss = 0.89117
I1015 22:56:31.914232  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.76918 (* 1 = 0.76918 loss)
I1015 22:56:31.914238  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0433713 (* 1 = 0.0433713 loss)
I1015 22:56:31.914244  4233 sgd_solver.cpp:138] Iteration 42800, lr = 0.000125
I1015 22:57:31.346529  4233 solver.cpp:243] Iteration 42900, loss = 0.813275
I1015 22:57:31.346560  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.730116 (* 1 = 0.730116 loss)
I1015 22:57:31.346566  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0513192 (* 1 = 0.0513192 loss)
I1015 22:57:31.346572  4233 sgd_solver.cpp:138] Iteration 42900, lr = 0.000125
I1015 22:58:29.574498  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_43000.caffemodel
I1015 22:58:29.815795  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_43000.solverstate
I1015 22:58:30.393348  4233 solver.cpp:243] Iteration 43000, loss = 1.17633
I1015 22:58:30.393375  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.344475 (* 1 = 0.344475 loss)
I1015 22:58:30.393381  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0619828 (* 1 = 0.0619828 loss)
I1015 22:58:30.393386  4233 sgd_solver.cpp:138] Iteration 43000, lr = 0.000125
I1015 22:59:30.271327  4233 solver.cpp:243] Iteration 43100, loss = 0.512303
I1015 22:59:30.271358  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.395204 (* 1 = 0.395204 loss)
I1015 22:59:30.271364  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.037666 (* 1 = 0.037666 loss)
I1015 22:59:30.271369  4233 sgd_solver.cpp:138] Iteration 43100, lr = 0.000125
I1015 23:00:30.355489  4233 solver.cpp:243] Iteration 43200, loss = 0.651159
I1015 23:00:30.355522  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.840762 (* 1 = 0.840762 loss)
I1015 23:00:30.355528  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0493023 (* 1 = 0.0493023 loss)
I1015 23:00:30.355535  4233 sgd_solver.cpp:138] Iteration 43200, lr = 0.000125
I1015 23:01:30.696043  4233 solver.cpp:243] Iteration 43300, loss = 0.319737
I1015 23:01:30.696071  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.259357 (* 1 = 0.259357 loss)
I1015 23:01:30.696077  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0325109 (* 1 = 0.0325109 loss)
I1015 23:01:30.696082  4233 sgd_solver.cpp:138] Iteration 43300, lr = 0.000125
I1015 23:01:51.019757  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:02:30.125499  4233 solver.cpp:243] Iteration 43400, loss = 0.703267
I1015 23:02:30.125531  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.410317 (* 1 = 0.410317 loss)
I1015 23:02:30.125537  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0435943 (* 1 = 0.0435943 loss)
I1015 23:02:30.125543  4233 sgd_solver.cpp:138] Iteration 43400, lr = 0.000125
I1015 23:03:28.369623  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_43500.caffemodel
I1015 23:03:28.594133  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_43500.solverstate
I1015 23:03:29.167533  4233 solver.cpp:243] Iteration 43500, loss = 0.668953
I1015 23:03:29.167567  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.520434 (* 1 = 0.520434 loss)
I1015 23:03:29.167573  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0345509 (* 1 = 0.0345509 loss)
I1015 23:03:29.167578  4233 sgd_solver.cpp:138] Iteration 43500, lr = 0.000125
I1015 23:04:28.923466  4233 solver.cpp:243] Iteration 43600, loss = 1.15922
I1015 23:04:28.923499  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.744719 (* 1 = 0.744719 loss)
I1015 23:04:28.923506  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0474482 (* 1 = 0.0474482 loss)
I1015 23:04:28.923511  4233 sgd_solver.cpp:138] Iteration 43600, lr = 0.000125
I1015 23:05:28.572921  4233 solver.cpp:243] Iteration 43700, loss = 0.642949
I1015 23:05:28.572953  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.695839 (* 1 = 0.695839 loss)
I1015 23:05:28.572960  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.044989 (* 1 = 0.044989 loss)
I1015 23:05:28.572965  4233 sgd_solver.cpp:138] Iteration 43700, lr = 0.000125
I1015 23:06:29.128954  4233 solver.cpp:243] Iteration 43800, loss = 0.55255
I1015 23:06:29.128988  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.315539 (* 1 = 0.315539 loss)
I1015 23:06:29.128993  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0491737 (* 1 = 0.0491737 loss)
I1015 23:06:29.128998  4233 sgd_solver.cpp:138] Iteration 43800, lr = 0.000125
I1015 23:07:28.783243  4233 solver.cpp:243] Iteration 43900, loss = 0.545063
I1015 23:07:28.783277  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.226787 (* 1 = 0.226787 loss)
I1015 23:07:28.783282  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0473594 (* 1 = 0.0473594 loss)
I1015 23:07:28.783288  4233 sgd_solver.cpp:138] Iteration 43900, lr = 0.000125
I1015 23:08:27.898260  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_44000.caffemodel
I1015 23:08:28.132999  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_44000.solverstate
I1015 23:08:28.329814  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 23:09:35.247336  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:10:06.453197  4233 solver.cpp:243] Iteration 44000, loss = 0.890152
I1015 23:10:06.453230  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.808979 (* 1 = 0.808979 loss)
I1015 23:10:06.453236  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0811725 (* 1 = 0.0811725 loss)
I1015 23:10:06.453243  4233 sgd_solver.cpp:138] Iteration 44000, lr = 0.000125
I1015 23:11:04.025988  4233 solver.cpp:243] Iteration 44100, loss = 0.957608
I1015 23:11:04.026021  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.53265 (* 1 = 1.53265 loss)
I1015 23:11:04.026027  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0368849 (* 1 = 0.0368849 loss)
I1015 23:11:04.026033  4233 sgd_solver.cpp:138] Iteration 44100, lr = 0.000125
I1015 23:12:03.487429  4233 solver.cpp:243] Iteration 44200, loss = 0.380791
I1015 23:12:03.487476  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.187967 (* 1 = 0.187967 loss)
I1015 23:12:03.487483  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0491402 (* 1 = 0.0491402 loss)
I1015 23:12:03.487488  4233 sgd_solver.cpp:138] Iteration 44200, lr = 0.000125
I1015 23:13:03.490501  4233 solver.cpp:243] Iteration 44300, loss = 0.619764
I1015 23:13:03.490546  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.41323 (* 1 = 0.41323 loss)
I1015 23:13:03.490552  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0513933 (* 1 = 0.0513933 loss)
I1015 23:13:03.490557  4233 sgd_solver.cpp:138] Iteration 44300, lr = 0.000125
I1015 23:14:03.392170  4233 solver.cpp:243] Iteration 44400, loss = 0.542703
I1015 23:14:03.392217  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.326651 (* 1 = 0.326651 loss)
I1015 23:14:03.392223  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0410382 (* 1 = 0.0410382 loss)
I1015 23:14:03.392230  4233 sgd_solver.cpp:138] Iteration 44400, lr = 0.000125
I1015 23:15:02.048933  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_44500.caffemodel
I1015 23:15:02.893880  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_44500.solverstate
I1015 23:15:03.476537  4233 solver.cpp:243] Iteration 44500, loss = 0.627922
I1015 23:15:03.476578  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.22841 (* 1 = 1.22841 loss)
I1015 23:15:03.476584  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0400171 (* 1 = 0.0400171 loss)
I1015 23:15:03.476590  4233 sgd_solver.cpp:138] Iteration 44500, lr = 0.000125
I1015 23:16:00.922480  4233 solver.cpp:243] Iteration 44600, loss = 0.535104
I1015 23:16:00.922543  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.56281 (* 1 = 0.56281 loss)
I1015 23:16:00.922549  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0460274 (* 1 = 0.0460274 loss)
I1015 23:16:00.922554  4233 sgd_solver.cpp:138] Iteration 44600, lr = 0.000125
I1015 23:17:00.833411  4233 solver.cpp:243] Iteration 44700, loss = 0.84334
I1015 23:17:00.833442  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.408142 (* 1 = 0.408142 loss)
I1015 23:17:00.833448  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418214 (* 1 = 0.0418214 loss)
I1015 23:17:00.833454  4233 sgd_solver.cpp:138] Iteration 44700, lr = 0.000125
I1015 23:18:00.371528  4233 solver.cpp:243] Iteration 44800, loss = 0.586923
I1015 23:18:00.371575  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.653788 (* 1 = 0.653788 loss)
I1015 23:18:00.371582  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.038832 (* 1 = 0.038832 loss)
I1015 23:18:00.371587  4233 sgd_solver.cpp:138] Iteration 44800, lr = 0.000125
I1015 23:18:32.891227  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:19:00.641263  4233 solver.cpp:243] Iteration 44900, loss = 0.320995
I1015 23:19:00.641310  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.187128 (* 1 = 0.187128 loss)
I1015 23:19:00.641316  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0519921 (* 1 = 0.0519921 loss)
I1015 23:19:00.641322  4233 sgd_solver.cpp:138] Iteration 44900, lr = 0.000125
I1015 23:19:59.196385  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_45000.caffemodel
I1015 23:19:59.436889  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_45000.solverstate
I1015 23:20:00.023656  4233 solver.cpp:243] Iteration 45000, loss = 0.548237
I1015 23:20:00.023696  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.398995 (* 1 = 0.398995 loss)
I1015 23:20:00.023702  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0669176 (* 1 = 0.0669176 loss)
I1015 23:20:00.023708  4233 sgd_solver.cpp:138] Iteration 45000, lr = 0.000125
I1015 23:20:58.752256  4233 solver.cpp:243] Iteration 45100, loss = 0.657602
I1015 23:20:58.752305  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.617271 (* 1 = 0.617271 loss)
I1015 23:20:58.752310  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370888 (* 1 = 0.0370888 loss)
I1015 23:20:58.752315  4233 sgd_solver.cpp:138] Iteration 45100, lr = 0.000125
I1015 23:21:57.790972  4233 solver.cpp:243] Iteration 45200, loss = 1.37524
I1015 23:21:57.791005  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.15049 (* 1 = 1.15049 loss)
I1015 23:21:57.791012  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0552345 (* 1 = 0.0552345 loss)
I1015 23:21:57.791018  4233 sgd_solver.cpp:138] Iteration 45200, lr = 0.000125
I1015 23:22:57.086611  4233 solver.cpp:243] Iteration 45300, loss = 0.576641
I1015 23:22:57.086659  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.743977 (* 1 = 0.743977 loss)
I1015 23:22:57.086665  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0296476 (* 1 = 0.0296476 loss)
I1015 23:22:57.086671  4233 sgd_solver.cpp:138] Iteration 45300, lr = 0.000125
I1015 23:23:57.158720  4233 solver.cpp:243] Iteration 45400, loss = 0.411725
I1015 23:23:57.158766  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0730101 (* 1 = 0.0730101 loss)
I1015 23:23:57.158772  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0444642 (* 1 = 0.0444642 loss)
I1015 23:23:57.158777  4233 sgd_solver.cpp:138] Iteration 45400, lr = 0.000125
I1015 23:24:56.424168  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_45500.caffemodel
I1015 23:24:56.660403  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_45500.solverstate
I1015 23:24:57.236938  4233 solver.cpp:243] Iteration 45500, loss = 0.980657
I1015 23:24:57.236968  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.81418 (* 1 = 0.81418 loss)
I1015 23:24:57.236975  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0639035 (* 1 = 0.0639035 loss)
I1015 23:24:57.236980  4233 sgd_solver.cpp:138] Iteration 45500, lr = 0.000125
I1015 23:25:56.006142  4233 solver.cpp:243] Iteration 45600, loss = 0.610017
I1015 23:25:56.006175  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.230515 (* 1 = 0.230515 loss)
I1015 23:25:56.006181  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0403899 (* 1 = 0.0403899 loss)
I1015 23:25:56.006186  4233 sgd_solver.cpp:138] Iteration 45600, lr = 0.000125
I1015 23:26:54.543977  4233 solver.cpp:243] Iteration 45700, loss = 0.709787
I1015 23:26:54.544008  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.624313 (* 1 = 0.624313 loss)
I1015 23:26:54.544014  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0474451 (* 1 = 0.0474451 loss)
I1015 23:26:54.544019  4233 sgd_solver.cpp:138] Iteration 45700, lr = 0.000125
I1015 23:27:54.189461  4233 solver.cpp:243] Iteration 45800, loss = 0.368766
I1015 23:27:54.189507  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.2566 (* 1 = 0.2566 loss)
I1015 23:27:54.189512  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0365554 (* 1 = 0.0365554 loss)
I1015 23:27:54.189518  4233 sgd_solver.cpp:138] Iteration 45800, lr = 0.000125
I1015 23:28:28.681278  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:28:53.966979  4233 solver.cpp:243] Iteration 45900, loss = 0.608762
I1015 23:28:53.967027  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.313735 (* 1 = 0.313735 loss)
I1015 23:28:53.967033  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0451839 (* 1 = 0.0451839 loss)
I1015 23:28:53.967038  4233 sgd_solver.cpp:138] Iteration 45900, lr = 0.000125
I1015 23:29:53.495321  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_46000.caffemodel
I1015 23:29:53.739467  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_46000.solverstate
I1015 23:29:54.304677  4233 solver.cpp:243] Iteration 46000, loss = 0.41633
I1015 23:29:54.304728  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0612589 (* 1 = 0.0612589 loss)
I1015 23:29:54.304733  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0452891 (* 1 = 0.0452891 loss)
I1015 23:29:54.304738  4233 sgd_solver.cpp:138] Iteration 46000, lr = 0.000125
I1015 23:30:53.156183  4233 solver.cpp:243] Iteration 46100, loss = 0.631076
I1015 23:30:53.156234  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.19931 (* 1 = 1.19931 loss)
I1015 23:30:53.156239  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0424351 (* 1 = 0.0424351 loss)
I1015 23:30:53.156245  4233 sgd_solver.cpp:138] Iteration 46100, lr = 0.000125
I1015 23:31:51.747261  4233 solver.cpp:243] Iteration 46200, loss = 0.590957
I1015 23:31:51.747314  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.448779 (* 1 = 0.448779 loss)
I1015 23:31:51.747321  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0311611 (* 1 = 0.0311611 loss)
I1015 23:31:51.747328  4233 sgd_solver.cpp:138] Iteration 46200, lr = 0.000125
I1015 23:32:51.252053  4233 solver.cpp:243] Iteration 46300, loss = 0.871083
I1015 23:32:51.252085  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.80847 (* 1 = 0.80847 loss)
I1015 23:32:51.252091  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0381599 (* 1 = 0.0381599 loss)
I1015 23:32:51.252097  4233 sgd_solver.cpp:138] Iteration 46300, lr = 0.000125
I1015 23:33:50.450906  4233 solver.cpp:243] Iteration 46400, loss = 0.905701
I1015 23:33:50.450953  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.26038 (* 1 = 1.26038 loss)
I1015 23:33:50.450958  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0338218 (* 1 = 0.0338218 loss)
I1015 23:33:50.450964  4233 sgd_solver.cpp:138] Iteration 46400, lr = 0.000125
I1015 23:34:50.009184  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_46500.caffemodel
I1015 23:34:50.251560  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_46500.solverstate
I1015 23:34:50.823334  4233 solver.cpp:243] Iteration 46500, loss = 0.635368
I1015 23:34:50.823364  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.256146 (* 1 = 0.256146 loss)
I1015 23:34:50.823369  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0407976 (* 1 = 0.0407976 loss)
I1015 23:34:50.823374  4233 sgd_solver.cpp:138] Iteration 46500, lr = 0.000125
I1015 23:35:50.295087  4233 solver.cpp:243] Iteration 46600, loss = 0.969412
I1015 23:35:50.295136  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.20568 (* 1 = 1.20568 loss)
I1015 23:35:50.295142  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.040856 (* 1 = 0.040856 loss)
I1015 23:35:50.295148  4233 sgd_solver.cpp:138] Iteration 46600, lr = 0.000125
I1015 23:36:49.501054  4233 solver.cpp:243] Iteration 46700, loss = 0.738374
I1015 23:36:49.501102  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.356201 (* 1 = 0.356201 loss)
I1015 23:36:49.501108  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0369899 (* 1 = 0.0369899 loss)
I1015 23:36:49.501113  4233 sgd_solver.cpp:138] Iteration 46700, lr = 0.000125
I1015 23:37:47.951645  4233 solver.cpp:243] Iteration 46800, loss = 0.658027
I1015 23:37:47.951694  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.370008 (* 1 = 0.370008 loss)
I1015 23:37:47.951700  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0437996 (* 1 = 0.0437996 loss)
I1015 23:37:47.951705  4233 sgd_solver.cpp:138] Iteration 46800, lr = 0.000125
I1015 23:38:25.073228  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:38:47.465612  4233 solver.cpp:243] Iteration 46900, loss = 0.530008
I1015 23:38:47.465658  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.420107 (* 1 = 0.420107 loss)
I1015 23:38:47.465664  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370337 (* 1 = 0.0370337 loss)
I1015 23:38:47.465670  4233 sgd_solver.cpp:138] Iteration 46900, lr = 0.000125
I1015 23:39:46.802987  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_47000.caffemodel
I1015 23:39:47.046550  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_47000.solverstate
I1015 23:39:47.622176  4233 solver.cpp:243] Iteration 47000, loss = 0.47393
I1015 23:39:47.622225  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.655845 (* 1 = 0.655845 loss)
I1015 23:39:47.622232  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398904 (* 1 = 0.0398904 loss)
I1015 23:39:47.622238  4233 sgd_solver.cpp:138] Iteration 47000, lr = 0.000125
I1015 23:40:47.358636  4233 solver.cpp:243] Iteration 47100, loss = 0.446116
I1015 23:40:47.358682  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.872223 (* 1 = 0.872223 loss)
I1015 23:40:47.358688  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0498221 (* 1 = 0.0498221 loss)
I1015 23:40:47.358693  4233 sgd_solver.cpp:138] Iteration 47100, lr = 0.000125
I1015 23:41:46.477682  4233 solver.cpp:243] Iteration 47200, loss = 0.703536
I1015 23:41:46.477730  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0842186 (* 1 = 0.0842186 loss)
I1015 23:41:46.477737  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0416539 (* 1 = 0.0416539 loss)
I1015 23:41:46.477742  4233 sgd_solver.cpp:138] Iteration 47200, lr = 0.000125
I1015 23:42:44.706243  4233 solver.cpp:243] Iteration 47300, loss = 0.542454
I1015 23:42:44.706291  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.93136 (* 1 = 0.93136 loss)
I1015 23:42:44.706298  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0465024 (* 1 = 0.0465024 loss)
I1015 23:42:44.706305  4233 sgd_solver.cpp:138] Iteration 47300, lr = 0.000125
I1015 23:43:44.575515  4233 solver.cpp:243] Iteration 47400, loss = 0.865253
I1015 23:43:44.575547  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.60853 (* 1 = 1.60853 loss)
I1015 23:43:44.575553  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0450274 (* 1 = 0.0450274 loss)
I1015 23:43:44.575559  4233 sgd_solver.cpp:138] Iteration 47400, lr = 0.000125
I1015 23:44:43.406639  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_47500.caffemodel
I1015 23:44:44.160969  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_47500.solverstate
I1015 23:44:44.739673  4233 solver.cpp:243] Iteration 47500, loss = 0.731699
I1015 23:44:44.739708  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.45109 (* 1 = 0.45109 loss)
I1015 23:44:44.739714  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0472816 (* 1 = 0.0472816 loss)
I1015 23:44:44.739719  4233 sgd_solver.cpp:138] Iteration 47500, lr = 0.000125
I1015 23:45:44.136461  4233 solver.cpp:243] Iteration 47600, loss = 0.440086
I1015 23:45:44.136507  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.133283 (* 1 = 0.133283 loss)
I1015 23:45:44.136512  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0355534 (* 1 = 0.0355534 loss)
I1015 23:45:44.136518  4233 sgd_solver.cpp:138] Iteration 47600, lr = 0.000125
I1015 23:46:43.399912  4233 solver.cpp:243] Iteration 47700, loss = 0.484265
I1015 23:46:43.399960  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.330027 (* 1 = 0.330027 loss)
I1015 23:46:43.399966  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418967 (* 1 = 0.0418967 loss)
I1015 23:46:43.399971  4233 sgd_solver.cpp:138] Iteration 47700, lr = 0.000125
I1015 23:47:42.438302  4233 solver.cpp:243] Iteration 47800, loss = 0.649098
I1015 23:47:42.438347  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.129955 (* 1 = 0.129955 loss)
I1015 23:47:42.438354  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370431 (* 1 = 0.0370431 loss)
I1015 23:47:42.438359  4233 sgd_solver.cpp:138] Iteration 47800, lr = 0.000125
I1015 23:48:22.704942  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:48:41.285740  4233 solver.cpp:243] Iteration 47900, loss = 0.954041
I1015 23:48:41.285786  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.919621 (* 1 = 0.919621 loss)
I1015 23:48:41.285792  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0811017 (* 1 = 0.0811017 loss)
I1015 23:48:41.285799  4233 sgd_solver.cpp:138] Iteration 47900, lr = 0.000125
I1015 23:49:40.132017  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_48000.caffemodel
I1015 23:49:40.375519  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_48000.solverstate
I1015 23:49:40.571736  4233 net.cpp:693] Ignoring source layer mbox_loss
I1015 23:51:18.127702  4233 solver.cpp:243] Iteration 48000, loss = 0.375822
I1015 23:51:18.127734  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.334445 (* 1 = 0.334445 loss)
I1015 23:51:18.127740  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413776 (* 1 = 0.0413776 loss)
I1015 23:51:18.127746  4233 sgd_solver.cpp:138] Iteration 48000, lr = 0.000125
I1015 23:52:16.983067  4233 solver.cpp:243] Iteration 48100, loss = 0.487868
I1015 23:52:16.983098  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.56672 (* 1 = 0.56672 loss)
I1015 23:52:16.983104  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0448671 (* 1 = 0.0448671 loss)
I1015 23:52:16.983109  4233 sgd_solver.cpp:138] Iteration 48100, lr = 0.000125
I1015 23:53:16.886649  4233 solver.cpp:243] Iteration 48200, loss = 0.481496
I1015 23:53:16.886680  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.599194 (* 1 = 0.599194 loss)
I1015 23:53:16.886687  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0358765 (* 1 = 0.0358765 loss)
I1015 23:53:16.886693  4233 sgd_solver.cpp:138] Iteration 48200, lr = 0.000125
I1015 23:54:15.989187  4233 solver.cpp:243] Iteration 48300, loss = 0.603907
I1015 23:54:15.989223  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.170154 (* 1 = 0.170154 loss)
I1015 23:54:15.989231  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0346131 (* 1 = 0.0346131 loss)
I1015 23:54:15.989254  4233 sgd_solver.cpp:138] Iteration 48300, lr = 0.000125
I1015 23:55:02.076866  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1015 23:55:14.332509  4233 solver.cpp:243] Iteration 48400, loss = 0.682223
I1015 23:55:14.332552  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0916547 (* 1 = 0.0916547 loss)
I1015 23:55:14.332558  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0458614 (* 1 = 0.0458614 loss)
I1015 23:55:14.332564  4233 sgd_solver.cpp:138] Iteration 48400, lr = 0.000125
I1015 23:56:13.670636  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_48500.caffemodel
I1015 23:56:14.507115  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_48500.solverstate
I1015 23:56:15.093621  4233 solver.cpp:243] Iteration 48500, loss = 0.626338
I1015 23:56:15.093652  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.134315 (* 1 = 0.134315 loss)
I1015 23:56:15.093658  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0505128 (* 1 = 0.0505128 loss)
I1015 23:56:15.093663  4233 sgd_solver.cpp:138] Iteration 48500, lr = 0.000125
I1015 23:57:14.013612  4233 solver.cpp:243] Iteration 48600, loss = 0.534896
I1015 23:57:14.013660  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.23242 (* 1 = 1.23242 loss)
I1015 23:57:14.013666  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0437608 (* 1 = 0.0437608 loss)
I1015 23:57:14.013671  4233 sgd_solver.cpp:138] Iteration 48600, lr = 0.000125
I1015 23:58:14.230381  4233 solver.cpp:243] Iteration 48700, loss = 0.477733
I1015 23:58:14.230428  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.108303 (* 1 = 0.108303 loss)
I1015 23:58:14.230434  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367302 (* 1 = 0.0367302 loss)
I1015 23:58:14.230442  4233 sgd_solver.cpp:138] Iteration 48700, lr = 0.000125
I1015 23:59:13.227608  4233 solver.cpp:243] Iteration 48800, loss = 0.621225
I1015 23:59:13.227640  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.292741 (* 1 = 0.292741 loss)
I1015 23:59:13.227646  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0488122 (* 1 = 0.0488122 loss)
I1015 23:59:13.227653  4233 sgd_solver.cpp:138] Iteration 48800, lr = 0.000125
I1016 00:00:11.966500  4233 solver.cpp:243] Iteration 48900, loss = 0.537181
I1016 00:00:11.966547  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.151806 (* 1 = 0.151806 loss)
I1016 00:00:11.966554  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0470855 (* 1 = 0.0470855 loss)
I1016 00:00:11.966559  4233 sgd_solver.cpp:138] Iteration 48900, lr = 0.000125
I1016 00:01:10.767402  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_49000.caffemodel
I1016 00:01:11.540788  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_49000.solverstate
I1016 00:01:12.146172  4233 solver.cpp:243] Iteration 49000, loss = 1.32437
I1016 00:01:12.146206  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.03305 (* 1 = 1.03305 loss)
I1016 00:01:12.146216  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0386834 (* 1 = 0.0386834 loss)
I1016 00:01:12.146239  4233 sgd_solver.cpp:138] Iteration 49000, lr = 0.000125
I1016 00:02:10.777904  4233 solver.cpp:243] Iteration 49100, loss = 0.66778
I1016 00:02:10.777935  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.912956 (* 1 = 0.912956 loss)
I1016 00:02:10.777945  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0328221 (* 1 = 0.0328221 loss)
I1016 00:02:10.777952  4233 sgd_solver.cpp:138] Iteration 49100, lr = 0.000125
I1016 00:03:10.764732  4233 solver.cpp:243] Iteration 49200, loss = 0.349214
I1016 00:03:10.764778  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.424866 (* 1 = 0.424866 loss)
I1016 00:03:10.764784  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0350269 (* 1 = 0.0350269 loss)
I1016 00:03:10.764791  4233 sgd_solver.cpp:138] Iteration 49200, lr = 0.000125
I1016 00:04:10.607327  4233 solver.cpp:243] Iteration 49300, loss = 0.671639
I1016 00:04:10.607374  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.647703 (* 1 = 0.647703 loss)
I1016 00:04:10.607380  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.038656 (* 1 = 0.038656 loss)
I1016 00:04:10.607386  4233 sgd_solver.cpp:138] Iteration 49300, lr = 0.000125
I1016 00:05:03.760664  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:05:09.620409  4233 solver.cpp:243] Iteration 49400, loss = 0.718497
I1016 00:05:09.620455  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.0965 (* 1 = 1.0965 loss)
I1016 00:05:09.620462  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0406254 (* 1 = 0.0406254 loss)
I1016 00:05:09.620467  4233 sgd_solver.cpp:138] Iteration 49400, lr = 0.000125
I1016 00:06:07.523563  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_49500.caffemodel
I1016 00:06:08.335194  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_49500.solverstate
I1016 00:06:08.905917  4233 solver.cpp:243] Iteration 49500, loss = 1.06936
I1016 00:06:08.905951  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.410588 (* 1 = 0.410588 loss)
I1016 00:06:08.905958  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0421328 (* 1 = 0.0421328 loss)
I1016 00:06:08.905964  4233 sgd_solver.cpp:138] Iteration 49500, lr = 0.000125
I1016 00:07:07.934221  4233 solver.cpp:243] Iteration 49600, loss = 0.388059
I1016 00:07:07.934265  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.397789 (* 1 = 0.397789 loss)
I1016 00:07:07.934271  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0364945 (* 1 = 0.0364945 loss)
I1016 00:07:07.934278  4233 sgd_solver.cpp:138] Iteration 49600, lr = 0.000125
I1016 00:08:07.638409  4233 solver.cpp:243] Iteration 49700, loss = 0.549785
I1016 00:08:07.638455  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.116776 (* 1 = 0.116776 loss)
I1016 00:08:07.638461  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.038713 (* 1 = 0.038713 loss)
I1016 00:08:07.638468  4233 sgd_solver.cpp:138] Iteration 49700, lr = 0.000125
I1016 00:09:07.730648  4233 solver.cpp:243] Iteration 49800, loss = 0.260968
I1016 00:09:07.730692  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.232668 (* 1 = 0.232668 loss)
I1016 00:09:07.730698  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0310603 (* 1 = 0.0310603 loss)
I1016 00:09:07.730705  4233 sgd_solver.cpp:138] Iteration 49800, lr = 0.000125
I1016 00:10:06.910213  4233 solver.cpp:243] Iteration 49900, loss = 0.55699
I1016 00:10:06.910259  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.2847 (* 1 = 1.2847 loss)
I1016 00:10:06.910265  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0431331 (* 1 = 0.0431331 loss)
I1016 00:10:06.910271  4233 sgd_solver.cpp:138] Iteration 49900, lr = 0.000125
I1016 00:11:04.835755  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_50000.caffemodel
I1016 00:11:05.603543  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_50000.solverstate
I1016 00:11:06.193809  4233 solver.cpp:243] Iteration 50000, loss = 0.637944
I1016 00:11:06.193856  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.678222 (* 1 = 0.678222 loss)
I1016 00:11:06.193862  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0296566 (* 1 = 0.0296566 loss)
I1016 00:11:06.193867  4233 sgd_solver.cpp:138] Iteration 50000, lr = 0.000125
I1016 00:12:05.064813  4233 solver.cpp:243] Iteration 50100, loss = 0.947103
I1016 00:12:05.064843  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.625823 (* 1 = 0.625823 loss)
I1016 00:12:05.064851  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0383149 (* 1 = 0.0383149 loss)
I1016 00:12:05.064855  4233 sgd_solver.cpp:138] Iteration 50100, lr = 0.000125
I1016 00:13:04.309329  4233 solver.cpp:243] Iteration 50200, loss = 0.505162
I1016 00:13:04.309376  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.275006 (* 1 = 0.275006 loss)
I1016 00:13:04.309382  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0528039 (* 1 = 0.0528039 loss)
I1016 00:13:04.309388  4233 sgd_solver.cpp:138] Iteration 50200, lr = 0.000125
I1016 00:14:04.551851  4233 solver.cpp:243] Iteration 50300, loss = 0.544572
I1016 00:14:04.551882  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.21028 (* 1 = 1.21028 loss)
I1016 00:14:04.551888  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490332 (* 1 = 0.0490332 loss)
I1016 00:14:04.551893  4233 sgd_solver.cpp:138] Iteration 50300, lr = 0.000125
I1016 00:15:03.927598  4233 solver.cpp:243] Iteration 50400, loss = 0.529485
I1016 00:15:03.927633  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.100518 (* 1 = 0.100518 loss)
I1016 00:15:03.927639  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0383502 (* 1 = 0.0383502 loss)
I1016 00:15:03.927644  4233 sgd_solver.cpp:138] Iteration 50400, lr = 0.000125
I1016 00:15:04.574476  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:16:02.732759  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_50500.caffemodel
I1016 00:16:02.966475  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_50500.solverstate
I1016 00:16:03.538077  4233 solver.cpp:243] Iteration 50500, loss = 0.850294
I1016 00:16:03.538105  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.879437 (* 1 = 0.879437 loss)
I1016 00:16:03.538111  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0342931 (* 1 = 0.0342931 loss)
I1016 00:16:03.538118  4233 sgd_solver.cpp:138] Iteration 50500, lr = 0.000125
I1016 00:17:01.996493  4233 solver.cpp:243] Iteration 50600, loss = 0.699114
I1016 00:17:01.996526  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.07455 (* 1 = 1.07455 loss)
I1016 00:17:01.996531  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.062896 (* 1 = 0.062896 loss)
I1016 00:17:01.996537  4233 sgd_solver.cpp:138] Iteration 50600, lr = 0.000125
I1016 00:18:01.452968  4233 solver.cpp:243] Iteration 50700, loss = 0.324345
I1016 00:18:01.452998  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.114924 (* 1 = 0.114924 loss)
I1016 00:18:01.453004  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0433855 (* 1 = 0.0433855 loss)
I1016 00:18:01.453009  4233 sgd_solver.cpp:138] Iteration 50700, lr = 0.000125
I1016 00:19:01.469972  4233 solver.cpp:243] Iteration 50800, loss = 0.482398
I1016 00:19:01.470005  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.463859 (* 1 = 0.463859 loss)
I1016 00:19:01.470011  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0818991 (* 1 = 0.0818991 loss)
I1016 00:19:01.470016  4233 sgd_solver.cpp:138] Iteration 50800, lr = 0.000125
I1016 00:20:01.383739  4233 solver.cpp:243] Iteration 50900, loss = 0.422387
I1016 00:20:01.383772  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0805773 (* 1 = 0.0805773 loss)
I1016 00:20:01.383779  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0405446 (* 1 = 0.0405446 loss)
I1016 00:20:01.383785  4233 sgd_solver.cpp:138] Iteration 50900, lr = 0.000125
I1016 00:21:00.053454  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_51000.caffemodel
I1016 00:21:00.270372  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_51000.solverstate
I1016 00:21:00.849809  4233 solver.cpp:243] Iteration 51000, loss = 0.423517
I1016 00:21:00.849856  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.39463 (* 1 = 0.39463 loss)
I1016 00:21:00.849862  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0396523 (* 1 = 0.0396523 loss)
I1016 00:21:00.849869  4233 sgd_solver.cpp:138] Iteration 51000, lr = 0.000125
I1016 00:21:58.805794  4233 solver.cpp:243] Iteration 51100, loss = 0.424684
I1016 00:21:58.805845  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.232297 (* 1 = 0.232297 loss)
I1016 00:21:58.805851  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0505599 (* 1 = 0.0505599 loss)
I1016 00:21:58.805857  4233 sgd_solver.cpp:138] Iteration 51100, lr = 0.000125
I1016 00:22:58.744683  4233 solver.cpp:243] Iteration 51200, loss = 0.685157
I1016 00:22:58.744730  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.16642 (* 1 = 0.16642 loss)
I1016 00:22:58.744736  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418567 (* 1 = 0.0418567 loss)
I1016 00:22:58.744741  4233 sgd_solver.cpp:138] Iteration 51200, lr = 0.000125
I1016 00:23:58.315425  4233 solver.cpp:243] Iteration 51300, loss = 0.505512
I1016 00:23:58.315472  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.436021 (* 1 = 0.436021 loss)
I1016 00:23:58.315479  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0420706 (* 1 = 0.0420706 loss)
I1016 00:23:58.315485  4233 sgd_solver.cpp:138] Iteration 51300, lr = 0.000125
I1016 00:24:58.589272  4233 solver.cpp:243] Iteration 51400, loss = 0.256572
I1016 00:24:58.589318  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.628276 (* 1 = 0.628276 loss)
I1016 00:24:58.589324  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0397946 (* 1 = 0.0397946 loss)
I1016 00:24:58.589330  4233 sgd_solver.cpp:138] Iteration 51400, lr = 0.000125
I1016 00:25:01.702456  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:25:57.069414  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_51500.caffemodel
I1016 00:25:57.321130  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_51500.solverstate
I1016 00:25:57.906286  4233 solver.cpp:243] Iteration 51500, loss = 0.438439
I1016 00:25:57.906332  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.427161 (* 1 = 0.427161 loss)
I1016 00:25:57.906337  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0441427 (* 1 = 0.0441427 loss)
I1016 00:25:57.906343  4233 sgd_solver.cpp:138] Iteration 51500, lr = 0.000125
I1016 00:26:57.107409  4233 solver.cpp:243] Iteration 51600, loss = 0.511071
I1016 00:26:57.107440  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.674323 (* 1 = 0.674323 loss)
I1016 00:26:57.107446  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0337924 (* 1 = 0.0337924 loss)
I1016 00:26:57.107452  4233 sgd_solver.cpp:138] Iteration 51600, lr = 0.000125
I1016 00:27:56.175487  4233 solver.cpp:243] Iteration 51700, loss = 1.15084
I1016 00:27:56.175536  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.80838 (* 1 = 0.80838 loss)
I1016 00:27:56.175544  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.050473 (* 1 = 0.050473 loss)
I1016 00:27:56.175549  4233 sgd_solver.cpp:138] Iteration 51700, lr = 0.000125
I1016 00:28:55.548990  4233 solver.cpp:243] Iteration 51800, loss = 0.424342
I1016 00:28:55.549037  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.401282 (* 1 = 0.401282 loss)
I1016 00:28:55.549043  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0384926 (* 1 = 0.0384926 loss)
I1016 00:28:55.549049  4233 sgd_solver.cpp:138] Iteration 51800, lr = 0.000125
I1016 00:29:55.573743  4233 solver.cpp:243] Iteration 51900, loss = 0.360862
I1016 00:29:55.573791  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.276146 (* 1 = 0.276146 loss)
I1016 00:29:55.573796  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0482582 (* 1 = 0.0482582 loss)
I1016 00:29:55.573802  4233 sgd_solver.cpp:138] Iteration 51900, lr = 0.000125
I1016 00:30:54.862582  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_52000.caffemodel
I1016 00:30:55.091291  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_52000.solverstate
I1016 00:30:55.281872  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 00:32:16.321218  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:32:34.339192  4233 solver.cpp:243] Iteration 52000, loss = 0.384126
I1016 00:32:34.339231  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.340544 (* 1 = 0.340544 loss)
I1016 00:32:34.339238  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0435818 (* 1 = 0.0435818 loss)
I1016 00:32:34.339244  4233 sgd_solver.cpp:138] Iteration 52000, lr = 0.000125
I1016 00:33:32.416069  4233 solver.cpp:243] Iteration 52100, loss = 0.507884
I1016 00:33:32.416115  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.23048 (* 1 = 1.23048 loss)
I1016 00:33:32.416123  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370661 (* 1 = 0.0370661 loss)
I1016 00:33:32.416129  4233 sgd_solver.cpp:138] Iteration 52100, lr = 0.000125
I1016 00:34:30.905386  4233 solver.cpp:243] Iteration 52200, loss = 0.560105
I1016 00:34:30.905434  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.790146 (* 1 = 0.790146 loss)
I1016 00:34:30.905441  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412135 (* 1 = 0.0412135 loss)
I1016 00:34:30.905447  4233 sgd_solver.cpp:138] Iteration 52200, lr = 0.000125
I1016 00:35:30.579401  4233 solver.cpp:243] Iteration 52300, loss = 0.303438
I1016 00:35:30.579437  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.204459 (* 1 = 0.204459 loss)
I1016 00:35:30.579447  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0437407 (* 1 = 0.0437407 loss)
I1016 00:35:30.579468  4233 sgd_solver.cpp:138] Iteration 52300, lr = 0.000125
I1016 00:36:30.324993  4233 solver.cpp:243] Iteration 52400, loss = 0.49632
I1016 00:36:30.325026  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.881401 (* 1 = 0.881401 loss)
I1016 00:36:30.325034  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0469585 (* 1 = 0.0469585 loss)
I1016 00:36:30.325057  4233 sgd_solver.cpp:138] Iteration 52400, lr = 0.000125
I1016 00:37:29.966269  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_52500.caffemodel
I1016 00:37:30.789026  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_52500.solverstate
I1016 00:37:31.385560  4233 solver.cpp:243] Iteration 52500, loss = 0.339582
I1016 00:37:31.385603  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.214714 (* 1 = 0.214714 loss)
I1016 00:37:31.385609  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0409831 (* 1 = 0.0409831 loss)
I1016 00:37:31.385615  4233 sgd_solver.cpp:138] Iteration 52500, lr = 0.000125
I1016 00:38:29.745375  4233 solver.cpp:243] Iteration 52600, loss = 0.435733
I1016 00:38:29.745420  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.385627 (* 1 = 0.385627 loss)
I1016 00:38:29.745426  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.034206 (* 1 = 0.034206 loss)
I1016 00:38:29.745432  4233 sgd_solver.cpp:138] Iteration 52600, lr = 0.000125
I1016 00:39:28.442378  4233 solver.cpp:243] Iteration 52700, loss = 0.593337
I1016 00:39:28.442425  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.857392 (* 1 = 0.857392 loss)
I1016 00:39:28.442430  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0393778 (* 1 = 0.0393778 loss)
I1016 00:39:28.442436  4233 sgd_solver.cpp:138] Iteration 52700, lr = 0.000125
I1016 00:40:27.954550  4233 solver.cpp:243] Iteration 52800, loss = 0.778416
I1016 00:40:27.954596  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.560442 (* 1 = 0.560442 loss)
I1016 00:40:27.954602  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0441431 (* 1 = 0.0441431 loss)
I1016 00:40:27.954608  4233 sgd_solver.cpp:138] Iteration 52800, lr = 0.000125
I1016 00:41:27.177979  4233 solver.cpp:243] Iteration 52900, loss = 0.72186
I1016 00:41:27.178011  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.442802 (* 1 = 0.442802 loss)
I1016 00:41:27.178017  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.038657 (* 1 = 0.038657 loss)
I1016 00:41:27.178023  4233 sgd_solver.cpp:138] Iteration 52900, lr = 0.000125
I1016 00:41:40.516918  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:42:26.746536  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_53000.caffemodel
I1016 00:42:26.985357  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_53000.solverstate
I1016 00:42:27.581552  4233 solver.cpp:243] Iteration 53000, loss = 0.509491
I1016 00:42:27.581598  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.09807 (* 1 = 1.09807 loss)
I1016 00:42:27.581604  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0462055 (* 1 = 0.0462055 loss)
I1016 00:42:27.581609  4233 sgd_solver.cpp:138] Iteration 53000, lr = 0.000125
I1016 00:43:27.007691  4233 solver.cpp:243] Iteration 53100, loss = 0.726808
I1016 00:43:27.007736  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.97684 (* 1 = 0.97684 loss)
I1016 00:43:27.007742  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0625172 (* 1 = 0.0625172 loss)
I1016 00:43:27.007748  4233 sgd_solver.cpp:138] Iteration 53100, lr = 0.000125
I1016 00:44:26.144692  4233 solver.cpp:243] Iteration 53200, loss = 0.639466
I1016 00:44:26.144739  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.591743 (* 1 = 0.591743 loss)
I1016 00:44:26.144745  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0337738 (* 1 = 0.0337738 loss)
I1016 00:44:26.144752  4233 sgd_solver.cpp:138] Iteration 53200, lr = 0.000125
I1016 00:45:24.633725  4233 solver.cpp:243] Iteration 53300, loss = 0.55713
I1016 00:45:24.633774  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.53362 (* 1 = 0.53362 loss)
I1016 00:45:24.633780  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0419156 (* 1 = 0.0419156 loss)
I1016 00:45:24.633785  4233 sgd_solver.cpp:138] Iteration 53300, lr = 0.000125
I1016 00:46:24.228309  4233 solver.cpp:243] Iteration 53400, loss = 0.415382
I1016 00:46:24.228358  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.435054 (* 1 = 0.435054 loss)
I1016 00:46:24.228363  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367606 (* 1 = 0.0367606 loss)
I1016 00:46:24.228369  4233 sgd_solver.cpp:138] Iteration 53400, lr = 0.000125
I1016 00:47:23.702706  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_53500.caffemodel
I1016 00:47:23.935394  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_53500.solverstate
I1016 00:47:24.496605  4233 solver.cpp:243] Iteration 53500, loss = 0.384855
I1016 00:47:24.496651  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.2086 (* 1 = 0.2086 loss)
I1016 00:47:24.496659  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0427243 (* 1 = 0.0427243 loss)
I1016 00:47:24.496665  4233 sgd_solver.cpp:138] Iteration 53500, lr = 0.000125
I1016 00:48:24.334471  4233 solver.cpp:243] Iteration 53600, loss = 0.296291
I1016 00:48:24.334518  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.121288 (* 1 = 0.121288 loss)
I1016 00:48:24.334525  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0372628 (* 1 = 0.0372628 loss)
I1016 00:48:24.334530  4233 sgd_solver.cpp:138] Iteration 53600, lr = 0.000125
I1016 00:49:23.474203  4233 solver.cpp:243] Iteration 53700, loss = 0.590413
I1016 00:49:23.474251  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.352634 (* 1 = 0.352634 loss)
I1016 00:49:23.474256  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412347 (* 1 = 0.0412347 loss)
I1016 00:49:23.474262  4233 sgd_solver.cpp:138] Iteration 53700, lr = 0.000125
I1016 00:50:21.705266  4233 solver.cpp:243] Iteration 53800, loss = 0.444112
I1016 00:50:21.705314  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.323202 (* 1 = 0.323202 loss)
I1016 00:50:21.705322  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0358205 (* 1 = 0.0358205 loss)
I1016 00:50:21.705327  4233 sgd_solver.cpp:138] Iteration 53800, lr = 0.000125
I1016 00:51:21.533366  4233 solver.cpp:243] Iteration 53900, loss = 0.662784
I1016 00:51:21.533413  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.630293 (* 1 = 0.630293 loss)
I1016 00:51:21.533419  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0368184 (* 1 = 0.0368184 loss)
I1016 00:51:21.533426  4233 sgd_solver.cpp:138] Iteration 53900, lr = 0.000125
I1016 00:51:36.991539  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 00:52:20.447758  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_54000.caffemodel
I1016 00:52:21.272547  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_54000.solverstate
I1016 00:52:21.856806  4233 solver.cpp:243] Iteration 54000, loss = 0.591462
I1016 00:52:21.856853  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.75476 (* 1 = 0.75476 loss)
I1016 00:52:21.856858  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0731612 (* 1 = 0.0731612 loss)
I1016 00:52:21.856864  4233 sgd_solver.cpp:138] Iteration 54000, lr = 0.000125
I1016 00:53:21.262217  4233 solver.cpp:243] Iteration 54100, loss = 0.406671
I1016 00:53:21.262249  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.100151 (* 1 = 0.100151 loss)
I1016 00:53:21.262255  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0325078 (* 1 = 0.0325078 loss)
I1016 00:53:21.262261  4233 sgd_solver.cpp:138] Iteration 54100, lr = 0.000125
I1016 00:54:20.508632  4233 solver.cpp:243] Iteration 54200, loss = 0.379612
I1016 00:54:20.508677  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.232905 (* 1 = 0.232905 loss)
I1016 00:54:20.508683  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0530075 (* 1 = 0.0530075 loss)
I1016 00:54:20.508689  4233 sgd_solver.cpp:138] Iteration 54200, lr = 0.000125
I1016 00:55:19.656792  4233 solver.cpp:243] Iteration 54300, loss = 0.63871
I1016 00:55:19.656839  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.180919 (* 1 = 0.180919 loss)
I1016 00:55:19.656847  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0410667 (* 1 = 0.0410667 loss)
I1016 00:55:19.656852  4233 sgd_solver.cpp:138] Iteration 54300, lr = 0.000125
I1016 00:56:18.531236  4233 solver.cpp:243] Iteration 54400, loss = 0.78375
I1016 00:56:18.531268  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.846425 (* 1 = 0.846425 loss)
I1016 00:56:18.531275  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0578435 (* 1 = 0.0578435 loss)
I1016 00:56:18.531280  4233 sgd_solver.cpp:138] Iteration 54400, lr = 0.000125
I1016 00:57:17.543849  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_54500.caffemodel
I1016 00:57:17.788652  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_54500.solverstate
I1016 00:57:18.381305  4233 solver.cpp:243] Iteration 54500, loss = 0.177921
I1016 00:57:18.381350  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.2608 (* 1 = 0.2608 loss)
I1016 00:57:18.381357  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0385336 (* 1 = 0.0385336 loss)
I1016 00:57:18.381362  4233 sgd_solver.cpp:138] Iteration 54500, lr = 0.000125
I1016 00:58:18.130980  4233 solver.cpp:243] Iteration 54600, loss = 0.369413
I1016 00:58:18.131012  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.304744 (* 1 = 0.304744 loss)
I1016 00:58:18.131019  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398151 (* 1 = 0.0398151 loss)
I1016 00:58:18.131026  4233 sgd_solver.cpp:138] Iteration 54600, lr = 0.000125
I1016 00:59:18.025090  4233 solver.cpp:243] Iteration 54700, loss = 0.354395
I1016 00:59:18.025138  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.453647 (* 1 = 0.453647 loss)
I1016 00:59:18.025144  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0570812 (* 1 = 0.0570812 loss)
I1016 00:59:18.025151  4233 sgd_solver.cpp:138] Iteration 54700, lr = 0.000125
I1016 01:00:17.150934  4233 solver.cpp:243] Iteration 54800, loss = 0.518457
I1016 01:00:17.150981  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.227867 (* 1 = 0.227867 loss)
I1016 01:00:17.150988  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0292864 (* 1 = 0.0292864 loss)
I1016 01:00:17.150993  4233 sgd_solver.cpp:138] Iteration 54800, lr = 0.000125
I1016 01:01:15.559902  4233 solver.cpp:243] Iteration 54900, loss = 0.5688
I1016 01:01:15.559949  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.172944 (* 1 = 0.172944 loss)
I1016 01:01:15.559955  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0345833 (* 1 = 0.0345833 loss)
I1016 01:01:15.559962  4233 sgd_solver.cpp:138] Iteration 54900, lr = 0.000125
I1016 01:01:35.486194  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:02:14.880784  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_55000.caffemodel
I1016 01:02:15.108644  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_55000.solverstate
I1016 01:02:15.680476  4233 solver.cpp:243] Iteration 55000, loss = 0.51035
I1016 01:02:15.680524  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.181664 (* 1 = 0.181664 loss)
I1016 01:02:15.680531  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0500683 (* 1 = 0.0500683 loss)
I1016 01:02:15.680536  4233 sgd_solver.cpp:138] Iteration 55000, lr = 0.000125
I1016 01:03:14.988579  4233 solver.cpp:243] Iteration 55100, loss = 0.35263
I1016 01:03:14.988626  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.279854 (* 1 = 0.279854 loss)
I1016 01:03:14.988631  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.047306 (* 1 = 0.047306 loss)
I1016 01:03:14.988637  4233 sgd_solver.cpp:138] Iteration 55100, lr = 0.000125
I1016 01:04:15.146729  4233 solver.cpp:243] Iteration 55200, loss = 0.401309
I1016 01:04:15.146777  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.121602 (* 1 = 0.121602 loss)
I1016 01:04:15.146783  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0300648 (* 1 = 0.0300648 loss)
I1016 01:04:15.146790  4233 sgd_solver.cpp:138] Iteration 55200, lr = 0.000125
I1016 01:05:14.202589  4233 solver.cpp:243] Iteration 55300, loss = 0.541365
I1016 01:05:14.202638  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.338015 (* 1 = 0.338015 loss)
I1016 01:05:14.202646  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.037482 (* 1 = 0.037482 loss)
I1016 01:05:14.202651  4233 sgd_solver.cpp:138] Iteration 55300, lr = 0.000125
I1016 01:06:12.918320  4233 solver.cpp:243] Iteration 55400, loss = 0.456746
I1016 01:06:12.918367  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.189168 (* 1 = 0.189168 loss)
I1016 01:06:12.918373  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0496282 (* 1 = 0.0496282 loss)
I1016 01:06:12.918380  4233 sgd_solver.cpp:138] Iteration 55400, lr = 0.000125
I1016 01:07:11.736560  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_55500.caffemodel
I1016 01:07:11.975384  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_55500.solverstate
I1016 01:07:12.563038  4233 solver.cpp:243] Iteration 55500, loss = 1.14954
I1016 01:07:12.563084  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.19504 (* 1 = 1.19504 loss)
I1016 01:07:12.563091  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.040927 (* 1 = 0.040927 loss)
I1016 01:07:12.563096  4233 sgd_solver.cpp:138] Iteration 55500, lr = 0.000125
I1016 01:08:11.613024  4233 solver.cpp:243] Iteration 55600, loss = 0.515728
I1016 01:08:11.613070  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.784531 (* 1 = 0.784531 loss)
I1016 01:08:11.613076  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0416935 (* 1 = 0.0416935 loss)
I1016 01:08:11.613082  4233 sgd_solver.cpp:138] Iteration 55600, lr = 0.000125
I1016 01:09:11.672618  4233 solver.cpp:243] Iteration 55700, loss = 0.261231
I1016 01:09:11.672652  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.10293 (* 1 = 0.10293 loss)
I1016 01:09:11.672662  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0377325 (* 1 = 0.0377325 loss)
I1016 01:09:11.672669  4233 sgd_solver.cpp:138] Iteration 55700, lr = 0.000125
I1016 01:10:11.530541  4233 solver.cpp:243] Iteration 55800, loss = 0.596395
I1016 01:10:11.530591  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.237645 (* 1 = 0.237645 loss)
I1016 01:10:11.530601  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370192 (* 1 = 0.0370192 loss)
I1016 01:10:11.530622  4233 sgd_solver.cpp:138] Iteration 55800, lr = 0.000125
I1016 01:11:10.618254  4233 solver.cpp:243] Iteration 55900, loss = 0.542275
I1016 01:11:10.618301  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.761876 (* 1 = 0.761876 loss)
I1016 01:11:10.618307  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0415524 (* 1 = 0.0415524 loss)
I1016 01:11:10.618314  4233 sgd_solver.cpp:138] Iteration 55900, lr = 0.000125
I1016 01:11:32.335201  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:12:08.476439  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_56000.caffemodel
I1016 01:12:08.684635  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_56000.solverstate
I1016 01:12:08.881513  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 01:13:46.328675  4233 solver.cpp:243] Iteration 56000, loss = 0.79504
I1016 01:13:46.328711  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.749308 (* 1 = 0.749308 loss)
I1016 01:13:46.328716  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0457319 (* 1 = 0.0457319 loss)
I1016 01:13:46.328722  4233 sgd_solver.cpp:138] Iteration 56000, lr = 0.000125
I1016 01:14:44.779162  4233 solver.cpp:243] Iteration 56100, loss = 0.320633
I1016 01:14:44.779211  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.135836 (* 1 = 0.135836 loss)
I1016 01:14:44.779217  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0438001 (* 1 = 0.0438001 loss)
I1016 01:14:44.779222  4233 sgd_solver.cpp:138] Iteration 56100, lr = 0.000125
I1016 01:15:44.615303  4233 solver.cpp:243] Iteration 56200, loss = 0.467869
I1016 01:15:44.615350  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.556779 (* 1 = 0.556779 loss)
I1016 01:15:44.615356  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0506641 (* 1 = 0.0506641 loss)
I1016 01:15:44.615362  4233 sgd_solver.cpp:138] Iteration 56200, lr = 0.000125
I1016 01:16:44.866147  4233 solver.cpp:243] Iteration 56300, loss = 0.224488
I1016 01:16:44.866179  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.158674 (* 1 = 0.158674 loss)
I1016 01:16:44.866189  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0463528 (* 1 = 0.0463528 loss)
I1016 01:16:44.866196  4233 sgd_solver.cpp:138] Iteration 56300, lr = 0.000125
I1016 01:17:44.340318  4233 solver.cpp:243] Iteration 56400, loss = 0.356591
I1016 01:17:44.340366  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.321402 (* 1 = 0.321402 loss)
I1016 01:17:44.340373  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367865 (* 1 = 0.0367865 loss)
I1016 01:17:44.340378  4233 sgd_solver.cpp:138] Iteration 56400, lr = 0.000125
I1016 01:18:12.157781  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:18:42.422641  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_56500.caffemodel
I1016 01:18:42.683028  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_56500.solverstate
I1016 01:18:43.276731  4233 solver.cpp:243] Iteration 56500, loss = 0.512667
I1016 01:18:43.276763  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.820422 (* 1 = 0.820422 loss)
I1016 01:18:43.276770  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0319285 (* 1 = 0.0319285 loss)
I1016 01:18:43.276777  4233 sgd_solver.cpp:138] Iteration 56500, lr = 0.000125
I1016 01:19:42.738617  4233 solver.cpp:243] Iteration 56600, loss = 0.762987
I1016 01:19:42.738651  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.408313 (* 1 = 0.408313 loss)
I1016 01:19:42.738657  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0476942 (* 1 = 0.0476942 loss)
I1016 01:19:42.738662  4233 sgd_solver.cpp:138] Iteration 56600, lr = 0.000125
I1016 01:20:42.024350  4233 solver.cpp:243] Iteration 56700, loss = 0.417476
I1016 01:20:42.024395  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.314778 (* 1 = 0.314778 loss)
I1016 01:20:42.024401  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0525962 (* 1 = 0.0525962 loss)
I1016 01:20:42.024407  4233 sgd_solver.cpp:138] Iteration 56700, lr = 0.000125
I1016 01:21:42.254477  4233 solver.cpp:243] Iteration 56800, loss = 0.418141
I1016 01:21:42.254508  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.361218 (* 1 = 0.361218 loss)
I1016 01:21:42.254515  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0524131 (* 1 = 0.0524131 loss)
I1016 01:21:42.254521  4233 sgd_solver.cpp:138] Iteration 56800, lr = 0.000125
I1016 01:22:41.619297  4233 solver.cpp:243] Iteration 56900, loss = 0.557247
I1016 01:22:41.619348  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0909076 (* 1 = 0.0909076 loss)
I1016 01:22:41.619354  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0286702 (* 1 = 0.0286702 loss)
I1016 01:22:41.619359  4233 sgd_solver.cpp:138] Iteration 56900, lr = 0.000125
I1016 01:23:40.311408  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_57000.caffemodel
I1016 01:23:41.053045  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_57000.solverstate
I1016 01:23:41.625246  4233 solver.cpp:243] Iteration 57000, loss = 0.69557
I1016 01:23:41.625280  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.21645 (* 1 = 1.21645 loss)
I1016 01:23:41.625289  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0365128 (* 1 = 0.0365128 loss)
I1016 01:23:41.625296  4233 sgd_solver.cpp:138] Iteration 57000, lr = 0.000125
I1016 01:24:39.582583  4233 solver.cpp:243] Iteration 57100, loss = 0.492365
I1016 01:24:39.582618  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.30399 (* 1 = 1.30399 loss)
I1016 01:24:39.582628  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0614523 (* 1 = 0.0614523 loss)
I1016 01:24:39.582634  4233 sgd_solver.cpp:138] Iteration 57100, lr = 0.000125
I1016 01:25:39.062861  4233 solver.cpp:243] Iteration 57200, loss = 0.293662
I1016 01:25:39.062908  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.170026 (* 1 = 0.170026 loss)
I1016 01:25:39.062914  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0432399 (* 1 = 0.0432399 loss)
I1016 01:25:39.062921  4233 sgd_solver.cpp:138] Iteration 57200, lr = 0.000125
I1016 01:26:39.052315  4233 solver.cpp:243] Iteration 57300, loss = 0.378332
I1016 01:26:39.052361  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.111765 (* 1 = 0.111765 loss)
I1016 01:26:39.052367  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0460725 (* 1 = 0.0460725 loss)
I1016 01:26:39.052373  4233 sgd_solver.cpp:138] Iteration 57300, lr = 0.000125
I1016 01:27:38.992687  4233 solver.cpp:243] Iteration 57400, loss = 0.38744
I1016 01:27:38.992719  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0953414 (* 1 = 0.0953414 loss)
I1016 01:27:38.992725  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0348569 (* 1 = 0.0348569 loss)
I1016 01:27:38.992730  4233 sgd_solver.cpp:138] Iteration 57400, lr = 0.000125
I1016 01:28:10.838035  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:28:37.598726  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_57500.caffemodel
I1016 01:28:38.370566  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_57500.solverstate
I1016 01:28:38.946132  4233 solver.cpp:243] Iteration 57500, loss = 0.365685
I1016 01:28:38.946166  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.33856 (* 1 = 0.33856 loss)
I1016 01:28:38.946172  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0338447 (* 1 = 0.0338447 loss)
I1016 01:28:38.946178  4233 sgd_solver.cpp:138] Iteration 57500, lr = 0.000125
I1016 01:29:36.465535  4233 solver.cpp:243] Iteration 57600, loss = 0.349603
I1016 01:29:36.465581  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.416112 (* 1 = 0.416112 loss)
I1016 01:29:36.465587  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0650122 (* 1 = 0.0650122 loss)
I1016 01:29:36.465593  4233 sgd_solver.cpp:138] Iteration 57600, lr = 0.000125
I1016 01:30:36.322980  4233 solver.cpp:243] Iteration 57700, loss = 0.629947
I1016 01:30:36.323011  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.266295 (* 1 = 0.266295 loss)
I1016 01:30:36.323017  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0349522 (* 1 = 0.0349522 loss)
I1016 01:30:36.323022  4233 sgd_solver.cpp:138] Iteration 57700, lr = 0.000125
I1016 01:31:35.903499  4233 solver.cpp:243] Iteration 57800, loss = 0.413643
I1016 01:31:35.903544  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.125749 (* 1 = 0.125749 loss)
I1016 01:31:35.903550  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0461345 (* 1 = 0.0461345 loss)
I1016 01:31:35.903556  4233 sgd_solver.cpp:138] Iteration 57800, lr = 0.000125
I1016 01:32:36.206203  4233 solver.cpp:243] Iteration 57900, loss = 0.178307
I1016 01:32:36.206234  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.167098 (* 1 = 0.167098 loss)
I1016 01:32:36.206239  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0498712 (* 1 = 0.0498712 loss)
I1016 01:32:36.206245  4233 sgd_solver.cpp:138] Iteration 57900, lr = 0.000125
I1016 01:33:34.725203  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_58000.caffemodel
I1016 01:33:34.954417  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_58000.solverstate
I1016 01:33:35.533501  4233 solver.cpp:243] Iteration 58000, loss = 0.34944
I1016 01:33:35.533546  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.194981 (* 1 = 0.194981 loss)
I1016 01:33:35.533552  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0403128 (* 1 = 0.0403128 loss)
I1016 01:33:35.533558  4233 sgd_solver.cpp:138] Iteration 58000, lr = 0.000125
I1016 01:34:34.391156  4233 solver.cpp:243] Iteration 58100, loss = 0.380442
I1016 01:34:34.391203  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.342751 (* 1 = 0.342751 loss)
I1016 01:34:34.391209  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0377447 (* 1 = 0.0377447 loss)
I1016 01:34:34.391216  4233 sgd_solver.cpp:138] Iteration 58100, lr = 0.000125
I1016 01:35:33.371052  4233 solver.cpp:243] Iteration 58200, loss = 0.923217
I1016 01:35:33.371099  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.13784 (* 1 = 1.13784 loss)
I1016 01:35:33.371105  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.048673 (* 1 = 0.048673 loss)
I1016 01:35:33.371111  4233 sgd_solver.cpp:138] Iteration 58200, lr = 0.000125
I1016 01:36:32.685030  4233 solver.cpp:243] Iteration 58300, loss = 0.325732
I1016 01:36:32.685063  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.390095 (* 1 = 0.390095 loss)
I1016 01:36:32.685087  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367132 (* 1 = 0.0367132 loss)
I1016 01:36:32.685096  4233 sgd_solver.cpp:138] Iteration 58300, lr = 0.000125
I1016 01:37:32.767359  4233 solver.cpp:243] Iteration 58400, loss = 0.294356
I1016 01:37:32.767390  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.342066 (* 1 = 0.342066 loss)
I1016 01:37:32.767398  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0350403 (* 1 = 0.0350403 loss)
I1016 01:37:32.767421  4233 sgd_solver.cpp:138] Iteration 58400, lr = 0.000125
I1016 01:38:09.534176  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:38:32.099728  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_58500.caffemodel
I1016 01:38:32.323549  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_58500.solverstate
I1016 01:38:32.894394  4233 solver.cpp:243] Iteration 58500, loss = 0.668647
I1016 01:38:32.894424  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.0255 (* 1 = 1.0255 loss)
I1016 01:38:32.894430  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0496329 (* 1 = 0.0496329 loss)
I1016 01:38:32.894436  4233 sgd_solver.cpp:138] Iteration 58500, lr = 0.000125
I1016 01:39:31.607463  4233 solver.cpp:243] Iteration 58600, loss = 0.334325
I1016 01:39:31.607508  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.249905 (* 1 = 0.249905 loss)
I1016 01:39:31.607514  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0466173 (* 1 = 0.0466173 loss)
I1016 01:39:31.607519  4233 sgd_solver.cpp:138] Iteration 58600, lr = 0.000125
I1016 01:40:30.074656  4233 solver.cpp:243] Iteration 58700, loss = 0.436954
I1016 01:40:30.074702  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.25765 (* 1 = 1.25765 loss)
I1016 01:40:30.074708  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0455729 (* 1 = 0.0455729 loss)
I1016 01:40:30.074714  4233 sgd_solver.cpp:138] Iteration 58700, lr = 0.000125
I1016 01:41:29.689254  4233 solver.cpp:243] Iteration 58800, loss = 0.275916
I1016 01:41:29.689303  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.334322 (* 1 = 0.334322 loss)
I1016 01:41:29.689309  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0390153 (* 1 = 0.0390153 loss)
I1016 01:41:29.689314  4233 sgd_solver.cpp:138] Iteration 58800, lr = 0.000125
I1016 01:42:29.402498  4233 solver.cpp:243] Iteration 58900, loss = 0.337204
I1016 01:42:29.402545  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.221879 (* 1 = 0.221879 loss)
I1016 01:42:29.402551  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0414522 (* 1 = 0.0414522 loss)
I1016 01:42:29.402557  4233 sgd_solver.cpp:138] Iteration 58900, lr = 0.000125
I1016 01:43:28.851111  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_59000.caffemodel
I1016 01:43:29.075649  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_59000.solverstate
I1016 01:43:29.636886  4233 solver.cpp:243] Iteration 59000, loss = 0.27003
I1016 01:43:29.636930  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.33421 (* 1 = 0.33421 loss)
I1016 01:43:29.636936  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0361023 (* 1 = 0.0361023 loss)
I1016 01:43:29.636941  4233 sgd_solver.cpp:138] Iteration 59000, lr = 0.000125
I1016 01:44:28.438061  4233 solver.cpp:243] Iteration 59100, loss = 0.340318
I1016 01:44:28.438092  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.138552 (* 1 = 0.138552 loss)
I1016 01:44:28.438099  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0368994 (* 1 = 0.0368994 loss)
I1016 01:44:28.438105  4233 sgd_solver.cpp:138] Iteration 59100, lr = 0.000125
I1016 01:45:27.132416  4233 solver.cpp:243] Iteration 59200, loss = 0.451208
I1016 01:45:27.132450  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.729978 (* 1 = 0.729978 loss)
I1016 01:45:27.132457  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0375108 (* 1 = 0.0375108 loss)
I1016 01:45:27.132462  4233 sgd_solver.cpp:138] Iteration 59200, lr = 0.000125
I1016 01:46:26.644668  4233 solver.cpp:243] Iteration 59300, loss = 0.687847
I1016 01:46:26.644717  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.267931 (* 1 = 0.267931 loss)
I1016 01:46:26.644724  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.055137 (* 1 = 0.055137 loss)
I1016 01:46:26.644729  4233 sgd_solver.cpp:138] Iteration 59300, lr = 0.000125
I1016 01:47:25.983206  4233 solver.cpp:243] Iteration 59400, loss = 0.623371
I1016 01:47:25.983237  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.316643 (* 1 = 0.316643 loss)
I1016 01:47:25.983243  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0326706 (* 1 = 0.0326706 loss)
I1016 01:47:25.983249  4233 sgd_solver.cpp:138] Iteration 59400, lr = 0.000125
I1016 01:48:05.169652  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:48:25.488337  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_59500.caffemodel
I1016 01:48:25.715087  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_59500.solverstate
I1016 01:48:26.306380  4233 solver.cpp:243] Iteration 59500, loss = 0.371926
I1016 01:48:26.306416  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.580634 (* 1 = 0.580634 loss)
I1016 01:48:26.306424  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0551682 (* 1 = 0.0551682 loss)
I1016 01:48:26.306432  4233 sgd_solver.cpp:138] Iteration 59500, lr = 0.000125
I1016 01:49:25.836501  4233 solver.cpp:243] Iteration 59600, loss = 0.581754
I1016 01:49:25.836539  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.996746 (* 1 = 0.996746 loss)
I1016 01:49:25.836562  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0408166 (* 1 = 0.0408166 loss)
I1016 01:49:25.836570  4233 sgd_solver.cpp:138] Iteration 59600, lr = 0.000125
I1016 01:50:24.939569  4233 solver.cpp:243] Iteration 59700, loss = 0.545485
I1016 01:50:24.939617  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.434759 (* 1 = 0.434759 loss)
I1016 01:50:24.939623  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0298363 (* 1 = 0.0298363 loss)
I1016 01:50:24.939630  4233 sgd_solver.cpp:138] Iteration 59700, lr = 0.000125
I1016 01:51:23.374101  4233 solver.cpp:243] Iteration 59800, loss = 0.487021
I1016 01:51:23.374136  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.288697 (* 1 = 0.288697 loss)
I1016 01:51:23.374145  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0419867 (* 1 = 0.0419867 loss)
I1016 01:51:23.374152  4233 sgd_solver.cpp:138] Iteration 59800, lr = 0.000125
I1016 01:52:22.990929  4233 solver.cpp:243] Iteration 59900, loss = 0.351955
I1016 01:52:22.990965  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.394517 (* 1 = 0.394517 loss)
I1016 01:52:22.990993  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0321006 (* 1 = 0.0321006 loss)
I1016 01:52:22.991001  4233 sgd_solver.cpp:138] Iteration 59900, lr = 0.000125
I1016 01:53:22.308717  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_60000.caffemodel
I1016 01:53:22.530488  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_60000.solverstate
I1016 01:53:22.729847  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 01:54:54.883385  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 01:55:00.977579  4233 solver.cpp:243] Iteration 60000, loss = 0.392314
I1016 01:55:00.977613  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.353169 (* 1 = 0.353169 loss)
I1016 01:55:00.977619  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0391458 (* 1 = 0.0391458 loss)
I1016 01:55:00.977627  4233 sgd_solver.cpp:138] Iteration 60000, lr = 0.000125
I1016 01:55:59.711797  4233 solver.cpp:243] Iteration 60100, loss = 0.243747
I1016 01:55:59.711845  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.606744 (* 1 = 0.606744 loss)
I1016 01:55:59.711851  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0439712 (* 1 = 0.0439712 loss)
I1016 01:55:59.711856  4233 sgd_solver.cpp:138] Iteration 60100, lr = 0.000125
I1016 01:56:58.806481  4233 solver.cpp:243] Iteration 60200, loss = 0.476919
I1016 01:56:58.806529  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.610225 (* 1 = 0.610225 loss)
I1016 01:56:58.806535  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0399436 (* 1 = 0.0399436 loss)
I1016 01:56:58.806541  4233 sgd_solver.cpp:138] Iteration 60200, lr = 0.000125
I1016 01:57:57.238034  4233 solver.cpp:243] Iteration 60300, loss = 0.37379
I1016 01:57:57.238066  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.171404 (* 1 = 0.171404 loss)
I1016 01:57:57.238073  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0407934 (* 1 = 0.0407934 loss)
I1016 01:57:57.238080  4233 sgd_solver.cpp:138] Iteration 60300, lr = 0.000125
I1016 01:58:57.069051  4233 solver.cpp:243] Iteration 60400, loss = 0.632636
I1016 01:58:57.069098  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.38783 (* 1 = 0.38783 loss)
I1016 01:58:57.069105  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0405964 (* 1 = 0.0405964 loss)
I1016 01:58:57.069111  4233 sgd_solver.cpp:138] Iteration 60400, lr = 0.000125
I1016 01:59:55.922960  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_60500.caffemodel
I1016 01:59:56.743659  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_60500.solverstate
I1016 01:59:57.322696  4233 solver.cpp:243] Iteration 60500, loss = 0.44137
I1016 01:59:57.322746  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.38242 (* 1 = 0.38242 loss)
I1016 01:59:57.322752  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0307184 (* 1 = 0.0307184 loss)
I1016 01:59:57.322757  4233 sgd_solver.cpp:138] Iteration 60500, lr = 0.000125
I1016 02:00:56.676511  4233 solver.cpp:243] Iteration 60600, loss = 0.335946
I1016 02:00:56.676543  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.127516 (* 1 = 0.127516 loss)
I1016 02:00:56.676568  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0355097 (* 1 = 0.0355097 loss)
I1016 02:00:56.676574  4233 sgd_solver.cpp:138] Iteration 60600, lr = 0.000125
I1016 02:01:55.963470  4233 solver.cpp:243] Iteration 60700, loss = 0.327968
I1016 02:01:55.963505  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.336287 (* 1 = 0.336287 loss)
I1016 02:01:55.963515  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0580632 (* 1 = 0.0580632 loss)
I1016 02:01:55.963538  4233 sgd_solver.cpp:138] Iteration 60700, lr = 0.000125
I1016 02:02:55.158390  4233 solver.cpp:243] Iteration 60800, loss = 0.649016
I1016 02:02:55.158438  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.178762 (* 1 = 0.178762 loss)
I1016 02:02:55.158444  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367052 (* 1 = 0.0367052 loss)
I1016 02:02:55.158449  4233 sgd_solver.cpp:138] Iteration 60800, lr = 0.000125
I1016 02:03:53.865378  4233 solver.cpp:243] Iteration 60900, loss = 0.590741
I1016 02:03:53.865424  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.352005 (* 1 = 0.352005 loss)
I1016 02:03:53.865432  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0328534 (* 1 = 0.0328534 loss)
I1016 02:03:53.865437  4233 sgd_solver.cpp:138] Iteration 60900, lr = 0.000125
I1016 02:04:42.680624  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:04:52.729032  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_61000.caffemodel
I1016 02:04:53.514361  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_61000.solverstate
I1016 02:04:54.092394  4233 solver.cpp:243] Iteration 61000, loss = 0.148924
I1016 02:04:54.092445  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.13078 (* 1 = 0.13078 loss)
I1016 02:04:54.092453  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0722224 (* 1 = 0.0722224 loss)
I1016 02:04:54.092458  4233 sgd_solver.cpp:138] Iteration 61000, lr = 0.000125
I1016 02:05:53.350785  4233 solver.cpp:243] Iteration 61100, loss = 0.378965
I1016 02:05:53.350828  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.271054 (* 1 = 0.271054 loss)
I1016 02:05:53.350836  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0426432 (* 1 = 0.0426432 loss)
I1016 02:05:53.350841  4233 sgd_solver.cpp:138] Iteration 61100, lr = 0.000125
I1016 02:06:53.228629  4233 solver.cpp:243] Iteration 61200, loss = 0.273121
I1016 02:06:53.228677  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.181606 (* 1 = 0.181606 loss)
I1016 02:06:53.228683  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.040701 (* 1 = 0.040701 loss)
I1016 02:06:53.228688  4233 sgd_solver.cpp:138] Iteration 61200, lr = 0.000125
I1016 02:07:52.327754  4233 solver.cpp:243] Iteration 61300, loss = 0.413558
I1016 02:07:52.327802  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.166785 (* 1 = 0.166785 loss)
I1016 02:07:52.327810  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0379129 (* 1 = 0.0379129 loss)
I1016 02:07:52.327814  4233 sgd_solver.cpp:138] Iteration 61300, lr = 0.000125
I1016 02:08:50.523332  4233 solver.cpp:243] Iteration 61400, loss = 0.513508
I1016 02:08:50.523367  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.234949 (* 1 = 0.234949 loss)
I1016 02:08:50.523376  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0563424 (* 1 = 0.0563424 loss)
I1016 02:08:50.523398  4233 sgd_solver.cpp:138] Iteration 61400, lr = 0.000125
I1016 02:09:49.878212  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_61500.caffemodel
I1016 02:09:50.102582  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_61500.solverstate
I1016 02:09:50.667856  4233 solver.cpp:243] Iteration 61500, loss = 0.421944
I1016 02:09:50.667901  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.344055 (* 1 = 0.344055 loss)
I1016 02:09:50.667907  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0422422 (* 1 = 0.0422422 loss)
I1016 02:09:50.667912  4233 sgd_solver.cpp:138] Iteration 61500, lr = 0.000125
I1016 02:10:49.998100  4233 solver.cpp:243] Iteration 61600, loss = 0.286983
I1016 02:10:49.998134  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.160801 (* 1 = 0.160801 loss)
I1016 02:10:49.998140  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0356449 (* 1 = 0.0356449 loss)
I1016 02:10:49.998147  4233 sgd_solver.cpp:138] Iteration 61600, lr = 0.000125
I1016 02:11:50.290890  4233 solver.cpp:243] Iteration 61700, loss = 0.315838
I1016 02:11:50.290938  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.166616 (* 1 = 0.166616 loss)
I1016 02:11:50.290944  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413453 (* 1 = 0.0413453 loss)
I1016 02:11:50.290949  4233 sgd_solver.cpp:138] Iteration 61700, lr = 0.000125
I1016 02:12:49.332124  4233 solver.cpp:243] Iteration 61800, loss = 0.492042
I1016 02:12:49.332171  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.233416 (* 1 = 0.233416 loss)
I1016 02:12:49.332177  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0395649 (* 1 = 0.0395649 loss)
I1016 02:12:49.332182  4233 sgd_solver.cpp:138] Iteration 61800, lr = 0.000125
I1016 02:13:48.146297  4233 solver.cpp:243] Iteration 61900, loss = 0.364683
I1016 02:13:48.146342  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.857677 (* 1 = 0.857677 loss)
I1016 02:13:48.146348  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0576133 (* 1 = 0.0576133 loss)
I1016 02:13:48.146353  4233 sgd_solver.cpp:138] Iteration 61900, lr = 0.000125
I1016 02:14:40.911965  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:14:46.914249  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_62000.caffemodel
I1016 02:14:47.146880  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_62000.solverstate
I1016 02:14:47.731701  4233 solver.cpp:243] Iteration 62000, loss = 0.940531
I1016 02:14:47.731739  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.969681 (* 1 = 0.969681 loss)
I1016 02:14:47.731747  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0465206 (* 1 = 0.0465206 loss)
I1016 02:14:47.731770  4233 sgd_solver.cpp:138] Iteration 62000, lr = 0.000125
I1016 02:15:46.886868  4233 solver.cpp:243] Iteration 62100, loss = 0.395603
I1016 02:15:46.886900  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.569113 (* 1 = 0.569113 loss)
I1016 02:15:46.886909  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0328545 (* 1 = 0.0328545 loss)
I1016 02:15:46.886931  4233 sgd_solver.cpp:138] Iteration 62100, lr = 0.000125
I1016 02:16:46.944085  4233 solver.cpp:243] Iteration 62200, loss = 0.214227
I1016 02:16:46.944119  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.246289 (* 1 = 0.246289 loss)
I1016 02:16:46.944128  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0363696 (* 1 = 0.0363696 loss)
I1016 02:16:46.944151  4233 sgd_solver.cpp:138] Iteration 62200, lr = 0.000125
I1016 02:17:46.781543  4233 solver.cpp:243] Iteration 62300, loss = 0.549332
I1016 02:17:46.781577  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.477276 (* 1 = 0.477276 loss)
I1016 02:17:46.781586  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0395702 (* 1 = 0.0395702 loss)
I1016 02:17:46.781610  4233 sgd_solver.cpp:138] Iteration 62300, lr = 0.000125
I1016 02:18:45.770807  4233 solver.cpp:243] Iteration 62400, loss = 0.450873
I1016 02:18:45.770841  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.558342 (* 1 = 0.558342 loss)
I1016 02:18:45.770850  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0366317 (* 1 = 0.0366317 loss)
I1016 02:18:45.770859  4233 sgd_solver.cpp:138] Iteration 62400, lr = 0.000125
I1016 02:19:43.678124  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_62500.caffemodel
I1016 02:19:43.933650  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_62500.solverstate
I1016 02:19:44.506845  4233 solver.cpp:243] Iteration 62500, loss = 0.763032
I1016 02:19:44.506876  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.69781 (* 1 = 0.69781 loss)
I1016 02:19:44.506884  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0447373 (* 1 = 0.0447373 loss)
I1016 02:19:44.506908  4233 sgd_solver.cpp:138] Iteration 62500, lr = 0.000125
I1016 02:20:43.833271  4233 solver.cpp:243] Iteration 62600, loss = 0.283899
I1016 02:20:43.833304  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.398753 (* 1 = 0.398753 loss)
I1016 02:20:43.833313  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0440039 (* 1 = 0.0440039 loss)
I1016 02:20:43.833335  4233 sgd_solver.cpp:138] Iteration 62600, lr = 0.000125
I1016 02:21:43.639909  4233 solver.cpp:243] Iteration 62700, loss = 0.37923
I1016 02:21:43.639957  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.489523 (* 1 = 0.489523 loss)
I1016 02:21:43.639963  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0428336 (* 1 = 0.0428336 loss)
I1016 02:21:43.639969  4233 sgd_solver.cpp:138] Iteration 62700, lr = 0.000125
I1016 02:22:43.792567  4233 solver.cpp:243] Iteration 62800, loss = 0.196605
I1016 02:22:43.792599  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0935013 (* 1 = 0.0935013 loss)
I1016 02:22:43.792605  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0352851 (* 1 = 0.0352851 loss)
I1016 02:22:43.792611  4233 sgd_solver.cpp:138] Iteration 62800, lr = 0.000125
I1016 02:23:43.001179  4233 solver.cpp:243] Iteration 62900, loss = 0.298747
I1016 02:23:43.001226  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.101767 (* 1 = 0.101767 loss)
I1016 02:23:43.001232  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.032257 (* 1 = 0.032257 loss)
I1016 02:23:43.001238  4233 sgd_solver.cpp:138] Iteration 62900, lr = 0.000125
I1016 02:24:37.598856  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:24:41.027693  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_63000.caffemodel
I1016 02:24:41.264314  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_63000.solverstate
I1016 02:24:41.860868  4233 solver.cpp:243] Iteration 63000, loss = 0.402097
I1016 02:24:41.860914  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.241948 (* 1 = 0.241948 loss)
I1016 02:24:41.860920  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0302535 (* 1 = 0.0302535 loss)
I1016 02:24:41.860926  4233 sgd_solver.cpp:138] Iteration 63000, lr = 0.000125
I1016 02:25:41.232317  4233 solver.cpp:243] Iteration 63100, loss = 0.650238
I1016 02:25:41.232367  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.4389 (* 1 = 1.4389 loss)
I1016 02:25:41.232372  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0617919 (* 1 = 0.0617919 loss)
I1016 02:25:41.232378  4233 sgd_solver.cpp:138] Iteration 63100, lr = 0.000125
I1016 02:26:40.534523  4233 solver.cpp:243] Iteration 63200, loss = 0.341194
I1016 02:26:40.534569  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.362987 (* 1 = 0.362987 loss)
I1016 02:26:40.534574  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0451972 (* 1 = 0.0451972 loss)
I1016 02:26:40.534580  4233 sgd_solver.cpp:138] Iteration 63200, lr = 0.000125
I1016 02:27:40.653957  4233 solver.cpp:243] Iteration 63300, loss = 0.368985
I1016 02:27:40.653988  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.39999 (* 1 = 0.39999 loss)
I1016 02:27:40.653995  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0365457 (* 1 = 0.0365457 loss)
I1016 02:27:40.654000  4233 sgd_solver.cpp:138] Iteration 63300, lr = 0.000125
I1016 02:28:40.148228  4233 solver.cpp:243] Iteration 63400, loss = 0.504606
I1016 02:28:40.148277  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.208614 (* 1 = 0.208614 loss)
I1016 02:28:40.148283  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0352347 (* 1 = 0.0352347 loss)
I1016 02:28:40.148288  4233 sgd_solver.cpp:138] Iteration 63400, lr = 0.000125
I1016 02:29:38.835454  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_63500.caffemodel
I1016 02:29:39.062336  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_63500.solverstate
I1016 02:29:39.655813  4233 solver.cpp:243] Iteration 63500, loss = 0.517178
I1016 02:29:39.655856  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.861713 (* 1 = 0.861713 loss)
I1016 02:29:39.655864  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0583261 (* 1 = 0.0583261 loss)
I1016 02:29:39.655869  4233 sgd_solver.cpp:138] Iteration 63500, lr = 0.000125
I1016 02:30:38.098289  4233 solver.cpp:243] Iteration 63600, loss = 0.333733
I1016 02:30:38.098335  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.231953 (* 1 = 0.231953 loss)
I1016 02:30:38.098342  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0394739 (* 1 = 0.0394739 loss)
I1016 02:30:38.098347  4233 sgd_solver.cpp:138] Iteration 63600, lr = 0.000125
I1016 02:31:37.643788  4233 solver.cpp:243] Iteration 63700, loss = 0.273607
I1016 02:31:37.643837  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.135685 (* 1 = 0.135685 loss)
I1016 02:31:37.643843  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0403976 (* 1 = 0.0403976 loss)
I1016 02:31:37.643849  4233 sgd_solver.cpp:138] Iteration 63700, lr = 0.000125
I1016 02:32:37.593333  4233 solver.cpp:243] Iteration 63800, loss = 0.322058
I1016 02:32:37.593381  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.753211 (* 1 = 0.753211 loss)
I1016 02:32:37.593387  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0530548 (* 1 = 0.0530548 loss)
I1016 02:32:37.593394  4233 sgd_solver.cpp:138] Iteration 63800, lr = 0.000125
I1016 02:33:37.502337  4233 solver.cpp:243] Iteration 63900, loss = 0.354946
I1016 02:33:37.502368  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.127614 (* 1 = 0.127614 loss)
I1016 02:33:37.502375  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0359375 (* 1 = 0.0359375 loss)
I1016 02:33:37.502380  4233 sgd_solver.cpp:138] Iteration 63900, lr = 0.000125
I1016 02:34:34.983422  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:34:36.154711  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_64000.caffemodel
I1016 02:34:36.379642  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_64000.solverstate
I1016 02:34:36.563303  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 02:36:14.540774  4233 solver.cpp:243] Iteration 64000, loss = 0.224317
I1016 02:36:14.540813  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.187522 (* 1 = 0.187522 loss)
I1016 02:36:14.540822  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367951 (* 1 = 0.0367951 loss)
I1016 02:36:14.540832  4233 sgd_solver.cpp:138] Iteration 64000, lr = 0.000125
I1016 02:37:11.777242  4233 solver.cpp:243] Iteration 64100, loss = 0.317257
I1016 02:37:11.777290  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.396391 (* 1 = 0.396391 loss)
I1016 02:37:11.777297  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0329745 (* 1 = 0.0329745 loss)
I1016 02:37:11.777302  4233 sgd_solver.cpp:138] Iteration 64100, lr = 0.000125
I1016 02:38:11.554165  4233 solver.cpp:243] Iteration 64200, loss = 0.519446
I1016 02:38:11.554195  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.18279 (* 1 = 0.18279 loss)
I1016 02:38:11.554203  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0342585 (* 1 = 0.0342585 loss)
I1016 02:38:11.554208  4233 sgd_solver.cpp:138] Iteration 64200, lr = 0.000125
I1016 02:39:11.065150  4233 solver.cpp:243] Iteration 64300, loss = 0.387624
I1016 02:39:11.065181  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0732328 (* 1 = 0.0732328 loss)
I1016 02:39:11.065186  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0383347 (* 1 = 0.0383347 loss)
I1016 02:39:11.065192  4233 sgd_solver.cpp:138] Iteration 64300, lr = 0.000125
I1016 02:40:11.348384  4233 solver.cpp:243] Iteration 64400, loss = 0.166682
I1016 02:40:11.348417  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.104316 (* 1 = 0.104316 loss)
I1016 02:40:11.348423  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0508683 (* 1 = 0.0508683 loss)
I1016 02:40:11.348428  4233 sgd_solver.cpp:138] Iteration 64400, lr = 0.000125
I1016 02:41:09.979923  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_64500.caffemodel
I1016 02:41:10.705387  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_64500.solverstate
I1016 02:41:11.269695  4233 solver.cpp:243] Iteration 64500, loss = 0.313187
I1016 02:41:11.269737  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.269437 (* 1 = 0.269437 loss)
I1016 02:41:11.269743  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.029868 (* 1 = 0.029868 loss)
I1016 02:41:11.269748  4233 sgd_solver.cpp:138] Iteration 64500, lr = 0.000125
I1016 02:41:18.346302  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:42:09.604156  4233 solver.cpp:243] Iteration 64600, loss = 0.314409
I1016 02:42:09.604198  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0941117 (* 1 = 0.0941117 loss)
I1016 02:42:09.604204  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0313416 (* 1 = 0.0313416 loss)
I1016 02:42:09.604210  4233 sgd_solver.cpp:138] Iteration 64600, lr = 0.000125
I1016 02:43:08.667080  4233 solver.cpp:243] Iteration 64700, loss = 0.751265
I1016 02:43:08.667129  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.64983 (* 1 = 0.64983 loss)
I1016 02:43:08.667135  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0884159 (* 1 = 0.0884159 loss)
I1016 02:43:08.667140  4233 sgd_solver.cpp:138] Iteration 64700, lr = 0.000125
I1016 02:44:08.064251  4233 solver.cpp:243] Iteration 64800, loss = 0.240218
I1016 02:44:08.064281  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.204504 (* 1 = 0.204504 loss)
I1016 02:44:08.064287  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0549364 (* 1 = 0.0549364 loss)
I1016 02:44:08.064293  4233 sgd_solver.cpp:138] Iteration 64800, lr = 0.000125
I1016 02:45:08.058485  4233 solver.cpp:243] Iteration 64900, loss = 0.24539
I1016 02:45:08.058517  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.103605 (* 1 = 0.103605 loss)
I1016 02:45:08.058526  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0363575 (* 1 = 0.0363575 loss)
I1016 02:45:08.058533  4233 sgd_solver.cpp:138] Iteration 64900, lr = 0.000125
I1016 02:46:07.416551  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_65000.caffemodel
I1016 02:46:07.652202  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_65000.solverstate
I1016 02:46:08.734707  4233 solver.cpp:243] Iteration 65000, loss = 0.575011
I1016 02:46:08.734755  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.581123 (* 1 = 0.581123 loss)
I1016 02:46:08.734761  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0523063 (* 1 = 0.0523063 loss)
I1016 02:46:08.734767  4233 sgd_solver.cpp:138] Iteration 65000, lr = 0.000125
I1016 02:47:07.266458  4233 solver.cpp:243] Iteration 65100, loss = 0.284473
I1016 02:47:07.266506  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.418714 (* 1 = 0.418714 loss)
I1016 02:47:07.266512  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0363884 (* 1 = 0.0363884 loss)
I1016 02:47:07.266517  4233 sgd_solver.cpp:138] Iteration 65100, lr = 0.000125
I1016 02:48:05.686514  4233 solver.cpp:243] Iteration 65200, loss = 0.36285
I1016 02:48:05.686563  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.499889 (* 1 = 0.499889 loss)
I1016 02:48:05.686568  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0535315 (* 1 = 0.0535315 loss)
I1016 02:48:05.686573  4233 sgd_solver.cpp:138] Iteration 65200, lr = 0.000125
I1016 02:49:05.350788  4233 solver.cpp:243] Iteration 65300, loss = 0.249646
I1016 02:49:05.350836  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.18992 (* 1 = 0.18992 loss)
I1016 02:49:05.350842  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0308462 (* 1 = 0.0308462 loss)
I1016 02:49:05.350847  4233 sgd_solver.cpp:138] Iteration 65300, lr = 0.000125
I1016 02:50:04.941154  4233 solver.cpp:243] Iteration 65400, loss = 0.279233
I1016 02:50:04.941201  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.306149 (* 1 = 0.306149 loss)
I1016 02:50:04.941207  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0404689 (* 1 = 0.0404689 loss)
I1016 02:50:04.941213  4233 sgd_solver.cpp:138] Iteration 65400, lr = 0.000125
I1016 02:51:04.627210  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_65500.caffemodel
I1016 02:51:04.850033  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_65500.solverstate
I1016 02:51:05.417584  4233 solver.cpp:243] Iteration 65500, loss = 0.215951
I1016 02:51:05.417629  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.21747 (* 1 = 0.21747 loss)
I1016 02:51:05.417636  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0444089 (* 1 = 0.0444089 loss)
I1016 02:51:05.417642  4233 sgd_solver.cpp:138] Iteration 65500, lr = 0.000125
I1016 02:51:17.118614  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 02:52:04.249816  4233 solver.cpp:243] Iteration 65600, loss = 0.290176
I1016 02:52:04.249867  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0957196 (* 1 = 0.0957196 loss)
I1016 02:52:04.249874  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.043415 (* 1 = 0.043415 loss)
I1016 02:52:04.249879  4233 sgd_solver.cpp:138] Iteration 65600, lr = 0.000125
I1016 02:53:02.910295  4233 solver.cpp:243] Iteration 65700, loss = 0.332395
I1016 02:53:02.910343  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.347951 (* 1 = 0.347951 loss)
I1016 02:53:02.910349  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0351187 (* 1 = 0.0351187 loss)
I1016 02:53:02.910356  4233 sgd_solver.cpp:138] Iteration 65700, lr = 0.000125
I1016 02:54:02.276731  4233 solver.cpp:243] Iteration 65800, loss = 0.571286
I1016 02:54:02.276779  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.455891 (* 1 = 0.455891 loss)
I1016 02:54:02.276787  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0323681 (* 1 = 0.0323681 loss)
I1016 02:54:02.276793  4233 sgd_solver.cpp:138] Iteration 65800, lr = 0.000125
I1016 02:55:01.456487  4233 solver.cpp:243] Iteration 65900, loss = 0.585479
I1016 02:55:01.456533  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.168935 (* 1 = 0.168935 loss)
I1016 02:55:01.456540  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0372672 (* 1 = 0.0372672 loss)
I1016 02:55:01.456547  4233 sgd_solver.cpp:138] Iteration 65900, lr = 0.000125
I1016 02:56:01.018254  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_66000.caffemodel
I1016 02:56:01.830021  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_66000.solverstate
I1016 02:56:02.416926  4233 solver.cpp:243] Iteration 66000, loss = 0.29429
I1016 02:56:02.416961  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.456256 (* 1 = 0.456256 loss)
I1016 02:56:02.416970  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0857707 (* 1 = 0.0857707 loss)
I1016 02:56:02.416993  4233 sgd_solver.cpp:138] Iteration 66000, lr = 0.000125
I1016 02:57:01.498162  4233 solver.cpp:243] Iteration 66100, loss = 0.455897
I1016 02:57:01.498196  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.700583 (* 1 = 0.700583 loss)
I1016 02:57:01.498205  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0387049 (* 1 = 0.0387049 loss)
I1016 02:57:01.498227  4233 sgd_solver.cpp:138] Iteration 66100, lr = 0.000125
I1016 02:58:00.638470  4233 solver.cpp:243] Iteration 66200, loss = 0.448222
I1016 02:58:00.638501  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.297473 (* 1 = 0.297473 loss)
I1016 02:58:00.638509  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0373233 (* 1 = 0.0373233 loss)
I1016 02:58:00.638532  4233 sgd_solver.cpp:138] Iteration 66200, lr = 0.000125
I1016 02:58:59.313097  4233 solver.cpp:243] Iteration 66300, loss = 0.402372
I1016 02:58:59.313132  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.300646 (* 1 = 0.300646 loss)
I1016 02:58:59.313140  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413608 (* 1 = 0.0413608 loss)
I1016 02:58:59.313148  4233 sgd_solver.cpp:138] Iteration 66300, lr = 0.000125
I1016 02:59:58.886711  4233 solver.cpp:243] Iteration 66400, loss = 0.28342
I1016 02:59:58.886759  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.239625 (* 1 = 0.239625 loss)
I1016 02:59:58.886765  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0305636 (* 1 = 0.0305636 loss)
I1016 02:59:58.886771  4233 sgd_solver.cpp:138] Iteration 66400, lr = 0.000125
I1016 03:00:58.214541  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_66500.caffemodel
I1016 03:00:58.442853  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_66500.solverstate
I1016 03:00:59.025938  4233 solver.cpp:243] Iteration 66500, loss = 0.287182
I1016 03:00:59.025974  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.259408 (* 1 = 0.259408 loss)
I1016 03:00:59.025980  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0519879 (* 1 = 0.0519879 loss)
I1016 03:00:59.025986  4233 sgd_solver.cpp:138] Iteration 66500, lr = 0.000125
I1016 03:01:15.103459  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:01:58.948006  4233 solver.cpp:243] Iteration 66600, loss = 0.170294
I1016 03:01:58.948053  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0961241 (* 1 = 0.0961241 loss)
I1016 03:01:58.948060  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0340483 (* 1 = 0.0340483 loss)
I1016 03:01:58.948065  4233 sgd_solver.cpp:138] Iteration 66600, lr = 0.000125
I1016 03:02:58.139931  4233 solver.cpp:243] Iteration 66700, loss = 0.359111
I1016 03:02:58.139978  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.309256 (* 1 = 0.309256 loss)
I1016 03:02:58.139984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0363099 (* 1 = 0.0363099 loss)
I1016 03:02:58.139989  4233 sgd_solver.cpp:138] Iteration 66700, lr = 0.000125
I1016 03:03:56.390874  4233 solver.cpp:243] Iteration 66800, loss = 0.33006
I1016 03:03:56.390925  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.345412 (* 1 = 0.345412 loss)
I1016 03:03:56.390934  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0289689 (* 1 = 0.0289689 loss)
I1016 03:03:56.390956  4233 sgd_solver.cpp:138] Iteration 66800, lr = 0.000125
I1016 03:04:56.050688  4233 solver.cpp:243] Iteration 66900, loss = 0.607906
I1016 03:04:56.050722  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.403702 (* 1 = 0.403702 loss)
I1016 03:04:56.050747  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0276096 (* 1 = 0.0276096 loss)
I1016 03:04:56.050755  4233 sgd_solver.cpp:138] Iteration 66900, lr = 0.000125
I1016 03:05:54.822372  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_67000.caffemodel
I1016 03:05:55.038120  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_67000.solverstate
I1016 03:05:55.615667  4233 solver.cpp:243] Iteration 67000, loss = 0.340075
I1016 03:05:55.615715  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.469126 (* 1 = 0.469126 loss)
I1016 03:05:55.615720  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0368043 (* 1 = 0.0368043 loss)
I1016 03:05:55.615725  4233 sgd_solver.cpp:138] Iteration 67000, lr = 0.000125
I1016 03:06:55.684948  4233 solver.cpp:243] Iteration 67100, loss = 0.283483
I1016 03:06:55.684996  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.213547 (* 1 = 0.213547 loss)
I1016 03:06:55.685003  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0410976 (* 1 = 0.0410976 loss)
I1016 03:06:55.685009  4233 sgd_solver.cpp:138] Iteration 67100, lr = 0.000125
I1016 03:07:54.891748  4233 solver.cpp:243] Iteration 67200, loss = 0.289439
I1016 03:07:54.891795  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.210053 (* 1 = 0.210053 loss)
I1016 03:07:54.891803  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0446291 (* 1 = 0.0446291 loss)
I1016 03:07:54.891808  4233 sgd_solver.cpp:138] Iteration 67200, lr = 0.000125
I1016 03:08:54.161679  4233 solver.cpp:243] Iteration 67300, loss = 0.58305
I1016 03:08:54.161725  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.224357 (* 1 = 0.224357 loss)
I1016 03:08:54.161731  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0342508 (* 1 = 0.0342508 loss)
I1016 03:08:54.161736  4233 sgd_solver.cpp:138] Iteration 67300, lr = 0.000125
I1016 03:09:52.914295  4233 solver.cpp:243] Iteration 67400, loss = 0.519383
I1016 03:09:52.914342  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.673005 (* 1 = 0.673005 loss)
I1016 03:09:52.914348  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0610253 (* 1 = 0.0610253 loss)
I1016 03:09:52.914355  4233 sgd_solver.cpp:138] Iteration 67400, lr = 0.000125
I1016 03:10:51.766479  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_67500.caffemodel
I1016 03:10:51.983572  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_67500.solverstate
I1016 03:10:52.561839  4233 solver.cpp:243] Iteration 67500, loss = 0.139342
I1016 03:10:52.561875  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0443335 (* 1 = 0.0443335 loss)
I1016 03:10:52.561884  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0142008 (* 1 = 0.0142008 loss)
I1016 03:10:52.561892  4233 sgd_solver.cpp:138] Iteration 67500, lr = 0.000125
I1016 03:11:10.920038  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:11:52.322505  4233 solver.cpp:243] Iteration 67600, loss = 0.316347
I1016 03:11:52.322537  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.217685 (* 1 = 0.217685 loss)
I1016 03:11:52.322546  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0345208 (* 1 = 0.0345208 loss)
I1016 03:11:52.322554  4233 sgd_solver.cpp:138] Iteration 67600, lr = 0.000125
I1016 03:12:52.147469  4233 solver.cpp:243] Iteration 67700, loss = 0.238894
I1016 03:12:52.147505  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.379623 (* 1 = 0.379623 loss)
I1016 03:12:52.147514  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0519604 (* 1 = 0.0519604 loss)
I1016 03:12:52.147521  4233 sgd_solver.cpp:138] Iteration 67700, lr = 0.000125
I1016 03:13:51.327687  4233 solver.cpp:243] Iteration 67800, loss = 0.351895
I1016 03:13:51.327723  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.213455 (* 1 = 0.213455 loss)
I1016 03:13:51.327731  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0376216 (* 1 = 0.0376216 loss)
I1016 03:13:51.327754  4233 sgd_solver.cpp:138] Iteration 67800, lr = 0.000125
I1016 03:14:49.585618  4233 solver.cpp:243] Iteration 67900, loss = 0.433338
I1016 03:14:49.585654  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.05951 (* 1 = 1.05951 loss)
I1016 03:14:49.585662  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0468555 (* 1 = 0.0468555 loss)
I1016 03:14:49.585669  4233 sgd_solver.cpp:138] Iteration 67900, lr = 0.000125
I1016 03:15:48.989658  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_68000.caffemodel
I1016 03:15:49.212502  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_68000.solverstate
I1016 03:15:49.399633  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 03:17:27.270606  4233 solver.cpp:243] Iteration 68000, loss = 0.36178
I1016 03:17:27.270643  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.342668 (* 1 = 0.342668 loss)
I1016 03:17:27.270653  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0191127 (* 1 = 0.0191127 loss)
I1016 03:17:27.270660  4233 sgd_solver.cpp:138] Iteration 68000, lr = 0.000125
I1016 03:17:51.076534  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:18:25.668459  4233 solver.cpp:243] Iteration 68100, loss = 0.252641
I1016 03:18:25.668494  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.119559 (* 1 = 0.119559 loss)
I1016 03:18:25.668503  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0350345 (* 1 = 0.0350345 loss)
I1016 03:18:25.668510  4233 sgd_solver.cpp:138] Iteration 68100, lr = 0.000125
I1016 03:19:25.995360  4233 solver.cpp:243] Iteration 68200, loss = 0.257264
I1016 03:19:25.995393  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.106425 (* 1 = 0.106425 loss)
I1016 03:19:25.995402  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0349379 (* 1 = 0.0349379 loss)
I1016 03:19:25.995410  4233 sgd_solver.cpp:138] Iteration 68200, lr = 0.000125
I1016 03:20:25.156014  4233 solver.cpp:243] Iteration 68300, loss = 0.446209
I1016 03:20:25.156051  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.248039 (* 1 = 0.248039 loss)
I1016 03:20:25.156059  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0454307 (* 1 = 0.0454307 loss)
I1016 03:20:25.156066  4233 sgd_solver.cpp:138] Iteration 68300, lr = 0.000125
I1016 03:21:24.028843  4233 solver.cpp:243] Iteration 68400, loss = 0.253571
I1016 03:21:24.028890  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.158564 (* 1 = 0.158564 loss)
I1016 03:21:24.028897  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0290597 (* 1 = 0.0290597 loss)
I1016 03:21:24.028903  4233 sgd_solver.cpp:138] Iteration 68400, lr = 0.000125
I1016 03:22:22.756855  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_68500.caffemodel
I1016 03:22:23.025454  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_68500.solverstate
I1016 03:22:23.644466  4233 solver.cpp:243] Iteration 68500, loss = 0.814494
I1016 03:22:23.644516  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.218194 (* 1 = 0.218194 loss)
I1016 03:22:23.644522  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0382457 (* 1 = 0.0382457 loss)
I1016 03:22:23.644528  4233 sgd_solver.cpp:138] Iteration 68500, lr = 0.000125
I1016 03:23:22.890081  4233 solver.cpp:243] Iteration 68600, loss = 0.299838
I1016 03:23:22.890120  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.895396 (* 1 = 0.895396 loss)
I1016 03:23:22.890125  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0562017 (* 1 = 0.0562017 loss)
I1016 03:23:22.890132  4233 sgd_solver.cpp:138] Iteration 68600, lr = 0.000125
I1016 03:24:22.870959  4233 solver.cpp:243] Iteration 68700, loss = 0.170702
I1016 03:24:22.871004  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.364789 (* 1 = 0.364789 loss)
I1016 03:24:22.871011  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0418661 (* 1 = 0.0418661 loss)
I1016 03:24:22.871016  4233 sgd_solver.cpp:138] Iteration 68700, lr = 0.000125
I1016 03:25:22.755388  4233 solver.cpp:243] Iteration 68800, loss = 0.473153
I1016 03:25:22.755434  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.316248 (* 1 = 0.316248 loss)
I1016 03:25:22.755440  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0439324 (* 1 = 0.0439324 loss)
I1016 03:25:22.755446  4233 sgd_solver.cpp:138] Iteration 68800, lr = 0.000125
I1016 03:26:21.785755  4233 solver.cpp:243] Iteration 68900, loss = 0.384154
I1016 03:26:21.785786  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.138893 (* 1 = 0.138893 loss)
I1016 03:26:21.785794  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0372494 (* 1 = 0.0372494 loss)
I1016 03:26:21.785799  4233 sgd_solver.cpp:138] Iteration 68900, lr = 0.000125
I1016 03:27:19.769419  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_69000.caffemodel
I1016 03:27:20.566293  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_69000.solverstate
I1016 03:27:21.146093  4233 solver.cpp:243] Iteration 69000, loss = 0.628807
I1016 03:27:21.146124  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.131163 (* 1 = 0.131163 loss)
I1016 03:27:21.146131  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0408161 (* 1 = 0.0408161 loss)
I1016 03:27:21.146136  4233 sgd_solver.cpp:138] Iteration 69000, lr = 0.000125
I1016 03:27:50.534493  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:28:20.041492  4233 solver.cpp:243] Iteration 69100, loss = 0.243613
I1016 03:28:20.041539  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.117347 (* 1 = 0.117347 loss)
I1016 03:28:20.041545  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0459238 (* 1 = 0.0459238 loss)
I1016 03:28:20.041551  4233 sgd_solver.cpp:138] Iteration 69100, lr = 0.000125
I1016 03:29:19.815024  4233 solver.cpp:243] Iteration 69200, loss = 0.284679
I1016 03:29:19.815070  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.208455 (* 1 = 0.208455 loss)
I1016 03:29:19.815076  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.065158 (* 1 = 0.065158 loss)
I1016 03:29:19.815081  4233 sgd_solver.cpp:138] Iteration 69200, lr = 0.000125
I1016 03:30:19.859460  4233 solver.cpp:243] Iteration 69300, loss = 0.175313
I1016 03:30:19.859493  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.124558 (* 1 = 0.124558 loss)
I1016 03:30:19.859499  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0407927 (* 1 = 0.0407927 loss)
I1016 03:30:19.859504  4233 sgd_solver.cpp:138] Iteration 69300, lr = 0.000125
I1016 03:31:18.998903  4233 solver.cpp:243] Iteration 69400, loss = 0.257317
I1016 03:31:18.998939  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0909922 (* 1 = 0.0909922 loss)
I1016 03:31:18.998946  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314861 (* 1 = 0.0314861 loss)
I1016 03:31:18.998970  4233 sgd_solver.cpp:138] Iteration 69400, lr = 0.000125
I1016 03:32:16.921627  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_69500.caffemodel
I1016 03:32:17.157085  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_69500.solverstate
I1016 03:32:17.730320  4233 solver.cpp:243] Iteration 69500, loss = 0.356266
I1016 03:32:17.730351  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.183797 (* 1 = 0.183797 loss)
I1016 03:32:17.730357  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0368701 (* 1 = 0.0368701 loss)
I1016 03:32:17.730363  4233 sgd_solver.cpp:138] Iteration 69500, lr = 0.000125
I1016 03:33:17.058920  4233 solver.cpp:243] Iteration 69600, loss = 0.470172
I1016 03:33:17.058965  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.948752 (* 1 = 0.948752 loss)
I1016 03:33:17.058971  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0525924 (* 1 = 0.0525924 loss)
I1016 03:33:17.058976  4233 sgd_solver.cpp:138] Iteration 69600, lr = 0.000125
I1016 03:34:16.251214  4233 solver.cpp:243] Iteration 69700, loss = 0.269117
I1016 03:34:16.251263  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0553285 (* 1 = 0.0553285 loss)
I1016 03:34:16.251268  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0337565 (* 1 = 0.0337565 loss)
I1016 03:34:16.251276  4233 sgd_solver.cpp:138] Iteration 69700, lr = 0.000125
I1016 03:35:16.436005  4233 solver.cpp:243] Iteration 69800, loss = 0.299879
I1016 03:35:16.436051  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.110615 (* 1 = 0.110615 loss)
I1016 03:35:16.436058  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0300841 (* 1 = 0.0300841 loss)
I1016 03:35:16.436062  4233 sgd_solver.cpp:138] Iteration 69800, lr = 0.000125
I1016 03:36:15.901144  4233 solver.cpp:243] Iteration 69900, loss = 0.461428
I1016 03:36:15.901191  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.466782 (* 1 = 0.466782 loss)
I1016 03:36:15.901197  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0360462 (* 1 = 0.0360462 loss)
I1016 03:36:15.901202  4233 sgd_solver.cpp:138] Iteration 69900, lr = 0.000125
I1016 03:37:14.608433  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_70000.caffemodel
I1016 03:37:14.836596  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_70000.solverstate
I1016 03:37:15.423029  4233 solver.cpp:243] Iteration 70000, loss = 0.415951
I1016 03:37:15.423074  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.661087 (* 1 = 0.661087 loss)
I1016 03:37:15.423080  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0453507 (* 1 = 0.0453507 loss)
I1016 03:37:15.423087  4233 sgd_solver.cpp:138] Iteration 70000, lr = 0.000125
I1016 03:37:46.360985  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:38:13.815553  4233 solver.cpp:243] Iteration 70100, loss = 0.308695
I1016 03:38:13.815585  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.502181 (* 1 = 0.502181 loss)
I1016 03:38:13.815591  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0372434 (* 1 = 0.0372434 loss)
I1016 03:38:13.815598  4233 sgd_solver.cpp:138] Iteration 70100, lr = 0.000125
I1016 03:39:13.352855  4233 solver.cpp:243] Iteration 70200, loss = 0.23484
I1016 03:39:13.352900  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.236669 (* 1 = 0.236669 loss)
I1016 03:39:13.352907  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0357239 (* 1 = 0.0357239 loss)
I1016 03:39:13.352913  4233 sgd_solver.cpp:138] Iteration 70200, lr = 0.000125
I1016 03:40:13.230206  4233 solver.cpp:243] Iteration 70300, loss = 0.2278
I1016 03:40:13.230250  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.126434 (* 1 = 0.126434 loss)
I1016 03:40:13.230257  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0600199 (* 1 = 0.0600199 loss)
I1016 03:40:13.230263  4233 sgd_solver.cpp:138] Iteration 70300, lr = 0.000125
I1016 03:41:13.133985  4233 solver.cpp:243] Iteration 70400, loss = 0.323934
I1016 03:41:13.134017  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.191473 (* 1 = 0.191473 loss)
I1016 03:41:13.134024  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0357914 (* 1 = 0.0357914 loss)
I1016 03:41:13.134029  4233 sgd_solver.cpp:138] Iteration 70400, lr = 0.000125
I1016 03:42:11.779780  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_70500.caffemodel
I1016 03:42:12.011126  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_70500.solverstate
I1016 03:42:12.588310  4233 solver.cpp:243] Iteration 70500, loss = 0.272015
I1016 03:42:12.588359  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0957065 (* 1 = 0.0957065 loss)
I1016 03:42:12.588366  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0430551 (* 1 = 0.0430551 loss)
I1016 03:42:12.588372  4233 sgd_solver.cpp:138] Iteration 70500, lr = 0.000125
I1016 03:43:10.625291  4233 solver.cpp:243] Iteration 70600, loss = 0.251413
I1016 03:43:10.625339  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0908109 (* 1 = 0.0908109 loss)
I1016 03:43:10.625344  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0278099 (* 1 = 0.0278099 loss)
I1016 03:43:10.625349  4233 sgd_solver.cpp:138] Iteration 70600, lr = 0.000125
I1016 03:44:10.522677  4233 solver.cpp:243] Iteration 70700, loss = 0.498734
I1016 03:44:10.522723  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.314477 (* 1 = 0.314477 loss)
I1016 03:44:10.522729  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412794 (* 1 = 0.0412794 loss)
I1016 03:44:10.522734  4233 sgd_solver.cpp:138] Iteration 70700, lr = 0.000125
I1016 03:45:09.918278  4233 solver.cpp:243] Iteration 70800, loss = 0.349296
I1016 03:45:09.918325  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.140959 (* 1 = 0.140959 loss)
I1016 03:45:09.918331  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0324033 (* 1 = 0.0324033 loss)
I1016 03:45:09.918337  4233 sgd_solver.cpp:138] Iteration 70800, lr = 0.000125
I1016 03:46:10.155205  4233 solver.cpp:243] Iteration 70900, loss = 0.1493
I1016 03:46:10.155237  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0448178 (* 1 = 0.0448178 loss)
I1016 03:46:10.155243  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314198 (* 1 = 0.0314198 loss)
I1016 03:46:10.155248  4233 sgd_solver.cpp:138] Iteration 70900, lr = 0.000125
I1016 03:47:08.772367  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_71000.caffemodel
I1016 03:47:08.987495  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_71000.solverstate
I1016 03:47:09.569970  4233 solver.cpp:243] Iteration 71000, loss = 0.293794
I1016 03:47:09.570000  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.27304 (* 1 = 0.27304 loss)
I1016 03:47:09.570008  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0469962 (* 1 = 0.0469962 loss)
I1016 03:47:09.570013  4233 sgd_solver.cpp:138] Iteration 71000, lr = 0.000125
I1016 03:47:43.737433  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:48:08.364568  4233 solver.cpp:243] Iteration 71100, loss = 0.329806
I1016 03:48:08.364616  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.143636 (* 1 = 0.143636 loss)
I1016 03:48:08.364622  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0390756 (* 1 = 0.0390756 loss)
I1016 03:48:08.364629  4233 sgd_solver.cpp:138] Iteration 71100, lr = 0.000125
I1016 03:49:07.338291  4233 solver.cpp:243] Iteration 71200, loss = 0.599466
I1016 03:49:07.338338  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.733505 (* 1 = 0.733505 loss)
I1016 03:49:07.338344  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0554686 (* 1 = 0.0554686 loss)
I1016 03:49:07.338351  4233 sgd_solver.cpp:138] Iteration 71200, lr = 0.000125
I1016 03:50:06.694991  4233 solver.cpp:243] Iteration 71300, loss = 0.194311
I1016 03:50:06.695037  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.165451 (* 1 = 0.165451 loss)
I1016 03:50:06.695044  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0436173 (* 1 = 0.0436173 loss)
I1016 03:50:06.695050  4233 sgd_solver.cpp:138] Iteration 71300, lr = 0.000125
I1016 03:51:06.641364  4233 solver.cpp:243] Iteration 71400, loss = 0.218894
I1016 03:51:06.641396  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0865428 (* 1 = 0.0865428 loss)
I1016 03:51:06.641402  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0408535 (* 1 = 0.0408535 loss)
I1016 03:51:06.641407  4233 sgd_solver.cpp:138] Iteration 71400, lr = 0.000125
I1016 03:52:05.924307  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_71500.caffemodel
I1016 03:52:06.166971  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_71500.solverstate
I1016 03:52:06.741380  4233 solver.cpp:243] Iteration 71500, loss = 0.466358
I1016 03:52:06.741430  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.415381 (* 1 = 0.415381 loss)
I1016 03:52:06.741436  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0426568 (* 1 = 0.0426568 loss)
I1016 03:52:06.741441  4233 sgd_solver.cpp:138] Iteration 71500, lr = 0.000125
I1016 03:53:05.491231  4233 solver.cpp:243] Iteration 71600, loss = 0.263807
I1016 03:53:05.491277  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.234775 (* 1 = 0.234775 loss)
I1016 03:53:05.491284  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.034247 (* 1 = 0.034247 loss)
I1016 03:53:05.491289  4233 sgd_solver.cpp:138] Iteration 71600, lr = 0.000125
I1016 03:54:03.884568  4233 solver.cpp:243] Iteration 71700, loss = 0.324799
I1016 03:54:03.884599  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.258044 (* 1 = 0.258044 loss)
I1016 03:54:03.884605  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0725017 (* 1 = 0.0725017 loss)
I1016 03:54:03.884610  4233 sgd_solver.cpp:138] Iteration 71700, lr = 0.000125
I1016 03:55:03.556084  4233 solver.cpp:243] Iteration 71800, loss = 0.242003
I1016 03:55:03.556129  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.158104 (* 1 = 0.158104 loss)
I1016 03:55:03.556135  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0497196 (* 1 = 0.0497196 loss)
I1016 03:55:03.556141  4233 sgd_solver.cpp:138] Iteration 71800, lr = 0.000125
I1016 03:56:03.309672  4233 solver.cpp:243] Iteration 71900, loss = 0.223154
I1016 03:56:03.309720  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0900916 (* 1 = 0.0900916 loss)
I1016 03:56:03.309726  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314493 (* 1 = 0.0314493 loss)
I1016 03:56:03.309732  4233 sgd_solver.cpp:138] Iteration 71900, lr = 0.000125
I1016 03:57:02.967525  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_72000.caffemodel
I1016 03:57:03.192931  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_72000.solverstate
I1016 03:57:03.972847  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 03:57:16.305155  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 03:58:42.462321  4233 solver.cpp:243] Iteration 72000, loss = 0.168189
I1016 03:58:42.462352  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.131823 (* 1 = 0.131823 loss)
I1016 03:58:42.462358  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0363654 (* 1 = 0.0363654 loss)
I1016 03:58:42.462364  4233 sgd_solver.cpp:138] Iteration 72000, lr = 0.000125
I1016 03:59:40.440183  4233 solver.cpp:243] Iteration 72100, loss = 0.32785
I1016 03:59:40.440215  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.173653 (* 1 = 0.173653 loss)
I1016 03:59:40.440223  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0551281 (* 1 = 0.0551281 loss)
I1016 03:59:40.440246  4233 sgd_solver.cpp:138] Iteration 72100, lr = 0.000125
I1016 04:00:39.182770  4233 solver.cpp:243] Iteration 72200, loss = 0.291574
I1016 04:00:39.182803  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.142023 (* 1 = 0.142023 loss)
I1016 04:00:39.182811  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0374993 (* 1 = 0.0374993 loss)
I1016 04:00:39.182835  4233 sgd_solver.cpp:138] Iteration 72200, lr = 0.000125
I1016 04:01:38.623286  4233 solver.cpp:243] Iteration 72300, loss = 0.51775
I1016 04:01:38.623330  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.323196 (* 1 = 0.323196 loss)
I1016 04:01:38.623337  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0411776 (* 1 = 0.0411776 loss)
I1016 04:01:38.623342  4233 sgd_solver.cpp:138] Iteration 72300, lr = 0.000125
I1016 04:02:38.038493  4233 solver.cpp:243] Iteration 72400, loss = 0.473206
I1016 04:02:38.038539  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.101518 (* 1 = 0.101518 loss)
I1016 04:02:38.038545  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0257502 (* 1 = 0.0257502 loss)
I1016 04:02:38.038552  4233 sgd_solver.cpp:138] Iteration 72400, lr = 0.000125
I1016 04:03:37.500856  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_72500.caffemodel
I1016 04:03:37.733810  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_72500.solverstate
I1016 04:03:38.297137  4233 solver.cpp:243] Iteration 72500, loss = 0.216756
I1016 04:03:38.297185  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.146569 (* 1 = 0.146569 loss)
I1016 04:03:38.297191  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0475888 (* 1 = 0.0475888 loss)
I1016 04:03:38.297196  4233 sgd_solver.cpp:138] Iteration 72500, lr = 0.000125
I1016 04:04:21.361779  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:04:37.838503  4233 solver.cpp:243] Iteration 72600, loss = 0.35676
I1016 04:04:37.838551  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.384108 (* 1 = 0.384108 loss)
I1016 04:04:37.838558  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.029619 (* 1 = 0.029619 loss)
I1016 04:04:37.838563  4233 sgd_solver.cpp:138] Iteration 72600, lr = 0.000125
I1016 04:05:36.927525  4233 solver.cpp:243] Iteration 72700, loss = 0.386529
I1016 04:05:36.927572  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.380009 (* 1 = 0.380009 loss)
I1016 04:05:36.927578  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0341941 (* 1 = 0.0341941 loss)
I1016 04:05:36.927583  4233 sgd_solver.cpp:138] Iteration 72700, lr = 0.000125
I1016 04:06:35.525601  4233 solver.cpp:243] Iteration 72800, loss = 0.393859
I1016 04:06:35.525647  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.414932 (* 1 = 0.414932 loss)
I1016 04:06:35.525653  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398044 (* 1 = 0.0398044 loss)
I1016 04:06:35.525658  4233 sgd_solver.cpp:138] Iteration 72800, lr = 0.000125
I1016 04:07:35.315104  4233 solver.cpp:243] Iteration 72900, loss = 0.261858
I1016 04:07:35.315152  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.172258 (* 1 = 0.172258 loss)
I1016 04:07:35.315158  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0370645 (* 1 = 0.0370645 loss)
I1016 04:07:35.315165  4233 sgd_solver.cpp:138] Iteration 72900, lr = 0.000125
I1016 04:08:34.528254  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_73000.caffemodel
I1016 04:08:35.374570  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_73000.solverstate
I1016 04:08:35.991304  4233 solver.cpp:243] Iteration 73000, loss = 0.238027
I1016 04:08:35.991336  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.125044 (* 1 = 0.125044 loss)
I1016 04:08:35.991343  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0341004 (* 1 = 0.0341004 loss)
I1016 04:08:35.991348  4233 sgd_solver.cpp:138] Iteration 73000, lr = 0.000125
I1016 04:09:35.201182  4233 solver.cpp:243] Iteration 73100, loss = 0.14432
I1016 04:09:35.201231  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.297901 (* 1 = 0.297901 loss)
I1016 04:09:35.201237  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0355016 (* 1 = 0.0355016 loss)
I1016 04:09:35.201242  4233 sgd_solver.cpp:138] Iteration 73100, lr = 0.000125
I1016 04:10:34.283948  4233 solver.cpp:243] Iteration 73200, loss = 0.302659
I1016 04:10:34.283998  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.256928 (* 1 = 0.256928 loss)
I1016 04:10:34.284003  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0361791 (* 1 = 0.0361791 loss)
I1016 04:10:34.284009  4233 sgd_solver.cpp:138] Iteration 73200, lr = 0.000125
I1016 04:11:32.713003  4233 solver.cpp:243] Iteration 73300, loss = 0.277643
I1016 04:11:32.713052  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.197974 (* 1 = 0.197974 loss)
I1016 04:11:32.713057  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0269648 (* 1 = 0.0269648 loss)
I1016 04:11:32.713063  4233 sgd_solver.cpp:138] Iteration 73300, lr = 0.000125
I1016 04:12:32.475633  4233 solver.cpp:243] Iteration 73400, loss = 0.493126
I1016 04:12:32.475680  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.214379 (* 1 = 0.214379 loss)
I1016 04:12:32.475687  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.053665 (* 1 = 0.053665 loss)
I1016 04:12:32.475692  4233 sgd_solver.cpp:138] Iteration 73400, lr = 0.000125
I1016 04:13:31.178418  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_73500.caffemodel
I1016 04:13:31.939719  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_73500.solverstate
I1016 04:13:32.526602  4233 solver.cpp:243] Iteration 73500, loss = 0.264827
I1016 04:13:32.526648  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.212738 (* 1 = 0.212738 loss)
I1016 04:13:32.526655  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0498589 (* 1 = 0.0498589 loss)
I1016 04:13:32.526661  4233 sgd_solver.cpp:138] Iteration 73500, lr = 0.000125
I1016 04:14:21.631522  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:14:31.926527  4233 solver.cpp:243] Iteration 73600, loss = 0.239085
I1016 04:14:31.926560  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.123606 (* 1 = 0.123606 loss)
I1016 04:14:31.926565  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0307353 (* 1 = 0.0307353 loss)
I1016 04:14:31.926571  4233 sgd_solver.cpp:138] Iteration 73600, lr = 0.000125
I1016 04:15:31.167083  4233 solver.cpp:243] Iteration 73700, loss = 0.265109
I1016 04:15:31.167130  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.439743 (* 1 = 0.439743 loss)
I1016 04:15:31.167136  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0392282 (* 1 = 0.0392282 loss)
I1016 04:15:31.167143  4233 sgd_solver.cpp:138] Iteration 73700, lr = 0.000125
I1016 04:16:30.411195  4233 solver.cpp:243] Iteration 73800, loss = 0.518709
I1016 04:16:30.411239  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.437022 (* 1 = 0.437022 loss)
I1016 04:16:30.411245  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0453751 (* 1 = 0.0453751 loss)
I1016 04:16:30.411252  4233 sgd_solver.cpp:138] Iteration 73800, lr = 0.000125
I1016 04:17:29.094105  4233 solver.cpp:243] Iteration 73900, loss = 0.399945
I1016 04:17:29.094138  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.284634 (* 1 = 0.284634 loss)
I1016 04:17:29.094144  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367219 (* 1 = 0.0367219 loss)
I1016 04:17:29.094151  4233 sgd_solver.cpp:138] Iteration 73900, lr = 0.000125
I1016 04:18:27.967743  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_74000.caffemodel
I1016 04:18:28.192314  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_74000.solverstate
I1016 04:18:28.770907  4233 solver.cpp:243] Iteration 74000, loss = 0.132561
I1016 04:18:28.770953  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0422334 (* 1 = 0.0422334 loss)
I1016 04:18:28.770959  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0245463 (* 1 = 0.0245463 loss)
I1016 04:18:28.770965  4233 sgd_solver.cpp:138] Iteration 74000, lr = 0.000125
I1016 04:19:28.736846  4233 solver.cpp:243] Iteration 74100, loss = 0.280129
I1016 04:19:28.736881  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.12138 (* 1 = 0.12138 loss)
I1016 04:19:28.736886  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0382749 (* 1 = 0.0382749 loss)
I1016 04:19:28.736892  4233 sgd_solver.cpp:138] Iteration 74100, lr = 0.000125
I1016 04:20:28.528185  4233 solver.cpp:243] Iteration 74200, loss = 0.209235
I1016 04:20:28.528232  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.578249 (* 1 = 0.578249 loss)
I1016 04:20:28.528239  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0523925 (* 1 = 0.0523925 loss)
I1016 04:20:28.528244  4233 sgd_solver.cpp:138] Iteration 74200, lr = 0.000125
I1016 04:21:27.645498  4233 solver.cpp:243] Iteration 74300, loss = 0.296195
I1016 04:21:27.645546  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.448796 (* 1 = 0.448796 loss)
I1016 04:21:27.645552  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0312323 (* 1 = 0.0312323 loss)
I1016 04:21:27.645558  4233 sgd_solver.cpp:138] Iteration 74300, lr = 0.000125
I1016 04:22:25.864528  4233 solver.cpp:243] Iteration 74400, loss = 0.295621
I1016 04:22:25.864576  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.507362 (* 1 = 0.507362 loss)
I1016 04:22:25.864583  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0425959 (* 1 = 0.0425959 loss)
I1016 04:22:25.864588  4233 sgd_solver.cpp:138] Iteration 74400, lr = 0.000125
I1016 04:23:25.239256  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_74500.caffemodel
I1016 04:23:25.460501  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_74500.solverstate
I1016 04:23:26.036106  4233 solver.cpp:243] Iteration 74500, loss = 0.30589
I1016 04:23:26.036151  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.600981 (* 1 = 0.600981 loss)
I1016 04:23:26.036157  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.023763 (* 1 = 0.023763 loss)
I1016 04:23:26.036162  4233 sgd_solver.cpp:138] Iteration 74500, lr = 0.000125
I1016 04:24:17.548859  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:24:25.304201  4233 solver.cpp:243] Iteration 74600, loss = 0.261495
I1016 04:24:25.304235  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.200708 (* 1 = 0.200708 loss)
I1016 04:24:25.304241  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0316334 (* 1 = 0.0316334 loss)
I1016 04:24:25.304247  4233 sgd_solver.cpp:138] Iteration 74600, lr = 0.000125
I1016 04:25:25.580108  4233 solver.cpp:243] Iteration 74700, loss = 0.228067
I1016 04:25:25.580154  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.144423 (* 1 = 0.144423 loss)
I1016 04:25:25.580160  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0330884 (* 1 = 0.0330884 loss)
I1016 04:25:25.580165  4233 sgd_solver.cpp:138] Iteration 74700, lr = 0.000125
I1016 04:26:24.633510  4233 solver.cpp:243] Iteration 74800, loss = 0.434252
I1016 04:26:24.633556  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.76288 (* 1 = 0.76288 loss)
I1016 04:26:24.633563  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0339632 (* 1 = 0.0339632 loss)
I1016 04:26:24.633569  4233 sgd_solver.cpp:138] Iteration 74800, lr = 0.000125
I1016 04:27:23.589507  4233 solver.cpp:243] Iteration 74900, loss = 0.236031
I1016 04:27:23.589540  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.202636 (* 1 = 0.202636 loss)
I1016 04:27:23.589546  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0427129 (* 1 = 0.0427129 loss)
I1016 04:27:23.589552  4233 sgd_solver.cpp:138] Iteration 74900, lr = 0.000125
I1016 04:28:22.302335  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_75000.caffemodel
I1016 04:28:22.524441  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_75000.solverstate
I1016 04:28:23.091939  4233 solver.cpp:243] Iteration 75000, loss = 0.721044
I1016 04:28:23.091987  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.533034 (* 1 = 0.533034 loss)
I1016 04:28:23.091994  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0709691 (* 1 = 0.0709691 loss)
I1016 04:28:23.092000  4233 sgd_solver.cpp:138] Iteration 75000, lr = 0.000125
I1016 04:29:22.156867  4233 solver.cpp:243] Iteration 75100, loss = 0.198246
I1016 04:29:22.156901  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.134971 (* 1 = 0.134971 loss)
I1016 04:29:22.156924  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0306309 (* 1 = 0.0306309 loss)
I1016 04:29:22.156932  4233 sgd_solver.cpp:138] Iteration 75100, lr = 0.000125
I1016 04:30:22.099514  4233 solver.cpp:243] Iteration 75200, loss = 0.153364
I1016 04:30:22.099550  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.044692 (* 1 = 0.044692 loss)
I1016 04:30:22.099558  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0358819 (* 1 = 0.0358819 loss)
I1016 04:30:22.099581  4233 sgd_solver.cpp:138] Iteration 75200, lr = 0.000125
I1016 04:31:21.942390  4233 solver.cpp:243] Iteration 75300, loss = 0.413377
I1016 04:31:21.942440  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.420828 (* 1 = 0.420828 loss)
I1016 04:31:21.942445  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0454681 (* 1 = 0.0454681 loss)
I1016 04:31:21.942451  4233 sgd_solver.cpp:138] Iteration 75300, lr = 0.000125
I1016 04:32:20.990236  4233 solver.cpp:243] Iteration 75400, loss = 0.373082
I1016 04:32:20.990283  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.203079 (* 1 = 0.203079 loss)
I1016 04:32:20.990289  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0426818 (* 1 = 0.0426818 loss)
I1016 04:32:20.990294  4233 sgd_solver.cpp:138] Iteration 75400, lr = 0.000125
I1016 04:33:18.938422  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_75500.caffemodel
I1016 04:33:19.147601  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_75500.solverstate
I1016 04:33:20.273663  4233 solver.cpp:243] Iteration 75500, loss = 0.55348
I1016 04:33:20.273710  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.672642 (* 1 = 0.672642 loss)
I1016 04:33:20.273717  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0579607 (* 1 = 0.0579607 loss)
I1016 04:33:20.273723  4233 sgd_solver.cpp:138] Iteration 75500, lr = 0.000125
I1016 04:34:15.955197  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:34:19.424135  4233 solver.cpp:243] Iteration 75600, loss = 0.195984
I1016 04:34:19.424168  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.116901 (* 1 = 0.116901 loss)
I1016 04:34:19.424177  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0407341 (* 1 = 0.0407341 loss)
I1016 04:34:19.424199  4233 sgd_solver.cpp:138] Iteration 75600, lr = 0.000125
I1016 04:35:19.225585  4233 solver.cpp:243] Iteration 75700, loss = 0.252203
I1016 04:35:19.225631  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.244934 (* 1 = 0.244934 loss)
I1016 04:35:19.225637  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0463016 (* 1 = 0.0463016 loss)
I1016 04:35:19.225642  4233 sgd_solver.cpp:138] Iteration 75700, lr = 0.000125
I1016 04:36:19.284452  4233 solver.cpp:243] Iteration 75800, loss = 0.168761
I1016 04:36:19.284498  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.120521 (* 1 = 0.120521 loss)
I1016 04:36:19.284504  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0378982 (* 1 = 0.0378982 loss)
I1016 04:36:19.284510  4233 sgd_solver.cpp:138] Iteration 75800, lr = 0.000125
I1016 04:37:18.361668  4233 solver.cpp:243] Iteration 75900, loss = 0.240843
I1016 04:37:18.361716  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0607873 (* 1 = 0.0607873 loss)
I1016 04:37:18.361722  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0389191 (* 1 = 0.0389191 loss)
I1016 04:37:18.361727  4233 sgd_solver.cpp:138] Iteration 75900, lr = 0.000125
I1016 04:38:16.308724  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_76000.caffemodel
I1016 04:38:16.547029  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_76000.solverstate
I1016 04:38:16.735838  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 04:39:33.708604  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 04:39:39.147117  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 04:39:54.057988  4233 solver.cpp:243] Iteration 76000, loss = 0.175262
I1016 04:39:54.058022  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.146031 (* 1 = 0.146031 loss)
I1016 04:39:54.058028  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0292309 (* 1 = 0.0292309 loss)
I1016 04:39:54.058034  4233 sgd_solver.cpp:138] Iteration 76000, lr = 0.000125
I1016 04:40:52.579057  4233 solver.cpp:243] Iteration 76100, loss = 0.351731
I1016 04:40:52.579103  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.591355 (* 1 = 0.591355 loss)
I1016 04:40:52.579109  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0318886 (* 1 = 0.0318886 loss)
I1016 04:40:52.579115  4233 sgd_solver.cpp:138] Iteration 76100, lr = 0.000125
I1016 04:40:55.598903  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:41:51.970389  4233 solver.cpp:243] Iteration 76200, loss = 0.248195
I1016 04:41:51.970420  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0805005 (* 1 = 0.0805005 loss)
I1016 04:41:51.970427  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0404086 (* 1 = 0.0404086 loss)
I1016 04:41:51.970432  4233 sgd_solver.cpp:138] Iteration 76200, lr = 0.000125
I1016 04:42:52.126101  4233 solver.cpp:243] Iteration 76300, loss = 0.278273
I1016 04:42:52.126134  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0887885 (* 1 = 0.0887885 loss)
I1016 04:42:52.126142  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0354322 (* 1 = 0.0354322 loss)
I1016 04:42:52.126147  4233 sgd_solver.cpp:138] Iteration 76300, lr = 0.000125
I1016 04:43:51.563836  4233 solver.cpp:243] Iteration 76400, loss = 0.392844
I1016 04:43:51.563884  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0988546 (* 1 = 0.0988546 loss)
I1016 04:43:51.563890  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412144 (* 1 = 0.0412144 loss)
I1016 04:43:51.563896  4233 sgd_solver.cpp:138] Iteration 76400, lr = 0.000125
I1016 04:44:50.191417  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_76500.caffemodel
I1016 04:44:50.965787  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_76500.solverstate
I1016 04:44:51.544088  4233 solver.cpp:243] Iteration 76500, loss = 0.326324
I1016 04:44:51.544137  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.117858 (* 1 = 0.117858 loss)
I1016 04:44:51.544144  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0497778 (* 1 = 0.0497778 loss)
I1016 04:44:51.544149  4233 sgd_solver.cpp:138] Iteration 76500, lr = 0.000125
I1016 04:45:49.407810  4233 solver.cpp:243] Iteration 76600, loss = 0.251992
I1016 04:45:49.407858  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.26913 (* 1 = 0.26913 loss)
I1016 04:45:49.407865  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0328444 (* 1 = 0.0328444 loss)
I1016 04:45:49.407871  4233 sgd_solver.cpp:138] Iteration 76600, lr = 0.000125
I1016 04:46:49.125607  4233 solver.cpp:243] Iteration 76700, loss = 0.194878
I1016 04:46:49.125654  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.137518 (* 1 = 0.137518 loss)
I1016 04:46:49.125660  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0297476 (* 1 = 0.0297476 loss)
I1016 04:46:49.125665  4233 sgd_solver.cpp:138] Iteration 76700, lr = 0.000125
I1016 04:47:49.146677  4233 solver.cpp:243] Iteration 76800, loss = 0.190747
I1016 04:47:49.146713  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.256322 (* 1 = 0.256322 loss)
I1016 04:47:49.146721  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0362799 (* 1 = 0.0362799 loss)
I1016 04:47:49.146728  4233 sgd_solver.cpp:138] Iteration 76800, lr = 0.000125
I1016 04:48:49.146517  4233 solver.cpp:243] Iteration 76900, loss = 0.289871
I1016 04:48:49.146562  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.364445 (* 1 = 0.364445 loss)
I1016 04:48:49.146569  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0347321 (* 1 = 0.0347321 loss)
I1016 04:48:49.146574  4233 sgd_solver.cpp:138] Iteration 76900, lr = 0.000125
I1016 04:49:47.743724  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_77000.caffemodel
I1016 04:49:47.985924  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_77000.solverstate
I1016 04:49:48.549877  4233 solver.cpp:243] Iteration 77000, loss = 0.295153
I1016 04:49:48.549908  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0562429 (* 1 = 0.0562429 loss)
I1016 04:49:48.549913  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0360839 (* 1 = 0.0360839 loss)
I1016 04:49:48.549921  4233 sgd_solver.cpp:138] Iteration 77000, lr = 0.000125
I1016 04:50:46.476413  4233 solver.cpp:243] Iteration 77100, loss = 0.228888
I1016 04:50:46.476460  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0649886 (* 1 = 0.0649886 loss)
I1016 04:50:46.476466  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413753 (* 1 = 0.0413753 loss)
I1016 04:50:46.476471  4233 sgd_solver.cpp:138] Iteration 77100, lr = 0.000125
I1016 04:50:53.696403  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 04:51:46.345026  4233 solver.cpp:243] Iteration 77200, loss = 0.427982
I1016 04:51:46.345074  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.295862 (* 1 = 0.295862 loss)
I1016 04:51:46.345082  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0431049 (* 1 = 0.0431049 loss)
I1016 04:51:46.345086  4233 sgd_solver.cpp:138] Iteration 77200, lr = 0.000125
I1016 04:52:45.678668  4233 solver.cpp:243] Iteration 77300, loss = 0.345778
I1016 04:52:45.678699  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.240867 (* 1 = 0.240867 loss)
I1016 04:52:45.678705  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0422737 (* 1 = 0.0422737 loss)
I1016 04:52:45.678711  4233 sgd_solver.cpp:138] Iteration 77300, lr = 0.000125
I1016 04:53:45.888659  4233 solver.cpp:243] Iteration 77400, loss = 0.14497
I1016 04:53:45.888706  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.267259 (* 1 = 0.267259 loss)
I1016 04:53:45.888713  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0342703 (* 1 = 0.0342703 loss)
I1016 04:53:45.888720  4233 sgd_solver.cpp:138] Iteration 77400, lr = 0.000125
I1016 04:54:44.513624  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_77500.caffemodel
I1016 04:54:44.756793  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_77500.solverstate
I1016 04:54:45.337271  4233 solver.cpp:243] Iteration 77500, loss = 0.264563
I1016 04:54:45.337304  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.320771 (* 1 = 0.320771 loss)
I1016 04:54:45.337313  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398051 (* 1 = 0.0398051 loss)
I1016 04:54:45.337332  4233 sgd_solver.cpp:138] Iteration 77500, lr = 0.000125
I1016 04:55:44.212755  4233 solver.cpp:243] Iteration 77600, loss = 0.308323
I1016 04:55:44.212790  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.13736 (* 1 = 0.13736 loss)
I1016 04:55:44.212815  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0504056 (* 1 = 0.0504056 loss)
I1016 04:55:44.212822  4233 sgd_solver.cpp:138] Iteration 77600, lr = 0.000125
I1016 04:56:43.203088  4233 solver.cpp:243] Iteration 77700, loss = 0.48237
I1016 04:56:43.203122  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.618926 (* 1 = 0.618926 loss)
I1016 04:56:43.203131  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0556256 (* 1 = 0.0556256 loss)
I1016 04:56:43.203155  4233 sgd_solver.cpp:138] Iteration 77700, lr = 0.000125
I1016 04:57:42.504400  4233 solver.cpp:243] Iteration 77800, loss = 0.155523
I1016 04:57:42.504432  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.11826 (* 1 = 0.11826 loss)
I1016 04:57:42.504441  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0335732 (* 1 = 0.0335732 loss)
I1016 04:57:42.504463  4233 sgd_solver.cpp:138] Iteration 77800, lr = 0.000125
I1016 04:58:42.398599  4233 solver.cpp:243] Iteration 77900, loss = 0.201305
I1016 04:58:42.398633  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.307388 (* 1 = 0.307388 loss)
I1016 04:58:42.398656  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0364436 (* 1 = 0.0364436 loss)
I1016 04:58:42.398664  4233 sgd_solver.cpp:138] Iteration 77900, lr = 0.000125
I1016 04:59:41.725244  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_78000.caffemodel
I1016 04:59:41.958544  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_78000.solverstate
I1016 04:59:42.541712  4233 solver.cpp:243] Iteration 78000, loss = 0.382452
I1016 04:59:42.541743  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.21874 (* 1 = 0.21874 loss)
I1016 04:59:42.541749  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0436284 (* 1 = 0.0436284 loss)
I1016 04:59:42.541754  4233 sgd_solver.cpp:138] Iteration 78000, lr = 0.000125
I1016 05:00:41.254650  4233 solver.cpp:243] Iteration 78100, loss = 0.247168
I1016 05:00:41.254698  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.447629 (* 1 = 0.447629 loss)
I1016 05:00:41.254705  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0357371 (* 1 = 0.0357371 loss)
I1016 05:00:41.254710  4233 sgd_solver.cpp:138] Iteration 78100, lr = 0.000125
I1016 05:00:50.790796  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:01:39.692411  4233 solver.cpp:243] Iteration 78200, loss = 0.320013
I1016 05:01:39.692458  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0948186 (* 1 = 0.0948186 loss)
I1016 05:01:39.692464  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.033441 (* 1 = 0.033441 loss)
I1016 05:01:39.692471  4233 sgd_solver.cpp:138] Iteration 78200, lr = 0.000125
I1016 05:02:39.499864  4233 solver.cpp:243] Iteration 78300, loss = 0.260989
I1016 05:02:39.499913  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0999661 (* 1 = 0.0999661 loss)
I1016 05:02:39.499919  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0310805 (* 1 = 0.0310805 loss)
I1016 05:02:39.499924  4233 sgd_solver.cpp:138] Iteration 78300, lr = 0.000125
I1016 05:03:39.210225  4233 solver.cpp:243] Iteration 78400, loss = 0.194429
I1016 05:03:39.210270  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0615773 (* 1 = 0.0615773 loss)
I1016 05:03:39.210276  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0432692 (* 1 = 0.0432692 loss)
I1016 05:03:39.210281  4233 sgd_solver.cpp:138] Iteration 78400, lr = 0.000125
I1016 05:04:38.924633  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_78500.caffemodel
I1016 05:04:39.149874  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_78500.solverstate
I1016 05:04:39.724640  4233 solver.cpp:243] Iteration 78500, loss = 0.162502
I1016 05:04:39.724685  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.166303 (* 1 = 0.166303 loss)
I1016 05:04:39.724691  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0315441 (* 1 = 0.0315441 loss)
I1016 05:04:39.724697  4233 sgd_solver.cpp:138] Iteration 78500, lr = 0.000125
I1016 05:05:38.548081  4233 solver.cpp:243] Iteration 78600, loss = 0.287167
I1016 05:05:38.548115  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.212801 (* 1 = 0.212801 loss)
I1016 05:05:38.548121  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445314 (* 1 = 0.0445314 loss)
I1016 05:05:38.548127  4233 sgd_solver.cpp:138] Iteration 78600, lr = 0.000125
I1016 05:06:37.270328  4233 solver.cpp:243] Iteration 78700, loss = 0.264278
I1016 05:06:37.270375  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.148069 (* 1 = 0.148069 loss)
I1016 05:06:37.270380  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0393592 (* 1 = 0.0393592 loss)
I1016 05:06:37.270386  4233 sgd_solver.cpp:138] Iteration 78700, lr = 0.000125
I1016 05:07:36.751893  4233 solver.cpp:243] Iteration 78800, loss = 0.544867
I1016 05:07:36.751940  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.219698 (* 1 = 0.219698 loss)
I1016 05:07:36.751945  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0282988 (* 1 = 0.0282988 loss)
I1016 05:07:36.751952  4233 sgd_solver.cpp:138] Iteration 78800, lr = 0.000125
I1016 05:08:35.954111  4233 solver.cpp:243] Iteration 78900, loss = 0.417402
I1016 05:08:35.954145  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.123162 (* 1 = 0.123162 loss)
I1016 05:08:35.954151  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0251091 (* 1 = 0.0251091 loss)
I1016 05:08:35.954156  4233 sgd_solver.cpp:138] Iteration 78900, lr = 0.000125
I1016 05:09:35.432852  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_79000.caffemodel
I1016 05:09:35.652433  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_79000.solverstate
I1016 05:09:36.763700  4233 solver.cpp:243] Iteration 79000, loss = 0.184791
I1016 05:09:36.763749  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.202907 (* 1 = 0.202907 loss)
I1016 05:09:36.763756  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0485239 (* 1 = 0.0485239 loss)
I1016 05:09:36.763761  4233 sgd_solver.cpp:138] Iteration 79000, lr = 0.000125
I1016 05:10:35.899027  4233 solver.cpp:243] Iteration 79100, loss = 0.303664
I1016 05:10:35.899061  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.290458 (* 1 = 0.290458 loss)
I1016 05:10:35.899067  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0312653 (* 1 = 0.0312653 loss)
I1016 05:10:35.899073  4233 sgd_solver.cpp:138] Iteration 79100, lr = 0.000125
I1016 05:10:49.383354  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:11:34.937227  4233 solver.cpp:243] Iteration 79200, loss = 0.333088
I1016 05:11:34.937274  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.148501 (* 1 = 0.148501 loss)
I1016 05:11:34.937280  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0335717 (* 1 = 0.0335717 loss)
I1016 05:11:34.937286  4233 sgd_solver.cpp:138] Iteration 79200, lr = 0.000125
I1016 05:12:33.437232  4233 solver.cpp:243] Iteration 79300, loss = 0.343093
I1016 05:12:33.437263  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.272678 (* 1 = 0.272678 loss)
I1016 05:12:33.437269  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0291969 (* 1 = 0.0291969 loss)
I1016 05:12:33.437274  4233 sgd_solver.cpp:138] Iteration 79300, lr = 0.000125
I1016 05:13:32.964152  4233 solver.cpp:243] Iteration 79400, loss = 0.221141
I1016 05:13:32.964184  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.108488 (* 1 = 0.108488 loss)
I1016 05:13:32.964190  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.032629 (* 1 = 0.032629 loss)
I1016 05:13:32.964195  4233 sgd_solver.cpp:138] Iteration 79400, lr = 0.000125
I1016 05:14:32.184995  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_79500.caffemodel
I1016 05:14:32.412411  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_79500.solverstate
I1016 05:14:33.596926  4233 solver.cpp:243] Iteration 79500, loss = 0.248754
I1016 05:14:33.596959  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0566167 (* 1 = 0.0566167 loss)
I1016 05:14:33.596966  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0473296 (* 1 = 0.0473296 loss)
I1016 05:14:33.596971  4233 sgd_solver.cpp:138] Iteration 79500, lr = 0.000125
I1016 05:15:32.972456  4233 solver.cpp:243] Iteration 79600, loss = 0.110976
I1016 05:15:32.972503  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0652806 (* 1 = 0.0652806 loss)
I1016 05:15:32.972510  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0318231 (* 1 = 0.0318231 loss)
I1016 05:15:32.972515  4233 sgd_solver.cpp:138] Iteration 79600, lr = 0.000125
I1016 05:16:32.170120  4233 solver.cpp:243] Iteration 79700, loss = 0.253553
I1016 05:16:32.170156  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.693029 (* 1 = 0.693029 loss)
I1016 05:16:32.170164  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0424143 (* 1 = 0.0424143 loss)
I1016 05:16:32.170171  4233 sgd_solver.cpp:138] Iteration 79700, lr = 0.000125
I1016 05:17:30.577579  4233 solver.cpp:243] Iteration 79800, loss = 0.257729
I1016 05:17:30.577615  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.036674 (* 1 = 0.036674 loss)
I1016 05:17:30.577638  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0461349 (* 1 = 0.0461349 loss)
I1016 05:17:30.577646  4233 sgd_solver.cpp:138] Iteration 79800, lr = 0.000125
I1016 05:18:30.223645  4233 solver.cpp:243] Iteration 79900, loss = 0.443873
I1016 05:18:30.223681  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.527076 (* 1 = 0.527076 loss)
I1016 05:18:30.223690  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0453369 (* 1 = 0.0453369 loss)
I1016 05:18:30.223713  4233 sgd_solver.cpp:138] Iteration 79900, lr = 0.000125
I1016 05:19:28.991461  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_80000.caffemodel
I1016 05:19:29.217552  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_80000.solverstate
I1016 05:19:29.413969  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 05:19:54.833190  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
>>> 2018-10-15 16:12:51.070685 Begin seg tests
>>> 2018-10-15 16:14:30.096285 Iteration 4000 loss 0.19781170722842217
>>> 2018-10-15 16:14:30.096385 Iteration 4000 overall accuracy 0.9285822916666666
>>> 2018-10-15 16:14:30.096416 Iteration 4000 mean accuracy 0.929122787750787
>>> 2018-10-15 16:14:30.096551 Iteration 4000 mean IU 0.8548738280113692
>>> 2018-10-15 16:14:30.096623 Iteration 4000 fwavacc 0.868567383770033
>>> 2018-10-15 16:54:26.916996 Begin seg tests
>>> 2018-10-15 16:56:05.637392 Iteration 8000 loss 0.27422703355550765
>>> 2018-10-15 16:56:05.637467 Iteration 8000 overall accuracy 0.9307981901041666
>>> 2018-10-15 16:56:05.637496 Iteration 8000 mean accuracy 0.9161855316168891
>>> 2018-10-15 16:56:05.637614 Iteration 8000 mean IU 0.8564484030594026
>>> 2018-10-15 16:56:05.637682 Iteration 8000 fwavacc 0.870633336646087
>>> 2018-10-15 17:36:02.875806 Begin seg tests
>>> 2018-10-15 17:37:41.791624 Iteration 12000 loss 0.27752755949646235
>>> 2018-10-15 17:37:41.791708 Iteration 12000 overall accuracy 0.9428456380208333
>>> 2018-10-15 17:37:41.791738 Iteration 12000 mean accuracy 0.9290843677412592
>>> 2018-10-15 17:37:41.791866 Iteration 12000 mean IU 0.8801964862669315
>>> 2018-10-15 17:37:41.791934 Iteration 12000 fwavacc 0.8916759350729819
>>> 2018-10-15 18:17:07.403115 Begin seg tests
>>> 2018-10-15 18:18:44.426860 Iteration 16000 loss 0.5738773314654827
>>> 2018-10-15 18:18:44.426938 Iteration 16000 overall accuracy 0.9326020963541667
>>> 2018-10-15 18:18:44.426967 Iteration 16000 mean accuracy 0.93431153295137
>>> 2018-10-15 18:18:44.427087 Iteration 16000 mean IU 0.8621026873206571
>>> 2018-10-15 18:18:44.427155 Iteration 16000 fwavacc 0.875586954045616
>>> 2018-10-15 18:58:06.928103 Begin seg tests
>>> 2018-10-15 18:59:44.611426 Iteration 20000 loss 0.8791613072231412
>>> 2018-10-15 18:59:44.611740 Iteration 20000 overall accuracy 0.9277974088541666
>>> 2018-10-15 18:59:44.611771 Iteration 20000 mean accuracy 0.9277112469949047
>>> 2018-10-15 18:59:44.611902 Iteration 20000 mean IU 0.8560452049810146
>>> 2018-10-15 18:59:44.611974 Iteration 20000 fwavacc 0.8667519614704615
>>> 2018-10-15 19:39:28.509139 Begin seg tests
>>> 2018-10-15 19:41:07.684460 Iteration 24000 loss 0.4424095237404108
>>> 2018-10-15 19:41:07.684540 Iteration 24000 overall accuracy 0.936766875
>>> 2018-10-15 19:41:07.684570 Iteration 24000 mean accuracy 0.9398868076662064
>>> 2018-10-15 19:41:07.684697 Iteration 24000 mean IU 0.8708717130071547
>>> 2018-10-15 19:41:07.684764 Iteration 24000 fwavacc 0.8827586281384043
>>> 2018-10-15 20:21:10.352226 Begin seg tests
>>> 2018-10-15 20:22:48.916893 Iteration 28000 loss 0.8149552249237895
>>> 2018-10-15 20:22:48.916969 Iteration 28000 overall accuracy 0.9245430989583333
>>> 2018-10-15 20:22:48.917009 Iteration 28000 mean accuracy 0.8997316371032755
>>> 2018-10-15 20:22:48.917128 Iteration 28000 mean IU 0.8419375096189885
>>> 2018-10-15 20:22:48.917194 Iteration 28000 fwavacc 0.8584595395067338
>>> 2018-10-15 21:03:25.522694 Begin seg tests
>>> 2018-10-15 21:05:05.130995 Iteration 32000 loss 0.6413919521793723
>>> 2018-10-15 21:05:05.131073 Iteration 32000 overall accuracy 0.9179317578125
>>> 2018-10-15 21:05:05.131101 Iteration 32000 mean accuracy 0.9280483169760767
>>> 2018-10-15 21:05:05.131226 Iteration 32000 mean IU 0.8385678213446498
>>> 2018-10-15 21:05:05.131293 Iteration 32000 fwavacc 0.8512785438231016
>>> 2018-10-15 21:45:10.308006 Begin seg tests
>>> 2018-10-15 21:46:48.152001 Iteration 36000 loss 0.694741497259587
>>> 2018-10-15 21:46:48.154082 Iteration 36000 overall accuracy 0.9366088541666666
>>> 2018-10-15 21:46:48.154135 Iteration 36000 mean accuracy 0.9212243293055982
>>> 2018-10-15 21:46:48.158508 Iteration 36000 mean IU 0.867435951782816
>>> 2018-10-15 21:46:48.158588 Iteration 36000 fwavacc 0.8805888494514575
>>> 2018-10-15 22:27:01.353371 Begin seg tests
>>> 2018-10-15 22:28:39.663213 Iteration 40000 loss 0.6338774400986731
>>> 2018-10-15 22:28:39.663288 Iteration 40000 overall accuracy 0.9435795833333334
>>> 2018-10-15 22:28:39.663316 Iteration 40000 mean accuracy 0.9385511671387059
>>> 2018-10-15 22:28:39.663437 Iteration 40000 mean IU 0.8828703610820721
>>> 2018-10-15 22:28:39.663514 Iteration 40000 fwavacc 0.8938939185176495
>>> 2018-10-15 23:08:28.329622 Begin seg tests
>>> 2018-10-15 23:10:06.045696 Iteration 44000 loss 0.5663427894711495
>>> 2018-10-15 23:10:06.045801 Iteration 44000 overall accuracy 0.9397666536458333
>>> 2018-10-15 23:10:06.045851 Iteration 44000 mean accuracy 0.9386388689922098
>>> 2018-10-15 23:10:06.045977 Iteration 44000 mean IU 0.8755817128706955
>>> 2018-10-15 23:10:06.046055 Iteration 44000 fwavacc 0.8876418583382293
>>> 2018-10-15 23:49:40.571518 Begin seg tests
>>> 2018-10-15 23:51:17.734346 Iteration 48000 loss 0.8218433417901396
>>> 2018-10-15 23:51:17.734416 Iteration 48000 overall accuracy 0.9240146484375
>>> 2018-10-15 23:51:17.734444 Iteration 48000 mean accuracy 0.9290461892078999
>>> 2018-10-15 23:51:17.734558 Iteration 48000 mean IU 0.8503545012717391
>>> 2018-10-15 23:51:17.734629 Iteration 48000 fwavacc 0.8607466315838205
>>> 2018-10-16 00:30:55.281621 Begin seg tests
>>> 2018-10-16 00:32:33.934909 Iteration 52000 loss 0.4524674616754055
>>> 2018-10-16 00:32:33.934987 Iteration 52000 overall accuracy 0.9404834244791667
>>> 2018-10-16 00:32:33.935016 Iteration 52000 mean accuracy 0.9382522778358229
>>> 2018-10-16 00:32:33.935141 Iteration 52000 mean IU 0.8766028727597164
>>> 2018-10-16 00:32:33.935209 Iteration 52000 fwavacc 0.8888160530296298
>>> 2018-10-16 01:12:08.881323 Begin seg tests
>>> 2018-10-16 01:13:45.906592 Iteration 56000 loss 0.6514853629991412
>>> 2018-10-16 01:13:45.906664 Iteration 56000 overall accuracy 0.939571875
>>> 2018-10-16 01:13:45.906693 Iteration 56000 mean accuracy 0.9306599720649189
>>> 2018-10-16 01:13:45.906831 Iteration 56000 mean IU 0.8744834000698332
>>> 2018-10-16 01:13:45.906901 Iteration 56000 fwavacc 0.8864843157812266
>>> 2018-10-16 01:53:22.729476 Begin seg tests
>>> 2018-10-16 01:55:00.566356 Iteration 60000 loss 0.6674583707600832
>>> 2018-10-16 01:55:00.566453 Iteration 60000 overall accuracy 0.935463359375
>>> 2018-10-16 01:55:00.566486 Iteration 60000 mean accuracy 0.9194759944959379
>>> 2018-10-16 01:55:00.566611 Iteration 60000 mean IU 0.8654850905027149
>>> 2018-10-16 01:55:00.566679 Iteration 60000 fwavacc 0.8784516886989538
>>> 2018-10-16 02:34:36.563011 Begin seg tests
>>> 2018-10-16 02:36:14.144905 Iteration 64000 loss 0.4377977508157492
>>> 2018-10-16 02:36:14.144989 Iteration 64000 overall accuracy 0.9406950390625
>>> 2018-10-16 02:36:14.145017 Iteration 64000 mean accuracy 0.9414214371621112
>>> 2018-10-16 02:36:14.145142 Iteration 64000 mean IU 0.87716390261392
>>> 2018-10-16 02:36:14.145211 Iteration 64000 fwavacc 0.8894747810505381
>>> 2018-10-16 03:15:49.399347 Begin seg tests
>>> 2018-10-16 03:17:26.860454 Iteration 68000 loss 0.9116204918250441
>>> 2018-10-16 03:17:26.860525 Iteration 68000 overall accuracy 0.93799203125
>>> 2018-10-16 03:17:26.860553 Iteration 68000 mean accuracy 0.9275593453988551
>>> 2018-10-16 03:17:26.860670 Iteration 68000 mean IU 0.872546251510484
>>> 2018-10-16 03:17:26.860738 Iteration 68000 fwavacc 0.8833568683634474
>>> 2018-10-16 03:57:03.972594 Begin seg tests
>>> 2018-10-16 03:58:42.058602 Iteration 72000 loss 0.5658149348795414
>>> 2018-10-16 03:58:42.058677 Iteration 72000 overall accuracy 0.9394879557291667
>>> 2018-10-16 03:58:42.058706 Iteration 72000 mean accuracy 0.938264842182384
>>> 2018-10-16 03:58:42.058830 Iteration 72000 mean IU 0.8751215266718267
>>> 2018-10-16 03:58:42.058897 Iteration 72000 fwavacc 0.8871376043842076
>>> 2018-10-16 04:38:16.735573 Begin seg tests
>>> 2018-10-16 04:39:53.640968 Iteration 76000 loss 0.8222628077790141
>>> 2018-10-16 04:39:53.641045 Iteration 76000 overall accuracy 0.9381969791666667
>>> 2018-10-16 04:39:53.641075 Iteration 76000 mean accuracy 0.9301318357975329
>>> 2018-10-16 04:39:53.641198 Iteration 76000 mean IU 0.8722695530882757
>>> 2018-10-16 04:39:53.641266 Iteration 76000 fwavacc 0.8841342712448756
>>> 2018-10-16 05:19:29.413747 Begin seg tests
>>> 2018-10-16 05:21:07.676869 Iteration 80000I1016 05:21:08.097893  4233 solver.cpp:243] Iteration 80000, loss = 0.459483
I1016 05:21:08.097935  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.423413 (* 1 = 0.423413 loss)
I1016 05:21:08.097942  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.03607 (* 1 = 0.03607 loss)
I1016 05:21:08.097949  4233 sgd_solver.cpp:138] Iteration 80000, lr = 0.000125
I1016 05:22:07.376713  4233 solver.cpp:243] Iteration 80100, loss = 0.210709
I1016 05:22:07.376744  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.20869 (* 1 = 0.20869 loss)
I1016 05:22:07.376751  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0317676 (* 1 = 0.0317676 loss)
I1016 05:22:07.376756  4233 sgd_solver.cpp:138] Iteration 80100, lr = 0.000125
I1016 05:23:06.592887  4233 solver.cpp:243] Iteration 80200, loss = 0.222062
I1016 05:23:06.592921  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.368725 (* 1 = 0.368725 loss)
I1016 05:23:06.592927  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0313489 (* 1 = 0.0313489 loss)
I1016 05:23:06.592933  4233 sgd_solver.cpp:138] Iteration 80200, lr = 0.000125
I1016 05:24:05.864076  4233 solver.cpp:243] Iteration 80300, loss = 0.500228
I1016 05:24:05.864125  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.257479 (* 1 = 0.257479 loss)
I1016 05:24:05.864130  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0373286 (* 1 = 0.0373286 loss)
I1016 05:24:05.864136  4233 sgd_solver.cpp:138] Iteration 80300, lr = 0.000125
I1016 05:25:04.666832  4233 solver.cpp:243] Iteration 80400, loss = 0.342318
I1016 05:25:04.666882  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.295309 (* 1 = 0.295309 loss)
I1016 05:25:04.666888  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0360578 (* 1 = 0.0360578 loss)
I1016 05:25:04.666894  4233 sgd_solver.cpp:138] Iteration 80400, lr = 0.000125
I1016 05:26:03.615928  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_80500.caffemodel
I1016 05:26:03.834231  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_80500.solverstate
I1016 05:26:04.435075  4233 solver.cpp:243] Iteration 80500, loss = 0.13202
I1016 05:26:04.435108  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0649351 (* 1 = 0.0649351 loss)
I1016 05:26:04.435114  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0381981 (* 1 = 0.0381981 loss)
I1016 05:26:04.435120  4233 sgd_solver.cpp:138] Iteration 80500, lr = 0.000125
I1016 05:27:04.360177  4233 solver.cpp:243] Iteration 80600, loss = 0.243139
I1016 05:27:04.360209  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.152971 (* 1 = 0.152971 loss)
I1016 05:27:04.360215  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0447374 (* 1 = 0.0447374 loss)
I1016 05:27:04.360221  4233 sgd_solver.cpp:138] Iteration 80600, lr = 0.000125
I1016 05:27:28.467787  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:28:04.202008  4233 solver.cpp:243] Iteration 80700, loss = 0.15287
I1016 05:28:04.202039  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0707356 (* 1 = 0.0707356 loss)
I1016 05:28:04.202045  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.032478 (* 1 = 0.032478 loss)
I1016 05:28:04.202051  4233 sgd_solver.cpp:138] Iteration 80700, lr = 0.000125
I1016 05:29:03.285473  4233 solver.cpp:243] Iteration 80800, loss = 0.238676
I1016 05:29:03.285521  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.357228 (* 1 = 0.357228 loss)
I1016 05:29:03.285527  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0335347 (* 1 = 0.0335347 loss)
I1016 05:29:03.285533  4233 sgd_solver.cpp:138] Iteration 80800, lr = 0.000125
I1016 05:30:01.479902  4233 solver.cpp:243] Iteration 80900, loss = 0.229156
I1016 05:30:01.479952  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.323185 (* 1 = 0.323185 loss)
I1016 05:30:01.479959  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0387373 (* 1 = 0.0387373 loss)
I1016 05:30:01.479964  4233 sgd_solver.cpp:138] Iteration 80900, lr = 0.000125
I1016 05:31:00.699327  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_81000.caffemodel
I1016 05:31:01.514483  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_81000.solverstate
I1016 05:31:02.121610  4233 solver.cpp:243] Iteration 81000, loss = 0.229223
I1016 05:31:02.121640  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.371475 (* 1 = 0.371475 loss)
I1016 05:31:02.121646  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0426774 (* 1 = 0.0426774 loss)
I1016 05:31:02.121652  4233 sgd_solver.cpp:138] Iteration 81000, lr = 0.000125
I1016 05:32:00.842455  4233 solver.cpp:243] Iteration 81100, loss = 0.228119
I1016 05:32:00.842502  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0519211 (* 1 = 0.0519211 loss)
I1016 05:32:00.842509  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0329617 (* 1 = 0.0329617 loss)
I1016 05:32:00.842514  4233 sgd_solver.cpp:138] Iteration 81100, lr = 0.000125
I1016 05:33:01.143143  4233 solver.cpp:243] Iteration 81200, loss = 0.190664
I1016 05:33:01.143189  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0716541 (* 1 = 0.0716541 loss)
I1016 05:33:01.143195  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.045072 (* 1 = 0.045072 loss)
I1016 05:33:01.143201  4233 sgd_solver.cpp:138] Iteration 81200, lr = 0.000125
I1016 05:34:00.205412  4233 solver.cpp:243] Iteration 81300, loss = 0.350505
I1016 05:34:00.205459  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.146602 (* 1 = 0.146602 loss)
I1016 05:34:00.205466  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0380971 (* 1 = 0.0380971 loss)
I1016 05:34:00.205471  4233 sgd_solver.cpp:138] Iteration 81300, lr = 0.000125
I1016 05:34:59.084815  4233 solver.cpp:243] Iteration 81400, loss = 0.241694
I1016 05:34:59.084864  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.252101 (* 1 = 0.252101 loss)
I1016 05:34:59.084870  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0289629 (* 1 = 0.0289629 loss)
I1016 05:34:59.084877  4233 sgd_solver.cpp:138] Iteration 81400, lr = 0.000125
I1016 05:35:57.795738  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_81500.caffemodel
I1016 05:35:58.032562  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_81500.solverstate
I1016 05:35:58.613490  4233 solver.cpp:243] Iteration 81500, loss = 0.65322
I1016 05:35:58.613535  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.870138 (* 1 = 0.870138 loss)
I1016 05:35:58.613541  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0752571 (* 1 = 0.0752571 loss)
I1016 05:35:58.613548  4233 sgd_solver.cpp:138] Iteration 81500, lr = 0.000125
I1016 05:36:57.693277  4233 solver.cpp:243] Iteration 81600, loss = 0.190049
I1016 05:36:57.693311  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.100395 (* 1 = 0.100395 loss)
I1016 05:36:57.693317  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0275569 (* 1 = 0.0275569 loss)
I1016 05:36:57.693323  4233 sgd_solver.cpp:138] Iteration 81600, lr = 0.000125
I1016 05:37:26.520977  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:37:57.622792  4233 solver.cpp:243] Iteration 81700, loss = 0.149492
I1016 05:37:57.622839  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0995052 (* 1 = 0.0995052 loss)
I1016 05:37:57.622845  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0369692 (* 1 = 0.0369692 loss)
I1016 05:37:57.622850  4233 sgd_solver.cpp:138] Iteration 81700, lr = 0.000125
I1016 05:38:57.316573  4233 solver.cpp:243] Iteration 81800, loss = 0.377619
I1016 05:38:57.316606  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.269943 (* 1 = 0.269943 loss)
I1016 05:38:57.316612  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0378221 (* 1 = 0.0378221 loss)
I1016 05:38:57.316617  4233 sgd_solver.cpp:138] Iteration 81800, lr = 0.000125
I1016 05:39:56.260511  4233 solver.cpp:243] Iteration 81900, loss = 0.329342
I1016 05:39:56.260561  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.167939 (* 1 = 0.167939 loss)
I1016 05:39:56.260568  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0332119 (* 1 = 0.0332119 loss)
I1016 05:39:56.260574  4233 sgd_solver.cpp:138] Iteration 81900, lr = 0.000125
I1016 05:40:54.191833  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_82000.caffemodel
I1016 05:40:54.414093  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_82000.solverstate
I1016 05:40:55.172943  4233 solver.cpp:243] Iteration 82000, loss = 0.455825
I1016 05:40:55.172989  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.367334 (* 1 = 0.367334 loss)
I1016 05:40:55.172996  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0452594 (* 1 = 0.0452594 loss)
I1016 05:40:55.173002  4233 sgd_solver.cpp:138] Iteration 82000, lr = 0.000125
I1016 05:41:54.415372  4233 solver.cpp:243] Iteration 82100, loss = 0.173166
I1016 05:41:54.415418  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0484143 (* 1 = 0.0484143 loss)
I1016 05:41:54.415424  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0336853 (* 1 = 0.0336853 loss)
I1016 05:41:54.415431  4233 sgd_solver.cpp:138] Iteration 82100, lr = 0.000125
I1016 05:42:54.114044  4233 solver.cpp:243] Iteration 82200, loss = 0.225383
I1016 05:42:54.114073  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.398365 (* 1 = 0.398365 loss)
I1016 05:42:54.114079  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0295769 (* 1 = 0.0295769 loss)
I1016 05:42:54.114085  4233 sgd_solver.cpp:138] Iteration 82200, lr = 0.000125
I1016 05:43:54.142854  4233 solver.cpp:243] Iteration 82300, loss = 0.160719
I1016 05:43:54.142886  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0878545 (* 1 = 0.0878545 loss)
I1016 05:43:54.142895  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0354381 (* 1 = 0.0354381 loss)
I1016 05:43:54.142918  4233 sgd_solver.cpp:138] Iteration 82300, lr = 0.000125
I1016 05:44:53.372196  4233 solver.cpp:243] Iteration 82400, loss = 0.227567
I1016 05:44:53.372229  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.146372 (* 1 = 0.146372 loss)
I1016 05:44:53.372237  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0300265 (* 1 = 0.0300265 loss)
I1016 05:44:53.372261  4233 sgd_solver.cpp:138] Iteration 82400, lr = 0.000125
I1016 05:45:51.335119  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_82500.caffemodel
I1016 05:45:51.563773  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_82500.solverstate
I1016 05:45:52.136700  4233 solver.cpp:243] Iteration 82500, loss = 0.319483
I1016 05:45:52.136732  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.250202 (* 1 = 0.250202 loss)
I1016 05:45:52.136741  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0352772 (* 1 = 0.0352772 loss)
I1016 05:45:52.136765  4233 sgd_solver.cpp:138] Iteration 82500, lr = 0.000125
I1016 05:46:51.530557  4233 solver.cpp:243] Iteration 82600, loss = 0.277301
I1016 05:46:51.530601  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.236938 (* 1 = 0.236938 loss)
I1016 05:46:51.530608  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0422006 (* 1 = 0.0422006 loss)
I1016 05:46:51.530613  4233 sgd_solver.cpp:138] Iteration 82600, lr = 0.000125
I1016 05:47:22.905936  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:47:50.749131  4233 solver.cpp:243] Iteration 82700, loss = 0.225385
I1016 05:47:50.749179  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.261387 (* 1 = 0.261387 loss)
I1016 05:47:50.749186  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0384321 (* 1 = 0.0384321 loss)
I1016 05:47:50.749191  4233 sgd_solver.cpp:138] Iteration 82700, lr = 0.000125
I1016 05:48:50.871789  4233 solver.cpp:243] Iteration 82800, loss = 0.245443
I1016 05:48:50.871837  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.155934 (* 1 = 0.155934 loss)
I1016 05:48:50.871843  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314682 (* 1 = 0.0314682 loss)
I1016 05:48:50.871850  4233 sgd_solver.cpp:138] Iteration 82800, lr = 0.000125
I1016 05:49:50.456936  4233 solver.cpp:243] Iteration 82900, loss = 0.346119
I1016 05:49:50.456984  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.200421 (* 1 = 0.200421 loss)
I1016 05:49:50.456990  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.032452 (* 1 = 0.032452 loss)
I1016 05:49:50.456995  4233 sgd_solver.cpp:138] Iteration 82900, lr = 0.000125
I1016 05:50:49.203164  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_83000.caffemodel
I1016 05:50:49.439075  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_83000.solverstate
I1016 05:50:50.016289  4233 solver.cpp:243] Iteration 83000, loss = 0.300419
I1016 05:50:50.016319  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.447958 (* 1 = 0.447958 loss)
I1016 05:50:50.016325  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0514091 (* 1 = 0.0514091 loss)
I1016 05:50:50.016331  4233 sgd_solver.cpp:138] Iteration 83000, lr = 0.000125
I1016 05:51:48.353731  4233 solver.cpp:243] Iteration 83100, loss = 0.223876
I1016 05:51:48.353762  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.117066 (* 1 = 0.117066 loss)
I1016 05:51:48.353768  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413373 (* 1 = 0.0413373 loss)
I1016 05:51:48.353775  4233 sgd_solver.cpp:138] Iteration 83100, lr = 0.000125
I1016 05:52:47.958551  4233 solver.cpp:243] Iteration 83200, loss = 0.173377
I1016 05:52:47.958598  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.147602 (* 1 = 0.147602 loss)
I1016 05:52:47.958604  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0376534 (* 1 = 0.0376534 loss)
I1016 05:52:47.958611  4233 sgd_solver.cpp:138] Iteration 83200, lr = 0.000125
I1016 05:53:47.889648  4233 solver.cpp:243] Iteration 83300, loss = 0.156694
I1016 05:53:47.889694  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.125406 (* 1 = 0.125406 loss)
I1016 05:53:47.889700  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.046105 (* 1 = 0.046105 loss)
I1016 05:53:47.889706  4233 sgd_solver.cpp:138] Iteration 83300, lr = 0.000125
I1016 05:54:47.866827  4233 solver.cpp:243] Iteration 83400, loss = 0.235423
I1016 05:54:47.866875  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.100938 (* 1 = 0.100938 loss)
I1016 05:54:47.866881  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0291879 (* 1 = 0.0291879 loss)
I1016 05:54:47.866888  4233 sgd_solver.cpp:138] Iteration 83400, lr = 0.000125
I1016 05:55:46.422319  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_83500.caffemodel
I1016 05:55:46.678362  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_83500.solverstate
I1016 05:55:47.249521  4233 solver.cpp:243] Iteration 83500, loss = 0.277335
I1016 05:55:47.249568  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.175222 (* 1 = 0.175222 loss)
I1016 05:55:47.249574  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0329642 (* 1 = 0.0329642 loss)
I1016 05:55:47.249580  4233 sgd_solver.cpp:138] Iteration 83500, lr = 0.000125
I1016 05:56:45.261016  4233 solver.cpp:243] Iteration 83600, loss = 0.218387
I1016 05:56:45.261065  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0733041 (* 1 = 0.0733041 loss)
I1016 05:56:45.261071  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.03427 (* 1 = 0.03427 loss)
I1016 05:56:45.261078  4233 sgd_solver.cpp:138] Iteration 83600, lr = 0.000125
I1016 05:57:19.592264  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 05:57:45.151244  4233 solver.cpp:243] Iteration 83700, loss = 0.385383
I1016 05:57:45.151291  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.148756 (* 1 = 0.148756 loss)
I1016 05:57:45.151298  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0358958 (* 1 = 0.0358958 loss)
I1016 05:57:45.151302  4233 sgd_solver.cpp:138] Iteration 83700, lr = 0.000125
I1016 05:58:44.621783  4233 solver.cpp:243] Iteration 83800, loss = 0.313675
I1016 05:58:44.621834  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.38111 (* 1 = 0.38111 loss)
I1016 05:58:44.621840  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0318289 (* 1 = 0.0318289 loss)
I1016 05:58:44.621845  4233 sgd_solver.cpp:138] Iteration 83800, lr = 0.000125
I1016 05:59:44.839462  4233 solver.cpp:243] Iteration 83900, loss = 0.122893
I1016 05:59:44.839494  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0627307 (* 1 = 0.0627307 loss)
I1016 05:59:44.839502  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0332841 (* 1 = 0.0332841 loss)
I1016 05:59:44.839524  4233 sgd_solver.cpp:138] Iteration 83900, lr = 0.000125
I1016 06:00:43.390091  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_84000.caffemodel
I1016 06:00:43.616643  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_84000.solverstate
I1016 06:00:43.809777  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 06:02:21.464211  4233 solver.cpp:243] Iteration 84000, loss = 0.121902
I1016 06:02:21.464251  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0835678 (* 1 = 0.0835678 loss)
I1016 06:02:21.464257  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0383337 (* 1 = 0.0383337 loss)
I1016 06:02:21.464262  4233 sgd_solver.cpp:138] Iteration 84000, lr = 0.000125
I1016 06:03:19.506094  4233 solver.cpp:243] Iteration 84100, loss = 0.281002
I1016 06:03:19.506127  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.64394 (* 1 = 0.64394 loss)
I1016 06:03:19.506134  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0346085 (* 1 = 0.0346085 loss)
I1016 06:03:19.506139  4233 sgd_solver.cpp:138] Iteration 84100, lr = 0.000125
I1016 06:03:59.254405  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:04:18.477777  4233 solver.cpp:243] Iteration 84200, loss = 0.376503
I1016 06:04:18.477825  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.592989 (* 1 = 0.592989 loss)
I1016 06:04:18.477831  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.046705 (* 1 = 0.046705 loss)
I1016 06:04:18.477838  4233 sgd_solver.cpp:138] Iteration 84200, lr = 0.000125
I1016 06:05:17.836541  4233 solver.cpp:243] Iteration 84300, loss = 0.140351
I1016 06:05:17.836589  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.24887 (* 1 = 0.24887 loss)
I1016 06:05:17.836596  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0318067 (* 1 = 0.0318067 loss)
I1016 06:05:17.836601  4233 sgd_solver.cpp:138] Iteration 84300, lr = 0.000125
I1016 06:06:18.296030  4233 solver.cpp:243] Iteration 84400, loss = 0.18386
I1016 06:06:18.296077  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0874366 (* 1 = 0.0874366 loss)
I1016 06:06:18.296083  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412906 (* 1 = 0.0412906 loss)
I1016 06:06:18.296088  4233 sgd_solver.cpp:138] Iteration 84400, lr = 0.000125
I1016 06:07:17.631955  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_84500.caffemodel
I1016 06:07:18.422422  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_84500.solverstate
I1016 06:07:19.002918  4233 solver.cpp:243] Iteration 84500, loss = 0.325832
I1016 06:07:19.002964  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.5016 (* 1 = 0.5016 loss)
I1016 06:07:19.002970  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0487834 (* 1 = 0.0487834 loss)
I1016 06:07:19.002976  4233 sgd_solver.cpp:138] Iteration 84500, lr = 0.000125
I1016 06:08:17.246861  4233 solver.cpp:243] Iteration 84600, loss = 0.199186
I1016 06:08:17.246909  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0881035 (* 1 = 0.0881035 loss)
I1016 06:08:17.246915  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0280765 (* 1 = 0.0280765 loss)
I1016 06:08:17.246922  4233 sgd_solver.cpp:138] Iteration 84600, lr = 0.000125
I1016 06:09:15.563063  4233 solver.cpp:243] Iteration 84700, loss = 0.341091
I1016 06:09:15.563112  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.256579 (* 1 = 0.256579 loss)
I1016 06:09:15.563118  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0360716 (* 1 = 0.0360716 loss)
I1016 06:09:15.563124  4233 sgd_solver.cpp:138] Iteration 84700, lr = 0.000125
I1016 06:10:15.277335  4233 solver.cpp:243] Iteration 84800, loss = 0.232802
I1016 06:10:15.277382  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0939886 (* 1 = 0.0939886 loss)
I1016 06:10:15.277390  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0305636 (* 1 = 0.0305636 loss)
I1016 06:10:15.277395  4233 sgd_solver.cpp:138] Iteration 84800, lr = 0.000125
I1016 06:11:14.928442  4233 solver.cpp:243] Iteration 84900, loss = 0.210185
I1016 06:11:14.928489  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.122208 (* 1 = 0.122208 loss)
I1016 06:11:14.928496  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0413757 (* 1 = 0.0413757 loss)
I1016 06:11:14.928501  4233 sgd_solver.cpp:138] Iteration 84900, lr = 0.000125
I1016 06:12:14.596182  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_85000.caffemodel
I1016 06:12:15.412829  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_85000.solverstate
I1016 06:12:15.988816  4233 solver.cpp:243] Iteration 85000, loss = 0.171609
I1016 06:12:15.988858  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.166332 (* 1 = 0.166332 loss)
I1016 06:12:15.988864  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0394357 (* 1 = 0.0394357 loss)
I1016 06:12:15.988869  4233 sgd_solver.cpp:138] Iteration 85000, lr = 0.000125
I1016 06:13:14.219938  4233 solver.cpp:243] Iteration 85100, loss = 0.44574
I1016 06:13:14.219985  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.185869 (* 1 = 0.185869 loss)
I1016 06:13:14.219990  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0461981 (* 1 = 0.0461981 loss)
I1016 06:13:14.219996  4233 sgd_solver.cpp:138] Iteration 85100, lr = 0.000125
I1016 06:14:00.973712  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:14:12.983139  4233 solver.cpp:243] Iteration 85200, loss = 0.217015
I1016 06:14:12.983186  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.401306 (* 1 = 0.401306 loss)
I1016 06:14:12.983191  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0364864 (* 1 = 0.0364864 loss)
I1016 06:14:12.983197  4233 sgd_solver.cpp:138] Iteration 85200, lr = 0.000125
I1016 06:15:12.417124  4233 solver.cpp:243] Iteration 85300, loss = 0.549036
I1016 06:15:12.417176  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.135383 (* 1 = 0.135383 loss)
I1016 06:15:12.417186  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0371751 (* 1 = 0.0371751 loss)
I1016 06:15:12.417192  4233 sgd_solver.cpp:138] Iteration 85300, lr = 0.000125
I1016 06:16:11.611438  4233 solver.cpp:243] Iteration 85400, loss = 0.369519
I1016 06:16:11.611469  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.241185 (* 1 = 0.241185 loss)
I1016 06:16:11.611475  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0345473 (* 1 = 0.0345473 loss)
I1016 06:16:11.611481  4233 sgd_solver.cpp:138] Iteration 85400, lr = 0.000125
I1016 06:17:11.129045  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_85500.caffemodel
I1016 06:17:11.361964  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_85500.solverstate
I1016 06:17:11.933856  4233 solver.cpp:243] Iteration 85500, loss = 0.149599
I1016 06:17:11.933885  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.139449 (* 1 = 0.139449 loss)
I1016 06:17:11.933892  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0396585 (* 1 = 0.0396585 loss)
I1016 06:17:11.933897  4233 sgd_solver.cpp:138] Iteration 85500, lr = 0.000125
I1016 06:18:11.497020  4233 solver.cpp:243] Iteration 85600, loss = 0.284235
I1016 06:18:11.497071  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.064654 (* 1 = 0.064654 loss)
I1016 06:18:11.497076  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0297538 (* 1 = 0.0297538 loss)
I1016 06:18:11.497081  4233 sgd_solver.cpp:138] Iteration 85600, lr = 0.000125
I1016 06:19:10.594002  4233 solver.cpp:243] Iteration 85700, loss = 0.334087
I1016 06:19:10.594039  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.148973 (* 1 = 0.148973 loss)
I1016 06:19:10.594048  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0285318 (* 1 = 0.0285318 loss)
I1016 06:19:10.594055  4233 sgd_solver.cpp:138] Iteration 85700, lr = 0.000125
I1016 06:20:09.018522  4233 solver.cpp:243] Iteration 85800, loss = 0.402987
I1016 06:20:09.018558  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.21002 (* 1 = 0.21002 loss)
I1016 06:20:09.018566  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0334753 (* 1 = 0.0334753 loss)
I1016 06:20:09.018573  4233 sgd_solver.cpp:138] Iteration 85800, lr = 0.000125
I1016 06:21:08.619511  4233 solver.cpp:243] Iteration 85900, loss = 0.210598
I1016 06:21:08.619547  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.07898 (* 1 = 0.07898 loss)
I1016 06:21:08.619571  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0272759 (* 1 = 0.0272759 loss)
I1016 06:21:08.619580  4233 sgd_solver.cpp:138] Iteration 85900, lr = 0.000125
I1016 06:22:07.914312  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_86000.caffemodel
I1016 06:22:08.725083  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_86000.solverstate
I1016 06:22:09.315871  4233 solver.cpp:243] Iteration 86000, loss = 0.218238
I1016 06:22:09.315917  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.101802 (* 1 = 0.101802 loss)
I1016 06:22:09.315923  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0300693 (* 1 = 0.0300693 loss)
I1016 06:22:09.315929  4233 sgd_solver.cpp:138] Iteration 86000, lr = 0.000125
I1016 06:23:08.782644  4233 solver.cpp:243] Iteration 86100, loss = 0.102104
I1016 06:23:08.782691  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0775935 (* 1 = 0.0775935 loss)
I1016 06:23:08.782696  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0276245 (* 1 = 0.0276245 loss)
I1016 06:23:08.782702  4233 sgd_solver.cpp:138] Iteration 86100, lr = 0.000125
I1016 06:23:59.036495  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:24:07.933704  4233 solver.cpp:243] Iteration 86200, loss = 0.206495
I1016 06:24:07.933768  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.171845 (* 1 = 0.171845 loss)
I1016 06:24:07.933773  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0401079 (* 1 = 0.0401079 loss)
I1016 06:24:07.933779  4233 sgd_solver.cpp:138] Iteration 86200, lr = 0.000125
I1016 06:25:06.324290  4233 solver.cpp:243] Iteration 86300, loss = 0.249219
I1016 06:25:06.324334  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0824667 (* 1 = 0.0824667 loss)
I1016 06:25:06.324342  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0330595 (* 1 = 0.0330595 loss)
I1016 06:25:06.324347  4233 sgd_solver.cpp:138] Iteration 86300, lr = 0.000125
I1016 06:26:06.108381  4233 solver.cpp:243] Iteration 86400, loss = 0.36878
I1016 06:26:06.108428  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.355055 (* 1 = 0.355055 loss)
I1016 06:26:06.108433  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0256754 (* 1 = 0.0256754 loss)
I1016 06:26:06.108439  4233 sgd_solver.cpp:138] Iteration 86400, lr = 0.000125
I1016 06:27:04.979591  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_86500.caffemodel
I1016 06:27:05.217849  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_86500.solverstate
I1016 06:27:05.798213  4233 solver.cpp:243] Iteration 86500, loss = 0.19007
I1016 06:27:05.798257  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.329546 (* 1 = 0.329546 loss)
I1016 06:27:05.798264  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0324907 (* 1 = 0.0324907 loss)
I1016 06:27:05.798269  4233 sgd_solver.cpp:138] Iteration 86500, lr = 0.000125
I1016 06:28:05.818310  4233 solver.cpp:243] Iteration 86600, loss = 0.177755
I1016 06:28:05.818358  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.199801 (* 1 = 0.199801 loss)
I1016 06:28:05.818365  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0350932 (* 1 = 0.0350932 loss)
I1016 06:28:05.818370  4233 sgd_solver.cpp:138] Iteration 86600, lr = 0.000125
I1016 06:29:05.700745  4233 solver.cpp:243] Iteration 86700, loss = 0.172143
I1016 06:29:05.700795  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.210182 (* 1 = 0.210182 loss)
I1016 06:29:05.700803  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0236754 (* 1 = 0.0236754 loss)
I1016 06:29:05.700806  4233 sgd_solver.cpp:138] Iteration 86700, lr = 0.000125
I1016 06:30:05.112682  4233 solver.cpp:243] Iteration 86800, loss = 0.451949
I1016 06:30:05.112730  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.14221 (* 1 = 0.14221 loss)
I1016 06:30:05.112735  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0381901 (* 1 = 0.0381901 loss)
I1016 06:30:05.112741  4233 sgd_solver.cpp:138] Iteration 86800, lr = 0.000125
I1016 06:31:03.868489  4233 solver.cpp:243] Iteration 86900, loss = 0.281034
I1016 06:31:03.868535  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0601393 (* 1 = 0.0601393 loss)
I1016 06:31:03.868541  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0392795 (* 1 = 0.0392795 loss)
I1016 06:31:03.868546  4233 sgd_solver.cpp:138] Iteration 86900, lr = 0.000125
I1016 06:32:02.687836  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_87000.caffemodel
I1016 06:32:02.912400  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_87000.solverstate
I1016 06:32:03.983745  4233 solver.cpp:243] Iteration 87000, loss = 0.114864
I1016 06:32:03.983788  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0276504 (* 1 = 0.0276504 loss)
I1016 06:32:03.983794  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0223647 (* 1 = 0.0223647 loss)
I1016 06:32:03.983800  4233 sgd_solver.cpp:138] Iteration 87000, lr = 0.000125
I1016 06:33:03.309186  4233 solver.cpp:243] Iteration 87100, loss = 0.213309
I1016 06:33:03.309233  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.305413 (* 1 = 0.305413 loss)
I1016 06:33:03.309239  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0384905 (* 1 = 0.0384905 loss)
I1016 06:33:03.309245  4233 sgd_solver.cpp:138] Iteration 87100, lr = 0.000125
I1016 06:33:58.783599  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:34:03.419528  4233 solver.cpp:243] Iteration 87200, loss = 0.155553
I1016 06:34:03.419564  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0870249 (* 1 = 0.0870249 loss)
I1016 06:34:03.419587  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0300321 (* 1 = 0.0300321 loss)
I1016 06:34:03.419595  4233 sgd_solver.cpp:138] Iteration 87200, lr = 0.000125
I1016 06:35:02.553941  4233 solver.cpp:243] Iteration 87300, loss = 0.208057
I1016 06:35:02.553975  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.163033 (* 1 = 0.163033 loss)
I1016 06:35:02.553982  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0337613 (* 1 = 0.0337613 loss)
I1016 06:35:02.553987  4233 sgd_solver.cpp:138] Iteration 87300, lr = 0.000125
I1016 06:36:00.761026  4233 solver.cpp:243] Iteration 87400, loss = 0.187042
I1016 06:36:00.761073  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.535749 (* 1 = 0.535749 loss)
I1016 06:36:00.761080  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0389528 (* 1 = 0.0389528 loss)
I1016 06:36:00.761085  4233 sgd_solver.cpp:138] Iteration 87400, lr = 0.000125
I1016 06:37:00.221516  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_87500.caffemodel
I1016 06:37:00.448056  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_87500.solverstate
I1016 06:37:01.019726  4233 solver.cpp:243] Iteration 87500, loss = 0.214056
I1016 06:37:01.019773  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.278821 (* 1 = 0.278821 loss)
I1016 06:37:01.019779  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.041094 (* 1 = 0.041094 loss)
I1016 06:37:01.019784  4233 sgd_solver.cpp:138] Iteration 87500, lr = 0.000125
I1016 06:38:00.306361  4233 solver.cpp:243] Iteration 87600, loss = 0.219979
I1016 06:38:00.306411  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.452264 (* 1 = 0.452264 loss)
I1016 06:38:00.306417  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0398948 (* 1 = 0.0398948 loss)
I1016 06:38:00.306424  4233 sgd_solver.cpp:138] Iteration 87600, lr = 0.000125
I1016 06:39:00.632038  4233 solver.cpp:243] Iteration 87700, loss = 0.163713
I1016 06:39:00.632086  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.364085 (* 1 = 0.364085 loss)
I1016 06:39:00.632091  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0479166 (* 1 = 0.0479166 loss)
I1016 06:39:00.632097  4233 sgd_solver.cpp:138] Iteration 87700, lr = 0.000125
I1016 06:39:59.788045  4233 solver.cpp:243] Iteration 87800, loss = 0.338833
I1016 06:39:59.788091  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.69836 (* 1 = 1.69836 loss)
I1016 06:39:59.788097  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0375166 (* 1 = 0.0375166 loss)
I1016 06:39:59.788103  4233 sgd_solver.cpp:138] Iteration 87800, lr = 0.000125
I1016 06:40:58.735177  4233 solver.cpp:243] Iteration 87900, loss = 0.215186
I1016 06:40:58.735208  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.127907 (* 1 = 0.127907 loss)
I1016 06:40:58.735214  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.032656 (* 1 = 0.032656 loss)
I1016 06:40:58.735220  4233 sgd_solver.cpp:138] Iteration 87900, lr = 0.000125
I1016 06:41:57.395702  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_88000.caffemodel
I1016 06:41:57.648461  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_88000.solverstate
I1016 06:41:57.853416  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 06:42:16.583969  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 06:42:22.019026  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 06:42:36.161001  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:43:36.443150  4233 solver.cpp:243] Iteration 88000, loss = 1.04966
I1016 06:43:36.443184  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.975918 (* 1 = 0.975918 loss)
I1016 06:43:36.443190  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0737472 (* 1 = 0.0737472 loss)
I1016 06:43:36.443195  4233 sgd_solver.cpp:138] Iteration 88000, lr = 0.000125
I1016 06:44:34.629395  4233 solver.cpp:243] Iteration 88100, loss = 0.160188
I1016 06:44:34.629441  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0489059 (* 1 = 0.0489059 loss)
I1016 06:44:34.629447  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314266 (* 1 = 0.0314266 loss)
I1016 06:44:34.629452  4233 sgd_solver.cpp:138] Iteration 88100, lr = 0.000125
I1016 06:45:34.574203  4233 solver.cpp:243] Iteration 88200, loss = 0.148641
I1016 06:45:34.574237  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0360745 (* 1 = 0.0360745 loss)
I1016 06:45:34.574244  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0290962 (* 1 = 0.0290962 loss)
I1016 06:45:34.574249  4233 sgd_solver.cpp:138] Iteration 88200, lr = 0.000125
I1016 06:46:34.472124  4233 solver.cpp:243] Iteration 88300, loss = 0.367103
I1016 06:46:34.472156  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.544522 (* 1 = 0.544522 loss)
I1016 06:46:34.472162  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0348498 (* 1 = 0.0348498 loss)
I1016 06:46:34.472167  4233 sgd_solver.cpp:138] Iteration 88300, lr = 0.000125
I1016 06:47:33.723711  4233 solver.cpp:243] Iteration 88400, loss = 0.294791
I1016 06:47:33.723745  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.4374 (* 1 = 0.4374 loss)
I1016 06:47:33.723769  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0378863 (* 1 = 0.0378863 loss)
I1016 06:47:33.723778  4233 sgd_solver.cpp:138] Iteration 88400, lr = 0.000125
I1016 06:48:31.749850  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_88500.caffemodel
I1016 06:48:32.541846  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_88500.solverstate
I1016 06:48:33.171370  4233 solver.cpp:243] Iteration 88500, loss = 0.389356
I1016 06:48:33.171414  4233 solver.cpp:259]     Train net output #0: mbox_loss = 1.01203 (* 1 = 1.01203 loss)
I1016 06:48:33.171420  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0580821 (* 1 = 0.0580821 loss)
I1016 06:48:33.171427  4233 sgd_solver.cpp:138] Iteration 88500, lr = 0.000125
I1016 06:49:32.010538  4233 solver.cpp:243] Iteration 88600, loss = 0.186576
I1016 06:49:32.010583  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.205013 (* 1 = 0.205013 loss)
I1016 06:49:32.010589  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0340854 (* 1 = 0.0340854 loss)
I1016 06:49:32.010596  4233 sgd_solver.cpp:138] Iteration 88600, lr = 0.000125
I1016 06:50:31.796396  4233 solver.cpp:243] Iteration 88700, loss = 0.179059
I1016 06:50:31.796430  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.114137 (* 1 = 0.114137 loss)
I1016 06:50:31.796439  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0359277 (* 1 = 0.0359277 loss)
I1016 06:50:31.796447  4233 sgd_solver.cpp:138] Iteration 88700, lr = 0.000125
I1016 06:50:38.481734  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 06:51:31.888417  4233 solver.cpp:243] Iteration 88800, loss = 0.141641
I1016 06:51:31.888451  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0722416 (* 1 = 0.0722416 loss)
I1016 06:51:31.888461  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.029607 (* 1 = 0.029607 loss)
I1016 06:51:31.888468  4233 sgd_solver.cpp:138] Iteration 88800, lr = 0.000125
I1016 06:52:30.969146  4233 solver.cpp:243] Iteration 88900, loss = 0.197311
I1016 06:52:30.969179  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.100744 (* 1 = 0.100744 loss)
I1016 06:52:30.969188  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0309101 (* 1 = 0.0309101 loss)
I1016 06:52:30.969195  4233 sgd_solver.cpp:138] Iteration 88900, lr = 0.000125
I1016 06:53:29.017282  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_89000.caffemodel
I1016 06:53:29.793794  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_89000.solverstate
I1016 06:53:30.366639  4233 solver.cpp:243] Iteration 89000, loss = 0.277978
I1016 06:53:30.366681  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.142751 (* 1 = 0.142751 loss)
I1016 06:53:30.366690  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0326667 (* 1 = 0.0326667 loss)
I1016 06:53:30.366699  4233 sgd_solver.cpp:138] Iteration 89000, lr = 0.000125
I1016 06:54:29.191275  4233 solver.cpp:243] Iteration 89100, loss = 0.254089
I1016 06:54:29.191323  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.298438 (* 1 = 0.298438 loss)
I1016 06:54:29.191329  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0352605 (* 1 = 0.0352605 loss)
I1016 06:54:29.191334  4233 sgd_solver.cpp:138] Iteration 89100, lr = 0.000125
I1016 06:55:28.383364  4233 solver.cpp:243] Iteration 89200, loss = 0.212028
I1016 06:55:28.383410  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0820352 (* 1 = 0.0820352 loss)
I1016 06:55:28.383416  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0345166 (* 1 = 0.0345166 loss)
I1016 06:55:28.383421  4233 sgd_solver.cpp:138] Iteration 89200, lr = 0.000125
I1016 06:56:28.545714  4233 solver.cpp:243] Iteration 89300, loss = 0.22944
I1016 06:56:28.545761  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0535495 (* 1 = 0.0535495 loss)
I1016 06:56:28.545768  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0331142 (* 1 = 0.0331142 loss)
I1016 06:56:28.545773  4233 sgd_solver.cpp:138] Iteration 89300, lr = 0.000125
I1016 06:57:28.140405  4233 solver.cpp:243] Iteration 89400, loss = 0.315341
I1016 06:57:28.140452  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.213495 (* 1 = 0.213495 loss)
I1016 06:57:28.140460  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0293589 (* 1 = 0.0293589 loss)
I1016 06:57:28.140465  4233 sgd_solver.cpp:138] Iteration 89400, lr = 0.000125
I1016 06:58:26.710860  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_89500.caffemodel
I1016 06:58:26.933091  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_89500.solverstate
I1016 06:58:27.495570  4233 solver.cpp:243] Iteration 89500, loss = 0.246319
I1016 06:58:27.495601  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.552671 (* 1 = 0.552671 loss)
I1016 06:58:27.495625  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0439519 (* 1 = 0.0439519 loss)
I1016 06:58:27.495633  4233 sgd_solver.cpp:138] Iteration 89500, lr = 0.000125
I1016 06:59:25.804292  4233 solver.cpp:243] Iteration 89600, loss = 0.207687
I1016 06:59:25.804327  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.155822 (* 1 = 0.155822 loss)
I1016 06:59:25.804337  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0338081 (* 1 = 0.0338081 loss)
I1016 06:59:25.804358  4233 sgd_solver.cpp:138] Iteration 89600, lr = 0.000125
I1016 07:00:25.430882  4233 solver.cpp:243] Iteration 89700, loss = 0.209295
I1016 07:00:25.430927  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0756336 (* 1 = 0.0756336 loss)
I1016 07:00:25.430934  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0358062 (* 1 = 0.0358062 loss)
I1016 07:00:25.430939  4233 sgd_solver.cpp:138] Iteration 89700, lr = 0.000125
I1016 07:00:36.824964  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:01:25.269712  4233 solver.cpp:243] Iteration 89800, loss = 0.168096
I1016 07:01:25.269760  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.103763 (* 1 = 0.103763 loss)
I1016 07:01:25.269767  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0309453 (* 1 = 0.0309453 loss)
I1016 07:01:25.269773  4233 sgd_solver.cpp:138] Iteration 89800, lr = 0.000125
I1016 07:02:25.191375  4233 solver.cpp:243] Iteration 89900, loss = 0.206034
I1016 07:02:25.191423  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.27834 (* 1 = 0.27834 loss)
I1016 07:02:25.191431  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0346606 (* 1 = 0.0346606 loss)
I1016 07:02:25.191437  4233 sgd_solver.cpp:138] Iteration 89900, lr = 0.000125
I1016 07:03:23.678540  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_90000.caffemodel
I1016 07:03:23.896545  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_90000.solverstate
I1016 07:03:25.057297  4233 solver.cpp:243] Iteration 90000, loss = 0.24297
I1016 07:03:25.057328  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.220679 (* 1 = 0.220679 loss)
I1016 07:03:25.057338  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0306044 (* 1 = 0.0306044 loss)
I1016 07:03:25.057361  4233 sgd_solver.cpp:138] Iteration 90000, lr = 0.000125
I1016 07:04:22.407683  4233 solver.cpp:243] Iteration 90100, loss = 0.216664
I1016 07:04:22.407719  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0730441 (* 1 = 0.0730441 loss)
I1016 07:04:22.407743  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0297681 (* 1 = 0.0297681 loss)
I1016 07:04:22.407752  4233 sgd_solver.cpp:138] Iteration 90100, lr = 0.000125
I1016 07:05:22.241093  4233 solver.cpp:243] Iteration 90200, loss = 0.357405
I1016 07:05:22.241142  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.351807 (* 1 = 0.351807 loss)
I1016 07:05:22.241147  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0349825 (* 1 = 0.0349825 loss)
I1016 07:05:22.241153  4233 sgd_solver.cpp:138] Iteration 90200, lr = 0.000125
I1016 07:06:21.701403  4233 solver.cpp:243] Iteration 90300, loss = 0.262991
I1016 07:06:21.701452  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.109703 (* 1 = 0.109703 loss)
I1016 07:06:21.701457  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0324906 (* 1 = 0.0324906 loss)
I1016 07:06:21.701463  4233 sgd_solver.cpp:138] Iteration 90300, lr = 0.000125
I1016 07:07:21.947204  4233 solver.cpp:243] Iteration 90400, loss = 0.113806
I1016 07:07:21.947252  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0640761 (* 1 = 0.0640761 loss)
I1016 07:07:21.947257  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0277604 (* 1 = 0.0277604 loss)
I1016 07:07:21.947263  4233 sgd_solver.cpp:138] Iteration 90400, lr = 0.000125
I1016 07:08:20.665334  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_90500.caffemodel
I1016 07:08:20.894191  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_90500.solverstate
I1016 07:08:21.489619  4233 solver.cpp:243] Iteration 90500, loss = 0.19816
I1016 07:08:21.489665  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.166319 (* 1 = 0.166319 loss)
I1016 07:08:21.489671  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0378869 (* 1 = 0.0378869 loss)
I1016 07:08:21.489676  4233 sgd_solver.cpp:138] Iteration 90500, lr = 0.000125
I1016 07:09:20.339794  4233 solver.cpp:243] Iteration 90600, loss = 0.239753
I1016 07:09:20.339841  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.199746 (* 1 = 0.199746 loss)
I1016 07:09:20.339848  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0490736 (* 1 = 0.0490736 loss)
I1016 07:09:20.339854  4233 sgd_solver.cpp:138] Iteration 90600, lr = 0.000125
I1016 07:10:19.300590  4233 solver.cpp:243] Iteration 90700, loss = 0.287974
I1016 07:10:19.300637  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.403413 (* 1 = 0.403413 loss)
I1016 07:10:19.300642  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0546072 (* 1 = 0.0546072 loss)
I1016 07:10:19.300647  4233 sgd_solver.cpp:138] Iteration 90700, lr = 0.000125
I1016 07:10:35.563096  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:11:18.717702  4233 solver.cpp:243] Iteration 90800, loss = 0.107934
I1016 07:11:18.717747  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.126136 (* 1 = 0.126136 loss)
I1016 07:11:18.717754  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0322861 (* 1 = 0.0322861 loss)
I1016 07:11:18.717759  4233 sgd_solver.cpp:138] Iteration 90800, lr = 0.000125
I1016 07:12:18.639243  4233 solver.cpp:243] Iteration 90900, loss = 0.166451
I1016 07:12:18.639276  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.165994 (* 1 = 0.165994 loss)
I1016 07:12:18.639282  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0414006 (* 1 = 0.0414006 loss)
I1016 07:12:18.639287  4233 sgd_solver.cpp:138] Iteration 90900, lr = 0.000125
I1016 07:13:17.954181  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_91000.caffemodel
I1016 07:13:18.191354  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_91000.solverstate
I1016 07:13:18.772874  4233 solver.cpp:243] Iteration 91000, loss = 0.258273
I1016 07:13:18.772918  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.336584 (* 1 = 0.336584 loss)
I1016 07:13:18.772925  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0347069 (* 1 = 0.0347069 loss)
I1016 07:13:18.772930  4233 sgd_solver.cpp:138] Iteration 91000, lr = 0.000125
I1016 07:14:17.522840  4233 solver.cpp:243] Iteration 91100, loss = 0.2053
I1016 07:14:17.522889  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0927173 (* 1 = 0.0927173 loss)
I1016 07:14:17.522897  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0271028 (* 1 = 0.0271028 loss)
I1016 07:14:17.522902  4233 sgd_solver.cpp:138] Iteration 91100, lr = 0.000125
I1016 07:15:15.870963  4233 solver.cpp:243] Iteration 91200, loss = 0.297519
I1016 07:15:15.871011  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0863998 (* 1 = 0.0863998 loss)
I1016 07:15:15.871017  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0312846 (* 1 = 0.0312846 loss)
I1016 07:15:15.871022  4233 sgd_solver.cpp:138] Iteration 91200, lr = 0.000125
I1016 07:16:15.586127  4233 solver.cpp:243] Iteration 91300, loss = 0.226457
I1016 07:16:15.586187  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0830612 (* 1 = 0.0830612 loss)
I1016 07:16:15.586194  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0364588 (* 1 = 0.0364588 loss)
I1016 07:16:15.586199  4233 sgd_solver.cpp:138] Iteration 91300, lr = 0.000125
I1016 07:17:15.209993  4233 solver.cpp:243] Iteration 91400, loss = 0.20526
I1016 07:17:15.210026  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0822379 (* 1 = 0.0822379 loss)
I1016 07:17:15.210032  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0401072 (* 1 = 0.0401072 loss)
I1016 07:17:15.210037  4233 sgd_solver.cpp:138] Iteration 91400, lr = 0.000125
I1016 07:18:14.815402  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_91500.caffemodel
I1016 07:18:15.639983  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_91500.solverstate
I1016 07:18:16.226946  4233 solver.cpp:243] Iteration 91500, loss = 0.14365
I1016 07:18:16.226977  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.103136 (* 1 = 0.103136 loss)
I1016 07:18:16.226984  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0437265 (* 1 = 0.0437265 loss)
I1016 07:18:16.226989  4233 sgd_solver.cpp:138] Iteration 91500, lr = 0.000125
I1016 07:19:14.397543  4233 solver.cpp:243] Iteration 91600, loss = 0.423623
I1016 07:19:14.397594  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.118835 (* 1 = 0.118835 loss)
I1016 07:19:14.397600  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0311048 (* 1 = 0.0311048 loss)
I1016 07:19:14.397606  4233 sgd_solver.cpp:138] Iteration 91600, lr = 0.000125
I1016 07:20:13.108101  4233 solver.cpp:243] Iteration 91700, loss = 0.159995
I1016 07:20:13.108134  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.126407 (* 1 = 0.126407 loss)
I1016 07:20:13.108139  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0252921 (* 1 = 0.0252921 loss)
I1016 07:20:13.108144  4233 sgd_solver.cpp:138] Iteration 91700, lr = 0.000125
I1016 07:20:33.473160  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:21:12.558552  4233 solver.cpp:243] Iteration 91800, loss = 0.520409
I1016 07:21:12.558598  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.377635 (* 1 = 0.377635 loss)
I1016 07:21:12.558604  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0400776 (* 1 = 0.0400776 loss)
I1016 07:21:12.558611  4233 sgd_solver.cpp:138] Iteration 91800, lr = 0.000125
I1016 07:22:11.732049  4233 solver.cpp:243] Iteration 91900, loss = 0.326938
I1016 07:22:11.732096  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.319117 (* 1 = 0.319117 loss)
I1016 07:22:11.732102  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0277815 (* 1 = 0.0277815 loss)
I1016 07:22:11.732108  4233 sgd_solver.cpp:138] Iteration 91900, lr = 0.000125
I1016 07:23:11.150408  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_92000.caffemodel
I1016 07:23:11.914388  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_92000.solverstate
I1016 07:23:12.117758  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 07:24:49.783795  4233 solver.cpp:243] Iteration 92000, loss = 0.178436
I1016 07:24:49.783833  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.138848 (* 1 = 0.138848 loss)
I1016 07:24:49.783838  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0395872 (* 1 = 0.0395872 loss)
I1016 07:24:49.783844  4233 sgd_solver.cpp:138] Iteration 92000, lr = 0.000125
I1016 07:25:48.537673  4233 solver.cpp:243] Iteration 92100, loss = 0.261737
I1016 07:25:48.537720  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.203204 (* 1 = 0.203204 loss)
I1016 07:25:48.537727  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0309413 (* 1 = 0.0309413 loss)
I1016 07:25:48.537732  4233 sgd_solver.cpp:138] Iteration 92100, lr = 0.000125
I1016 07:26:47.617503  4233 solver.cpp:243] Iteration 92200, loss = 0.30391
I1016 07:26:47.617550  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.121211 (* 1 = 0.121211 loss)
I1016 07:26:47.617557  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0320492 (* 1 = 0.0320492 loss)
I1016 07:26:47.617563  4233 sgd_solver.cpp:138] Iteration 92200, lr = 0.000125
I1016 07:27:13.851670  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:27:46.033054  4233 solver.cpp:243] Iteration 92300, loss = 0.372874
I1016 07:27:46.033089  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.13131 (* 1 = 0.13131 loss)
I1016 07:27:46.033097  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0673901 (* 1 = 0.0673901 loss)
I1016 07:27:46.033120  4233 sgd_solver.cpp:138] Iteration 92300, lr = 0.000125
I1016 07:28:45.748760  4233 solver.cpp:243] Iteration 92400, loss = 0.235333
I1016 07:28:45.748793  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.613151 (* 1 = 0.613151 loss)
I1016 07:28:45.748801  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0326426 (* 1 = 0.0326426 loss)
I1016 07:28:45.748809  4233 sgd_solver.cpp:138] Iteration 92400, lr = 0.000125
I1016 07:29:45.030519  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_92500.caffemodel
I1016 07:29:45.866602  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_92500.solverstate
I1016 07:29:46.450181  4233 solver.cpp:243] Iteration 92500, loss = 0.191143
I1016 07:29:46.450223  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.268257 (* 1 = 0.268257 loss)
I1016 07:29:46.450228  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0445766 (* 1 = 0.0445766 loss)
I1016 07:29:46.450234  4233 sgd_solver.cpp:138] Iteration 92500, lr = 0.000125
I1016 07:30:45.617172  4233 solver.cpp:243] Iteration 92600, loss = 0.0937875
I1016 07:30:45.617219  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0332191 (* 1 = 0.0332191 loss)
I1016 07:30:45.617225  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0253833 (* 1 = 0.0253833 loss)
I1016 07:30:45.617231  4233 sgd_solver.cpp:138] Iteration 92600, lr = 0.000125
I1016 07:31:44.675340  4233 solver.cpp:243] Iteration 92700, loss = 0.19256
I1016 07:31:44.675387  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.302179 (* 1 = 0.302179 loss)
I1016 07:31:44.675393  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0424737 (* 1 = 0.0424737 loss)
I1016 07:31:44.675400  4233 sgd_solver.cpp:138] Iteration 92700, lr = 0.000125
I1016 07:32:43.007911  4233 solver.cpp:243] Iteration 92800, loss = 0.229456
I1016 07:32:43.007959  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.227261 (* 1 = 0.227261 loss)
I1016 07:32:43.007966  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0312373 (* 1 = 0.0312373 loss)
I1016 07:32:43.007972  4233 sgd_solver.cpp:138] Iteration 92800, lr = 0.000125
I1016 07:33:42.580451  4233 solver.cpp:243] Iteration 92900, loss = 0.315519
I1016 07:33:42.580483  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.196445 (* 1 = 0.196445 loss)
I1016 07:33:42.580489  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0295766 (* 1 = 0.0295766 loss)
I1016 07:33:42.580497  4233 sgd_solver.cpp:138] Iteration 92900, lr = 0.000125
I1016 07:34:41.344774  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_93000.caffemodel
I1016 07:34:42.121670  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_93000.solverstate
I1016 07:34:42.683755  4233 solver.cpp:243] Iteration 93000, loss = 0.176983
I1016 07:34:42.683802  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.117447 (* 1 = 0.117447 loss)
I1016 07:34:42.683809  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0378584 (* 1 = 0.0378584 loss)
I1016 07:34:42.683815  4233 sgd_solver.cpp:138] Iteration 93000, lr = 0.000125
I1016 07:35:42.498883  4233 solver.cpp:243] Iteration 93100, loss = 0.154425
I1016 07:35:42.498931  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0561235 (* 1 = 0.0561235 loss)
I1016 07:35:42.498937  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0364262 (* 1 = 0.0364262 loss)
I1016 07:35:42.498942  4233 sgd_solver.cpp:138] Iteration 93100, lr = 0.000125
I1016 07:36:41.778071  4233 solver.cpp:243] Iteration 93200, loss = 0.143558
I1016 07:36:41.778102  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0541326 (* 1 = 0.0541326 loss)
I1016 07:36:41.778108  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.026841 (* 1 = 0.026841 loss)
I1016 07:36:41.778115  4233 sgd_solver.cpp:138] Iteration 93200, lr = 0.000125
I1016 07:37:14.561897  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:37:40.994778  4233 solver.cpp:243] Iteration 93300, loss = 0.412492
I1016 07:37:40.994827  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.506346 (* 1 = 0.506346 loss)
I1016 07:37:40.994833  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0412187 (* 1 = 0.0412187 loss)
I1016 07:37:40.994838  4233 sgd_solver.cpp:138] Iteration 93300, lr = 0.000125
I1016 07:38:39.613044  4233 solver.cpp:243] Iteration 93400, loss = 0.248458
I1016 07:38:39.613090  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.073535 (* 1 = 0.073535 loss)
I1016 07:38:39.613096  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0310593 (* 1 = 0.0310593 loss)
I1016 07:38:39.613102  4233 sgd_solver.cpp:138] Iteration 93400, lr = 0.000125
I1016 07:39:38.509585  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_93500.caffemodel
I1016 07:39:39.306919  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_93500.solverstate
I1016 07:39:39.912570  4233 solver.cpp:243] Iteration 93500, loss = 0.115391
I1016 07:39:39.912616  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0542247 (* 1 = 0.0542247 loss)
I1016 07:39:39.912622  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0306729 (* 1 = 0.0306729 loss)
I1016 07:39:39.912627  4233 sgd_solver.cpp:138] Iteration 93500, lr = 0.000125
I1016 07:40:39.366058  4233 solver.cpp:243] Iteration 93600, loss = 0.180698
I1016 07:40:39.366089  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.111599 (* 1 = 0.111599 loss)
I1016 07:40:39.366096  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0527389 (* 1 = 0.0527389 loss)
I1016 07:40:39.366101  4233 sgd_solver.cpp:138] Iteration 93600, lr = 0.000125
I1016 07:41:39.610366  4233 solver.cpp:243] Iteration 93700, loss = 0.157433
I1016 07:41:39.610402  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.111431 (* 1 = 0.111431 loss)
I1016 07:41:39.610410  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0294312 (* 1 = 0.0294312 loss)
I1016 07:41:39.610433  4233 sgd_solver.cpp:138] Iteration 93700, lr = 0.000125
I1016 07:42:38.689054  4233 solver.cpp:243] Iteration 93800, loss = 0.188721
I1016 07:42:38.689088  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.171756 (* 1 = 0.171756 loss)
I1016 07:42:38.689112  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0311043 (* 1 = 0.0311043 loss)
I1016 07:42:38.689121  4233 sgd_solver.cpp:138] Iteration 93800, lr = 0.000125
I1016 07:43:36.847442  4233 solver.cpp:243] Iteration 93900, loss = 0.133533
I1016 07:43:36.847491  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.071204 (* 1 = 0.071204 loss)
I1016 07:43:36.847496  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0382172 (* 1 = 0.0382172 loss)
I1016 07:43:36.847502  4233 sgd_solver.cpp:138] Iteration 93900, lr = 0.000125
I1016 07:44:36.205509  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_94000.caffemodel
I1016 07:44:36.436617  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_94000.solverstate
I1016 07:44:37.351631  4233 solver.cpp:243] Iteration 94000, loss = 0.220107
I1016 07:44:37.351677  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.102503 (* 1 = 0.102503 loss)
I1016 07:44:37.351685  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0272522 (* 1 = 0.0272522 loss)
I1016 07:44:37.351689  4233 sgd_solver.cpp:138] Iteration 94000, lr = 0.000125
I1016 07:45:36.373857  4233 solver.cpp:243] Iteration 94100, loss = 0.178602
I1016 07:45:36.373890  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.164207 (* 1 = 0.164207 loss)
I1016 07:45:36.373900  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.00612569 (* 1 = 0.00612569 loss)
I1016 07:45:36.373908  4233 sgd_solver.cpp:138] Iteration 94100, lr = 0.000125
I1016 07:46:36.630620  4233 solver.cpp:243] Iteration 94200, loss = 0.125535
I1016 07:46:36.630667  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.155227 (* 1 = 0.155227 loss)
I1016 07:46:36.630674  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0318097 (* 1 = 0.0318097 loss)
I1016 07:46:36.630681  4233 sgd_solver.cpp:138] Iteration 94200, lr = 0.000125
I1016 07:47:14.845074  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:47:35.796861  4233 solver.cpp:243] Iteration 94300, loss = 0.156015
I1016 07:47:35.796908  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0248946 (* 1 = 0.0248946 loss)
I1016 07:47:35.796914  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0598257 (* 1 = 0.0598257 loss)
I1016 07:47:35.796919  4233 sgd_solver.cpp:138] Iteration 94300, lr = 0.000125
I1016 07:48:34.711669  4233 solver.cpp:243] Iteration 94400, loss = 0.221958
I1016 07:48:34.711699  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0581321 (* 1 = 0.0581321 loss)
I1016 07:48:34.711705  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0273666 (* 1 = 0.0273666 loss)
I1016 07:48:34.711711  4233 sgd_solver.cpp:138] Iteration 94400, lr = 0.000125
I1016 07:49:33.271257  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_94500.caffemodel
I1016 07:49:33.517101  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_94500.solverstate
I1016 07:49:34.115689  4233 solver.cpp:243] Iteration 94500, loss = 0.450146
I1016 07:49:34.115720  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.389627 (* 1 = 0.389627 loss)
I1016 07:49:34.115730  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0635163 (* 1 = 0.0635163 loss)
I1016 07:49:34.115737  4233 sgd_solver.cpp:138] Iteration 94500, lr = 0.000125
I1016 07:50:33.254765  4233 solver.cpp:243] Iteration 94600, loss = 0.155941
I1016 07:50:33.254811  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.120383 (* 1 = 0.120383 loss)
I1016 07:50:33.254817  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0316786 (* 1 = 0.0316786 loss)
I1016 07:50:33.254822  4233 sgd_solver.cpp:138] Iteration 94600, lr = 0.000125
I1016 07:51:33.271692  4233 solver.cpp:243] Iteration 94700, loss = 0.137519
I1016 07:51:33.271741  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0218005 (* 1 = 0.0218005 loss)
I1016 07:51:33.271747  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0293519 (* 1 = 0.0293519 loss)
I1016 07:51:33.271754  4233 sgd_solver.cpp:138] Iteration 94700, lr = 0.000125
I1016 07:52:33.048947  4233 solver.cpp:243] Iteration 94800, loss = 0.319198
I1016 07:52:33.048995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.112231 (* 1 = 0.112231 loss)
I1016 07:52:33.049000  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0367877 (* 1 = 0.0367877 loss)
I1016 07:52:33.049006  4233 sgd_solver.cpp:138] Iteration 94800, lr = 0.000125
I1016 07:53:32.076897  4233 solver.cpp:243] Iteration 94900, loss = 0.242597
I1016 07:53:32.076943  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0978956 (* 1 = 0.0978956 loss)
I1016 07:53:32.076949  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0444212 (* 1 = 0.0444212 loss)
I1016 07:53:32.076954  4233 sgd_solver.cpp:138] Iteration 94900, lr = 0.000125
I1016 07:54:29.971226  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_95000.caffemodel
I1016 07:54:30.199347  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_95000.solverstate
I1016 07:54:30.775686  4233 solver.cpp:243] Iteration 95000, loss = 0.267312
I1016 07:54:30.775732  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.51564 (* 1 = 0.51564 loss)
I1016 07:54:30.775738  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0391704 (* 1 = 0.0391704 loss)
I1016 07:54:30.775743  4233 sgd_solver.cpp:138] Iteration 95000, lr = 0.000125
I1016 07:55:30.179180  4233 solver.cpp:243] Iteration 95100, loss = 0.128562
I1016 07:55:30.179215  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.273326 (* 1 = 0.273326 loss)
I1016 07:55:30.179221  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0280353 (* 1 = 0.0280353 loss)
I1016 07:55:30.179226  4233 sgd_solver.cpp:138] Iteration 95100, lr = 0.000125
I1016 07:56:29.834058  4233 solver.cpp:243] Iteration 95200, loss = 0.193461
I1016 07:56:29.834092  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0333975 (* 1 = 0.0333975 loss)
I1016 07:56:29.834100  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0258709 (* 1 = 0.0258709 loss)
I1016 07:56:29.834107  4233 sgd_solver.cpp:138] Iteration 95200, lr = 0.000125
I1016 07:57:10.873960  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 07:57:29.896649  4233 solver.cpp:243] Iteration 95300, loss = 0.143955
I1016 07:57:29.896682  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0996085 (* 1 = 0.0996085 loss)
I1016 07:57:29.896687  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0254274 (* 1 = 0.0254274 loss)
I1016 07:57:29.896692  4233 sgd_solver.cpp:138] Iteration 95300, lr = 0.000125
I1016 07:58:28.991534  4233 solver.cpp:243] Iteration 95400, loss = 0.199966
I1016 07:58:28.991566  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.373106 (* 1 = 0.373106 loss)
I1016 07:58:28.991572  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0349135 (* 1 = 0.0349135 loss)
I1016 07:58:28.991577  4233 sgd_solver.cpp:138] Iteration 95400, lr = 0.000125
I1016 07:59:27.062132  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_95500.caffemodel
I1016 07:59:27.880723  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_95500.solverstate
I1016 07:59:28.467237  4233 solver.cpp:243] Iteration 95500, loss = 0.269921
I1016 07:59:28.467267  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0828418 (* 1 = 0.0828418 loss)
I1016 07:59:28.467272  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0331009 (* 1 = 0.0331009 loss)
I1016 07:59:28.467278  4233 sgd_solver.cpp:138] Iteration 95500, lr = 0.000125
I1016 08:00:27.211208  4233 solver.cpp:243] Iteration 95600, loss = 0.256933
I1016 08:00:27.211239  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.101702 (* 1 = 0.101702 loss)
I1016 08:00:27.211246  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0344584 (* 1 = 0.0344584 loss)
I1016 08:00:27.211251  4233 sgd_solver.cpp:138] Iteration 95600, lr = 0.000125
I1016 08:01:26.482749  4233 solver.cpp:243] Iteration 95700, loss = 0.242817
I1016 08:01:26.482780  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.243893 (* 1 = 0.243893 loss)
I1016 08:01:26.482786  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0242559 (* 1 = 0.0242559 loss)
I1016 08:01:26.482792  4233 sgd_solver.cpp:138] Iteration 95700, lr = 0.000125
I1016 08:02:26.583442  4233 solver.cpp:243] Iteration 95800, loss = 0.209112
I1016 08:02:26.583473  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0765534 (* 1 = 0.0765534 loss)
I1016 08:02:26.583479  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0256472 (* 1 = 0.0256472 loss)
I1016 08:02:26.583485  4233 sgd_solver.cpp:138] Iteration 95800, lr = 0.000125
I1016 08:03:26.310981  4233 solver.cpp:243] Iteration 95900, loss = 0.286982
I1016 08:03:26.311013  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0693841 (* 1 = 0.0693841 loss)
I1016 08:03:26.311019  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0277373 (* 1 = 0.0277373 loss)
I1016 08:03:26.311040  4233 sgd_solver.cpp:138] Iteration 95900, lr = 0.000125
I1016 08:04:25.044642  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_96000.caffemodel
I1016 08:04:25.824256  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_96000.solverstate
I1016 08:04:26.002714  4233 net.cpp:693] Ignoring source layer mbox_loss
I1016 08:05:19.932714  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 08:05:23.751606  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 08:05:29.197072  4233 detection_output_layer.cu:113] Couldn't find any detections
I1016 08:06:03.569064  4233 solver.cpp:243] Iteration 96000, loss = 0.215559
I1016 08:06:03.569099  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.181216 (* 1 = 0.181216 loss)
I1016 08:06:03.569105  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0343438 (* 1 = 0.0343438 loss)
I1016 08:06:03.569111  4233 sgd_solver.cpp:138] Iteration 96000, lr = 0.000125
I1016 08:07:01.067623  4233 solver.cpp:243] Iteration 96100, loss = 0.185522
I1016 08:07:01.067656  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0780158 (* 1 = 0.0780158 loss)
I1016 08:07:01.067662  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0321423 (* 1 = 0.0321423 loss)
I1016 08:07:01.067667  4233 sgd_solver.cpp:138] Iteration 96100, lr = 0.000125
I1016 08:08:00.710427  4233 solver.cpp:243] Iteration 96200, loss = 0.193129
I1016 08:08:00.710459  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0744934 (* 1 = 0.0744934 loss)
I1016 08:08:00.710465  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.033051 (* 1 = 0.033051 loss)
I1016 08:08:00.710470  4233 sgd_solver.cpp:138] Iteration 96200, lr = 0.000125
I1016 08:09:00.562784  4233 solver.cpp:243] Iteration 96300, loss = 0.143152
I1016 08:09:00.562817  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.111585 (* 1 = 0.111585 loss)
I1016 08:09:00.562824  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0332553 (* 1 = 0.0332553 loss)
I1016 08:09:00.562829  4233 sgd_solver.cpp:138] Iteration 96300, lr = 0.000125
I1016 08:10:00.534531  4233 solver.cpp:243] Iteration 96400, loss = 0.172916
I1016 08:10:00.534564  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.162274 (* 1 = 0.162274 loss)
I1016 08:10:00.534570  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0275378 (* 1 = 0.0275378 loss)
I1016 08:10:00.534591  4233 sgd_solver.cpp:138] Iteration 96400, lr = 0.000125
I1016 08:10:59.298988  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_96500.caffemodel
I1016 08:11:00.074576  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_96500.solverstate
I1016 08:11:00.670205  4233 solver.cpp:243] Iteration 96500, loss = 0.230876
I1016 08:11:00.670253  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.275156 (* 1 = 0.275156 loss)
I1016 08:11:00.670259  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0313138 (* 1 = 0.0313138 loss)
I1016 08:11:00.670264  4233 sgd_solver.cpp:138] Iteration 96500, lr = 0.000125
I1016 08:11:58.102502  4233 solver.cpp:243] Iteration 96600, loss = 0.203001
I1016 08:11:58.102550  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.182201 (* 1 = 0.182201 loss)
I1016 08:11:58.102557  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0334618 (* 1 = 0.0334618 loss)
I1016 08:11:58.102562  4233 sgd_solver.cpp:138] Iteration 96600, lr = 0.000125
I1016 08:12:57.897166  4233 solver.cpp:243] Iteration 96700, loss = 0.285448
I1016 08:12:57.897213  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.311636 (* 1 = 0.311636 loss)
I1016 08:12:57.897220  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0411405 (* 1 = 0.0411405 loss)
I1016 08:12:57.897225  4233 sgd_solver.cpp:138] Iteration 96700, lr = 0.000125
I1016 08:13:50.789185  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 08:13:57.377357  4233 solver.cpp:243] Iteration 96800, loss = 0.236035
I1016 08:13:57.377403  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.160879 (* 1 = 0.160879 loss)
I1016 08:13:57.377408  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0332687 (* 1 = 0.0332687 loss)
I1016 08:13:57.377414  4233 sgd_solver.cpp:138] Iteration 96800, lr = 0.000125
I1016 08:14:57.571249  4233 solver.cpp:243] Iteration 96900, loss = 0.12417
I1016 08:14:57.571297  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0224761 (* 1 = 0.0224761 loss)
I1016 08:14:57.571303  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0252057 (* 1 = 0.0252057 loss)
I1016 08:14:57.571310  4233 sgd_solver.cpp:138] Iteration 96900, lr = 0.000125
I1016 08:15:56.253419  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_97000.caffemodel
I1016 08:15:56.485707  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_97000.solverstate
I1016 08:15:57.057996  4233 solver.cpp:243] Iteration 97000, loss = 0.162508
I1016 08:15:57.058027  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0524606 (* 1 = 0.0524606 loss)
I1016 08:15:57.058034  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0454321 (* 1 = 0.0454321 loss)
I1016 08:15:57.058043  4233 sgd_solver.cpp:138] Iteration 97000, lr = 0.000125
I1016 08:16:56.202396  4233 solver.cpp:243] Iteration 97100, loss = 0.22361
I1016 08:16:56.202443  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.294759 (* 1 = 0.294759 loss)
I1016 08:16:56.202450  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0415657 (* 1 = 0.0415657 loss)
I1016 08:16:56.202456  4233 sgd_solver.cpp:138] Iteration 97100, lr = 0.000125
I1016 08:17:55.071589  4233 solver.cpp:243] Iteration 97200, loss = 0.252871
I1016 08:17:55.071636  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.412491 (* 1 = 0.412491 loss)
I1016 08:17:55.071642  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0530728 (* 1 = 0.0530728 loss)
I1016 08:17:55.071647  4233 sgd_solver.cpp:138] Iteration 97200, lr = 0.000125
I1016 08:18:54.311947  4233 solver.cpp:243] Iteration 97300, loss = 0.0953154
I1016 08:18:54.311995  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.105604 (* 1 = 0.105604 loss)
I1016 08:18:54.312001  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0314335 (* 1 = 0.0314335 loss)
I1016 08:18:54.312006  4233 sgd_solver.cpp:138] Iteration 97300, lr = 0.000125
I1016 08:19:54.214926  4233 solver.cpp:243] Iteration 97400, loss = 0.153075
I1016 08:19:54.214970  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0413893 (* 1 = 0.0413893 loss)
I1016 08:19:54.214977  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0308511 (* 1 = 0.0308511 loss)
I1016 08:19:54.214982  4233 sgd_solver.cpp:138] Iteration 97400, lr = 0.000125
I1016 08:20:53.502902  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_97500.caffemodel
I1016 08:20:54.263738  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_97500.solverstate
I1016 08:20:54.857764  4233 solver.cpp:243] Iteration 97500, loss = 0.214641
I1016 08:20:54.857811  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.435682 (* 1 = 0.435682 loss)
I1016 08:20:54.857817  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0322965 (* 1 = 0.0322965 loss)
I1016 08:20:54.857826  4233 sgd_solver.cpp:138] Iteration 97500, lr = 0.000125
I1016 08:21:53.162070  4233 solver.cpp:243] Iteration 97600, loss = 0.180616
I1016 08:21:53.162104  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0673931 (* 1 = 0.0673931 loss)
I1016 08:21:53.162111  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0281063 (* 1 = 0.0281063 loss)
I1016 08:21:53.162117  4233 sgd_solver.cpp:138] Iteration 97600, lr = 0.000125
I1016 08:22:51.467634  4233 solver.cpp:243] Iteration 97700, loss = 0.275338
I1016 08:22:51.467665  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.038587 (* 1 = 0.038587 loss)
I1016 08:22:51.467672  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.038812 (* 1 = 0.038812 loss)
I1016 08:22:51.467677  4233 sgd_solver.cpp:138] Iteration 97700, lr = 0.000125
I1016 08:23:48.980034  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 08:23:51.292150  4233 solver.cpp:243] Iteration 97800, loss = 0.198931
I1016 08:23:51.292197  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0715016 (* 1 = 0.0715016 loss)
I1016 08:23:51.292204  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0269875 (* 1 = 0.0269875 loss)
I1016 08:23:51.292209  4233 sgd_solver.cpp:138] Iteration 97800, lr = 0.000125
I1016 08:24:50.915290  4233 solver.cpp:243] Iteration 97900, loss = 0.186402
I1016 08:24:50.915338  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.286475 (* 1 = 0.286475 loss)
I1016 08:24:50.915343  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0401488 (* 1 = 0.0401488 loss)
I1016 08:24:50.915349  4233 sgd_solver.cpp:138] Iteration 97900, lr = 0.000125
I1016 08:25:50.654541  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_98000.caffemodel
I1016 08:25:50.888545  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_98000.solverstate
I1016 08:25:51.453652  4233 solver.cpp:243] Iteration 98000, loss = 0.136612
I1016 08:25:51.453693  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.110631 (* 1 = 0.110631 loss)
I1016 08:25:51.453699  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0337067 (* 1 = 0.0337067 loss)
I1016 08:25:51.453704  4233 sgd_solver.cpp:138] Iteration 98000, lr = 0.000125
I1016 08:26:50.276695  4233 solver.cpp:243] Iteration 98100, loss = 0.405892
I1016 08:26:50.276726  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.210432 (* 1 = 0.210432 loss)
I1016 08:26:50.276732  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0477285 (* 1 = 0.0477285 loss)
I1016 08:26:50.276737  4233 sgd_solver.cpp:138] Iteration 98100, lr = 0.000125
I1016 08:27:48.985541  4233 solver.cpp:243] Iteration 98200, loss = 0.160666
I1016 08:27:48.985589  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.098988 (* 1 = 0.098988 loss)
I1016 08:27:48.985594  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0269345 (* 1 = 0.0269345 loss)
I1016 08:27:48.985600  4233 sgd_solver.cpp:138] Iteration 98200, lr = 0.000125
I1016 08:28:48.363147  4233 solver.cpp:243] Iteration 98300, loss = 0.461607
I1016 08:28:48.363194  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.528518 (* 1 = 0.528518 loss)
I1016 08:28:48.363200  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0409254 (* 1 = 0.0409254 loss)
I1016 08:28:48.363205  4233 sgd_solver.cpp:138] Iteration 98300, lr = 0.000125
I1016 08:29:47.634402  4233 solver.cpp:243] Iteration 98400, loss = 0.281639
I1016 08:29:47.634449  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.544825 (* 1 = 0.544825 loss)
I1016 08:29:47.634456  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0343684 (* 1 = 0.0343684 loss)
I1016 08:29:47.634462  4233 sgd_solver.cpp:138] Iteration 98400, lr = 0.000125
I1016 08:30:47.138864  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_98500.caffemodel
I1016 08:30:47.371250  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_98500.solverstate
I1016 08:30:47.938025  4233 solver.cpp:243] Iteration 98500, loss = 0.102304
I1016 08:30:47.938056  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0896648 (* 1 = 0.0896648 loss)
I1016 08:30:47.938062  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.04442 (* 1 = 0.04442 loss)
I1016 08:30:47.938068  4233 sgd_solver.cpp:138] Iteration 98500, lr = 0.000125
I1016 08:31:47.503895  4233 solver.cpp:243] Iteration 98600, loss = 0.23736
I1016 08:31:47.503939  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.226674 (* 1 = 0.226674 loss)
I1016 08:31:47.503945  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0307833 (* 1 = 0.0307833 loss)
I1016 08:31:47.503952  4233 sgd_solver.cpp:138] Iteration 98600, lr = 0.000125
I1016 08:32:46.470708  4233 solver.cpp:243] Iteration 98700, loss = 0.301433
I1016 08:32:46.470754  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.204256 (* 1 = 0.204256 loss)
I1016 08:32:46.470760  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0373598 (* 1 = 0.0373598 loss)
I1016 08:32:46.470767  4233 sgd_solver.cpp:138] Iteration 98700, lr = 0.000125
I1016 08:33:44.976564  4233 solver.cpp:243] Iteration 98800, loss = 0.343898
I1016 08:33:44.976610  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0770637 (* 1 = 0.0770637 loss)
I1016 08:33:44.976616  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0393885 (* 1 = 0.0393885 loss)
I1016 08:33:44.976622  4233 sgd_solver.cpp:138] Iteration 98800, lr = 0.000125
I1016 08:33:45.059346  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 08:34:44.685051  4233 solver.cpp:243] Iteration 98900, loss = 0.158579
I1016 08:34:44.685083  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0763761 (* 1 = 0.0763761 loss)
I1016 08:34:44.685089  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0256218 (* 1 = 0.0256218 loss)
I1016 08:34:44.685094  4233 sgd_solver.cpp:138] Iteration 98900, lr = 0.000125
I1016 08:35:43.877704  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_99000.caffemodel
I1016 08:35:44.111680  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_99000.solverstate
I1016 08:35:45.225041  4233 solver.cpp:243] Iteration 99000, loss = 0.157805
I1016 08:35:45.225092  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0595795 (* 1 = 0.0595795 loss)
I1016 08:35:45.225097  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0350245 (* 1 = 0.0350245 loss)
I1016 08:35:45.225103  4233 sgd_solver.cpp:138] Iteration 99000, lr = 0.000125
I1016 08:36:44.726295  4233 solver.cpp:243] Iteration 99100, loss = 0.0871974
I1016 08:36:44.726335  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0566548 (* 1 = 0.0566548 loss)
I1016 08:36:44.726342  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0286617 (* 1 = 0.0286617 loss)
I1016 08:36:44.726351  4233 sgd_solver.cpp:138] Iteration 99100, lr = 0.000125
I1016 08:37:43.882655  4233 solver.cpp:243] Iteration 99200, loss = 0.164862
I1016 08:37:43.882705  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.128854 (* 1 = 0.128854 loss)
I1016 08:37:43.882711  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0286838 (* 1 = 0.0286838 loss)
I1016 08:37:43.882717  4233 sgd_solver.cpp:138] Iteration 99200, lr = 0.000125
I1016 08:38:42.264271  4233 solver.cpp:243] Iteration 99300, loss = 0.194002
I1016 08:38:42.264320  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.119522 (* 1 = 0.119522 loss)
I1016 08:38:42.264328  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0273741 (* 1 = 0.0273741 loss)
I1016 08:38:42.264333  4233 sgd_solver.cpp:138] Iteration 99300, lr = 0.000125
I1016 08:39:41.878026  4233 solver.cpp:243] Iteration 99400, loss = 0.291507
I1016 08:39:41.878062  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0793427 (* 1 = 0.0793427 loss)
I1016 08:39:41.878067  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.040284 (* 1 = 0.040284 loss)
I1016 08:39:41.878072  4233 sgd_solver.cpp:138] Iteration 99400, lr = 0.000125
I1016 08:40:40.637282  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_99500.caffemodel
I1016 08:40:40.869627  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_99500.solverstate
I1016 08:40:41.459079  4233 solver.cpp:243] Iteration 99500, loss = 0.179147
I1016 08:40:41.459126  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.106053 (* 1 = 0.106053 loss)
I1016 08:40:41.459132  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0389441 (* 1 = 0.0389441 loss)
I1016 08:40:41.459139  4233 sgd_solver.cpp:138] Iteration 99500, lr = 0.000125
I1016 08:41:41.499768  4233 solver.cpp:243] Iteration 99600, loss = 0.151981
I1016 08:41:41.499817  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.0655955 (* 1 = 0.0655955 loss)
I1016 08:41:41.499824  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0244846 (* 1 = 0.0244846 loss)
I1016 08:41:41.499830  4233 sgd_solver.cpp:138] Iteration 99600, lr = 0.000125
I1016 08:42:40.870298  4233 solver.cpp:243] Iteration 99700, loss = 0.156464
I1016 08:42:40.870345  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.104688 (* 1 = 0.104688 loss)
I1016 08:42:40.870352  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0235884 (* 1 = 0.0235884 loss)
I1016 08:42:40.870358  4233 sgd_solver.cpp:138] Iteration 99700, lr = 0.000125
I1016 08:43:40.022809  4233 solver.cpp:243] Iteration 99800, loss = 0.370347
I1016 08:43:40.022857  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.295423 (* 1 = 0.295423 loss)
I1016 08:43:40.022863  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0764838 (* 1 = 0.0764838 loss)
I1016 08:43:40.022868  4233 sgd_solver.cpp:138] Iteration 99800, lr = 0.000125
I1016 08:43:44.109867  4233 blocking_queue.cpp:50] Data layer prefetch queue empty
I1016 08:44:38.653156  4233 solver.cpp:243] Iteration 99900, loss = 0.240632
I1016 08:44:38.653203  4233 solver.cpp:259]     Train net output #0: mbox_loss = 0.447632 (* 1 = 0.447632 loss)
I1016 08:44:38.653209  4233 solver.cpp:259]     Train net output #1: seg_loss = 0.0261879 (* 1 = 0.0261879 loss)
I1016 08:44:38.653215  4233 sgd_solver.cpp:138] Iteration 99900, lr = 0.000125
I1016 08:45:37.582651  4233 solver.cpp:596] Snapshotting to binary proto file snapshot/union/_iter_100000.caffemodel
I1016 08:45:38.355319  4233 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/union/_iter_100000.solverstate
I1016 08:45:38.562445  4233 net.cpp:693] Ignoring source layer mbox_loss
 loss 0.5315965518578887
>>> 2018-10-16 05:21:07.685710 Iteration 80000 overall accuracy 0.9422063932291667
>>> 2018-10-16 05:21:07.685746 Iteration 80000 mean accuracy 0.9310521968013472
>>> 2018-10-16 05:21:07.685881 Iteration 80000 mean IU 0.8786926825466381
>>> 2018-10-16 05:21:07.685958 Iteration 80000 fwavacc 0.890937975182022
>>> 2018-10-16 06:00:43.809563 Begin seg tests
>>> 2018-10-16 06:02:21.065091 Iteration 84000 loss 0.7709549854770302
>>> 2018-10-16 06:02:21.065174 Iteration 84000 overall accuracy 0.9381327604166667
>>> 2018-10-16 06:02:21.065204 Iteration 84000 mean accuracy 0.9255423731155057
>>> 2018-10-16 06:02:21.065330 Iteration 84000 mean IU 0.8710388780801208
>>> 2018-10-16 06:02:21.065400 Iteration 84000 fwavacc 0.8835646223434281
>>> 2018-10-16 06:41:57.853174 Begin seg tests
>>> 2018-10-16 06:43:36.014271 Iteration 88000 loss 0.5971082194671035
>>> 2018-10-16 06:43:36.014349 Iteration 88000 overall accuracy 0.943345078125
>>> 2018-10-16 06:43:36.014378 Iteration 88000 mean accuracy 0.9353590450885718
>>> 2018-10-16 06:43:36.014502 Iteration 88000 mean IU 0.8818015397213221
>>> 2018-10-16 06:43:36.014569 Iteration 88000 fwavacc 0.8932181484532316
>>> 2018-10-16 07:23:12.117568 Begin seg tests
>>> 2018-10-16 07:24:49.381654 Iteration 92000 loss 0.6002857258915901
>>> 2018-10-16 07:24:49.381736 Iteration 92000 overall accuracy 0.9440786848958334
>>> 2018-10-16 07:24:49.381766 Iteration 92000 mean accuracy 0.9396485697427022
>>> 2018-10-16 07:24:49.381908 Iteration 92000 mean IU 0.883170768965693
>>> 2018-10-16 07:24:49.381977 Iteration 92000 fwavacc 0.8949190094622017
>>> 2018-10-16 08:04:26.002432 Begin seg tests
>>> 2018-10-16 08:06:03.153320 Iteration 96000 loss 0.9663620512038469
>>> 2018-10-16 08:06:03.153392 Iteration 96000 overall accuracy 0.9380506510416666
>>> 2018-10-16 08:06:03.153422 Iteration 96000 mean accuracy 0.9292320942298657
>>> 2018-10-16 08:06:03.153536 Iteration 96000 mean IU 0.8730368249893721
>>> 2018-10-16 08:06:03.153604 Iteration 96000 fwavacc 0.8836280972134768
>>> 2018-10-16 08:45:38.562194 Begin seg tests
>>> 2018-10-16 08:47:17.525046 Iteration 100000 loss 0.5256028625071049
>>> 2018-10-16 08:47:17.525125 Iteration 100000 overall accuracy 0.943016796875
>>> 2018-10-16 08:47:17.525153 Iteration 100000 mean accuracy 0.9380427566623813
>>> 2018-10-16 08:47:17.525276 Iteration 100000 mean IU 0.8808974233820324
>>> 2018-10-16 08:47:17.525345 Iteration 100000 fwavacc 0.8930202970983614
